{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MATH&ML-9. Математика ансамблевых методов**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Представьте, что вы выполняете важный проект по машинному обучению. Конечно, вы можете делать всё самостоятельно, но если вы дополнительно узнаете мнение коллег, попросите ментора проверить ваши расчёты, найдёте как можно больше информации по вашей теме, то точно получите наилучший результат, ведь вы учтёте не только свои знания и выводы, но и информацию от других компетентных людей.\n",
    "\n",
    "Составление прогнозов в машинном обучении может следовать такой же логике: один алгоритм часто даёт далёкий от желаемой точности прогноз, ведь у каждого метода есть свои ограничения, и в целом создание модели, которая строит очень близкие к реальности предсказания, — достаточно сложная задача. Однако если мы обучим на наших данных несколько моделей и обобщим результаты определённым образом, то сможем получить куда более точный результат.\n",
    "\n",
    "Такой алгоритм решения задач машинного обучения называется **ансамблем моделей**.\n",
    "\n",
    "> **Ансамбль моделей** — это метод, в котором несколько алгоритмов (или вариации одного и того же) обучаются на одних данных, а итоговый прогноз строится на основе всех полученных от моделей прогнозов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c284641ce53a2d60f7bfedb59aa830a3/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_1_1.png)\n",
    "\n",
    "Вы уже встречались с ансамблями, однако последние модули существенно обогатили ваши знания по математике, и теперь вы сможете изучить математическую основу и тонкости данных методов: особенности настройки параметров, различные библиотеки, нюансы применения тех или иных ансамблей. Это сделает вас более компетентными специалистами, глубоко понимающими суть применяемых методов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.7\n",
    "\n",
    "Найдите минимум функции \\(x^{2}+x y-y+y^{3}\\).\n",
    "\n",
    "В качестве ответа введите координату по оси ординат. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точки экстремумов (x, y):  [(-1/3, 2/3), (1/4, -1/2)]\n",
      "Значение функции в первой точке:  -13/27\n",
      "Значение функции во второй точке:  5/16\n"
     ]
    }
   ],
   "source": [
    "from sympy import *\n",
    "\n",
    "f, x, y = symbols('f x y')\n",
    "\n",
    "f = x**2 + x*y - y + y**3\n",
    "\n",
    "diff_x  = f.diff(x)\n",
    "\n",
    "diff_y  = f.diff(y)\n",
    "\n",
    "extr = solve([diff_x, diff_y], [x, y])\n",
    "\n",
    "print('Точки экстремумов (x, y): ', extr)\n",
    "\n",
    "print('Значение функции в первой точке: ', f.subs([(x, extr[0][0]), (y, extr[0][1])]))\n",
    "\n",
    "print('Значение функции во второй точке: ', f.subs([(x, extr[1][0]), (y, extr[1][1])]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ Вы справились с тестированием — поздравляем! Теперь вы точно можете быть уверены, что ваша подготовка достаточна для освоения данного модуля. Прежде чем приступить, давайте обозначим основные цели на следующие семь юнитов:\n",
    "\n",
    "1. **Изучить основную терминологию, связанную с ансамблями моделей.**\n",
    "Мы повторим уже знакомые вам основные понятия, которые используются в ансамблях, и познакомимся с рядом новых.\n",
    "2. **Подробно разобрать реализацию разных видов ансамблей с математической и смысловой точек зрения.**\n",
    "Мы намного подробнее, чем раньше, разберём все алгоритмы и изучим их математическую составляющую, чтобы лучше понимать принцип их работы, уметь более тонко их настраивать и за счёт этого добиваться наилучшей эффективности.\n",
    "3. **Научиться решать задачи регрессии и классификации с использованием ансамблей моделей.**\n",
    "Конечно же, полученные знания мы будем использовать для решения настоящих практических задач.\n",
    "4. **Научиться настраивать параметры моделей для повышения прогностической точности.**\n",
    "Мы рассмотрим параметры алгоритмов, которые можно регулировать, и разберёмся, как менять каждый из них для повышения точности предсказания.\n",
    "\n",
    "Важно обозначить, что мы будем рассматривать три вида построения ансамблей: бэггинг, бустинг и стекинг. Для каждого из них мы изучим популярные вариации, программную реализацию и, конечно же, сравним их эффективность при решении задач.\n",
    "\n",
    "В результате освоения этого модуля вы сможете применять ансамблевые методы для решения задач машинного обучения. Вы не просто будете знать плюсы и минусы ансамблевых методов и то, какие из них уместны в том или ином случае, но также будете понимать их суть и математическую составляющую.\n",
    "\n",
    "Итак, вперёд к ансамблям! →"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ансамбли моделей. Бутстреппинг. Бэггинг"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В этом юните вы углубите свои знания ансамблей алгоритмов. Вы познакомитесь с тем, как формируются бутстреп-выборки, а также досконально изучите принцип **бэггинга** — самого простого варианта ансамблей.\n",
    "\n",
    "В основе бэггинга лежит статистический метод, который называется **бутстрепом (bootstrap)**. Идея бутстрепа заключается в генерации выборок размера n из исходного датасета размера N путём случайного выбора элементов с повторениями в каждом из наблюдений.\n",
    "\n",
    "**Рассмотрим идею бутстрепа на элементарном примере.**\n",
    "\n",
    "Пусть у нас есть выборка из 12 клиентов компании: у каждого из них есть свой ID (от 1 до 12) и какие-то характеристики. Мы можем создавать из данной выборки множество различных новых выборок клиентов с новым количеством человек (в данном случае представлены выборки из пяти человек). При этом информацию про одного и того же клиента можно использовать повторно.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/95929bfe488e7dd592014067919c91ad/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_2_1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это намного проще, чем находить новые выборки. По сути, мы собираем данные лишь единожды, а затем на их основе генерируем много выборок для обучения моделей. Это экономит огромные объёмы ресурсов и времени.\n",
    "\n",
    "При некотором приближении можно считать, что получающиеся выборки являются независимыми и репрезентативными — **это важное допущение**.\n",
    "\n",
    "Выборки можно назвать **независимыми**, если результаты испытаний и измерения, осуществляемые для одной выборки, никак не влияют на результаты, получаемые на другой выборке.\n",
    "\n",
    "**Репрезентативность** заключается в соответствии характеристик выборки всей генеральной совокупности.\n",
    "\n",
    "К примеру, если мы хотим исследовать мнение всех женщин России по какому-то вопросу, то все женщины России — это **генеральная совокупность**.\n",
    "\n",
    "**Репрезентативная выборка** — это такая группа женщин, для которой основные характеристики соответствуют характеристикам для генеральной совокупности. Допустим, если среди всех российских женщин 60 % имеют детей, а 40 % — не имеют, то соотношение в выборке должно быть таким же."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бутстреп-выборки часто используются для оценки различных статистических показателей, например разброса или доверительного интервала.\n",
    "\n",
    "Если вычислять статистические оценки на нескольких независимых выборках, то мы можем, например, оценить их математическое ожидание или разброс. Приведём пример того, как это происходит с точки зрения математики.\n",
    "\n",
    "Допустим, у нас есть некоторая выборка $x=(5,1,3,6,4)$, и мы хотим оценить для неё математическое ожидание. Например, это может быть выборка количества товаров, которые приобретали покупатели нашего магазина, и мы хотим найти ожидаемое количество товаров, которое купит случайный клиент.\n",
    "\n",
    "Конечно, мы без проблем можем его вычислить:\n",
    "\n",
    "$$E(x) =E(5,1,3,6,4) = \\frac{1}{5} \\cdot 5 + \\frac{1}{5} \\cdot1 + \\frac{1}{5} \\cdot3 + \\frac{1}{5} \\cdot6 + \\frac{1}{5} \\cdot4 = 1+0.2 +0.6 + 1.2 + 0.8 = 3.8$$\n",
    "\n",
    "Однако это значение лишь на одной выборке, а мы хотели бы вычислить эту статистическую оценку на нескольких выборках и затем проанализировать разброс оценок.\n",
    "\n",
    "Создаём несколько выборок с помощью бутстрепа и на каждой оцениваем математическое ожидание:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/880fd8813d3d070f2434c836167af820/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_2_2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили ряд значений:\n",
    "\n",
    "$4.4, 3.8, 4.8, 4.0, 3.4, 4.2, 5.2$\n",
    "\n",
    "Теперь давайте найдём дисперсию для этого ряда. Мы с вами делали это в модуле по теории вероятностей — самое время вспомнить!\n",
    "\n",
    "### Задание 2.2\n",
    "\n",
    "Вычислите дисперсию для этого ряда. Результат округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.317"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statistics import pvariance\n",
    "\n",
    "pvariance([4.4, 3.8, 4.8, 4.0, 3.4, 4.2, 5.2]).__round__(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы понимаем, что если мы будем создавать различные новые выборки и вычислять для них средние значения, то для полученных значений дисперсия будет равна найденному вами выше значению. **Заметьте: мы узнали это, не собирая никаких новых данных.**\n",
    "\n",
    "Формализуем только что проделанные действия математически:\n",
    "\n",
    "1. Генерируем выборки. Необходимо создавать упорядоченные множества элементов, которые мы выбираем с возвратом из некоторого имеющегося у нас множества:\n",
    "\n",
    "$$\\left\\{X_{1}, \\ldots, X_{N}\\right\\}$$\n",
    "\n",
    "2. Повторяем несколько раз процедуру генерации выборки:\n",
    "\n",
    "$$X_{b}^{*}=\\left(X_{b 1}^{*}, \\ldots, X_{b N}^{*}\\right), \\ где \\ 1 \\leqslant b \\leqslant B$$\n",
    "\n",
    "3. Считаем интересующую нас статистику по каждой выборке:\n",
    "\n",
    "$$T_{1}^{*}=T\\left(X_{1}^{*}\\right), \\ldots, T_{B}^{*}=T\\left(X_{B}^{*}\\right)$$\n",
    "\n",
    "4. Получаем бутстрепную оценку для интересующей нас статистики по этой выборке статистик. Например, для дисперсии она будет вычисляться так:\n",
    "Отлично, мы разобрались с тем, что такое метод бутстрепа. Запомните его идею — совсем скоро она пригодится вам для понимания алгоритма бэггинга.\n",
    "\n",
    "$$\\widehat{D}_{\\text {boot }}=\\frac{1}{B} \\sum_{b=1}^{B} T_{b}^{* 2}-\\left(\\frac{1}{B} \\sum_{b=1}^{B} T_{b}^{*}\\right)^{2}$$\n",
    "\n",
    "Отлично, мы разобрались с тем, что такое метод бутстрепа. Запомните его идею — совсем скоро она пригодится вам для понимания алгоритма бэггинга."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIAS И VARIANCE\n",
    "\n",
    "Прежде чем перейти непосредственно к ансамблям моделей, нам необходимо повторить bias-variance decomposition, или, как его называют по-русски, «разложение ошибки на смещение и разброс». Оно очень полезно для анализа ансамблей моделей.\n",
    "\n",
    "> **Смещение** — это разница между математическим ожиданием для прогноза и реальным значением:\n",
    ">\n",
    "> $$Bias[\\hat{f}(x)] = E[\\hat{f}(x)]-y$$\n",
    "\n",
    "Здесь:\n",
    "\n",
    "* $E[\\hat{f}(x)]$ — математическое ожидание для прогноза,\n",
    "* $y$ — реальное значение функции.\n",
    "\n",
    "**Смысл смещения** — способность получить лучшую среди всех возможных моделей, то есть максимально точные прогнозы."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритмы со стабильно маленьким смещением:**\n",
    "* KNN (n = 1);\n",
    "* метод опорных векторов;\n",
    "* деревья решений с большой глубиной.\n",
    "\n",
    "**Алгоритмы с большим смещением:**\n",
    "* линейная регрессия;\n",
    "* логистическая регрессия;\n",
    "* деревья решений с маленькой глубиной.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также значение смещения часто называют **ошибкой смещения** или **ошибкой из-за смещения**.\n",
    "\n",
    "Если у модели большое смещение, это значит, что ошибка будет достаточно велика из-за слишком сильного упрощения модели.\n",
    "\n",
    "> **Разброс** — это величина разницы в результатах обучения модели на разных выборках:\n",
    ">\n",
    "> $$\\operatorname{Var}[\\hat{f}(x)]=\\mathrm{E}\\left[\\left(\\mathrm{E}[\\hat{f}(x)]-\\hat{f}(x)\\right)^{2}\\right]$$\n",
    "\n",
    "**Примечание**. С математической точки зрения разброс модели определяется как математическое ожидание квадрата разницы ожидаемого прогноза и реализованного прогноза модели.\n",
    "\n",
    "Разброс характеризует устойчивость модели к изменениям в обучающей выборке:\n",
    "\n",
    "* Если результат сильно зависит от того, какие объекты присутствуют в выборке, разброс будет большим.\n",
    "* Если алгоритм работает стабильно вне зависимости от особенностей выборки, разброс будет маленьким.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритмы, показывающие маленький разброс:**\n",
    "* линейная регрессия;\n",
    "* логистическая регрессия;\n",
    "* деревья решений с маленькой глубиной.\n",
    "\n",
    "**Алгоритмы, показывающие большой разброс:**\n",
    "* деревья решений с большой глубиной;\n",
    "* KNN;\n",
    "* метод опорных векторов.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте рассмотрим разложение на смещение и разброс для линейной регрессии.\n",
    "\n",
    "Пусть мы хотим предсказать значение y по значениям вектора $x$. Тогда зависимость $y$ от $x$ можно записать следующим образом:\n",
    "\n",
    "$$y=f(x)+\\varepsilon$$\n",
    "\n",
    "В качестве $f(x)$ здесь выступает истинная зависимость ответов $y$ от характеристик объекта $x$ — мы её не знаем и пытаемся предсказать с помощью модели. Предсказания обозначим как $\\hat{f}(x)$. Символом $\\varepsilon$ обозначается случайная ошибка. Предполагается, что её математическое ожидание равно нулю — это просто шум.\n",
    "\n",
    "Тогда давайте выразим ошибку для какого-то значения $х$. Она будет равняться математическому ожиданию для квадрата разницы между реальным и предсказанным значениями. По сути, это просто среднеквадратичная ошибка, записанная в немного иной форме:\n",
    "\n",
    "$$\\operatorname{Err}(x)=E\\left[(y-\\hat{f}(x))^{2}\\right]$$\n",
    "\n",
    "Также мы можем разложить среднеквадратичную ошибку следующим образом:\n",
    "\n",
    "$$\\operatorname{Err}(x)=(E[\\hat{f}(x)]-y)^{2}+E\\left[(\\hat{f}(x)-E[\\hat{f}(x)])^{2}\\right]+\\sigma_{\\varepsilon}^{2}$$\n",
    "\n",
    "$$\\operatorname{Err}(x)=\\operatorname{Bias}^{2}+Variance+Irreducible Error$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Доказательство равенства\n",
    "\n",
    "Для начала представим $y$ как сумму значения функции $f$ и ошибки (вместо $f(x)$ будем далее для краткости писать просто $f$):\n",
    "\n",
    "$$\\mathrm{E}\\left[(y-\\hat{f})^{2}\\right]=\\mathrm{E}\\left[(f+\\varepsilon-\\hat{f})^{2}\\right]$$\n",
    "\n",
    "Теперь в выражение, от которого мы ищем математическое ожидание, добавим математическое ожидание предсказанной функции и вычтем его же (это нужно для того, чтобы далее мы смогли выразить необходимые нам величины). Разумеется, если мы прибавляем какую-то величину, а потом её вычитаем, результат остаётся тем же.\n",
    "\n",
    "$$=\\mathrm{E}\\left[(f+\\varepsilon-\\hat{f}+\\mathrm{E}[\\hat{f}]-\\mathrm{E}[\\hat{f}])^{2}\\right]$$\n",
    "\n",
    "Далее раскроем скобки, то есть возведём в квадрат сумму трёх слагаемых:\n",
    "\n",
    "* $f-\\mathrm{E}[\\hat{f}]$,\n",
    "\n",
    "* $\\varepsilon$,\n",
    "\n",
    "* $\\mathrm{E}[\\hat{f}]-\\hat{f}$.\n",
    "\n",
    "**Примечание**. Для разложения пользуемся формулой из алгебры:\n",
    "\n",
    "$$(a+b+c)^{2}=a^{2}+b^{2}+c^{2}+2 a b+2 a c+2 b c$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем:\n",
    "\n",
    "$=\\mathrm{E}\\left[(f-\\mathrm{E}[\\hat{f}])^{2}\\right]+\\mathrm{E}\\left[\\varepsilon^{2}\\right]+\\mathrm{E}\\left[(\\mathrm{E}[\\hat{f}]-\\hat{f})^{2}\\right]+2 \\mathrm{E}[(f-\\mathrm{E}[\\hat{f}]) \\varepsilon]+2 \\mathrm{E}[\\varepsilon(\\mathrm{E}[\\hat{f}]-\\hat{f})]+2 \\mathrm{E}[(\\mathrm{E}[\\hat{f}]-\\hat{f})(f-\\mathrm{E}[\\hat{f}])]$\n",
    "\n",
    "$=(f-\\mathrm{E}[\\hat{f}])^{2}+\\mathrm{E}\\left[\\varepsilon^{2}\\right]+\\mathrm{E}\\left[(\\mathrm{E}[\\hat{f}]-\\hat{f})^{2}\\right]+2(f-\\mathrm{E}[\\hat{f}]) \\mathrm{E}[\\varepsilon]+2 \\mathrm{E}[\\varepsilon] \\mathrm{E}[\\mathrm{E}[\\hat{f}]-\\hat{f}]+2 \\mathrm{E}[\\mathrm{E}[\\hat{f}]-\\hat{f}](f-\\mathrm{E}[\\hat{f}])$\n",
    "\n",
    "Сокращаем одинаковые слагаемые:\n",
    "\n",
    "$=(f-\\mathrm{E}[\\hat{f}])^{2}+\\mathrm{E}\\left[\\varepsilon^{2}\\right]+\\mathrm{E}\\left[(\\mathrm{E}[\\hat{f}]-\\hat{f})^{2}\\right]$\n",
    "\n",
    "Видим, что у нас есть дисперсия ошибки и дисперсия предсказания:\n",
    "\n",
    "$=(f-\\mathrm{E}[\\hat{f}])^{2}+\\operatorname{Var}[\\varepsilon]+\\operatorname{Var}[\\hat{f}]$\n",
    "\n",
    "$=\\operatorname{Bias}[\\hat{f}]^{2}+\\sigma^{2}+\\operatorname{Var}[\\hat{f}]$\n",
    "\n",
    "Итак, мы получили, что наша ошибка — это сумма смещения для квадрата прогноза, разброса и неустранимой случайной ошибки. Теперь мы понимаем, из чего состоит ошибка модели. Такое представление помогает нам исследовать с теоретической точки зрения некоторые алгоритмы машинного обучения и часто используется при изучении ансамблей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили, что наша ошибка — это сумма смещения для квадрата прогноза, разброса и неустранимой случайной ошибки. Теперь мы понимаем, из чего состоит ошибка модели. Такое представление помогает нам исследовать с теоретической точки зрения некоторые алгоритмы машинного обучения и часто используется при изучении ансамблей.\n",
    "\n",
    "Рассмотрим иллюстрацию того, как сдвиг и разброс влияют на качество предсказания. На рисунке ниже вы видите цель (красный круг), в которую мы хотим попасть.\n",
    "\n",
    "Есть четыре ситуации:\n",
    "\n",
    "![](https://img.genial.ly/5fdc5ca1853b5759f6e69400/5040dd83-7a8e-444e-8fc0-a3445064b968.png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В моделях машинного обучения принцип тот же, только в качестве центра мишени выступает минимально возможная ошибка.\n",
    "\n",
    "Когда говорят про разложение на bias и variance, то часто упоминают некую **точку баланса**:\n",
    "\n",
    "* Если модель очень простая, с маленьким количеством параметров, то, скорее всего, у неё будет очень большое смещение, но маленький разброс.\n",
    "* Если модель очень сложная, со множеством параметров, у неё будет большой разброс и маленькое смещение.\n",
    "\n",
    "Схематично эти зависимости можно изобразить следующим образом (это схема не для конкретной модели, а лишь иллюстрация тенденций):\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/eccb230bf722e42b7fbeeadddf60daae/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_2_4.png)\n",
    "\n",
    "На графике выше по оси абсцисс отложена сложность модели ($Model \\ Complexity$), а по оси ординат — ошибка ($Error$). Также изображены смещение ($Bias^2$), разброс ($Variance$) и ошибка ($Total \\ Error$ — сумма смещения и разброса).\n",
    "\n",
    "Как вы можете видеть, есть некоторая оптимальная точка, в которой разброс и смещение небольшие, а ошибка минимальна. Именно эта точка нас и интересует."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## БЭГГИНГ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём к понятию **бэггинг**.\n",
    "\n",
    "При построении моделей всегда есть вероятность, что при обучении на других данных получились бы другие результаты. Для того чтобы нивелировать такую вероятность, можно использовать бэггинг.\n",
    "\n",
    "Его идея состоит в том, что мы берём несколько независимых моделей и усредняем полученные по ним результаты. Таким образом мы получаем модель, имеющую меньший разброс, так как при её построении мы учли несколько моделей.\n",
    "\n",
    "Как уже было сказано, в реальности получить много независимых выборок слишком сложно, так как найти столько данных обычно невозможно. Поэтому мы используем бутстреп-выборки, о которых говорили в начале юнита.\n",
    "\n",
    "Важно отметить, что при бэггинге размер каждой бутстреп-выборки должен совпадать с размером исходной выборки.\n",
    "\n",
    "Схематично процесс бэггинга можно представить следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/86233c8d821d894e9008415bda25a791/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_2_6.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте сформулируем и объясним эту идею математически.\n",
    "\n",
    "Пусть у нас есть некоторая выборка, и мы с помощью бутстрепа генерируем из неё ещё $B$ выборок:\n",
    "\n",
    "$$X_{1}, ..., X_{B}$$\n",
    "\n",
    "После этого мы определяем много базовых алгоритмов (всего $B$ моделей — по числу выборок) и обучаем каждый базовый алгоритм $a_{i}(x)$ на своей выборке. После этого получаем итоговый результат:\n",
    "\n",
    "$$a(x)=\\frac{1}{B} \\sum_{i=1}^{B} a_{i}(x)$$\n",
    "\n",
    "* Если мы рассматриваем задачу классификации, то, по сути, модели «голосуют» за свой класс.\n",
    "\n",
    "* Если мы рассматриваем задачу регрессии, то результат — просто среднее арифметическое прогнозов по всем моделям.\n",
    "\n",
    "Теперь посмотрим, **насколько применение бэггинга поможет нам улучшить качество модели**.\n",
    "\n",
    "Представим, что мы хотим использовать бэггинг для решения задачи регрессии и берём для этого $K$ базовых алгоритмов:\n",
    "\n",
    "$$a_{1}(x), ..., a_{K}(x)$$\n",
    "\n",
    "Конечно, если для каждого объекта известно значение целевой переменной, мы можем вычислить ошибку для каждой модели:\n",
    "\n",
    "$$\\varepsilon_{i}(x)=a_{i}(x)-y(x), i=1, \\ldots, K$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также мы можем выразить математическое ожидание квадратичной ошибки (т. е., по сути, среднеквадратичную ошибку):\n",
    "\n",
    "$$\\mathbb{E}_{x}\\left[\\left(a_{i}(x)-y(x)\\right)^{2}\\right]=\\mathbb{E}_{x}\\left[\\varepsilon_{i}^{2}(x)\\right]$$\n",
    "\n",
    "Ошибка здесь обозначается как .\n",
    "\n",
    "Тогда, если мы усредним значение ошибки по всем моделям регрессии, то получим следующее:\n",
    "\n",
    "$$\\mathbb{E}_{1}=\\frac{1}{n} \\mathbb{E}_{x} \\sum_{i=1}^{n} \\varepsilon_{i}^{2}(x)$$\n",
    "\n",
    "Будем считать, что математическое ожидание для всех ошибок равно нулю (то есть нет какого-то систематического смещения ошибок, и они случайные) и что все ошибки независимы друг от друга (то есть их коэффициент корреляции равен нулю):\n",
    "\n",
    "$$\\begin{aligned} \\mathbb{E}_{x} \\varepsilon_{i}(x) &=0 \\\\ \\mathbb{E}_{x} \\varepsilon_{i}(x) \\varepsilon_{j}(x) &=0, i \\neq j \\end{aligned}$$\n",
    "\n",
    "Теперь определим регрессионную функцию, которая будет брать ответы от всех обученных нами регрессионных моделей и просто усреднять их:\n",
    "\n",
    "$$f(x)=\\frac{1}{K} \\sum_{i=1}^{K} a_{i}(x)$$\n",
    "\n",
    "Теперь найдём для этой модели среднеквадратичную ошибку. Выразим её через математическое ожидание:\n",
    "\n",
    "$$\\mathbb{E}_{K}=\\mathbb{E}_{x}\\left(\\frac{1}{K} \\sum_{i=1}^{K} a_{i}(x)-y(x)\\right)^{2}$$\n",
    "\n",
    "Упростим часть внутри скобок, воспользовавшись введённым ранее утверждением о том, что $\\mathbb{E}_{x}\\left[\\left(a_{i}(x)-y(x)\\right)^{2}\\right]=\\mathbb{E}_{x}\\left[\\varepsilon_{i}^{2}(x)\\right]$, и получим следующее:\n",
    "\n",
    "$$\\mathbb{E}_{x}\\left[\\left(a_{i}(x)-y(x)\\right)^{2}\\right]=\\mathbb{E}_{x}\\left[\\varepsilon_{i}^{2}(x)\\right]$$\n",
    "\n",
    "$$=\\mathbb{E}_{x}\\left(\\frac{1}{K} \\sum_{i=1}^{K} \\varepsilon_{i}\\right)^{2}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого вынесем за скобку $\\frac{1}{K}$, а также возведём внутреннюю часть скобки в квадрат:\n",
    "\n",
    "$$=\\frac{1}{K^{2}} \\mathbb{E}_{x}\\left(\\sum_{i=1}^{K} \\varepsilon_{i}^{2}(x)+\\sum_{i \\neq j} \\varepsilon_{i}(x) \\varepsilon_{j}(x)\\right)$$\n",
    "\n",
    "Ранее мы уже выяснили, что $\\sum_{i \\neq j} \\varepsilon_{i}(x) \\varepsilon_{j}(x)$ равняется нулю, так как все ошибки независимы. Сокращаем выражение и получаем в итоге:\n",
    "\n",
    "$$\\mathbb{E}_{K}=\\frac{1}{K}\\mathbb{E}_{1}$$\n",
    "\n",
    "Получается, что путём усреднения предсказаний линейных регрессий мы смогли уменьшить среднеквадратичную ошибку в $K$ раз.\n",
    "\n",
    "Однако тут важно отметить, что при решении прикладных задач эффект будет не таким выраженным, так как здесь мы использовали предположение о полной независимости ошибок, а в реальной жизни такое случается редко.\n",
    "\n",
    "Также, чтобы иметь полное представление о характеристиках рассматриваемого алгоритма, давайте вспомним про разложение ошибки на смещение и разброс.\n",
    "\n",
    "Доказано, что бэггинг не ухудшает показатель смещения модели, то есть смещение у ансамбля ровно такое же, как и у одного базового алгоритма.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Доказательство\n",
    "\n",
    "Выберем из нашей выборки $X$ бутстрепом $K$ раз выборку длиной $N$. Получим выборки $X_{1}, X_{2}, ..., X_{K}$. Обучим базовые модели $a(x)$ на данных подвыборках. Первую модель $a_{1}(x) = a(x,X_{1})$  обучим на первой выборке бутстрепа, вторую $a_{2}(x) = a(x,X_{2})$ — на второй и так далее. Выполнив данную процедуру $n$ раз, мы получим предсказание как усреднение по всем обученным на подвыборках моделях.\n",
    "\n",
    "$$f(x,X) = \\frac{1}{K} \\sum_{i=1}^{K} (f_i (x))$$\n",
    "\n",
    "Теперь рассмотрим изменение смещения (bias) и разброса (variance) ансамблирования по отношению к базовым моделям.\n",
    "\n",
    "> **Смещение (bias)** есть не что иное, как математическое ожидание разности между истинными ответами y и предсказаниями ансамбля: \n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/0010efcbd8914782f96e32442230250f/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-51.png)\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c742c46100695e837ba46566856184cb/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-52.png)\n",
    "\n",
    "**Вывод**: смещение ансамбля равно смещению базовой модели ансамбля!\n",
    "\n",
    "> Разброс (variance, обозначим далее как ) — это дисперсия ответов алгоритма:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3d239a00c5d9d71aec09651f109a150f/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-53.png)\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c704097ba958bf98bb20e2aa7bbac971/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-54.png)\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/bc1b9ab29110bd4e40c3d2b1f947fbf1/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-55.png)\n",
    "\n",
    "При условии некоррелированности базовых моделей, которая достигается за счёт обучения на бутстрепе, последнее слагаемое равно нулю. Итого:\n",
    "\n",
    "$$var(f(x,X)) = \\frac{1}{K^2} \\sum_{i=1}^{K} E \\left [(a_i (x,X)- E \\left [a_i (x,X) \\right ] )\\right ]^2 = \\frac{1}{K^2} \\sum_{i=1}^{K} var(a(x, X_i))$$\n",
    "\n",
    "Тогда, зная, что модели не коррелированы, получаем:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/7c8d37f4978d49117ffa159ebaf2c527/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-57.png)\n",
    "\n",
    "**Вывод**: разброс ансамбля уменьшается в $K$ раз по сравнению с разбросом базовой модели!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем случае разброс бэггинга будет выражаться следующим образом:\n",
    "\n",
    "$$\\frac{1}{K}\\left(\\operatorname{Var} a_{n}(x)\\right)+\\operatorname{Cov}\\left(a_{n}(x), a_{m}(x)\\right)$$\n",
    "\n",
    "В данном выражении через $a_{n}(x)$ обозначен один из базовых алгоритмов, а за $a_{m}(x)$ — другой базовый алгоритм.\n",
    "\n",
    "Из этого следует, что если модели (в данной формуле — базовые модели $a_{n}(x)$ и $a_{m}(x)$) независимы, то разброс для ансамбля типа бэггинг будет в $K$ раз меньше, чем разброс у отдельной модели.\n",
    "\n",
    "**Резюмируем:**\n",
    "\n",
    "* Бэггинг даёт уменьшение ошибки в $K$ раз по сравнению с одиночной моделью.\n",
    "* Бэггинг не уменьшает смещение по сравнению с одиночной моделью.\n",
    "* Бэггинг уменьшает разброс в $K$ раз по сравнению с одиночной моделью.\n",
    "\n",
    "Важно отметить, что эти утверждения выведены и доказаны теоретически и будут выполняться на практике только в том случае, если между ошибками нулевая корреляция.\n",
    "\n",
    "Как видим, бэггинг — очень эффективный и полезный алгоритм, так что есть смысл попрактиковаться с ним."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.7\n",
    "\n",
    "Объёмная и содержательная практика у нас ещё впереди, но в качестве разминки давайте поработаем с уже известным вам датасетом о вине, который можно скачать [здесь](https://lms.skillfactory.ru/assets/courseware/v1/805b5c231251e174abb4fdbbd391adc3/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/wineQualityReds.zip).\n",
    "\n",
    "Ранее вы обучали на данных только один алгоритм, а теперь мы попробуем сравнить несколько.\n",
    "\n",
    "* Подготовьте данные к классификации. Условно разделите вино на хорошее и плохое. Хорошим вином будем называть то, параметр quality которого — 6 и более.\n",
    "* Сравните несколько методов классификации: логистическую регрессию, дерево решений и бэггинг. Это позволит вам увидеть, как меняется качество в зависимости от выбора того или иного алгоритма.\n",
    "* Разделите выборку на обучающую и тестовую в соотношении 70/30, в качестве значения параметра random_state возьмите число 42.\n",
    "* Для начала обучите два классификатора: логистическую регрессию (с параметрами по умолчанию) и дерево решений (random_state = 42, максимальная глубина — 10).\n",
    "\n",
    "1. Введите значение F1-score для классификатора, который показал наилучшее значение. Ответ округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fixed.acidity</th>\n",
       "      <th>volatile.acidity</th>\n",
       "      <th>citric.acid</th>\n",
       "      <th>residual.sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free.sulfur.dioxide</th>\n",
       "      <th>total.sulfur.dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  fixed.acidity  volatile.acidity  citric.acid  residual.sugar  \\\n",
       "0           1            7.4              0.70         0.00             1.9   \n",
       "1           2            7.8              0.88         0.00             2.6   \n",
       "2           3            7.8              0.76         0.04             2.3   \n",
       "3           4           11.2              0.28         0.56             1.9   \n",
       "4           5            7.4              0.70         0.00             1.9   \n",
       "\n",
       "   chlorides  free.sulfur.dioxide  total.sulfur.dioxide  density    pH  \\\n",
       "0      0.076                 11.0                  34.0   0.9978  3.51   \n",
       "1      0.098                 25.0                  67.0   0.9968  3.20   \n",
       "2      0.092                 15.0                  54.0   0.9970  3.26   \n",
       "3      0.075                 17.0                  60.0   0.9980  3.16   \n",
       "4      0.076                 11.0                  34.0   0.9978  3.51   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.56      9.4        0  \n",
       "1       0.68      9.8        0  \n",
       "2       0.65      9.8        0  \n",
       "3       0.58      9.8        1  \n",
       "4       0.56      9.4        0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "data = pd.read_csv('data/wineQualityReds.zip')\n",
    "\n",
    "data['quality'] = data['quality'].apply(lambda x: 1 if x >= 6 else 0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data[data.columns[:-1]]\n",
    "y = data[data.columns[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression F1 score: 0.739\n",
      "DecisionTreeClassifier F1 score: 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('LogisticRegression F1 score: {:.3f}'.format(metrics.f1_score(y_test, y_pred)))\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=10\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print('DecisionTreeClassifier F1 score: {:.3f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.8\n",
    "\n",
    "Обучите модель с использованием бэггинга (класс BaggingClassifier с random_state=42).\n",
    "\n",
    "Возьмите из предыдущего задания алгоритм, показавший наилучшее качество, и укажите для него новое количество моделей — 1500. Вычислите новое значение F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier F1 score: 0.824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bc = BaggingClassifier(\n",
    "    base_estimator=dt,\n",
    "    n_estimators=1500,\n",
    "    random_state=42    \n",
    ")\n",
    "\n",
    "bc.fit(X_train, y_train)\n",
    "y_pred = bc.predict(X_test)\n",
    "print('BaggingClassifier F1 score: {:.3f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Случайный лес"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущем юните мы поговорили о бэггинге — одном из видов ансамблей моделей. В этом юните мы будем разбирать модификацию бэггинга — **случайный лес**.\n",
    "\n",
    "Несмотря на то что вам уже известен данный алгоритм, рассмотрим совсем простой пример случайного леса для случая классификации, чтобы вспомнить логику реализации модели.\n",
    "\n",
    "Допустим, у нас есть набор данных с фруктами, для которого мы хотим решить задачу классификации. Известны цвет, диаметр, форма, время созревания и другие особенности каждого объекта.\n",
    "\n",
    "Наша задача состоит в том, чтобы построить модель классификации, которая в будущем сможет по характеристикам фрукта определять его вид.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/8d2126a3b7eb9df1e43f356e96026504/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_1.png)\n",
    "\n",
    "Строим три решающих дерева, которые делают предсказания следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/6a76fe69f3c19a4c17a1bd566f6f1268/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появляется новый фрукт, про который мы пока ничего не знаем, кроме его признаков:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c57d55ee6efcef0f5bb4a755f1d974c6/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_3.png)\n",
    "\n",
    "Наш **случайный лес**, состоящий из трёх деревьев, будет классифицировать этот фрукт следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/13f128b21512a6f7a5bf84055b907e28/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_4.png)\n",
    "\n",
    "Мы видим, что два дерева голосуют за то, что это апельсин, и одно дерево голосует за вишню. Тогда большинством голосов мы решаем, что это апельсин."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lms.skillfactory.ru/assets/courseware/v1/d762f79a8c196f94c23d0837b7e5c308/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_5.png)\n",
    "\n",
    "Вот и всё, мы решили задачу классификации с помощью случайного леса.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5447a7937de6636597fac98b4f0a9f62/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_6.png)\n",
    "\n",
    "Есть какое-то количество решающих деревьев, каждое из которых мы обучаем на некоторой подвыборке из данных. Получив вердикты от всех моделей, определяем итоговый результат для каждого объекта.\n",
    "\n",
    "**Для регрессии** правило формирования итогового результата формулируется следующим образом:\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x)=\\frac{1}{K} \\sum_{i=1}^{K} a_{i}(x)$$\n",
    "\n",
    "Здесь:\n",
    "\n",
    "$K$ — количество моделей,\n",
    "$a_i(x)$ — алгоритм решающего дерева,\n",
    "$f(x)$ — значение финального предсказания ансамбля.\n",
    "\n",
    "Это означает, что мы просто находим среднее арифметическое для всех полученных предсказаний.\n",
    "\n",
    "Правило формирования итогового результата **для классификации**:\n",
    "\n",
    "$$f(x)=\\arg \\max _{y \\in \\mathbb{Y}} \\sum_{i=1}^{K}\\left[a_{i}(x)=y\\right]$$\n",
    "\n",
    "Здесь деревья просто голосуют за некоторый класс, и объекту присваивается метка класса, за который было отдано наибольшее количество голосов.\n",
    "\n",
    "Давайте рассмотрим алгоритм реализации случайного леса.\n",
    "\n",
    "Одно из важных понятий, которое здесь появляется, — это **метод случайных подпространств**, который используется для построения ансамблей моделей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кратко опишем его принцип:\n",
    "\n",
    "1. Отбираем обучающую выборку.\n",
    "2. Определяем число моделей, которые войдут в ансамбль.\n",
    "3. Для каждой модели берём не все признаки, а только часть из них и формируем выборку с использованием случайно выбранного набора признаков.\n",
    "4. Объединяем все результаты и определяем итоговое решение по объектам.\n",
    "\n",
    "Обратите внимание на важную особенность:** здесь выбирается не только обучающая выборка, но ещё и случайная выборка из признаков.\n",
    "\n",
    "Алгоритм случайного леса в таком контексте реализуется следующим образом:\n",
    "\n",
    "1. Для того чтобы построить $i$-е дерево леса, из обучающей выборки $X$ берём случайную подвыборку $X_i$ того же размера, что и вся обучающая выборка.\n",
    "2. После этого в каждой вершине каждого дерева из $M$ возможных признаков выбираем случайную группу признаков объёма $L$. Для выбранных признаков ищем оптимальное разбиение. Рекомендуется использовать $L=\\sqrt{M}$ в задачах классификации и $\\frac{M}{3}$ — в задачах регрессии.\n",
    "3. Для получения предсказания необходимо воспользоваться обычным принципом бэггинга: взять усреднённый ответ в случае регрессии или самый популярный класс — для классификации.\n",
    "\n",
    "В контексте случайного леса важно обратить внимание на **несколько ключевых аспектов**:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Переобучение\n",
    "\n",
    "Случайный лес может переобучаться, однако это никак не связано с количеством деревьев. Наоборот, с ростом числа деревьев модель становится всё более эффективной в плане корректных прогнозов. На анимации ниже наглядно показано, что случайный лес не переобучается, а совершенствует своё предсказание.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/825d6b9296ccef04ea5207300fdc3e0a/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_7.gif)\n",
    "\n",
    "Здесь мы видим пространство признаков с объектами, которые относятся к двум классам (красные точки и синие точки). Мы пытаемся построить разделяющую их поверхность, которая корректируется по ходу увеличения числа деревьев (счётчик количества деревьев расположен сверху)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Out-of-Bag Error\n",
    "\n",
    "> **Ошибка Out-of-Bag** — это способ оценить качество случайного леса.\n",
    "\n",
    "Давайте разберём, как она вычисляется, на примере.\n",
    "\n",
    "Предположим, что в нашем случайном лесу пять решающих деревьев, и наша обучающая выборка выглядит следующим образом:\n",
    "\n",
    "Outlook|Temperature|Humidity|Wind|Play Tennis\n",
    "-|-|-|-|-\n",
    "Sunny|Hot|High|Weak|No\n",
    "Sunny|Hot|High|Strong|No\n",
    "Sunny|Hot|High|Weak|Yes\n",
    "Windy|Cold|Low|Weak|Yes\n",
    "\n",
    "В выборку внесены погодные условия и итоговое решение — подходит ли день для игры в теннис. Итоговое решение при одинаковых погодных условиях может отличаться, так как на него могли повлиять и другие факторы.\n",
    "\n",
    "Для первого дерева мы делаем такую подвыборку (Bootstrap Sample):\n",
    "\n",
    "Outlook|Temperature|Humidity|Wind|Play Tennis\n",
    "-|-|-|-|-\n",
    "**Sunny**|**Hot**|**High**|**Weak**|**No**\n",
    "**Sunny**|**Hot**|**High**|**Strong**|**No**\n",
    "**Sunny**|**Hot**|**High**|**Weak**|**Yes**\n",
    "Windy|Cold|Low|Weak|Yes\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда неучтённая часть выборки носит название подвыборки Out-of-Bag (Out-of-Bag Sample):\n",
    "\n",
    "Outlook|Temperature|Humidity|Wind|Play Tennis\n",
    "-|-|-|-|-\n",
    "Sunny|Hot|High|Weak|No\n",
    "Sunny|Hot|High|Strong|No\n",
    "Sunny|Hot|High|Weak|Yes\n",
    "**Windy**|**Cold**|**Low**|**Weak**|**Yes**\n",
    "\n",
    "После того как все деревья будут обучены, эта подвыборка будет передана всем деревьям, для которых она не входила в бутстреп-выборку, для формирования прогноза. Допустим, это были деревья под номерами 1, 3 и 5:\n",
    "\n",
    "Decision Tree|Prediction\n",
    "-|-\n",
    "1|YES\n",
    "3|NO\n",
    "5|YES\n",
    "Majority vote: |YES\n",
    "\n",
    "Мы видим, что большинство деревьев проголосовало, что день подходит для игры в теннис, то есть окончательный прогноз для этого объекта — YES. Это совпадает с реальной меткой. Значит, на этом наблюдении алгоритм дал верный прогноз.\n",
    "\n",
    "Таким же образом все объекты изначальной выборки проходят через все деревья, в подвыборку которых они не попали, и для каждого объекта осуществляется предсказание."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что можно доказать, что такие объекты составляют примерно 36.8 % от объёма подвыборки, то есть каждое дерево обучается на подвыборке, в которой в среднем 63.2 % уникальных наблюдений.\n",
    "\n",
    "Пусть в нашей выборке есть $N$ наблюдений. На каждом шаге каждое наблюдение попадает в выборку с вероятностью $\\frac{1}{N}$. Тогда вероятность того, что оно не попадает в выборку, — $1-\\frac{1}{N}$. Причём если выборка формируется $N$ раз, то вероятность становится равна $(1-\\frac{1}{N})^N$. Теперь можно применить пределы, чтобы получить итоговый процент:\n",
    "\n",
    "$$\\displaystyle \\lim_{N \\to \\infty }(1-\\frac{1}{N})^N=e^{-1}=0.368$$\n",
    "\n",
    "**Примечание**. Данный переход напрямую следует из второго замечательного предела. К сожалению, эта часть математического анализа выходит за пределы нашего курса, однако если вам интересно изучить её подробнее, рекомендуем ознакомиться с [этим материалом](https://math1.ru/education/limits/limitsecond.html).\n",
    "\n",
    "Получается почти 37 %. Out-of-Bag-оценка — это как раз усреднённая оценка базовых алгоритмов на этих ~37% данных, на которых они не обучались."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, для того чтобы найти out-of-Bag-оценку:\n",
    "\n",
    "1. Для каждого объекта $x_i$ получаем предсказания всех деревьев $a_b$, обучавшихся на бутстреп-выборках $X_b$, не содержащих $x_i$.\n",
    "2. Усредняем эти предсказания.\n",
    "3. Находим значение ошибки для усреднённого предсказания.\n",
    "4. Усредняем значение функционала ошибки для всех объектов выборки.\n",
    "Строго математически это можно записать следующим образом:\n",
    "\n",
    "$$\\mathrm{OOB}= \\frac{1}{N}\\sum_{i=1}^{N} L\\left(y_{i}, \\frac{1}{\\sum_{b=1}^{B}\\left[x_{i} \\notin X_{b}\\right]} \\sum_{b=1}^{B}\\left[x_{i} \\notin X_{b}\\right] a_{b}\\left(x_{i}\\right)\\right)$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Значимость признаков\n",
    "\n",
    "Разумеется, нам всегда интересно узнать, какие признаки сильнее всего влияют на результат. Случайный лес даёт нам такую возможность. Посмотрим на схематичное изображение решающего дерева:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/ee0bc094bfa6aaedf957d8cca4360ce0/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_9.png)\n",
    "\n",
    "Мы видим, что признак «возраст автовладельца > 40 лет» важнее, чем, например, тип автомобиля. Нам хотелось бы не только узнать самый важный признак, но и в целом проранжировать все признаки модели.\n",
    "\n",
    "В случайном лесе мы строим много деревьев, и чем в среднем выше какой-то признак находится в деревьях, тем он важнее. О том, как это вычислить программно, мы узнаем в следующем юните."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Оценка эффективности\n",
    "\n",
    "В предыдущем модуле мы разобрали решающие деревья, а в этом — бэггинг и случайный лес. Давайте попробуем сравнить эти алгоритмы и понять, какой из них является более эффективным и даёт бóльшую прогностическую точность.\n",
    "\n",
    "Реализуем три варианта моделей для случайно сгенерированных данных:\n",
    "\n",
    "* решающее дерево c глубиной 15;\n",
    "* бэггинг с десятью решающими деревьями:\n",
    "    * по одному — глубины 11, 14, 15, 16,\n",
    "    * четыре — глубины 13,\n",
    "    * два — глубины 12;\n",
    "* случайный лес с десятью решающими деревьями:\n",
    "* по одному — глубины 12, 18,\n",
    "* два — глубины 16,\n",
    "* шесть — глубины 13.\n",
    "\n",
    "Попробуем оценить качество в каждом случае. Результаты представлены на графиках ниже.\n",
    "\n",
    "**Примечание:**\n",
    "\n",
    "* **Синей линией** показаны истинные значения для выборки.\n",
    "* Точками, которые соединены линиями разных цветов, обозначены предсказания соответствующих моделей: **зелёная линия** — для решающего дерева, **жёлтая** — для бэггинга, **красная** — для случайного леса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lms.skillfactory.ru/assets/courseware/v1/972634da513a3f3602d9ad1afb3c9532/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_10.png)\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/11a9a19132b3cde466b81ad273717fed/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_11.png)\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/aab49db010bdd17491b8eb5153505149/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_3_12.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графиков можно увидеть, что ошибка для алгоритма бэггинга над решающими деревьями заметно меньше, чем ошибка для одного случайного дерева. Численные результаты подтверждают это. Случайный лес в данном случае обгоняет по эффективности бэггинг над решающими деревьями (однако это не является правилом, и с другими данными может получиться другой результат).\n",
    "\n",
    "Итак, мы разобрали все основные моменты, которые касаются случайного леса. Нам осталось лишь закрепить полученные знания на практике — этим мы займёмся уже совсем скоро. А пока давайте обобщим плюсы и минусы данного алгоритма, которые были упомянуты в этом юните и ранее.\n",
    "\n",
    "### Плюсы\n",
    "\n",
    "* Очень высокая точность предсказания (это один из самых эффективных алгоритмов).\n",
    "* Данные не обязательно масштабировать: случайный лес не чувствителен к масштабированию и в принципе к любым монотонным преобразованиям, поэтому в таких манипуляциях нет смысла.\n",
    "* Нет чувствительности к выбросам из-за формирования случайных выборок.\n",
    "* Не требуется тщательно настраивать множество параметров. Даже если реализовывать алгоритм с настройками по умолчанию, результат будет лучше, чем у большинства других моделей.\n",
    "* Нет склонности к переобучению.\n",
    "* Позволяет оценить значимость отдельных признаков.\n",
    "* Может эффективно работать с несбалансированными классами.\n",
    "* Показывает высокую точность на данных с большим количеством пропусков.\n",
    "\n",
    "### Минусы\n",
    "\n",
    "* Плохо работает с разрежёнными признаками (т. е. с такими, у которых преимущественно нулевые значения). Это может сказываться, к примеру, на качестве анализа текстов.\n",
    "* Сложно интерпретировать результ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более подробно рассматривать практическую сторону реализации случайного леса и варьировать различные параметры для получения наилучшего результата мы будем в следующем юните. Но давайте решим небольшую задачу уже сейчас. Все функции из неё вы уже использовали ранее, так что это отличный повод вспомнить их или поработать с документацией.\n",
    "\n",
    "Мы будем анализировать [набор данных Boston Houses](https://lms.skillfactory.ru/assets/courseware/v1/7785a02c9293b5baaae3ba9ea0e10092/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/boston__1_.zip), в котором объектами являются районы города, признаками — некие социальные и географические характеристики района, а целевой переменной — медианная стоимость домов в районе. Таким образом, мы будем решать задачу регрессии.\n",
    "\n",
    "Как и в предыдущем практическом задании, весь код, который мы напишем, можно применить к любым данным."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* crim_rate — уровень преступности в районе;\n",
    "* zn — доля участков площадью более 25 000 кв. футов;\n",
    "* business — уровень развитости бизнеса в районе;\n",
    "* river — наличие реки в районе;\n",
    "* nit_oxiden — концентрация оксидов азота в воздухе;\n",
    "* rooms — среднее число комнат в домах района;\n",
    "* age — процент домов, построенных до 1940 года;\n",
    "* dist — расстояние до центров занятости;\n",
    "* highways_index — индекс доступности крупных дорог;\n",
    "* tax — средняя ставка налога на имущество;\n",
    "* pup_per_teac — среднее число учеников на одного учителя;\n",
    "* lower — процент малообеспеченного населения в районе;\n",
    "* target — медианная стоимость домов в районе (целевая переменная)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.4\n",
    "\n",
    "1. Разбейте набор данных на обучающую и тестовую выборку в соотношении 70/30, при разбиении задайте параметр random_state = 13.\n",
    "\n",
    "    Какое получилось среднее значение медианных цен на обучающей выборке? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.77"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/boston__1_.zip', decimal=',')\n",
    "\n",
    "X = data[data.columns[:-1]]\n",
    "y = data[data.columns[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=13)\n",
    "\n",
    "round(y_train.mean(), 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите линейную регрессию с параметрами по умолчанию.\n",
    "\n",
    "    В качестве ответа введите ошибку MAE на тестовой выборке. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.72\n"
     ]
    }
   ],
   "source": [
    "lin_reg = linear_model.LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "print('MAE: {:.2f}'.format(metrics.mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Обучите решающее дерево с параметрами по умолчанию и аргументом random_state = 13.\n",
    "\n",
    "    Можно ли, опираясь на результаты, сделать вывод, что алгоритм переобучился?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.839\n"
     ]
    }
   ],
   "source": [
    "d_tree = tree.DecisionTreeRegressor(\n",
    "    random_state=13\n",
    ")\n",
    "\n",
    "d_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = d_tree.predict(X_test)\n",
    "\n",
    "print('MAE: {:.3f}'.format(metrics.mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Обучите четыре случайных леса с числом деревьев 3, 10, 100, 500 и параметром random_state = 13.\n",
    "\n",
    "    В качестве ответа введите наименьшую полученную ошибку MAE на тестовой выборке. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 3 estimators: 2.93\n",
      "MAE for 10 estimators: 2.47\n",
      "MAE for 100 estimators: 2.26\n",
      "MAE for 500 estimators: 2.24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "n_estimators = [3, 10, 100, 500]\n",
    "\n",
    "for n in n_estimators:\n",
    "        rf = RandomForestRegressor(random_state=13,\n",
    "                           n_estimators=n)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        print('MAE for {} estimators: {:.2f}'.format(n, metrics.mean_absolute_error(y_test, y_pred)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Случайный лес. Практика"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущем юните мы познакомились с теоретической основой случайного леса, а в этом закрепим пройденный материал на практике.\n",
    "\n",
    "Пожалуй, каждый из нас практически ежедневно смотрит прогноз погоды: будет сегодня тепло или холодно, брать ли зонт? Мы расстраиваемся, если внезапно идёт дождь, а мы оказались к этому не готовы. Иногда можно понять, что будет дождь, просто взглянув на небо, но часто такие предположения оказываются неверными. Надёжнее всего пользоваться прогнозами, которые публикуют специалисты. А задумывались ли вы, как формируются эти прогнозы?\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/130482f7182b58ae6bdc46d8817d84e6/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_4_1.jpg)\n",
    "\n",
    "Да-да, здесь тоже не обошлось без машинного обучения. В этом юните мы с вами немного коснёмся метеорологии, чтобы предсказать, будет ли дождь в Австралии. Попутно вы узнаете, какие факторы влияют на вероятность дождя — возможно, вы научитесь предсказывать его точнее, чем метеорологические службы, и больше никогда не окажетесь в нужный момент без зонта.\n",
    "\n",
    "Давайте посмотрим, с какими [данными](https://lms.skillfactory.ru/assets/courseware/v1/55a24d3591d52f74426896a40a048041/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/weatherAUS.zip) нам предстоит работать.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/10463bcb8a3c2dfbcb2576f1b68d043a/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_4_2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные содержат 23 признака и 145 460 наблюдений. Из этих 23 признаков шесть — категориальные, в одном записана дата, а остальные являются непрерывными числовыми данными.\n",
    "\n",
    "* Примеры числовых признаков: температура, скорость ветра, влажность, облачность, атмосферное давление в разное время суток, количество осадков, испарение, количество часов с солнечной погодой.\n",
    "* Примеры категориальных признаков: местоположение, направление ветра в разное время суток, наличие дождя сегодня или завтра.\n",
    "\n",
    "**Целевой переменной** является столбец RainTomorrow. Значение этой переменной мы и будем пытаться предсказать.\n",
    "\n",
    "##### Подробная расшифровка всех признаков\n",
    "\n",
    "* Date — дата, в которую зафиксировано наблюдение;\n",
    "* Location — местонахождение метеорологической станции;\n",
    "* MinTemp — минимальная температура (℃);\n",
    "* MaxTemp — максимальная температура (℃);\n",
    "* Rainfall — количество осадков (дождь) за сутки (мм);\n",
    "* Evaporation — количество испарений до 9 утра (мм);\n",
    "* Sunshine — количество часов в сутках, когда светило солнце;\n",
    "* WindGustDir — направление самого сильного порыва ветра за последние 24 часа;\n",
    "* WindGustSpeed — скорость самого сильного порыва ветра за последние 24 часа;\n",
    "* WindDir9am — направление ветра в 9 утра;\n",
    "* WindDir3pm — направление ветра в 3 часа дня;\n",
    "* WindSpeed9am — скорость ветра в 9 часов утра;\n",
    "* WindSpeed3pm — скорость ветра в 3 часа дня;\n",
    "* Humidity9am — влажность в 9 утра;\n",
    "* Humidity3pm — влажность в 3 часа дня;\n",
    "* Pressure9am — атмосферное давление в 9 утра;\n",
    "* Pressure3pm — атмосферное давление в 3 часа дня;\n",
    "* Cloud9am — часть неба, закрытая облаками, в 9 утра;\n",
    "* Cloud3pm — часть неба, закрытая облаками, в 3 часа дня;\n",
    "* Temp9am — температура в 9 утра;\n",
    "* Temp3pm — температура в 3 часа дня;\n",
    "* RainToday — наличие дождя в этот день;\n",
    "* RainTomorrow — наличие дождя на следующий день."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.1\n",
    "\n",
    "Сколько суммарно пропусков в данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343248"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/weatherAUS.zip')\n",
    "\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно отметить, что в данных много пропусков, но для нас это не проблема, так как случайный лес прекрасно работает в таких ситуациях, и скоро у нас будет возможность в этом убедиться."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.2\n",
    "\n",
    "В некоторых признаках пропусков более 40 % — удалите такие признаки. Сколько их было?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sunshine       0.480098\n",
       "Evaporation    0.431665\n",
       "Cloud3pm       0.408071\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with nulls over 40%:  3\n"
     ]
    }
   ],
   "source": [
    "nulls = data.isnull().mean().sort_values(ascending=False)\n",
    "\n",
    "display(nulls[nulls.values >= 0.4])\n",
    "print('Features with nulls over 40%: ', nulls[nulls.values >= 0.4].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = nulls[nulls.values >= 0.4].index\n",
    "\n",
    "data.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.3\n",
    "\n",
    "Теперь обработаем признаки RainToday и RainTomorrow таким образом, чтобы вместо yes было значение 1, а вместо no — значение 0. Обратите внимание на то, что в признаке RainTomorrow присутствуют пропуски, и их трогать не нужно, они должны остаться пропусками. Поэтому обрабатывайте столбцы таким образом, чтобы не видоизменить пропущенные значения.\n",
    "\n",
    "Вычислите среднее арифметическое для преобразованного признака RainToday и запишите его в ответ, предварительно округлив до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df.RainToday = df.RainToday.map({'No': 0, 'Yes': 1})\n",
    "df.RainTomorrow = df.RainTomorrow.map({'No': 0, 'Yes': 1})\n",
    "\n",
    "print(round(df['RainToday'].mean(), 2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.4\n",
    "\n",
    "Обработайте признак Date таким образом, чтобы выделить в отдельный признак Month (номер месяца). Изначальный признак Date удалите. Определите, в какой месяц в среднем за день выпадает больше всего дождей. В качестве ответа **введите порядковый номер месяца**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month\n",
       "7     0.270736\n",
       "6     0.263638\n",
       "8     0.253167\n",
       "9     0.229135\n",
       "5     0.222163\n",
       "3     0.217135\n",
       "4     0.216845\n",
       "12    0.213037\n",
       "11    0.210843\n",
       "2     0.206746\n",
       "10    0.196512\n",
       "1     0.189484\n",
       "Name: RainToday, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Month'] = pd.to_datetime(df.Date).dt.month\n",
    "df.drop(columns=['Date'], inplace=True)\n",
    "df.groupby(by='Month').mean()['RainToday'].sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.5\n",
    "\n",
    "Обработайте оставшиеся категориальные признаки. С помощью метода get_dummies с настройками по умолчанию создайте dummy-переменные для всех категориальных признаков (их пять), которые есть в данных на этот момент.\n",
    "\n",
    "Кодировку признаков важно выполнить именно в следующем порядке: categoricals = ['Month', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm']. Это необходимо для того, чтобы ваши дальнейшие ответы сходились с нашим решением, так как алгоритм случайного леса, который мы будем использовать в дальнейшем, чувствителен к порядку столбцов.\n",
    "\n",
    "Сколько теперь признаков в данных, если считать целевую переменную?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricals = ['Month', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
    "\n",
    "df_dummies = pd.get_dummies(df, columns=categoricals)\n",
    "\n",
    "df_dummies.shape[1]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.6\n",
    "\n",
    "Осталось совсем немного. Удалите все строки, где есть пропуски. Далее разбейте данные на обучающую и тестовую выборки в соотношении 70/30, в качестве значения параметра random_state возьмите число 31.\n",
    "\n",
    "Каково среднее значение целевой переменной на тестовой выборке? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = df_dummies.dropna()\n",
    "\n",
    "X = weather.drop(columns=['RainTomorrow'])\n",
    "y = weather['RainTomorrow']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=31)\n",
    "\n",
    "round(y_test.mean(), 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.7\n",
    "\n",
    "Теперь давайте вспомним про бутстреп. Он не понадобится нам для решения этой задачи, но будет полезно реализовать его «вручную».\n",
    "\n",
    "Сделайте оценку стандартного отклонения для среднего значения минимальной температуры для обучающей выборки (то есть для среднего значения по признаку MinTemp). Для этого сгенерируйте 1000 случайных выборок из наших данных — каждая из них должна быть такого же объёма, как и обучающая выборка. Для генерации выборки используйте np.random.randint(): сгенерируйте необходимое количество индексов и по ним извлеките соответствующие элементы выборки. Случайность фиксируйте с помощью np.random.seed(31).\n",
    "\n",
    "Для каждой выборки вычислите среднее значение, а после найдите стандартное отклонение для этих значений. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(31)\n",
    "\n",
    "min_temp_mean = []\n",
    "\n",
    "for n in range(1000):\n",
    "    \n",
    "    indexes = np.random.randint(X.shape[0], \n",
    "                  size=X_train.shape[0]\n",
    "                  )\n",
    "    min_temp_mean.append(X['MinTemp'].iloc[indexes].mean())\n",
    "    \n",
    "np.std(min_temp_mean).round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.8\n",
    "\n",
    "Теперь можно перейти к обучению прогностических моделей. Начнём с того, что построим простейшую логистическую регрессию (без настройки гиперпараметров). Это будет та модель, с качеством которой мы будем сравнивать результаты, полученные далее, чтобы оценить превосходство случайного леса над простыми методами.\n",
    "\n",
    "В качестве ответа введите значение метрики roc_auc на тестовой выборке. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression roc-auc score: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('LogisticRegression roc-auc score: {:.2f}'.format(metrics.roc_auc_score(y_test, y_pred)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.9\n",
    "\n",
    "Теперь попробуйте обучить на наших данных другой алгоритм — дерево решений. С помощью GridSearchCV сделайте перебор гиперпараметров по следующей сетке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_leaf_nodes': list(range(2, 10)), \n",
    "          'min_samples_split': [2, 3, 4], \n",
    "          'max_depth': [5,7,9,11]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для параметра кросс-валидации cv задайте значение 3. Для решающего дерева определите параметр random_state=42. Остальные параметры оставьте по умолчанию.\n",
    "\n",
    "1. Вычислите значение roc_auc для решающего дерева с гиперпараметрами, определёнными в качестве оптимальных. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 7, 9, 11],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 7, 9, 11],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [5, 7, 9, 11],\n",
       "                         'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'min_samples_split': [2, 3, 4]})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(cv=3,\n",
    "                  estimator=tree.DecisionTreeClassifier(\n",
    "                      random_state=42),\n",
    "                  param_grid=params)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch DTR roc-auc score: 0.70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'max_leaf_nodes': 9, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "print('GridSearch DTR roc-auc score: {:.2f}'.format(metrics.roc_auc_score(y_test, y_pred)))\n",
    "\n",
    "gs.best_params_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.10\n",
    "\n",
    "К сожалению, деревья решений не помогли нам в улучшении качества модели, так что попробуем ещё уменьшить ошибку с помощью ансамблей.\n",
    "\n",
    "Теперь постройте случайный лес, включающий 100 деревьев. Задайте параметр random_state=31. Остальные параметры оставьте по умолчанию.\n",
    "\n",
    "Какой теперь будет метрика roc_auc на тестовой выборке? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest roc-auc score: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=31,\n",
    "                           n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print('RandomForest roc-auc score: {:.2f}'.format(metrics.roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.11\n",
    "\n",
    "Основные параметры, которые отвечают за качество обучения в случайном лесе, следующие: 'max_features', 'min_samples_leaf', 'max_depth'.\n",
    "\n",
    "Возьмите случайный лес из 100 деревьев и найдите оптимальную комбинацию этих трёх параметров. Сетка для перебора следующая:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_features': [ 4, 5, 6, 7], \n",
    " 'min_samples_leaf': [3, 5, 7, 9, 11], \n",
    " 'max_depth': [5, 10, 15]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебор осуществите с помощью GridSearchCV. Для параметра кросс-валидации cv задайте значение 3. Случайности фиксируйте параметром random_state = 31. Остальные значения оставьте по умолчанию.\n",
    "\n",
    "Какое значение roc_auc получилось для оптимальных гиперпараметров?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10280/4256042076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                   param_grid=params)\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1373\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    820\u001b[0m                     )\n\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    823\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    765\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror_score\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    830\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m         \"\"\"\n\u001b[1;32m--> 832\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m         ]\n\u001b[0;32m    884\u001b[0m         \u001b[0mlock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n\u001b[0m\u001b[0;32m    886\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_accumulate_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m     \"\"\"\n\u001b[1;32m--> 664\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(cv=3,\n",
    "                  estimator=RandomForestClassifier(random_state=31),\n",
    "                  param_grid=params)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "print('GridSearchCV RandomForestClassifier roc-auc score: {:.2f}'.format(metrics.roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.12\n",
    "\n",
    "Как мы говорили в предыдущем юните, благодаря случайному лесу можно узнать, какие признаки оказывают большее влияние на целевую переменную по сравнению с другими.\n",
    "\n",
    "Оцените значимость признаков. Отметьте три признака, которые дают наибольший вклад в целевую переменную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Humidity3pm</td>\n",
       "      <td>0.250783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rainfall</td>\n",
       "      <td>0.079757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Humidity9am</td>\n",
       "      <td>0.070403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "7  Humidity3pm    0.250783\n",
       "2     Rainfall    0.079757\n",
       "6  Humidity9am    0.070403"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imps = pd.DataFrame(\n",
    "    {'feature' : gs.best_estimator_.feature_names_in_,\n",
    "    'importance' : gs.best_estimator_.feature_importances_}\n",
    "    )\n",
    "feature_imps.sort_values(by='importance', ascending=False)[:3]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Бустинг"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущих юнитах мы познакомились с одним из видов ансамблевых методов — бэггингом. Пришло время поговорить ещё об одном типе ансамблей — бустинге.\n",
    "\n",
    "В целом, идеи бустинга и бэггинга очень похожи: в обоих случаях мы берём слабые модели и объединяем их для получения более качественного прогноза. Однако есть одно ключевое различие:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/86ec44dadb1105d1e0717764b7e9d2a9/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_1.png)\n",
    "\n",
    "В бэггинге все модели обучаются одновременно, независимо и параллельно. В качестве итогового предсказания берётся усреднённый ответ (в задаче регрессии) или делается прогноз по большинству голосов (в задаче классификации)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примере ниже гольфист сначала пытается забить мяч в лунку в точкe $y$, но добирается только до координаты $f_1(x)$. Здесь отверстие в точке $y$ является целевой переменной. После переоценки направления и расстояния до лунки после каждого удара игрок несколько раз бьёт по мячу, более мягко направляя его к лунке, и так до тех пор, пока не попадёт в лунку.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/31d6f9cb240ddf94eb470688b13ae155/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_2.png)\n",
    "\n",
    "Основная концепция бустинга вам знакома, поэтому перейдём к его математической составляющей, но прежде необходимо вспомнить ещё одну особенность бустинга ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADABOOST\n",
    "\n",
    "Первый ансамбль типа бустинг, который мы рассмотрим, называется **AdaBoost (Adaptive Boosting)**.\n",
    "\n",
    "> Бустинг позволяет из большого количества относительно слабых и простых моделей получить одну сильную. В нашем случае будут рассматриваться деревья решений ограниченной глубины (всего из одного уровня) — их ещё называют **пнями**.\n",
    "\n",
    "Для начала давайте вспомним общую логику реализации данного алгоритма, а уже потом сформулируем его математически.\n",
    "\n",
    "Представим, что у нас есть изначальные данные двух классов: здоровые пациенты (обозначены минусом) и пациенты с диагностированным заболеванием (обозначены плюсом). Мы пытаемся решить задачу классификации. Как можно видеть на графиках ниже, результат первой слабой модели не очень удачный:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/bd69ae5381935d78fd560823713b7712/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_3.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда мы пересчитываем коэффициенты таким образом, чтобы уделить больше всего внимания именно тем наблюдениям, прогнозы для которых были сформированы неверно. На схеме ниже некоторые плюсы и минусы увеличились в размере — это иллюстрирует то, что мы увеличили их веса. После этого мы берём очередную слабую модель и строим новое предсказание (оно справа):\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/d63b4b2d021464baa04cead2eb40d72b/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_4.png)\n",
    "\n",
    "Как видим, результат получился снова не очень хорошим, однако он нивелировал некоторые ошибки, допущенные первым классификатором.  После двух итераций итог следующий:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/374be4aa87a5734c64d20e01c05aa383/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_5.png)\n",
    "\n",
    "Здесь $f(x)$ и $g(x)$ — результаты применения алгоритмов классификации."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То, что находится в цветной зоне, мы уже с достаточно высокой точностью можем отнести к верному классу. Однако нам необходимо повторять подключение новых моделей, чтобы классифицировать остальные объекты.\n",
    "\n",
    "Добавляя новые пни, мы в итоге можем добиться достаточно качественного разбиения спустя 30 итераций:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/f75993f2f97856890d4aeeef1a67f14a/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_6.png)\n",
    "\n",
    "Теперь, когда мы повторили смысл алгоритма AdaBoost, давайте обратимся к его математической составляющей и пропишем сам алгоритм:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Инициализируем веса объектов:\n",
    "\n",
    "    $$w_{j}=\\frac{1}{N}, j=1,2, \\ldots, N$$\n",
    "\n",
    "2. Для всех $i$ от $1$ до $K$ (если у нас $K$ базовых моделей):\n",
    "\n",
    "    2.1. Строим классификатор $a_i(x)$, используя веса $w_j$.\n",
    "\n",
    "    2.2. Вычисляем ошибку:\n",
    "\n",
    "    $$\\operatorname{err}_{i}=\\sum_{j=1}^{N} w_{j}\\left[y_{j} \\neq a_{i}\\left(x_{j}\\right)\\right]$$\n",
    "\n",
    "    2.3. Вычисляем вес нового алгоритма:\n",
    "\n",
    "    $$c_{i}=\\frac{1}{2} \\ln \\frac{1-e r r_{i}}{e r r_{i}}$$\n",
    "\n",
    "    2.4. Получаем новые веса объектов (классы определяются как -1 и +1):\n",
    "\n",
    "    $$w_{j} \\leftarrow w_{j} \\cdot \\exp \\left(c_{i}\\left[y_{j} \\neq a_{i}\\left(x_{j}\\right)\\right]\\right), j=1, \\ldots, N$$\n",
    "\n",
    "    2.5. Нормируем веса объектов:\n",
    "\n",
    "    $$w_{j} \\longleftarrow \\frac{w_{j}}{\\sum_{j=1}^{N} w_{j}}$$\n",
    "\n",
    "3. Группируем полученные модели:\n",
    "\n",
    "    $$f_{K}(x)=\\operatorname{sign}\\left[\\sum_{i=1}^{K} c_{i} a_{i}(x)\\right]$$\n",
    "\n",
    "    **Примечание**. $sign$ — это функция знака, которая извлекает знак действительного числа. Определяется следующим образом:\n",
    "\n",
    "    $$\\operatorname{sign}(x)=\\left\\{\\begin{aligned} 1, & x>0 \\\\ 0, & x=0 \\\\-1, & x<0 \\end{aligned}\\right.$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для лучшего понимания рассмотрим работу алгоритма на «игрушечном» *примере* ↓\n",
    "\n",
    "Допустим, у нас есть некоторый набор данных, на котором мы решаем задачу кредитного скоринга:\n",
    "\n",
    "$x_1$|$x_2$|$x_3$|$y$\n",
    "-|-|-|-\n",
    "1|1|0|1\n",
    "1|1|0|0\n",
    "1|0|0|1\n",
    "1|1|1|0\n",
    "0|1|0|0\n",
    "1|0|0|1\n",
    "\n",
    "Здесь есть три бинарных признака ($x_1$, $x_2$, $x_3$) и бинарная целевая переменная $y$:\n",
    "\n",
    "* бинарная целевая переменная $y$ означает, вернёт ли клиент кредит (1 — вернёт, 0 — не вернёт);\n",
    "* три бинарных признака $x_1$, $x_2$, $x_3$ означают характеристики клиента: есть ли у него залоговая недвижимость, долги по кредитам, постоянная работа."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первоначально все объекты данных будут иметь одинаковый вес $w$:\n",
    "\n",
    "$$w_{j}=\\frac{1}{N}, j=1,2, \\ldots, N,$$\n",
    "\n",
    "где $N$ — общее количество объектов.\n",
    "\n",
    "Можно обобщить всё в одну таблицу:\n",
    "\n",
    "$x_1$|$x_2$|$x_3$|$y$|Вес\n",
    "-|-|-|-|-\n",
    "1|1|0|1|1/6\n",
    "1|1|0|0|1/6\n",
    "1|0|0|1|1/6\n",
    "1|1|1|0|1/6\n",
    "0|1|0|0|1/6\n",
    "1|0|0|1|1/6\n",
    "\n",
    "Далее необходимо вычислить, например, значение критерия Джини, чтобы определить, какую переменную использовать для создания первого пня (так как этот коэффициент используется в деревьях решений как критерий качества разбиения). Напомним, что формула критерия Джини выражается следующим образом:\n",
    "\n",
    "$$H(Q)=\\sum_{k=0}^{K} P_{k}\\left(1-P_{k}\\right),$$\n",
    "\n",
    "где $Q=\\{(x, y)\\}$ — обучающая выборка, $P_k$ — вероятность принадлежности к классу $k$, $K$ — количество классов (у нас $K=2$).\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем формулу для нашего случая:\n",
    "\n",
    "$$\\begin{aligned} & H(Q)=\\sum_{k=0}^{K} P_{k}\\left(1-P_{k}\\right)=P_{0}\\left(1-P_{0}\\right)+P_{1}\\left(1-P_{1}\\right) \\\\=& P_{0}-\\left(P_{0}\\right)^{2}+P_{1}-\\left(P_{1}\\right)^{2}=1-\\left(P_{0}\\right)^{2}-\\left(P_{1}\\right)^{2} \\end{aligned}$$\n",
    "\n",
    "Здесь:\n",
    "\n",
    "* $P_1$ — вероятность принадлежности к классу 1;\n",
    "* $P_0$ — вероятность принадлежности к классу  0.\n",
    "\n",
    "После того как вычислен критерий Джини для каждой вершины, **взвешенная неоднородность вычисляется как средневзвешенное значение**.\n",
    "\n",
    "Рассмотрим вычисление критерия на примере решающего правила $[x_2 \\leq 0.5]$. Так как уникальных значений в признаке  всего два — 0 и 1, то это решающее правило будет разделять объекты на две категории: ту, для которой $x_2=0$, и ту, для которой $x_2=1$.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c3bf9d39044efcfc2b3a1b48c212920c/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_7.png)\n",
    "\n",
    "Выше приведена сводная таблица объектов, в которой показано количество наблюдений, попадающих в каждую категорию."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы можем вычислить критерий Джини каждого значения признака $x_2$:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/08eaa278e8791d7a269bc3734110f426/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_8.png)\n",
    "\n",
    "Немного поясним вычисления. Для значения $x_2=1$ один раз встречается единица и три раза — ноль, поэтому общее количество элементарных исходов равняется четырём. Мы можем рассчитать вероятности появления единицы и нуля. Ровно то же самое можно сделать и для $x_2=0$.\n",
    "\n",
    "После вычисления критерия Джини для каждого значения можно вычислить взвешенную неоднородность, взяв средневзвешенное значение двух критериев:\n",
    "\n",
    "$G = 0.375 \\left (\\frac{4}{4+2}  \\right ) + 0 \\left (\\frac{2}{4+2}  \\right )$\n",
    "\n",
    "$G=0.25$\n",
    "\n",
    "Получаем, что значение взвешенной неоднородности $G$ при разделении по предикату $[x_2 \\leq 0.5]$ равно $0.25$.\n",
    "\n",
    "Вы можете проделать тот же путь для каждого признака и в итоге получите, что у признака $x_2$ будет наименьшее значение взвешенной неоднородности. Это значит, именно $x_2$ будет использоваться для создания первого пня."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.2\n",
    "\n",
    "Найдите значение взвешенной неоднородности при разделении по признаку $x_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HQ = 1-(3/5)**2-(2/5)**2\n",
    "\n",
    "round(HQ*5/6, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы будем использовать общую ошибку, чтобы вычислить вес, который получает этот пень. Общая ошибка равна сумме весов неправильно классифицированных объектов. Тогда получается, что если алгоритм классифицировал первый объект неверно, а остальные — верно, то суммарная ошибка в нашем случае равна 1/6.\n",
    "\n",
    "$$c_{i}=\\frac{1}{2} \\ln \\frac{1-e r r_{i}}{e r r_{i}}$$\n",
    "\n",
    "Так как мы узнали ошибку, то можем рассчитать вес нового алгоритма:\n",
    "\n",
    "В нашем случае:\n",
    "\n",
    "$$\\frac{1}{2} \\ln \\left(\\frac{1-\\frac{1}{6}}{\\frac{1}{6}}\\right)=0.35$$\n",
    "\n",
    "Далее мы увеличиваем веса объектов, которые были неправильно классифицированы, и уменьшаем веса объектов, которые были классифицированы правильно, используя следующее правило:\n",
    "\n",
    "$$w_{j} \\leftarrow w_{j} \\cdot \\exp \\left(c_{i}\\left[y_{j} \\neq a_{i}\\left(x_{j}\\right)\\right]\\right), j=1, \\ldots, N$$\n",
    "\n",
    "Веса нормализуются, чтобы в сумме давать единицу:\n",
    "\n",
    "$$w_i \\leftarrow \\frac{w_i}{\\sum_{j=1}^{N} w_i}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате получаем следующие данные:\n",
    "\n",
    "$x_1$|$x_2$|$x_3$|$y$|Новый вес объекта|Нормализованный вес\n",
    "-|-|-|-|-|-\n",
    "1|1|0|1|0.24|0.29\n",
    "1|1|0|0|0.12|0.14\n",
    "1|0|0|1|0.12|0.14\n",
    "1|1|1|0|0.12|0.14\n",
    "0|1|0|0|0.12|0.14\n",
    "1|0|0|1|0.12|0.14\n",
    "\n",
    "Таким образом, мы смогли рассчитать новые веса выборки. Поскольку сумма весов равняется $0.84$, мы нормализовали веса выборки, разделив каждый вес на $0.84$, чтобы сумма новых весов выборки равнялась $1$.\n",
    "\n",
    "Теперь мы формируем новую выборку такого же объёма с повтором.\n",
    "\n",
    "Обратите внимание, что объект, который был классифицирован неправильно, имеет вес, более чем в два раза превышающий вес других объектов. Это означает, что он с большей вероятностью будет выбран несколько раз, и, таким образом, следующий пень будет больше сосредоточен на правильной классификации неправильно классифицированного образца. В этом и состоит идея AdaBoost."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы классифицировать новую точку, мы узнаём предсказание для неё на каждом пне. Затем количество голосов за каждый класс суммируется, и класс с наибольшим количеством голосов становится меткой нашей точки.\n",
    "\n",
    "Итак, мы разобрались с AdaBoost. Преимущества и недостатки этого алгоритма мы изучали, когда только начинали знакомство ним. Давайте вспомним их ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ГРАДИЕНТНЫЙ БУСТИНГ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переходим к следующему алгоритму, который очень популярен благодаря своей высокой эффективности, — к **градиентному бустингу**.\n",
    "\n",
    "Принцип его работы аналогичен AdaBoost: следующие модели улучшают композицию построенных ранее.\n",
    "\n",
    "Пусть у нас есть некоторая функция потерь $L(y, \\hat{y})$. Она зависит от двух аргументов: $y$  — истинный ответ, $\\hat{y} = a(x)$ — прогноз модели. \n",
    "\n",
    "Для задачи регрессии это может быть, например, квадратичная ошибка\n",
    "\n",
    "$$L(y, \\hat{y})=(y-\\hat{y})^{2},$$\n",
    "\n",
    "а для задачи классификации — логистическая функция потерь (классы определяются как 0 и 1):\n",
    "\n",
    "$$-\\frac{1}{N}\\sum^N_{i=1} = y_i \\cdot\\log{p(y_i)} + (1 - y_i) \\cdot\\log{(1 - p(y_i))},$$\n",
    "\n",
    "где $N$ — количество элементов в выборке, $y_i$ — метка класса, а $p(y_i)$ — предсказанная вероятность этого класса.\n",
    "\n",
    "Пусть к некоторому моменту обучены $K-1$ алгоритмов $a_1 (x), ..., a_{K-1}(x)$, то есть композиция имеет вид:\n",
    "\n",
    "$$f_{K-1}(x)=\\sum_{i=1}^{K-1} a_{i}(x)$$\n",
    "\n",
    "Теперь добавляем в композицию ещё один алгоритм — $a_K (x)$. Этот алгоритм обучается так, чтобы как можно сильнее уменьшить ошибку композиции на обучающей выборке:\n",
    "\n",
    "$$\\sum_{j=1}^{N} L\\left(y_{j}, f_{K-1}\\left(x_{j}\\right)+a_k\\left(x_{j}\\right)\\right) \\rightarrow \\min _{a_k}$$\n",
    "\n",
    "Для того чтобы найти $a_K$, минимизирующее функционал, задачу разбивают на две подзадачи:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. На первом этапе определяем, какие значения $s_1, ..., s_N$ должен принимать алгоритм $a_K (x_j) = s_j$, чтобы на объектах обучающей выборки ошибка была минимальной. Формально это можно представить так:\n",
    "\n",
    "    $$F(s)=\\sum_{j=1}^{N} L\\left(y_{j}, a_{K-1}\\left(x_{j}\\right)+s_{j}\\right) \\rightarrow \\min _{s},$$\n",
    "\n",
    "    где $s = (s_1, ..., s_n)$.\n",
    "\n",
    "    Иными словами, необходимо найти такой вектор сдвигов , который будет минимизировать функцию $F(s)$.\n",
    "\n",
    "    Вы, вероятно, помните, что направление наискорейшего убывания функции — это **антиградиент**, так что берём его в качестве вектора :\n",
    "\n",
    "    $$s=-\\nabla F=\\left[\\begin{array}{c}-L_{\\hat{y}}^{\\prime}\\left(y_{1}, a_{K-1}\\left(x_{1}\\right)\\right) \\\\ -L_{\\hat{y}}^{\\prime}\\left(y_{2}, a_{K-1}\\left(x_{2}\\right)\\right) \\\\ \\vdots \\\\ -L_{\\hat{y}}^{\\prime}\\left(y_{N}, a_{K-1}\\left(x_{N}\\right)\\right)\\end{array}\\right]$$\n",
    "\n",
    "    Компоненты данного вектора — это те значения, которые должен принимать алгоритм $a_K (x)$ на объектах обучающей выборки, чтобы итоговая ошибка композиции была как можно меньше."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Второй этап — построение такого алгоритма $a_K (x)$. По сути, задача построения алгоритма $a_K (x)$ — это обычная задача регрессии на размеченных данных. В данном случае у нас есть обучающая выборка $(x_j, s_j)^N_{j=1}$ — нам просто нужно предсказать значения вектора $s$. Например, используем квадратичную функцию потерь:\n",
    "\n",
    "    $$a_{K}(x)=\\arg \\min _{a} \\frac{1}{N} \\sum_{j=1}^{N}\\left(a\\left(x_{j}\\right)-s_{j}\\right)^{2}$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем последовательность шагов реализации алгоритма, которую можно запрограммировать:\n",
    "\n",
    "1. Инициализируем композицию **GBM (Gradient Boosting Machine)** — $f(x) = a_0 (x)$, то есть добавляем первый базовый алгоритм. Например, можно использовать:\n",
    "\n",
    "    * алгоритм $a_0 (x) = 0$, который всегда возвращает 0 (в задаче регрессии);\n",
    "    * более сложный алгоритм $a_0 (x) = \\frac{1}{N} \\sum_{j=1}^N y_i$, который возвращает средний истинный ответ по всем элементам обучающей выборки (в задаче регрессии);\n",
    "    * алгоритм $a_0 (x) = arg \\ max_{y \\in Y} \\sum_{j=1}^N \\left [y_i = y  \\right ]$, который всегда возвращает метку самого распространённого класса в обучающей выборке (в задаче классификации)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Итеративно повторяем следующие три шага:\n",
    "\n",
    "    2.1. Вычисляем вектор сдвига:\n",
    "\n",
    "    $$s=-\\nabla F=\\left[\\begin{array}{c}-L_{\\hat{y}}^{\\prime}\\left(y_{1}, a_{K-1}\\left(x_{1}\\right)\\right) \\\\ -L_{\\hat{y}}^{\\prime}\\left(y_{2}, a_{K-1}\\left(x_{2}\\right)\\right) \\\\ \\vdots \\\\ -L_{\\hat{y}}^{\\prime}\\left(y_{N}, a_{K-1}\\left(x_{N}\\right)\\right)\\end{array}\\right]$$\n",
    "\n",
    "    2.2. Строим очередной базовый алгоритм $a_K (x)$, который предсказывает вектор-сдвиг:\n",
    "\n",
    "    $$a_{K}(x)=\\arg \\min _{a} \\frac{1}{N} \\sum_{j=1}^{N}\\left(a\\left(x_{j}\\right)-s_{j}\\right)^{2}$$\n",
    "\n",
    "    2.3. Добавляем $a_K (x)$ в композицию:\n",
    "\n",
    "    $$a_{K}(x)=\\sum_{i=1}^{K} a_{i}(x)$$\n",
    "\n",
    "3. Если выполнен критерий остановки, останавливаем итеративный процесс."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте рассмотрим алгоритм на простейшем примере, чтобы лучше усвоить все шаги ↓\n",
    "\n",
    "Пусть мы решаем задачу регрессии для следующих данных:\n",
    "\n",
    "Количество цилиндров|Высота машины|Расположение двигателя|Цена\n",
    "-|-|-|-\n",
    "4|48.8|Спереди|12000\n",
    "6|48.8|Сзади|16500\n",
    "5|52.4|Сзади|15500\n",
    "4|54.3|Спереди|14000\n",
    "\n",
    "Необходимо предсказать стоимость машины на основе её характеристик.\n",
    "\n",
    "Будем решать данную задачу с помощью градиентного бустинга над решающими деревьями.\n",
    "\n",
    "Для начала, в соответствии с описанным выше алгоритмом, нам необходимо инициализировать GBM базовым алгоритмом. Сделаем это с помощью среднего значения целевой переменной."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Количество цилиндров|Высота машины|Расположение двигателя|Цена|Предсказание\n",
    "-|-|-|-|-\n",
    "4|48.8|Спереди|12000|14500\n",
    "6|48.8|Сзади|16500|14500\n",
    "5|52.4|Сзади|15500|14500\n",
    "4|54.3|Спереди|14000|14500\n",
    "\n",
    "Почему именно с помощью среднего значения, а не другого константного? Дело в том, что именно в среднем будет минимальное значение функции потерь. Давайте это докажем.\n",
    "\n",
    "Так как мы решаем задачу регрессии, то возьмём классическую для этого случая метрику MSE:\n",
    "\n",
    "$$L(y, \\ \\hat{y})=\\frac{1}{N} \\sum_{i}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$$\n",
    "\n",
    "Чтобы найти минимум, необходимо найти производную — вам это уже известно из модулей по математическому анализу. Производная:\n",
    "\n",
    "$$\\frac{\\mathrm{dL}}{\\mathrm{d} \\hat{y}}=\\frac{2}{2}\\left(\\sum_{i=0}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)\\right)=-\\sum_{i=0}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)$$\n",
    "\n",
    "Мы видим, что здесь антиградиентом является разница между реальным значением функции и предсказываемым — обычно эту разницу называют **псевдоостатками**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы подставим значения из нашего примера, результат будет следующим:\n",
    "\n",
    "$L=\\frac{1}{2}(12000-\\hat{y})^{2}+\\frac{1}{2}(16500-\\hat{y})^{2}+\\frac{1}{2}(15500-\\hat{y})^{2} +\\frac{1}{2}(14000-\\hat{y})^{2}$\n",
    "\n",
    "$\\frac{d \\mathrm{~L}}{d \\hat{y}}=\\frac{2}{2}(12000-\\hat{y})(-1)+\\frac{2}{2}(16500-\\hat{y})(-1)+\\frac{2}{2}(15500-\\hat{y})(-1)+\\frac{2}{2}(14000-\\hat{y})(-1)$\n",
    "\n",
    "$-(12000-\\hat{y}+16500-\\hat{y}+15500-\\hat{y}+14000-\\hat{y})=0$\n",
    "\n",
    "$(58000-4 \\hat{y})=0$\n",
    "\n",
    "$(58000=4 \\hat{y})$\n",
    "\n",
    "$\\hat{y}=\\frac{58000}{4}=14500$\n",
    "\n",
    "Собственно, мы получили как раз среднее арифметическое.\n",
    "\n",
    "Далее вычисляем псевдоостатки:\n",
    "\n",
    "Количество цилиндров|Высота машины|Расположение двигателя|Цена|Предсказание|Псевдоостатки\n",
    "-|-|-|-|-|-\n",
    "4|48.8|Спереди|12000|14500|-2500\n",
    "6|48.8|Сзади|16500|14500|2000\n",
    "5|52.4|Сзади|15500|14500|1000\n",
    "4|54.3|Спереди|14000|14500|-500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На следующем шаге мы строим регрессионную модель, которая будет предсказывать псевдоостатки.\n",
    "\n",
    "Находим значения для всех листьев нашего дерева решений. Предположим, дерево получилось таким:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/0db9e49a4812a296593c55f4080879b0/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_9.png)\n",
    "\n",
    "Нужно оставить в каждом листе по одному значению, которое будет минимизировать функцию: это либо сам остаток, либо среднее арифметическое чисел, если в листе их несколько.\n",
    "\n",
    "Мы берём именно эти значения, так как нам необходимо минимизировать разницу между реальной ценой и предсказанием. В алгоритме градиентного бустинга выше мы прописывали, что таким образом мы будем строить очередной базовый алгоритм, предсказывающий вектор-сдвиг:\n",
    "\n",
    "$\\hat{y}_{1,1}=\\operatorname{argmin} (12000-(14500+\\hat{y}))^{2}$\n",
    "\n",
    "$\\hat{y}_{1,1}=\\operatorname{argmin} (-2500-\\hat{y})^{2}$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорее всего, из модуля по математическому анализу вы помните, что для того, чтобы найти точку минимума функции, необходимо приравнять значение производной к нулю. Давайте сделаем это:\n",
    "\n",
    "$\\frac{d}{d \\hat{y}}(-2500-\\hat{y})^{2}=0$\n",
    "\n",
    "$-2500-\\hat{y}=0$\n",
    "\n",
    "$\\hat{y}=-2500$\n",
    "\n",
    "Для второго листа:\n",
    "\n",
    "$\\hat{y}_{2,1}=\\operatorname{argmin}\\left[(16500-(14500+\\hat{y}))^{2}+(15500-(14500+\\hat{y}))^{2}\\right]$\n",
    "\n",
    "$\\hat{y}_{2,1}=\\operatorname{argmin}\\left[(2000-\\hat{y})^{2}+(1000-\\hat{y})^{2}\\right]$\n",
    "\n",
    "$\\frac{d}{d \\hat{y}}\\left[(2000-\\hat{y})^{2}+\\left(1000-\\hat{y}^{2}\\right)]=0\\right.$\n",
    "\n",
    "$2000-\\hat{y}+1000-\\hat{y}=0$\n",
    "\n",
    "$3000-2 \\hat{y}=0$\n",
    "\n",
    "$\\frac{3000}{2}=\\hat{y}$\n",
    "\n",
    "$\\hat{y}=1500$\n",
    "\n",
    "Для третьего листа:\n",
    "\n",
    "$\\hat{y}_{1,1}=\\operatorname{argmin}(12000-(14500+\\hat{y}))^{2}$\n",
    "\n",
    "$\\hat{y}_{1,1}=\\operatorname{argmin}(-2500-\\hat{y})^{2}$\n",
    "\n",
    "$\\frac{d}{d \\hat{y}}(-500-\\hat{y})^{2}=0$\n",
    "\n",
    "$-500-\\hat{y}=0$\n",
    "\n",
    "$\\hat{y}=-500$\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/55a12b9fa4d472289f424bdb26ad3b3d/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_10.png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, наконец, обновляем нашу модель:\n",
    "\n",
    "$$f_{K+1}(x)=f_{K}(x)+\\eta a(x)$$\n",
    "\n",
    "За $\\eta$ здесь обозначен темп обучения.\n",
    "\n",
    "По сути, у нас получился уже известный вам алгоритм градиентного спуска, который реализован в пространстве ответов ансамбля.\n",
    "\n",
    "Схематично это можно изобразить так:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/2fa7917df7e177193de3ca54693780d7/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_11.png)\n",
    "\n",
    "Далее мы продолжаем повторять аналогичную процедуру, достраивая новые деревья в модель.\n",
    "\n",
    "Но прежде чем закончить с этим примером, давайте сделаем предсказание хотя бы на такой простой модели. Пусть у нас есть автомобиль, высота которого — 49 и у которого 6 цилиндров. В таком случае мы получаем подходящее для нас значение $\\hat{y}_{2,1} = 1500$ и вычисляем предсказание цены:\n",
    "\n",
    "$Цена = 14500 + 0.1*1500 = 14500 + 150 = 14650$\n",
    "\n",
    "Но, конечно, это лишь промежуточный результат. В реальности, чтобы прогноз был как можно точнее, должно было бы быть построено ещё много деревьев."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним изученные ранее **плюсы** и **минусы** бустинга:\n",
    "\n",
    "### Плюсы\n",
    "\n",
    "* модели обучаются последовательно, уточняя друг друга;\n",
    "* снижается смещение;\n",
    "* базовые модели — неглубокие деревья.\n",
    "\n",
    "### Минусы\n",
    "\n",
    "* вычисление плохо параллелится;\n",
    "* плохо интерпретируемые результаты."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST И CATBOOST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы разобрались с градиентным бустингом, необходимо также упомянуть о двух его популярных на данный момент вариациях — XGBoost и CatBoost.\n",
    "\n",
    "> **XGBoost** — одна из самых эффективных реализаций алгоритма Gradient Boosted Trees. Название XGBoost расшифровывается  как eXtreme Gradient Boosting. XGBoost — это улучшение GBM через системную оптимизацию и усовершенствование алгоритма.\n",
    "\n",
    "У XGBoost есть ряд существенных улучшений по сравнению с классической реализацией градиентного бустинга:\n",
    "\n",
    "* Регуляризация\n",
    "\n",
    "    В алгоритме XGBoost есть встроенные L1- и L2-регуляризации, которые предотвращают переобучение. Из-за этого XGBoost ещё иногда называют регуляризованным GBM.\n",
    "\n",
    "* Параллелизация вычислений\n",
    "\n",
    "    XGBoost использует параллельные вычисления, поэтому он работает быстрее, чем классический GBM.\n",
    "\n",
    "* Работа с разреженными данными\n",
    "\n",
    "    В алгоритме XGBoost есть встроенная возможность для обработки пропусков: при встрече с пропущенным значением алгоритм пробует различные варианты разделения и ищет оптимальное.\n",
    "\n",
    "* Кросс-валидация\n",
    "\n",
    "    XGBoost позволяет реализовывать кросс-валидацию на каждой итерации алгоритма.\n",
    "\n",
    "* Эффективная обрезка деревьев\n",
    "\n",
    "    XGBoost использует для обрезки более совершенный с точки зрения вычислительной производительности алгоритм.\n",
    "\n",
    "* Аппаратная оптимизация\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **CatBoost** — это библиотека градиентного бустинга, созданная Яндексом. Её особенность заключается в том, что в ней используются так называемые **небрежные (oblivious) деревья решений**, чтобы «вырастить» сбалансированное дерево.\n",
    "\n",
    "**Небрежные деревья** — это такие деревья, в которых одни и те же функции используются для левого и правого разбиения на одном уровне дерева:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/0f1a19adbbed589bcfa56a0bb865ca48/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_5_12.png)\n",
    "\n",
    "Одно из **главных преимуществ** CatBoost заключается в том, что его можно использовать для данных, где категориальные признаки заранее не были преобразованы.\n",
    "\n",
    "Подробнее узнать о CatBoost можно в [видеопрезентации Яндекса](https://youtu.be/UYDwhuyWYSo).\n",
    "\n",
    "Итак, мы разобрались с очень важным видом ансамблей — бустингом и рассмотрели несколько его моделей:\n",
    "\n",
    "* AdaBoost — самый простой вариант бустинга;\n",
    "* GBM — классический градиентный бустинг;\n",
    "* XGBoost — улучшенная версия градиентного бустинга;\n",
    "* CatBoost — улучшенная версия градиентного бустинга, адаптированная для работы с категориальными переменными.\n",
    "\n",
    "Уже в следующем юните мы отработаем полученные знания на практике →"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Бустинг. Практика"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущем юните мы разобрали ансамблевый метод под названием бустинг, а также рассмотрели различные его вариации. В этом юните мы решим практический кейс с использованием данного алгоритма, а также сравним изученные модификации бустинга.\n",
    "\n",
    "Мы будем работать c [данными](https://lms.skillfactory.ru/assets/courseware/v1/2dacbfb3d37387d2c3f028ed05c65589/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/AirPass.zip), которые содержат результаты опроса клиентов авиакомпании по поводу их удовлетворённости полётом.\n",
    "\n",
    "Нашей задачей будет предсказать удовлетворённость пассажиров.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/053f0cc25cadef1d709cd4a309bc363c/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_6_1.jpg)\n",
    "\n",
    "Признаки в данных:\n",
    "\n",
    "* Gender — пол пассажира (женский, мужской);\n",
    "* Customer Type — тип клиента (постоянный/непостоянный клиент);\n",
    "* Age — возраст клиента;\n",
    "* Type of Travel — цель перелета (личная/деловая поездка);\n",
    "* Class — туристический класс пассажира (Business, Eco, Eco Plus);\n",
    "* Flight distance — расстояние полета;\n",
    "* Inflight wifi service — уровень удовлетворённости Wi-Fi (0 — не * применимо, 1–5);\n",
    "* Departure/Arrival time convenient — уровень удовлетворённости временем * отправления и прибытия;\n",
    "* Ease of Online booking — уровень удовлетворённости * онлайн-бронированием;\n",
    "* Gate location — уровень удовлетворённости расположением выхода на * посадку;\n",
    "* Food and drink — уровень удовлетворённости едой и напитками;\n",
    "* Online boarding — уровень удовлетворённости онлайн-регистрацией;\n",
    "* Seat comfort — уровень удовлетворённости комфортом сидений;\n",
    "* Inflight entertainment — уровень удовлетворённости развлечениями на борту;\n",
    "* On-board service — уровень удовлетворённости сервисом на борту;\n",
    "* Leg room service — уровень удовлетворённости местом для ног;\n",
    "* Baggage handling — уровень удовлетворённости обработкой багажа;\n",
    "* Check-in service — уровень удовлетворённости услугами регистрации;\n",
    "* Inflight service — уровень удовлетворённости обслуживанием во время полёта;\n",
    "* Cleanliness — уровень удовлетворённости чистотой;\n",
    "* Departure Delay in Minutes — задержка при отправлении (в минутах);\n",
    "* Arrival Delay in Minutes — задержка при прибытии (в минутах);\n",
    "* Satisfaction — удовлетворённость авиакомпанией — целевая переменная (satisfaction/neutral/dissatisfaction).\n",
    "\n",
    "Перед тем как выполнить задания, вам необходимо установить несколько библиотек (если они у вас не установлены):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !conda install -c conda-forge py-xgboost\n",
    "# !conda install catboost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внимание! Если при открытии данных первый столбец (порядковый номер строки) считался как отдельный признак, удалите его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>...</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Inflight service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70172</td>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>13</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco Plus</td>\n",
       "      <td>460</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>18.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5047</td>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110028</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>26</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24026</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>562</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119299</td>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>61</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Gender      Customer Type  Age   Type of Travel     Class  \\\n",
       "0   70172    Male     Loyal Customer   13  Personal Travel  Eco Plus   \n",
       "1    5047    Male  disloyal Customer   25  Business travel  Business   \n",
       "2  110028  Female     Loyal Customer   26  Business travel  Business   \n",
       "3   24026  Female     Loyal Customer   25  Business travel  Business   \n",
       "4  119299    Male     Loyal Customer   61  Business travel  Business   \n",
       "\n",
       "   Flight Distance  Inflight wifi service  Departure/Arrival time convenient  \\\n",
       "0              460                      3                                  4   \n",
       "1              235                      3                                  2   \n",
       "2             1142                      2                                  2   \n",
       "3              562                      2                                  5   \n",
       "4              214                      3                                  3   \n",
       "\n",
       "   Ease of Online booking  ...  Inflight entertainment  On-board service  \\\n",
       "0                       3  ...                       5                 4   \n",
       "1                       3  ...                       1                 1   \n",
       "2                       2  ...                       5                 4   \n",
       "3                       5  ...                       2                 2   \n",
       "4                       3  ...                       3                 3   \n",
       "\n",
       "   Leg room service  Baggage handling  Checkin service  Inflight service  \\\n",
       "0                 3                 4                4                 5   \n",
       "1                 5                 3                1                 4   \n",
       "2                 3                 4                4                 4   \n",
       "3                 5                 3                1                 4   \n",
       "4                 4                 4                3                 3   \n",
       "\n",
       "   Cleanliness  Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
       "0            5                          25                      18.0   \n",
       "1            1                           1                       6.0   \n",
       "2            5                           0                       0.0   \n",
       "3            2                          11                       9.0   \n",
       "4            3                           0                       0.0   \n",
       "\n",
       "              satisfaction  \n",
       "0  neutral or dissatisfied  \n",
       "1  neutral or dissatisfied  \n",
       "2                satisfied  \n",
       "3  neutral or dissatisfied  \n",
       "4                satisfied  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/AirPass.zip').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.1\n",
    "\n",
    "Для начала сделаем небольшую предобработку данных. Сколько всего в данных пропущенных значений?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                     0\n",
       "Gender                                 0\n",
       "Customer Type                          0\n",
       "Age                                    0\n",
       "Type of Travel                         0\n",
       "Class                                  0\n",
       "Flight Distance                        0\n",
       "Inflight wifi service                  0\n",
       "Departure/Arrival time convenient      0\n",
       "Ease of Online booking                 0\n",
       "Gate location                          0\n",
       "Food and drink                         0\n",
       "Online boarding                        0\n",
       "Seat comfort                           0\n",
       "Inflight entertainment                 0\n",
       "On-board service                       0\n",
       "Leg room service                       0\n",
       "Baggage handling                       0\n",
       "Checkin service                        0\n",
       "Inflight service                       0\n",
       "Cleanliness                            0\n",
       "Departure Delay in Minutes             0\n",
       "Arrival Delay in Minutes             310\n",
       "satisfaction                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.2\n",
    "\n",
    "Теперь давайте избавимся от найденных пропусков. Заполните их все медианными значениями. После этого вычислите среднее арифметическое для признака, отражающего задержку при прибытии в минутах. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.13"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna({\n",
    "    'Arrival Delay in Minutes': data['Arrival Delay in Minutes'].median()\n",
    "})\n",
    "\n",
    "round(data['Arrival Delay in Minutes'].mean(), 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.3\n",
    "\n",
    "Проведём небольшой разведывательный анализ. Посмотрим, в каких категориях пассажиров превалировали удовлетворённые полетом клиенты.\n",
    "\n",
    "Совет: для ответов на вопросы попробуйте использовать как вычисления, так и визуализации.\n",
    "\n",
    "1. Сравните удовлетворённость полётом мужчин и женщин. Выберите верное утверждение:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender  satisfaction           \n",
       "Female  neutral or dissatisfied    30193\n",
       "        satisfied                  22534\n",
       "Male    neutral or dissatisfied    28686\n",
       "        satisfied                  22491\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satisfaction = data.groupby(\n",
    "    by=['Gender', 'satisfaction']\n",
    "    ).count()['id']\n",
    "\n",
    "satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "satisfaction.plot(\n",
    "    kind='barh', \n",
    "    title='Gender/Satisfaction diagramm'  \n",
    "    \n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Теперь сравним категории пассажиров в зависимости от их цели поездки. Выберите все верные утверждения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type of Travel   satisfaction           \n",
       "Business travel  neutral or dissatisfied    29909\n",
       "                 satisfied                  41746\n",
       "Personal Travel  neutral or dissatisfied    28970\n",
       "                 satisfied                   3279\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_of_travel = data.groupby(\n",
    "    by=['Type of Travel', 'satisfaction']\n",
    "    ).count()['id']\n",
    "\n",
    "type_of_travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_of_travel.plot(\n",
    "    kind='barh', \n",
    "    title='Type of Travel/satisfaction diagramm',\n",
    "    );"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. В каком туристическом классе наибольший процент довольных клиентов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_sat = data.pivot_table(\n",
    "    values='id',\n",
    "    index='Class',\n",
    "    columns='satisfaction',\n",
    "    aggfunc='count'\n",
    ")\n",
    "\n",
    "class_sat['Percentage'] = class_sat['satisfied']/(class_sat['satisfied']+class_sat['neutral or dissatisfied'])*100\n",
    "\n",
    "class_sat_per = class_sat.sort_values('Percentage').drop(columns=['neutral or dissatisfied', 'satisfied'])\n",
    "\n",
    "class_sat_per.plot(\n",
    "    kind='barh', \n",
    "    title='Class/satisfaction diagramm',\n",
    "    );\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перекодируем часть бинарных признаков, чтобы использовать их при обучении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['satisfaction'] = df['satisfaction'].map({'neutral or dissatisfied':0 , 'satisfied':1})\n",
    "df['Customer Type'] = df['Customer Type'].map({'Loyal Customer':1, 'disloyal Customer':0})\n",
    "df['Type of Travel'] = df['Type of Travel'].map({'Personal Travel':0, 'Business travel':1})\n",
    "df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.4\n",
    "\n",
    "Для остальных категориальных признаков создайте dummy-переменные. Сделайте это с помощью функции get_dummies() из библиотеки Pandas, параметры не меняйте. Сколько теперь признаков в данных (включая целевую переменную)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['Class'])\n",
    "\n",
    "df.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.5\n",
    "\n",
    "Мы практически добрались до обучения модели. Разбейте данные на обучающую и тестовую выборки в соотношении 80/20, параметр random_state = 26. Сколько наблюдений попало в тестовую выборку?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20781"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['satisfaction'])\n",
    "y = df['satisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=26)\n",
    "\n",
    "X_test.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.6\n",
    "\n",
    "Теперь нам необходимо реализовать масштабирование данных. Для этого обучите на обучающей выборке метод StandardScaler() и с помощью него преобразуйте и обучающую, и тестовую выборки. Не забудьте, что целевую переменную обрабатывать не нужно.\n",
    "\n",
    "Примечание. Отметим, что если бы дальше мы работали только с деревьями, масштабирование бы не требовалось. Однако мы реализуем его, чтобы можно было обучать и другие модели и сравнивать полученные результаты.\n",
    "\n",
    "В качестве ответа введите самое первое значение из матрицы преобразованных признаков тестовой выборки. Округлите значение до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train) \n",
    "X_test = scaler.transform(X_test) \n",
    "X_test[0][0].round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.7\n",
    "\n",
    "Перейдём к обучению моделей. В качестве первой модели возьмём самую простую — логистическую регрессию. Мы делаем это для того, чтобы потом сравнивать с ней полученные результаты: так вы сможете выяснить, насколько ансамбли смогут улучшить точность прогноза.\n",
    "\n",
    "Обучите логистическую регрессию с параметрами по умолчанию на наших данных. В качестве ответа введите значение метрики f1_score. Ответ округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression F1 score: 0.855\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('LogisticRegression F1 score: {:.3f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.8\n",
    "\n",
    "Теперь перейдём к бустингу. Начнём с обучения первой модели — AdaBoost. В качестве базовой модели для неё возьмите решающее дерево с параметром random_state = 26.\n",
    "\n",
    "Обучите AdaBoost, зафиксировав random_state со значением 26 и задав темп обучения 0.01. В качестве ответа введите значение метрики f1_score. Ответ округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost f1-score: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(\n",
    "    base_estimator=tree.DecisionTreeClassifier(\n",
    "        random_state=26\n",
    "    ),\n",
    "    learning_rate=0.01,\n",
    "    random_state=26\n",
    ")\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "print('AdaBoost f1-score: {:.3}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.9\n",
    "\n",
    "Перейдем к следующему алгоритму — градиентному бустингу.\n",
    "\n",
    "Будем настраивать количество деревьев и темп обучения, делая перебор по следующей сетке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"n_estimators\":2**np.arange(8), \n",
    "          \"learning_rate\":0.1**np.arange(3)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте для поиска оптимальных параметров GridSearchCV, а для ускорения работы алгоритма задайте параметр кросс-валидации, равный 3.\n",
    "\n",
    "Какое наибольшее значение метрики f1_score получилось? Ответ округлите до трёх знаков после точки-разделителя.\n",
    "\n",
    "Примечание. Необходимо указать лучший результат в методе GridSearchCV на тренировочных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch GradientBoosting f1-score: 0.951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gs = GridSearchCV(cv=3,\n",
    "                  estimator=GradientBoostingClassifier(\n",
    "                      random_state=26),\n",
    "                  param_grid=params,\n",
    "                  \n",
    "                  )\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "print('GridSearch GradientBoosting f1-score: {:.3f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.10\n",
    "\n",
    "Обучите алгоритм XGBoost. Так как он достаточно мощный «из коробки», определите его с параметрами по умолчанию, только задайте random_state = 26. Какое значение метрики f1_score получилось? Ответ округлите до трёх знаков после точки-разделителя.\n",
    "\n",
    "Подсказка. Для того чтобы обучить алгоритм XGBoost для решения задачи классификации, вам понадобится XGBClassifier из библиотеки xgboost, установленной ранее. Вся дальнейшая последовательность действий (обучение модели, предсказание, оценка качества) идентична другим алгоритмам, например логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    random_state=26\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "print('XGBClassifier f1-score: {:.3f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.11\n",
    "\n",
    "Обучите алгоритм CatBoost. Как и XGBoost, будем обучать его с настройками по умолчанию и заданным random_state = 26. Какое значение метрики f1_score получилось? Ответ округлите до трёх знаков после точки-разделителя.\n",
    "\n",
    "Подсказка. Для того чтобы обучить алгоритм CatBoost, вам понадобится CatBoostClassifier() из библиотеки catboost, установленной ранее. Вся дальнейшая последовательность действий (обучение модели, предсказание, оценка качества) идентична другим алгоритмам, например логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.068023\n",
      "0:\tlearn: 0.6018254\ttotal: 247ms\tremaining: 4m 6s\n",
      "1:\tlearn: 0.5020788\ttotal: 518ms\tremaining: 4m 18s\n",
      "2:\tlearn: 0.4472506\ttotal: 938ms\tremaining: 5m 11s\n",
      "3:\tlearn: 0.4028683\ttotal: 1.2s\tremaining: 4m 57s\n",
      "4:\tlearn: 0.3674742\ttotal: 1.36s\tremaining: 4m 31s\n",
      "5:\tlearn: 0.3397838\ttotal: 1.45s\tremaining: 4m\n",
      "6:\tlearn: 0.3121236\ttotal: 1.57s\tremaining: 3m 43s\n",
      "7:\tlearn: 0.2917493\ttotal: 1.73s\tremaining: 3m 34s\n",
      "8:\tlearn: 0.2749031\ttotal: 1.84s\tremaining: 3m 22s\n",
      "9:\tlearn: 0.2575194\ttotal: 1.94s\tremaining: 3m 11s\n",
      "10:\tlearn: 0.2473688\ttotal: 2.02s\tremaining: 3m 1s\n",
      "11:\tlearn: 0.2377536\ttotal: 2.1s\tremaining: 2m 53s\n",
      "12:\tlearn: 0.2279307\ttotal: 2.22s\tremaining: 2m 48s\n",
      "13:\tlearn: 0.2212511\ttotal: 2.3s\tremaining: 2m 42s\n",
      "14:\tlearn: 0.2100355\ttotal: 2.38s\tremaining: 2m 36s\n",
      "15:\tlearn: 0.2025734\ttotal: 2.44s\tremaining: 2m 30s\n",
      "16:\tlearn: 0.1942301\ttotal: 2.49s\tremaining: 2m 23s\n",
      "17:\tlearn: 0.1877938\ttotal: 2.55s\tremaining: 2m 19s\n",
      "18:\tlearn: 0.1832382\ttotal: 2.64s\tremaining: 2m 16s\n",
      "19:\tlearn: 0.1797364\ttotal: 2.69s\tremaining: 2m 11s\n",
      "20:\tlearn: 0.1766271\ttotal: 2.75s\tremaining: 2m 8s\n",
      "21:\tlearn: 0.1724834\ttotal: 2.83s\tremaining: 2m 5s\n",
      "22:\tlearn: 0.1681076\ttotal: 2.96s\tremaining: 2m 5s\n",
      "23:\tlearn: 0.1659677\ttotal: 3.07s\tremaining: 2m 4s\n",
      "24:\tlearn: 0.1636305\ttotal: 3.12s\tremaining: 2m 1s\n",
      "25:\tlearn: 0.1615296\ttotal: 3.19s\tremaining: 1m 59s\n",
      "26:\tlearn: 0.1591234\ttotal: 3.25s\tremaining: 1m 57s\n",
      "27:\tlearn: 0.1572188\ttotal: 3.41s\tremaining: 1m 58s\n",
      "28:\tlearn: 0.1557159\ttotal: 3.54s\tremaining: 1m 58s\n",
      "29:\tlearn: 0.1541992\ttotal: 3.6s\tremaining: 1m 56s\n",
      "30:\tlearn: 0.1527118\ttotal: 3.67s\tremaining: 1m 54s\n",
      "31:\tlearn: 0.1511750\ttotal: 3.75s\tremaining: 1m 53s\n",
      "32:\tlearn: 0.1495155\ttotal: 3.83s\tremaining: 1m 52s\n",
      "33:\tlearn: 0.1482199\ttotal: 3.9s\tremaining: 1m 50s\n",
      "34:\tlearn: 0.1447921\ttotal: 3.96s\tremaining: 1m 49s\n",
      "35:\tlearn: 0.1437618\ttotal: 4.04s\tremaining: 1m 48s\n",
      "36:\tlearn: 0.1428308\ttotal: 4.13s\tremaining: 1m 47s\n",
      "37:\tlearn: 0.1418337\ttotal: 4.27s\tremaining: 1m 48s\n",
      "38:\tlearn: 0.1405886\ttotal: 4.39s\tremaining: 1m 48s\n",
      "39:\tlearn: 0.1393058\ttotal: 4.44s\tremaining: 1m 46s\n",
      "40:\tlearn: 0.1385384\ttotal: 4.49s\tremaining: 1m 45s\n",
      "41:\tlearn: 0.1375509\ttotal: 4.55s\tremaining: 1m 43s\n",
      "42:\tlearn: 0.1359835\ttotal: 4.6s\tremaining: 1m 42s\n",
      "43:\tlearn: 0.1347066\ttotal: 4.65s\tremaining: 1m 41s\n",
      "44:\tlearn: 0.1327071\ttotal: 4.71s\tremaining: 1m 40s\n",
      "45:\tlearn: 0.1316579\ttotal: 4.81s\tremaining: 1m 39s\n",
      "46:\tlearn: 0.1304422\ttotal: 4.87s\tremaining: 1m 38s\n",
      "47:\tlearn: 0.1299834\ttotal: 4.92s\tremaining: 1m 37s\n",
      "48:\tlearn: 0.1295421\ttotal: 4.97s\tremaining: 1m 36s\n",
      "49:\tlearn: 0.1290790\ttotal: 5.03s\tremaining: 1m 35s\n",
      "50:\tlearn: 0.1285284\ttotal: 5.08s\tremaining: 1m 34s\n",
      "51:\tlearn: 0.1280241\ttotal: 5.13s\tremaining: 1m 33s\n",
      "52:\tlearn: 0.1272418\ttotal: 5.17s\tremaining: 1m 32s\n",
      "53:\tlearn: 0.1265524\ttotal: 5.24s\tremaining: 1m 31s\n",
      "54:\tlearn: 0.1258800\ttotal: 5.29s\tremaining: 1m 30s\n",
      "55:\tlearn: 0.1248606\ttotal: 5.34s\tremaining: 1m 30s\n",
      "56:\tlearn: 0.1242195\ttotal: 5.42s\tremaining: 1m 29s\n",
      "57:\tlearn: 0.1240465\ttotal: 5.48s\tremaining: 1m 29s\n",
      "58:\tlearn: 0.1227505\ttotal: 5.56s\tremaining: 1m 28s\n",
      "59:\tlearn: 0.1219310\ttotal: 5.61s\tremaining: 1m 27s\n",
      "60:\tlearn: 0.1214669\ttotal: 5.67s\tremaining: 1m 27s\n",
      "61:\tlearn: 0.1209628\ttotal: 5.75s\tremaining: 1m 26s\n",
      "62:\tlearn: 0.1204270\ttotal: 5.81s\tremaining: 1m 26s\n",
      "63:\tlearn: 0.1197952\ttotal: 5.86s\tremaining: 1m 25s\n",
      "64:\tlearn: 0.1188690\ttotal: 5.92s\tremaining: 1m 25s\n",
      "65:\tlearn: 0.1179641\ttotal: 5.98s\tremaining: 1m 24s\n",
      "66:\tlearn: 0.1175382\ttotal: 6.04s\tremaining: 1m 24s\n",
      "67:\tlearn: 0.1170936\ttotal: 6.1s\tremaining: 1m 23s\n",
      "68:\tlearn: 0.1167482\ttotal: 6.16s\tremaining: 1m 23s\n",
      "69:\tlearn: 0.1164256\ttotal: 6.33s\tremaining: 1m 24s\n",
      "70:\tlearn: 0.1161023\ttotal: 6.41s\tremaining: 1m 23s\n",
      "71:\tlearn: 0.1154266\ttotal: 6.46s\tremaining: 1m 23s\n",
      "72:\tlearn: 0.1143862\ttotal: 6.53s\tremaining: 1m 22s\n",
      "73:\tlearn: 0.1141024\ttotal: 6.61s\tremaining: 1m 22s\n",
      "74:\tlearn: 0.1138525\ttotal: 6.73s\tremaining: 1m 23s\n",
      "75:\tlearn: 0.1134943\ttotal: 6.79s\tremaining: 1m 22s\n",
      "76:\tlearn: 0.1132630\ttotal: 6.83s\tremaining: 1m 21s\n",
      "77:\tlearn: 0.1129337\ttotal: 6.89s\tremaining: 1m 21s\n",
      "78:\tlearn: 0.1123692\ttotal: 6.95s\tremaining: 1m 20s\n",
      "79:\tlearn: 0.1120446\ttotal: 7s\tremaining: 1m 20s\n",
      "80:\tlearn: 0.1117097\ttotal: 7.05s\tremaining: 1m 20s\n",
      "81:\tlearn: 0.1108358\ttotal: 7.12s\tremaining: 1m 19s\n",
      "82:\tlearn: 0.1102778\ttotal: 7.17s\tremaining: 1m 19s\n",
      "83:\tlearn: 0.1099572\ttotal: 7.22s\tremaining: 1m 18s\n",
      "84:\tlearn: 0.1098577\ttotal: 7.27s\tremaining: 1m 18s\n",
      "85:\tlearn: 0.1092686\ttotal: 7.34s\tremaining: 1m 18s\n",
      "86:\tlearn: 0.1090128\ttotal: 7.39s\tremaining: 1m 17s\n",
      "87:\tlearn: 0.1087985\ttotal: 7.43s\tremaining: 1m 17s\n",
      "88:\tlearn: 0.1081520\ttotal: 7.49s\tremaining: 1m 16s\n",
      "89:\tlearn: 0.1079693\ttotal: 7.56s\tremaining: 1m 16s\n",
      "90:\tlearn: 0.1077514\ttotal: 7.61s\tremaining: 1m 16s\n",
      "91:\tlearn: 0.1075283\ttotal: 7.66s\tremaining: 1m 15s\n",
      "92:\tlearn: 0.1071405\ttotal: 7.72s\tremaining: 1m 15s\n",
      "93:\tlearn: 0.1070247\ttotal: 7.77s\tremaining: 1m 14s\n",
      "94:\tlearn: 0.1068192\ttotal: 7.83s\tremaining: 1m 14s\n",
      "95:\tlearn: 0.1064461\ttotal: 7.9s\tremaining: 1m 14s\n",
      "96:\tlearn: 0.1059301\ttotal: 7.97s\tremaining: 1m 14s\n",
      "97:\tlearn: 0.1056716\ttotal: 8.06s\tremaining: 1m 14s\n",
      "98:\tlearn: 0.1054190\ttotal: 8.11s\tremaining: 1m 13s\n",
      "99:\tlearn: 0.1051352\ttotal: 8.16s\tremaining: 1m 13s\n",
      "100:\tlearn: 0.1047668\ttotal: 8.21s\tremaining: 1m 13s\n",
      "101:\tlearn: 0.1044767\ttotal: 8.26s\tremaining: 1m 12s\n",
      "102:\tlearn: 0.1041726\ttotal: 8.32s\tremaining: 1m 12s\n",
      "103:\tlearn: 0.1039212\ttotal: 8.38s\tremaining: 1m 12s\n",
      "104:\tlearn: 0.1034243\ttotal: 8.43s\tremaining: 1m 11s\n",
      "105:\tlearn: 0.1032076\ttotal: 8.49s\tremaining: 1m 11s\n",
      "106:\tlearn: 0.1030340\ttotal: 8.55s\tremaining: 1m 11s\n",
      "107:\tlearn: 0.1025610\ttotal: 8.6s\tremaining: 1m 11s\n",
      "108:\tlearn: 0.1022939\ttotal: 8.66s\tremaining: 1m 10s\n",
      "109:\tlearn: 0.1021190\ttotal: 8.72s\tremaining: 1m 10s\n",
      "110:\tlearn: 0.1017958\ttotal: 8.77s\tremaining: 1m 10s\n",
      "111:\tlearn: 0.1015855\ttotal: 8.83s\tremaining: 1m 9s\n",
      "112:\tlearn: 0.1011752\ttotal: 8.88s\tremaining: 1m 9s\n",
      "113:\tlearn: 0.1008759\ttotal: 8.93s\tremaining: 1m 9s\n",
      "114:\tlearn: 0.1006960\ttotal: 8.99s\tremaining: 1m 9s\n",
      "115:\tlearn: 0.1005649\ttotal: 9.04s\tremaining: 1m 8s\n",
      "116:\tlearn: 0.1003043\ttotal: 9.09s\tremaining: 1m 8s\n",
      "117:\tlearn: 0.1000931\ttotal: 9.14s\tremaining: 1m 8s\n",
      "118:\tlearn: 0.0999173\ttotal: 9.2s\tremaining: 1m 8s\n",
      "119:\tlearn: 0.0995890\ttotal: 9.27s\tremaining: 1m 7s\n",
      "120:\tlearn: 0.0992166\ttotal: 9.32s\tremaining: 1m 7s\n",
      "121:\tlearn: 0.0991357\ttotal: 9.38s\tremaining: 1m 7s\n",
      "122:\tlearn: 0.0990491\ttotal: 9.46s\tremaining: 1m 7s\n",
      "123:\tlearn: 0.0988977\ttotal: 9.67s\tremaining: 1m 8s\n",
      "124:\tlearn: 0.0987814\ttotal: 9.72s\tremaining: 1m 8s\n",
      "125:\tlearn: 0.0982177\ttotal: 9.78s\tremaining: 1m 7s\n",
      "126:\tlearn: 0.0979959\ttotal: 9.83s\tremaining: 1m 7s\n",
      "127:\tlearn: 0.0975458\ttotal: 9.93s\tremaining: 1m 7s\n",
      "128:\tlearn: 0.0973966\ttotal: 10s\tremaining: 1m 7s\n",
      "129:\tlearn: 0.0971498\ttotal: 10.1s\tremaining: 1m 7s\n",
      "130:\tlearn: 0.0969599\ttotal: 10.1s\tremaining: 1m 7s\n",
      "131:\tlearn: 0.0968171\ttotal: 10.2s\tremaining: 1m 6s\n",
      "132:\tlearn: 0.0966655\ttotal: 10.2s\tremaining: 1m 6s\n",
      "133:\tlearn: 0.0965935\ttotal: 10.3s\tremaining: 1m 6s\n",
      "134:\tlearn: 0.0965290\ttotal: 10.3s\tremaining: 1m 6s\n",
      "135:\tlearn: 0.0963293\ttotal: 10.4s\tremaining: 1m 5s\n",
      "136:\tlearn: 0.0962325\ttotal: 10.4s\tremaining: 1m 5s\n",
      "137:\tlearn: 0.0960271\ttotal: 10.5s\tremaining: 1m 5s\n",
      "138:\tlearn: 0.0957716\ttotal: 10.5s\tremaining: 1m 5s\n",
      "139:\tlearn: 0.0956518\ttotal: 10.6s\tremaining: 1m 5s\n",
      "140:\tlearn: 0.0954566\ttotal: 10.7s\tremaining: 1m 4s\n",
      "141:\tlearn: 0.0952811\ttotal: 10.7s\tremaining: 1m 4s\n",
      "142:\tlearn: 0.0951754\ttotal: 10.8s\tremaining: 1m 4s\n",
      "143:\tlearn: 0.0950737\ttotal: 10.8s\tremaining: 1m 4s\n",
      "144:\tlearn: 0.0948309\ttotal: 10.9s\tremaining: 1m 4s\n",
      "145:\tlearn: 0.0947879\ttotal: 10.9s\tremaining: 1m 4s\n",
      "146:\tlearn: 0.0942155\ttotal: 11s\tremaining: 1m 3s\n",
      "147:\tlearn: 0.0940962\ttotal: 11.1s\tremaining: 1m 3s\n",
      "148:\tlearn: 0.0939183\ttotal: 11.1s\tremaining: 1m 3s\n",
      "149:\tlearn: 0.0937728\ttotal: 11.2s\tremaining: 1m 3s\n",
      "150:\tlearn: 0.0935927\ttotal: 11.2s\tremaining: 1m 3s\n",
      "151:\tlearn: 0.0935436\ttotal: 11.3s\tremaining: 1m 2s\n",
      "152:\tlearn: 0.0931701\ttotal: 11.3s\tremaining: 1m 2s\n",
      "153:\tlearn: 0.0929398\ttotal: 11.4s\tremaining: 1m 2s\n",
      "154:\tlearn: 0.0928262\ttotal: 11.4s\tremaining: 1m 2s\n",
      "155:\tlearn: 0.0926362\ttotal: 11.5s\tremaining: 1m 2s\n",
      "156:\tlearn: 0.0923514\ttotal: 11.5s\tremaining: 1m 1s\n",
      "157:\tlearn: 0.0922529\ttotal: 11.6s\tremaining: 1m 1s\n",
      "158:\tlearn: 0.0921441\ttotal: 11.6s\tremaining: 1m 1s\n",
      "159:\tlearn: 0.0920109\ttotal: 11.7s\tremaining: 1m 1s\n",
      "160:\tlearn: 0.0918072\ttotal: 11.7s\tremaining: 1m 1s\n",
      "161:\tlearn: 0.0917630\ttotal: 11.8s\tremaining: 1m\n",
      "162:\tlearn: 0.0916563\ttotal: 11.8s\tremaining: 1m\n",
      "163:\tlearn: 0.0915352\ttotal: 11.9s\tremaining: 1m\n",
      "164:\tlearn: 0.0913332\ttotal: 11.9s\tremaining: 1m\n",
      "165:\tlearn: 0.0911235\ttotal: 12s\tremaining: 1m\n",
      "166:\tlearn: 0.0909360\ttotal: 12s\tremaining: 1m\n",
      "167:\tlearn: 0.0907373\ttotal: 12.1s\tremaining: 59.9s\n",
      "168:\tlearn: 0.0905481\ttotal: 12.1s\tremaining: 59.7s\n",
      "169:\tlearn: 0.0903530\ttotal: 12.2s\tremaining: 59.5s\n",
      "170:\tlearn: 0.0902766\ttotal: 12.2s\tremaining: 59.3s\n",
      "171:\tlearn: 0.0900627\ttotal: 12.3s\tremaining: 59.1s\n",
      "172:\tlearn: 0.0899773\ttotal: 12.3s\tremaining: 59s\n",
      "173:\tlearn: 0.0899037\ttotal: 12.4s\tremaining: 58.8s\n",
      "174:\tlearn: 0.0898765\ttotal: 12.4s\tremaining: 58.6s\n",
      "175:\tlearn: 0.0895876\ttotal: 12.5s\tremaining: 58.4s\n",
      "176:\tlearn: 0.0894685\ttotal: 12.5s\tremaining: 58.3s\n",
      "177:\tlearn: 0.0890055\ttotal: 12.6s\tremaining: 58.1s\n",
      "178:\tlearn: 0.0888122\ttotal: 12.6s\tremaining: 58s\n",
      "179:\tlearn: 0.0886588\ttotal: 12.7s\tremaining: 57.8s\n",
      "180:\tlearn: 0.0884732\ttotal: 12.7s\tremaining: 57.6s\n",
      "181:\tlearn: 0.0883847\ttotal: 12.8s\tremaining: 57.5s\n",
      "182:\tlearn: 0.0882856\ttotal: 12.8s\tremaining: 57.4s\n",
      "183:\tlearn: 0.0880919\ttotal: 12.9s\tremaining: 57.2s\n",
      "184:\tlearn: 0.0880151\ttotal: 12.9s\tremaining: 57s\n",
      "185:\tlearn: 0.0878947\ttotal: 13s\tremaining: 56.9s\n",
      "186:\tlearn: 0.0877951\ttotal: 13.1s\tremaining: 56.8s\n",
      "187:\tlearn: 0.0877173\ttotal: 13.1s\tremaining: 56.6s\n",
      "188:\tlearn: 0.0875884\ttotal: 13.2s\tremaining: 56.5s\n",
      "189:\tlearn: 0.0874739\ttotal: 13.2s\tremaining: 56.3s\n",
      "190:\tlearn: 0.0873819\ttotal: 13.2s\tremaining: 56.1s\n",
      "191:\tlearn: 0.0873243\ttotal: 13.3s\tremaining: 56s\n",
      "192:\tlearn: 0.0872106\ttotal: 13.4s\tremaining: 55.9s\n",
      "193:\tlearn: 0.0868751\ttotal: 13.4s\tremaining: 55.7s\n",
      "194:\tlearn: 0.0868073\ttotal: 13.5s\tremaining: 55.6s\n",
      "195:\tlearn: 0.0866899\ttotal: 13.5s\tremaining: 55.4s\n",
      "196:\tlearn: 0.0866602\ttotal: 13.6s\tremaining: 55.3s\n",
      "197:\tlearn: 0.0865830\ttotal: 13.6s\tremaining: 55.2s\n",
      "198:\tlearn: 0.0864733\ttotal: 13.7s\tremaining: 55s\n",
      "199:\tlearn: 0.0863976\ttotal: 13.7s\tremaining: 54.9s\n",
      "200:\tlearn: 0.0863709\ttotal: 13.8s\tremaining: 54.7s\n",
      "201:\tlearn: 0.0862875\ttotal: 13.8s\tremaining: 54.6s\n",
      "202:\tlearn: 0.0862256\ttotal: 13.9s\tremaining: 54.5s\n",
      "203:\tlearn: 0.0860925\ttotal: 13.9s\tremaining: 54.4s\n",
      "204:\tlearn: 0.0860167\ttotal: 14s\tremaining: 54.2s\n",
      "205:\tlearn: 0.0859477\ttotal: 14s\tremaining: 54.1s\n",
      "206:\tlearn: 0.0857809\ttotal: 14.1s\tremaining: 54s\n",
      "207:\tlearn: 0.0857557\ttotal: 14.1s\tremaining: 53.8s\n",
      "208:\tlearn: 0.0856532\ttotal: 14.2s\tremaining: 53.7s\n",
      "209:\tlearn: 0.0855534\ttotal: 14.2s\tremaining: 53.5s\n",
      "210:\tlearn: 0.0854461\ttotal: 14.3s\tremaining: 53.4s\n",
      "211:\tlearn: 0.0853731\ttotal: 14.3s\tremaining: 53.3s\n",
      "212:\tlearn: 0.0853162\ttotal: 14.4s\tremaining: 53.2s\n",
      "213:\tlearn: 0.0852594\ttotal: 14.4s\tremaining: 53s\n",
      "214:\tlearn: 0.0850989\ttotal: 14.5s\tremaining: 52.9s\n",
      "215:\tlearn: 0.0849044\ttotal: 14.6s\tremaining: 52.8s\n",
      "216:\tlearn: 0.0848469\ttotal: 14.6s\tremaining: 52.8s\n",
      "217:\tlearn: 0.0848221\ttotal: 14.7s\tremaining: 52.8s\n",
      "218:\tlearn: 0.0847094\ttotal: 14.8s\tremaining: 52.8s\n",
      "219:\tlearn: 0.0846723\ttotal: 14.8s\tremaining: 52.6s\n",
      "220:\tlearn: 0.0846440\ttotal: 14.9s\tremaining: 52.5s\n",
      "221:\tlearn: 0.0845894\ttotal: 14.9s\tremaining: 52.3s\n",
      "222:\tlearn: 0.0845481\ttotal: 15s\tremaining: 52.2s\n",
      "223:\tlearn: 0.0844411\ttotal: 15.1s\tremaining: 52.4s\n",
      "224:\tlearn: 0.0843515\ttotal: 15.2s\tremaining: 52.3s\n",
      "225:\tlearn: 0.0843300\ttotal: 15.3s\tremaining: 52.5s\n",
      "226:\tlearn: 0.0842472\ttotal: 15.4s\tremaining: 52.4s\n",
      "227:\tlearn: 0.0839467\ttotal: 15.5s\tremaining: 52.3s\n",
      "228:\tlearn: 0.0839087\ttotal: 15.5s\tremaining: 52.2s\n",
      "229:\tlearn: 0.0838258\ttotal: 15.6s\tremaining: 52.1s\n",
      "230:\tlearn: 0.0837398\ttotal: 15.6s\tremaining: 52s\n",
      "231:\tlearn: 0.0836643\ttotal: 15.7s\tremaining: 52.1s\n",
      "232:\tlearn: 0.0835223\ttotal: 16s\tremaining: 52.6s\n",
      "233:\tlearn: 0.0834513\ttotal: 16.1s\tremaining: 52.7s\n",
      "234:\tlearn: 0.0833224\ttotal: 16.2s\tremaining: 52.6s\n",
      "235:\tlearn: 0.0832615\ttotal: 16.2s\tremaining: 52.4s\n",
      "236:\tlearn: 0.0832157\ttotal: 16.3s\tremaining: 52.3s\n",
      "237:\tlearn: 0.0831126\ttotal: 16.4s\tremaining: 52.4s\n",
      "238:\tlearn: 0.0830538\ttotal: 16.5s\tremaining: 52.4s\n",
      "239:\tlearn: 0.0829205\ttotal: 16.5s\tremaining: 52.3s\n",
      "240:\tlearn: 0.0828935\ttotal: 16.6s\tremaining: 52.2s\n",
      "241:\tlearn: 0.0828248\ttotal: 16.6s\tremaining: 52.1s\n",
      "242:\tlearn: 0.0827820\ttotal: 16.7s\tremaining: 51.9s\n",
      "243:\tlearn: 0.0827162\ttotal: 16.7s\tremaining: 51.8s\n",
      "244:\tlearn: 0.0826119\ttotal: 16.8s\tremaining: 51.7s\n",
      "245:\tlearn: 0.0825494\ttotal: 16.8s\tremaining: 51.6s\n",
      "246:\tlearn: 0.0825159\ttotal: 16.9s\tremaining: 51.5s\n",
      "247:\tlearn: 0.0824281\ttotal: 16.9s\tremaining: 51.3s\n",
      "248:\tlearn: 0.0823822\ttotal: 17s\tremaining: 51.3s\n",
      "249:\tlearn: 0.0823288\ttotal: 17s\tremaining: 51.1s\n",
      "250:\tlearn: 0.0822671\ttotal: 17.1s\tremaining: 51s\n",
      "251:\tlearn: 0.0822090\ttotal: 17.1s\tremaining: 50.9s\n",
      "252:\tlearn: 0.0821880\ttotal: 17.2s\tremaining: 50.8s\n",
      "253:\tlearn: 0.0821448\ttotal: 17.3s\tremaining: 50.7s\n",
      "254:\tlearn: 0.0819959\ttotal: 17.3s\tremaining: 50.6s\n",
      "255:\tlearn: 0.0819728\ttotal: 17.4s\tremaining: 50.4s\n",
      "256:\tlearn: 0.0819570\ttotal: 17.4s\tremaining: 50.3s\n",
      "257:\tlearn: 0.0819052\ttotal: 17.4s\tremaining: 50.2s\n",
      "258:\tlearn: 0.0818522\ttotal: 17.5s\tremaining: 50.1s\n",
      "259:\tlearn: 0.0817934\ttotal: 17.6s\tremaining: 50.1s\n",
      "260:\tlearn: 0.0816748\ttotal: 17.7s\tremaining: 50.2s\n",
      "261:\tlearn: 0.0815657\ttotal: 17.8s\tremaining: 50.2s\n",
      "262:\tlearn: 0.0815184\ttotal: 17.9s\tremaining: 50.1s\n",
      "263:\tlearn: 0.0813985\ttotal: 17.9s\tremaining: 50s\n",
      "264:\tlearn: 0.0813494\ttotal: 18s\tremaining: 49.9s\n",
      "265:\tlearn: 0.0813153\ttotal: 18.1s\tremaining: 50s\n",
      "266:\tlearn: 0.0812177\ttotal: 18.2s\tremaining: 49.8s\n",
      "267:\tlearn: 0.0811038\ttotal: 18.2s\tremaining: 49.7s\n",
      "268:\tlearn: 0.0810491\ttotal: 18.3s\tremaining: 49.6s\n",
      "269:\tlearn: 0.0810137\ttotal: 18.3s\tremaining: 49.5s\n",
      "270:\tlearn: 0.0809586\ttotal: 18.4s\tremaining: 49.4s\n",
      "271:\tlearn: 0.0809270\ttotal: 18.4s\tremaining: 49.3s\n",
      "272:\tlearn: 0.0808764\ttotal: 18.5s\tremaining: 49.2s\n",
      "273:\tlearn: 0.0807604\ttotal: 18.5s\tremaining: 49.1s\n",
      "274:\tlearn: 0.0807036\ttotal: 18.6s\tremaining: 49s\n",
      "275:\tlearn: 0.0805880\ttotal: 18.6s\tremaining: 48.9s\n",
      "276:\tlearn: 0.0805392\ttotal: 18.7s\tremaining: 48.8s\n",
      "277:\tlearn: 0.0804855\ttotal: 18.7s\tremaining: 48.6s\n",
      "278:\tlearn: 0.0804263\ttotal: 18.8s\tremaining: 48.6s\n",
      "279:\tlearn: 0.0803725\ttotal: 18.8s\tremaining: 48.5s\n",
      "280:\tlearn: 0.0803244\ttotal: 18.9s\tremaining: 48.4s\n",
      "281:\tlearn: 0.0802653\ttotal: 18.9s\tremaining: 48.2s\n",
      "282:\tlearn: 0.0802097\ttotal: 19s\tremaining: 48.1s\n",
      "283:\tlearn: 0.0801934\ttotal: 19s\tremaining: 48s\n",
      "284:\tlearn: 0.0801799\ttotal: 19.1s\tremaining: 47.9s\n",
      "285:\tlearn: 0.0801547\ttotal: 19.1s\tremaining: 47.8s\n",
      "286:\tlearn: 0.0799630\ttotal: 19.2s\tremaining: 47.7s\n",
      "287:\tlearn: 0.0799127\ttotal: 19.2s\tremaining: 47.6s\n",
      "288:\tlearn: 0.0798367\ttotal: 19.3s\tremaining: 47.5s\n",
      "289:\tlearn: 0.0798001\ttotal: 19.4s\tremaining: 47.4s\n",
      "290:\tlearn: 0.0796747\ttotal: 19.4s\tremaining: 47.3s\n",
      "291:\tlearn: 0.0796501\ttotal: 19.5s\tremaining: 47.2s\n",
      "292:\tlearn: 0.0794754\ttotal: 19.5s\tremaining: 47.1s\n",
      "293:\tlearn: 0.0794244\ttotal: 19.6s\tremaining: 47s\n",
      "294:\tlearn: 0.0793909\ttotal: 19.6s\tremaining: 46.9s\n",
      "295:\tlearn: 0.0793320\ttotal: 19.7s\tremaining: 46.8s\n",
      "296:\tlearn: 0.0792217\ttotal: 19.7s\tremaining: 46.7s\n",
      "297:\tlearn: 0.0791801\ttotal: 19.8s\tremaining: 46.6s\n",
      "298:\tlearn: 0.0790408\ttotal: 19.8s\tremaining: 46.5s\n",
      "299:\tlearn: 0.0789915\ttotal: 19.9s\tremaining: 46.4s\n",
      "300:\tlearn: 0.0789210\ttotal: 19.9s\tremaining: 46.3s\n",
      "301:\tlearn: 0.0788611\ttotal: 20s\tremaining: 46.3s\n",
      "302:\tlearn: 0.0788354\ttotal: 20.1s\tremaining: 46.1s\n",
      "303:\tlearn: 0.0787231\ttotal: 20.1s\tremaining: 46s\n",
      "304:\tlearn: 0.0786988\ttotal: 20.2s\tremaining: 45.9s\n",
      "305:\tlearn: 0.0786597\ttotal: 20.2s\tremaining: 45.8s\n",
      "306:\tlearn: 0.0785950\ttotal: 20.3s\tremaining: 45.7s\n",
      "307:\tlearn: 0.0785539\ttotal: 20.3s\tremaining: 45.6s\n",
      "308:\tlearn: 0.0785206\ttotal: 20.4s\tremaining: 45.5s\n",
      "309:\tlearn: 0.0784858\ttotal: 20.4s\tremaining: 45.4s\n",
      "310:\tlearn: 0.0784017\ttotal: 20.5s\tremaining: 45.4s\n",
      "311:\tlearn: 0.0783833\ttotal: 20.5s\tremaining: 45.2s\n",
      "312:\tlearn: 0.0783364\ttotal: 20.6s\tremaining: 45.1s\n",
      "313:\tlearn: 0.0782526\ttotal: 20.6s\tremaining: 45s\n",
      "314:\tlearn: 0.0782308\ttotal: 20.7s\tremaining: 44.9s\n",
      "315:\tlearn: 0.0781067\ttotal: 20.7s\tremaining: 44.8s\n",
      "316:\tlearn: 0.0780759\ttotal: 20.8s\tremaining: 44.8s\n",
      "317:\tlearn: 0.0780558\ttotal: 20.8s\tremaining: 44.6s\n",
      "318:\tlearn: 0.0780150\ttotal: 20.9s\tremaining: 44.5s\n",
      "319:\tlearn: 0.0779769\ttotal: 20.9s\tremaining: 44.4s\n",
      "320:\tlearn: 0.0779506\ttotal: 21s\tremaining: 44.4s\n",
      "321:\tlearn: 0.0779211\ttotal: 21s\tremaining: 44.3s\n",
      "322:\tlearn: 0.0778426\ttotal: 21.1s\tremaining: 44.2s\n",
      "323:\tlearn: 0.0777700\ttotal: 21.1s\tremaining: 44.1s\n",
      "324:\tlearn: 0.0777144\ttotal: 21.2s\tremaining: 44s\n",
      "325:\tlearn: 0.0776575\ttotal: 21.2s\tremaining: 43.9s\n",
      "326:\tlearn: 0.0776023\ttotal: 21.3s\tremaining: 43.8s\n",
      "327:\tlearn: 0.0775654\ttotal: 21.3s\tremaining: 43.7s\n",
      "328:\tlearn: 0.0775459\ttotal: 21.4s\tremaining: 43.6s\n",
      "329:\tlearn: 0.0775045\ttotal: 21.4s\tremaining: 43.5s\n",
      "330:\tlearn: 0.0774829\ttotal: 21.5s\tremaining: 43.4s\n",
      "331:\tlearn: 0.0773886\ttotal: 21.5s\tremaining: 43.4s\n",
      "332:\tlearn: 0.0773355\ttotal: 21.6s\tremaining: 43.3s\n",
      "333:\tlearn: 0.0772632\ttotal: 21.6s\tremaining: 43.2s\n",
      "334:\tlearn: 0.0772082\ttotal: 21.7s\tremaining: 43.1s\n",
      "335:\tlearn: 0.0771226\ttotal: 21.8s\tremaining: 43s\n",
      "336:\tlearn: 0.0770861\ttotal: 21.8s\tremaining: 43s\n",
      "337:\tlearn: 0.0770018\ttotal: 21.9s\tremaining: 42.9s\n",
      "338:\tlearn: 0.0769568\ttotal: 22s\tremaining: 42.8s\n",
      "339:\tlearn: 0.0769022\ttotal: 22s\tremaining: 42.8s\n",
      "340:\tlearn: 0.0768526\ttotal: 22.1s\tremaining: 42.7s\n",
      "341:\tlearn: 0.0767812\ttotal: 22.1s\tremaining: 42.6s\n",
      "342:\tlearn: 0.0767333\ttotal: 22.3s\tremaining: 42.7s\n",
      "343:\tlearn: 0.0766830\ttotal: 22.4s\tremaining: 42.6s\n",
      "344:\tlearn: 0.0766331\ttotal: 22.4s\tremaining: 42.5s\n",
      "345:\tlearn: 0.0765435\ttotal: 22.5s\tremaining: 42.4s\n",
      "346:\tlearn: 0.0765212\ttotal: 22.5s\tremaining: 42.4s\n",
      "347:\tlearn: 0.0765055\ttotal: 22.6s\tremaining: 42.3s\n",
      "348:\tlearn: 0.0764916\ttotal: 22.7s\tremaining: 42.3s\n",
      "349:\tlearn: 0.0764617\ttotal: 22.7s\tremaining: 42.2s\n",
      "350:\tlearn: 0.0764241\ttotal: 22.8s\tremaining: 42.2s\n",
      "351:\tlearn: 0.0763930\ttotal: 22.9s\tremaining: 42.2s\n",
      "352:\tlearn: 0.0763753\ttotal: 23s\tremaining: 42.2s\n",
      "353:\tlearn: 0.0763042\ttotal: 23.1s\tremaining: 42.1s\n",
      "354:\tlearn: 0.0762690\ttotal: 23.1s\tremaining: 42s\n",
      "355:\tlearn: 0.0762256\ttotal: 23.2s\tremaining: 41.9s\n",
      "356:\tlearn: 0.0761877\ttotal: 23.2s\tremaining: 41.8s\n",
      "357:\tlearn: 0.0760790\ttotal: 23.3s\tremaining: 41.8s\n",
      "358:\tlearn: 0.0759542\ttotal: 23.3s\tremaining: 41.7s\n",
      "359:\tlearn: 0.0759027\ttotal: 23.4s\tremaining: 41.6s\n",
      "360:\tlearn: 0.0758690\ttotal: 23.4s\tremaining: 41.5s\n",
      "361:\tlearn: 0.0758023\ttotal: 23.5s\tremaining: 41.4s\n",
      "362:\tlearn: 0.0757626\ttotal: 23.5s\tremaining: 41.3s\n",
      "363:\tlearn: 0.0757099\ttotal: 23.6s\tremaining: 41.3s\n",
      "364:\tlearn: 0.0756803\ttotal: 23.7s\tremaining: 41.2s\n",
      "365:\tlearn: 0.0756430\ttotal: 23.7s\tremaining: 41.1s\n",
      "366:\tlearn: 0.0755995\ttotal: 23.8s\tremaining: 41.1s\n",
      "367:\tlearn: 0.0755676\ttotal: 23.9s\tremaining: 41s\n",
      "368:\tlearn: 0.0755445\ttotal: 23.9s\tremaining: 40.9s\n",
      "369:\tlearn: 0.0755181\ttotal: 24s\tremaining: 40.8s\n",
      "370:\tlearn: 0.0754847\ttotal: 24s\tremaining: 40.7s\n",
      "371:\tlearn: 0.0754267\ttotal: 24.1s\tremaining: 40.7s\n",
      "372:\tlearn: 0.0753875\ttotal: 24.1s\tremaining: 40.6s\n",
      "373:\tlearn: 0.0753277\ttotal: 24.2s\tremaining: 40.5s\n",
      "374:\tlearn: 0.0751877\ttotal: 24.3s\tremaining: 40.4s\n",
      "375:\tlearn: 0.0751484\ttotal: 24.3s\tremaining: 40.4s\n",
      "376:\tlearn: 0.0750849\ttotal: 24.4s\tremaining: 40.3s\n",
      "377:\tlearn: 0.0750584\ttotal: 24.4s\tremaining: 40.2s\n",
      "378:\tlearn: 0.0750216\ttotal: 24.5s\tremaining: 40.1s\n",
      "379:\tlearn: 0.0749952\ttotal: 24.5s\tremaining: 40s\n",
      "380:\tlearn: 0.0749532\ttotal: 24.6s\tremaining: 39.9s\n",
      "381:\tlearn: 0.0749135\ttotal: 24.6s\tremaining: 39.8s\n",
      "382:\tlearn: 0.0748782\ttotal: 24.7s\tremaining: 39.8s\n",
      "383:\tlearn: 0.0748102\ttotal: 24.7s\tremaining: 39.7s\n",
      "384:\tlearn: 0.0747828\ttotal: 24.8s\tremaining: 39.6s\n",
      "385:\tlearn: 0.0747668\ttotal: 24.8s\tremaining: 39.5s\n",
      "386:\tlearn: 0.0747217\ttotal: 24.9s\tremaining: 39.4s\n",
      "387:\tlearn: 0.0746876\ttotal: 24.9s\tremaining: 39.3s\n",
      "388:\tlearn: 0.0746383\ttotal: 25s\tremaining: 39.2s\n",
      "389:\tlearn: 0.0746085\ttotal: 25s\tremaining: 39.2s\n",
      "390:\tlearn: 0.0745527\ttotal: 25.1s\tremaining: 39.1s\n",
      "391:\tlearn: 0.0744968\ttotal: 25.2s\tremaining: 39s\n",
      "392:\tlearn: 0.0744532\ttotal: 25.2s\tremaining: 38.9s\n",
      "393:\tlearn: 0.0743925\ttotal: 25.4s\tremaining: 39s\n",
      "394:\tlearn: 0.0743347\ttotal: 25.4s\tremaining: 38.9s\n",
      "395:\tlearn: 0.0743244\ttotal: 25.5s\tremaining: 38.8s\n",
      "396:\tlearn: 0.0742826\ttotal: 25.5s\tremaining: 38.7s\n",
      "397:\tlearn: 0.0742319\ttotal: 25.6s\tremaining: 38.7s\n",
      "398:\tlearn: 0.0741480\ttotal: 25.6s\tremaining: 38.6s\n",
      "399:\tlearn: 0.0740895\ttotal: 25.7s\tremaining: 38.6s\n",
      "400:\tlearn: 0.0740628\ttotal: 25.8s\tremaining: 38.5s\n",
      "401:\tlearn: 0.0739713\ttotal: 25.9s\tremaining: 38.5s\n",
      "402:\tlearn: 0.0739055\ttotal: 26.1s\tremaining: 38.6s\n",
      "403:\tlearn: 0.0738647\ttotal: 26.3s\tremaining: 38.7s\n",
      "404:\tlearn: 0.0738385\ttotal: 26.4s\tremaining: 38.8s\n",
      "405:\tlearn: 0.0737615\ttotal: 26.4s\tremaining: 38.7s\n",
      "406:\tlearn: 0.0736884\ttotal: 26.5s\tremaining: 38.6s\n",
      "407:\tlearn: 0.0736784\ttotal: 26.6s\tremaining: 38.5s\n",
      "408:\tlearn: 0.0736090\ttotal: 26.6s\tremaining: 38.5s\n",
      "409:\tlearn: 0.0735861\ttotal: 26.7s\tremaining: 38.4s\n",
      "410:\tlearn: 0.0734720\ttotal: 26.7s\tremaining: 38.3s\n",
      "411:\tlearn: 0.0734608\ttotal: 26.8s\tremaining: 38.3s\n",
      "412:\tlearn: 0.0734376\ttotal: 26.9s\tremaining: 38.2s\n",
      "413:\tlearn: 0.0733910\ttotal: 26.9s\tremaining: 38.1s\n",
      "414:\tlearn: 0.0733571\ttotal: 27s\tremaining: 38s\n",
      "415:\tlearn: 0.0733172\ttotal: 27s\tremaining: 38s\n",
      "416:\tlearn: 0.0732835\ttotal: 27.1s\tremaining: 37.9s\n",
      "417:\tlearn: 0.0732484\ttotal: 27.2s\tremaining: 37.8s\n",
      "418:\tlearn: 0.0731982\ttotal: 27.2s\tremaining: 37.7s\n",
      "419:\tlearn: 0.0731738\ttotal: 27.3s\tremaining: 37.6s\n",
      "420:\tlearn: 0.0731290\ttotal: 27.3s\tremaining: 37.6s\n",
      "421:\tlearn: 0.0731069\ttotal: 27.4s\tremaining: 37.5s\n",
      "422:\tlearn: 0.0730184\ttotal: 27.4s\tremaining: 37.4s\n",
      "423:\tlearn: 0.0729837\ttotal: 27.5s\tremaining: 37.3s\n",
      "424:\tlearn: 0.0729596\ttotal: 27.5s\tremaining: 37.2s\n",
      "425:\tlearn: 0.0729389\ttotal: 27.6s\tremaining: 37.1s\n",
      "426:\tlearn: 0.0728978\ttotal: 27.6s\tremaining: 37.1s\n",
      "427:\tlearn: 0.0728392\ttotal: 27.7s\tremaining: 37s\n",
      "428:\tlearn: 0.0728353\ttotal: 27.7s\tremaining: 36.9s\n",
      "429:\tlearn: 0.0728081\ttotal: 27.8s\tremaining: 36.8s\n",
      "430:\tlearn: 0.0727590\ttotal: 27.8s\tremaining: 36.7s\n",
      "431:\tlearn: 0.0727197\ttotal: 27.9s\tremaining: 36.6s\n",
      "432:\tlearn: 0.0726721\ttotal: 27.9s\tremaining: 36.6s\n",
      "433:\tlearn: 0.0726192\ttotal: 28s\tremaining: 36.5s\n",
      "434:\tlearn: 0.0725420\ttotal: 28s\tremaining: 36.4s\n",
      "435:\tlearn: 0.0724518\ttotal: 28.1s\tremaining: 36.3s\n",
      "436:\tlearn: 0.0724081\ttotal: 28.2s\tremaining: 36.3s\n",
      "437:\tlearn: 0.0723729\ttotal: 28.2s\tremaining: 36.2s\n",
      "438:\tlearn: 0.0723311\ttotal: 28.3s\tremaining: 36.1s\n",
      "439:\tlearn: 0.0723228\ttotal: 28.3s\tremaining: 36s\n",
      "440:\tlearn: 0.0723017\ttotal: 28.4s\tremaining: 35.9s\n",
      "441:\tlearn: 0.0722264\ttotal: 28.4s\tremaining: 35.9s\n",
      "442:\tlearn: 0.0721942\ttotal: 28.5s\tremaining: 35.8s\n",
      "443:\tlearn: 0.0721587\ttotal: 28.5s\tremaining: 35.7s\n",
      "444:\tlearn: 0.0721316\ttotal: 28.6s\tremaining: 35.6s\n",
      "445:\tlearn: 0.0720979\ttotal: 28.6s\tremaining: 35.5s\n",
      "446:\tlearn: 0.0720394\ttotal: 28.7s\tremaining: 35.5s\n",
      "447:\tlearn: 0.0720273\ttotal: 28.7s\tremaining: 35.4s\n",
      "448:\tlearn: 0.0719805\ttotal: 28.8s\tremaining: 35.3s\n",
      "449:\tlearn: 0.0719708\ttotal: 28.8s\tremaining: 35.2s\n",
      "450:\tlearn: 0.0719539\ttotal: 28.9s\tremaining: 35.1s\n",
      "451:\tlearn: 0.0719058\ttotal: 28.9s\tremaining: 35.1s\n",
      "452:\tlearn: 0.0718970\ttotal: 29s\tremaining: 35s\n",
      "453:\tlearn: 0.0718910\ttotal: 29s\tremaining: 34.9s\n",
      "454:\tlearn: 0.0718720\ttotal: 29.1s\tremaining: 34.8s\n",
      "455:\tlearn: 0.0718267\ttotal: 29.1s\tremaining: 34.7s\n",
      "456:\tlearn: 0.0717513\ttotal: 29.2s\tremaining: 34.7s\n",
      "457:\tlearn: 0.0717347\ttotal: 29.3s\tremaining: 34.7s\n",
      "458:\tlearn: 0.0716934\ttotal: 29.4s\tremaining: 34.6s\n",
      "459:\tlearn: 0.0716609\ttotal: 29.4s\tremaining: 34.5s\n",
      "460:\tlearn: 0.0716190\ttotal: 29.5s\tremaining: 34.4s\n",
      "461:\tlearn: 0.0715754\ttotal: 29.5s\tremaining: 34.4s\n",
      "462:\tlearn: 0.0715385\ttotal: 29.6s\tremaining: 34.3s\n",
      "463:\tlearn: 0.0715032\ttotal: 29.6s\tremaining: 34.2s\n",
      "464:\tlearn: 0.0714576\ttotal: 29.7s\tremaining: 34.1s\n",
      "465:\tlearn: 0.0714165\ttotal: 29.7s\tremaining: 34.1s\n",
      "466:\tlearn: 0.0713874\ttotal: 29.8s\tremaining: 34s\n",
      "467:\tlearn: 0.0713523\ttotal: 29.8s\tremaining: 33.9s\n",
      "468:\tlearn: 0.0713197\ttotal: 29.9s\tremaining: 33.8s\n",
      "469:\tlearn: 0.0712775\ttotal: 29.9s\tremaining: 33.8s\n",
      "470:\tlearn: 0.0712573\ttotal: 30s\tremaining: 33.7s\n",
      "471:\tlearn: 0.0711538\ttotal: 30.1s\tremaining: 33.6s\n",
      "472:\tlearn: 0.0711265\ttotal: 30.1s\tremaining: 33.5s\n",
      "473:\tlearn: 0.0710955\ttotal: 30.2s\tremaining: 33.5s\n",
      "474:\tlearn: 0.0710594\ttotal: 30.2s\tremaining: 33.4s\n",
      "475:\tlearn: 0.0710170\ttotal: 30.3s\tremaining: 33.3s\n",
      "476:\tlearn: 0.0709580\ttotal: 30.3s\tremaining: 33.3s\n",
      "477:\tlearn: 0.0709059\ttotal: 30.4s\tremaining: 33.2s\n",
      "478:\tlearn: 0.0708810\ttotal: 30.5s\tremaining: 33.1s\n",
      "479:\tlearn: 0.0708595\ttotal: 30.5s\tremaining: 33s\n",
      "480:\tlearn: 0.0708365\ttotal: 30.5s\tremaining: 33s\n",
      "481:\tlearn: 0.0708160\ttotal: 30.6s\tremaining: 32.9s\n",
      "482:\tlearn: 0.0707703\ttotal: 30.7s\tremaining: 32.8s\n",
      "483:\tlearn: 0.0707147\ttotal: 30.7s\tremaining: 32.7s\n",
      "484:\tlearn: 0.0707065\ttotal: 30.8s\tremaining: 32.7s\n",
      "485:\tlearn: 0.0706694\ttotal: 30.8s\tremaining: 32.6s\n",
      "486:\tlearn: 0.0706340\ttotal: 30.9s\tremaining: 32.5s\n",
      "487:\tlearn: 0.0706052\ttotal: 30.9s\tremaining: 32.4s\n",
      "488:\tlearn: 0.0705491\ttotal: 31s\tremaining: 32.4s\n",
      "489:\tlearn: 0.0705111\ttotal: 31s\tremaining: 32.3s\n",
      "490:\tlearn: 0.0704995\ttotal: 31.1s\tremaining: 32.2s\n",
      "491:\tlearn: 0.0704564\ttotal: 31.1s\tremaining: 32.1s\n",
      "492:\tlearn: 0.0704498\ttotal: 31.2s\tremaining: 32.1s\n",
      "493:\tlearn: 0.0704407\ttotal: 31.2s\tremaining: 32s\n",
      "494:\tlearn: 0.0704236\ttotal: 31.3s\tremaining: 31.9s\n",
      "495:\tlearn: 0.0703743\ttotal: 31.3s\tremaining: 31.8s\n",
      "496:\tlearn: 0.0703507\ttotal: 31.4s\tremaining: 31.8s\n",
      "497:\tlearn: 0.0703434\ttotal: 31.5s\tremaining: 31.8s\n",
      "498:\tlearn: 0.0702982\ttotal: 31.6s\tremaining: 31.7s\n",
      "499:\tlearn: 0.0702683\ttotal: 31.7s\tremaining: 31.7s\n",
      "500:\tlearn: 0.0702636\ttotal: 31.7s\tremaining: 31.6s\n",
      "501:\tlearn: 0.0702328\ttotal: 31.8s\tremaining: 31.5s\n",
      "502:\tlearn: 0.0702136\ttotal: 31.8s\tremaining: 31.4s\n",
      "503:\tlearn: 0.0701712\ttotal: 31.9s\tremaining: 31.4s\n",
      "504:\tlearn: 0.0701240\ttotal: 31.9s\tremaining: 31.3s\n",
      "505:\tlearn: 0.0701022\ttotal: 32s\tremaining: 31.2s\n",
      "506:\tlearn: 0.0700670\ttotal: 32s\tremaining: 31.1s\n",
      "507:\tlearn: 0.0700410\ttotal: 32.1s\tremaining: 31.1s\n",
      "508:\tlearn: 0.0700142\ttotal: 32.1s\tremaining: 31s\n",
      "509:\tlearn: 0.0699750\ttotal: 32.2s\tremaining: 30.9s\n",
      "510:\tlearn: 0.0699462\ttotal: 32.2s\tremaining: 30.8s\n",
      "511:\tlearn: 0.0699253\ttotal: 32.3s\tremaining: 30.8s\n",
      "512:\tlearn: 0.0699107\ttotal: 32.3s\tremaining: 30.7s\n",
      "513:\tlearn: 0.0698753\ttotal: 32.4s\tremaining: 30.6s\n",
      "514:\tlearn: 0.0698339\ttotal: 32.4s\tremaining: 30.6s\n",
      "515:\tlearn: 0.0698122\ttotal: 32.5s\tremaining: 30.5s\n",
      "516:\tlearn: 0.0697717\ttotal: 32.5s\tremaining: 30.4s\n",
      "517:\tlearn: 0.0697694\ttotal: 32.6s\tremaining: 30.3s\n",
      "518:\tlearn: 0.0697420\ttotal: 32.7s\tremaining: 30.3s\n",
      "519:\tlearn: 0.0696890\ttotal: 32.7s\tremaining: 30.2s\n",
      "520:\tlearn: 0.0696256\ttotal: 32.7s\tremaining: 30.1s\n",
      "521:\tlearn: 0.0696061\ttotal: 32.8s\tremaining: 30s\n",
      "522:\tlearn: 0.0695787\ttotal: 32.9s\tremaining: 30s\n",
      "523:\tlearn: 0.0695471\ttotal: 32.9s\tremaining: 29.9s\n",
      "524:\tlearn: 0.0695084\ttotal: 33s\tremaining: 29.8s\n",
      "525:\tlearn: 0.0694709\ttotal: 33s\tremaining: 29.7s\n",
      "526:\tlearn: 0.0694345\ttotal: 33.1s\tremaining: 29.7s\n",
      "527:\tlearn: 0.0693840\ttotal: 33.1s\tremaining: 29.6s\n",
      "528:\tlearn: 0.0693551\ttotal: 33.2s\tremaining: 29.5s\n",
      "529:\tlearn: 0.0693378\ttotal: 33.2s\tremaining: 29.5s\n",
      "530:\tlearn: 0.0692564\ttotal: 33.3s\tremaining: 29.4s\n",
      "531:\tlearn: 0.0691800\ttotal: 33.3s\tremaining: 29.3s\n",
      "532:\tlearn: 0.0691303\ttotal: 33.4s\tremaining: 29.2s\n",
      "533:\tlearn: 0.0690435\ttotal: 33.4s\tremaining: 29.2s\n",
      "534:\tlearn: 0.0689930\ttotal: 33.5s\tremaining: 29.1s\n",
      "535:\tlearn: 0.0689487\ttotal: 33.5s\tremaining: 29s\n",
      "536:\tlearn: 0.0689150\ttotal: 33.6s\tremaining: 29s\n",
      "537:\tlearn: 0.0688774\ttotal: 33.6s\tremaining: 28.9s\n",
      "538:\tlearn: 0.0688615\ttotal: 33.7s\tremaining: 28.8s\n",
      "539:\tlearn: 0.0688414\ttotal: 33.7s\tremaining: 28.7s\n",
      "540:\tlearn: 0.0688373\ttotal: 33.8s\tremaining: 28.7s\n",
      "541:\tlearn: 0.0688105\ttotal: 33.8s\tremaining: 28.6s\n",
      "542:\tlearn: 0.0687905\ttotal: 33.9s\tremaining: 28.5s\n",
      "543:\tlearn: 0.0687544\ttotal: 33.9s\tremaining: 28.4s\n",
      "544:\tlearn: 0.0687233\ttotal: 34s\tremaining: 28.4s\n",
      "545:\tlearn: 0.0687186\ttotal: 34s\tremaining: 28.3s\n",
      "546:\tlearn: 0.0686999\ttotal: 34.1s\tremaining: 28.2s\n",
      "547:\tlearn: 0.0686550\ttotal: 34.1s\tremaining: 28.2s\n",
      "548:\tlearn: 0.0686213\ttotal: 34.2s\tremaining: 28.1s\n",
      "549:\tlearn: 0.0685911\ttotal: 34.2s\tremaining: 28s\n",
      "550:\tlearn: 0.0685264\ttotal: 34.3s\tremaining: 28s\n",
      "551:\tlearn: 0.0684961\ttotal: 34.4s\tremaining: 27.9s\n",
      "552:\tlearn: 0.0684357\ttotal: 34.4s\tremaining: 27.8s\n",
      "553:\tlearn: 0.0683787\ttotal: 34.5s\tremaining: 27.7s\n",
      "554:\tlearn: 0.0683567\ttotal: 34.5s\tremaining: 27.7s\n",
      "555:\tlearn: 0.0683217\ttotal: 34.6s\tremaining: 27.6s\n",
      "556:\tlearn: 0.0682958\ttotal: 34.6s\tremaining: 27.5s\n",
      "557:\tlearn: 0.0682617\ttotal: 34.7s\tremaining: 27.5s\n",
      "558:\tlearn: 0.0682432\ttotal: 34.7s\tremaining: 27.4s\n",
      "559:\tlearn: 0.0682107\ttotal: 34.8s\tremaining: 27.3s\n",
      "560:\tlearn: 0.0681996\ttotal: 34.8s\tremaining: 27.3s\n",
      "561:\tlearn: 0.0681859\ttotal: 34.9s\tremaining: 27.2s\n",
      "562:\tlearn: 0.0681598\ttotal: 34.9s\tremaining: 27.1s\n",
      "563:\tlearn: 0.0681148\ttotal: 35s\tremaining: 27.1s\n",
      "564:\tlearn: 0.0681035\ttotal: 35s\tremaining: 27s\n",
      "565:\tlearn: 0.0680686\ttotal: 35.1s\tremaining: 26.9s\n",
      "566:\tlearn: 0.0680575\ttotal: 35.1s\tremaining: 26.8s\n",
      "567:\tlearn: 0.0680300\ttotal: 35.2s\tremaining: 26.8s\n",
      "568:\tlearn: 0.0680199\ttotal: 35.3s\tremaining: 26.7s\n",
      "569:\tlearn: 0.0679886\ttotal: 35.3s\tremaining: 26.6s\n",
      "570:\tlearn: 0.0679419\ttotal: 35.4s\tremaining: 26.6s\n",
      "571:\tlearn: 0.0678890\ttotal: 35.4s\tremaining: 26.5s\n",
      "572:\tlearn: 0.0678244\ttotal: 35.5s\tremaining: 26.4s\n",
      "573:\tlearn: 0.0677831\ttotal: 35.5s\tremaining: 26.4s\n",
      "574:\tlearn: 0.0677423\ttotal: 35.6s\tremaining: 26.3s\n",
      "575:\tlearn: 0.0677055\ttotal: 35.6s\tremaining: 26.2s\n",
      "576:\tlearn: 0.0676764\ttotal: 35.7s\tremaining: 26.2s\n",
      "577:\tlearn: 0.0676569\ttotal: 35.8s\tremaining: 26.1s\n",
      "578:\tlearn: 0.0676325\ttotal: 35.8s\tremaining: 26s\n",
      "579:\tlearn: 0.0675952\ttotal: 35.9s\tremaining: 26s\n",
      "580:\tlearn: 0.0675308\ttotal: 36s\tremaining: 25.9s\n",
      "581:\tlearn: 0.0675026\ttotal: 36s\tremaining: 25.9s\n",
      "582:\tlearn: 0.0674720\ttotal: 36.1s\tremaining: 25.8s\n",
      "583:\tlearn: 0.0674552\ttotal: 36.2s\tremaining: 25.8s\n",
      "584:\tlearn: 0.0674371\ttotal: 36.3s\tremaining: 25.8s\n",
      "585:\tlearn: 0.0674189\ttotal: 36.4s\tremaining: 25.7s\n",
      "586:\tlearn: 0.0673945\ttotal: 36.5s\tremaining: 25.7s\n",
      "587:\tlearn: 0.0673495\ttotal: 36.5s\tremaining: 25.6s\n",
      "588:\tlearn: 0.0673058\ttotal: 36.6s\tremaining: 25.5s\n",
      "589:\tlearn: 0.0672804\ttotal: 36.6s\tremaining: 25.4s\n",
      "590:\tlearn: 0.0672579\ttotal: 36.7s\tremaining: 25.4s\n",
      "591:\tlearn: 0.0672126\ttotal: 36.7s\tremaining: 25.3s\n",
      "592:\tlearn: 0.0671968\ttotal: 36.8s\tremaining: 25.2s\n",
      "593:\tlearn: 0.0671881\ttotal: 36.8s\tremaining: 25.2s\n",
      "594:\tlearn: 0.0671570\ttotal: 36.9s\tremaining: 25.1s\n",
      "595:\tlearn: 0.0671262\ttotal: 36.9s\tremaining: 25s\n",
      "596:\tlearn: 0.0670824\ttotal: 37s\tremaining: 25s\n",
      "597:\tlearn: 0.0670314\ttotal: 37s\tremaining: 24.9s\n",
      "598:\tlearn: 0.0669945\ttotal: 37.1s\tremaining: 24.8s\n",
      "599:\tlearn: 0.0669675\ttotal: 37.1s\tremaining: 24.8s\n",
      "600:\tlearn: 0.0669566\ttotal: 37.2s\tremaining: 24.7s\n",
      "601:\tlearn: 0.0669165\ttotal: 37.2s\tremaining: 24.6s\n",
      "602:\tlearn: 0.0668817\ttotal: 37.3s\tremaining: 24.6s\n",
      "603:\tlearn: 0.0668537\ttotal: 37.4s\tremaining: 24.5s\n",
      "604:\tlearn: 0.0668456\ttotal: 37.4s\tremaining: 24.4s\n",
      "605:\tlearn: 0.0668224\ttotal: 37.5s\tremaining: 24.4s\n",
      "606:\tlearn: 0.0668038\ttotal: 37.5s\tremaining: 24.3s\n",
      "607:\tlearn: 0.0667623\ttotal: 37.6s\tremaining: 24.2s\n",
      "608:\tlearn: 0.0667354\ttotal: 37.6s\tremaining: 24.2s\n",
      "609:\tlearn: 0.0666940\ttotal: 37.7s\tremaining: 24.1s\n",
      "610:\tlearn: 0.0666154\ttotal: 37.7s\tremaining: 24s\n",
      "611:\tlearn: 0.0665635\ttotal: 37.8s\tremaining: 24s\n",
      "612:\tlearn: 0.0665319\ttotal: 37.8s\tremaining: 23.9s\n",
      "613:\tlearn: 0.0664984\ttotal: 37.9s\tremaining: 23.8s\n",
      "614:\tlearn: 0.0664745\ttotal: 38s\tremaining: 23.8s\n",
      "615:\tlearn: 0.0664325\ttotal: 38s\tremaining: 23.7s\n",
      "616:\tlearn: 0.0663872\ttotal: 38.1s\tremaining: 23.6s\n",
      "617:\tlearn: 0.0663143\ttotal: 38.1s\tremaining: 23.6s\n",
      "618:\tlearn: 0.0663067\ttotal: 38.2s\tremaining: 23.5s\n",
      "619:\tlearn: 0.0662627\ttotal: 38.2s\tremaining: 23.4s\n",
      "620:\tlearn: 0.0662477\ttotal: 38.3s\tremaining: 23.4s\n",
      "621:\tlearn: 0.0661794\ttotal: 38.3s\tremaining: 23.3s\n",
      "622:\tlearn: 0.0661397\ttotal: 38.4s\tremaining: 23.2s\n",
      "623:\tlearn: 0.0660897\ttotal: 38.4s\tremaining: 23.2s\n",
      "624:\tlearn: 0.0660658\ttotal: 38.5s\tremaining: 23.1s\n",
      "625:\tlearn: 0.0660198\ttotal: 38.5s\tremaining: 23s\n",
      "626:\tlearn: 0.0660042\ttotal: 38.6s\tremaining: 23s\n",
      "627:\tlearn: 0.0659765\ttotal: 38.6s\tremaining: 22.9s\n",
      "628:\tlearn: 0.0659663\ttotal: 38.7s\tremaining: 22.8s\n",
      "629:\tlearn: 0.0659572\ttotal: 38.8s\tremaining: 22.8s\n",
      "630:\tlearn: 0.0659429\ttotal: 38.8s\tremaining: 22.7s\n",
      "631:\tlearn: 0.0659271\ttotal: 38.9s\tremaining: 22.7s\n",
      "632:\tlearn: 0.0659110\ttotal: 39s\tremaining: 22.6s\n",
      "633:\tlearn: 0.0658862\ttotal: 39s\tremaining: 22.5s\n",
      "634:\tlearn: 0.0658724\ttotal: 39.1s\tremaining: 22.5s\n",
      "635:\tlearn: 0.0658532\ttotal: 39.2s\tremaining: 22.4s\n",
      "636:\tlearn: 0.0657882\ttotal: 39.2s\tremaining: 22.4s\n",
      "637:\tlearn: 0.0657493\ttotal: 39.3s\tremaining: 22.3s\n",
      "638:\tlearn: 0.0657173\ttotal: 39.3s\tremaining: 22.2s\n",
      "639:\tlearn: 0.0657075\ttotal: 39.4s\tremaining: 22.2s\n",
      "640:\tlearn: 0.0656911\ttotal: 39.4s\tremaining: 22.1s\n",
      "641:\tlearn: 0.0656414\ttotal: 39.5s\tremaining: 22s\n",
      "642:\tlearn: 0.0656061\ttotal: 39.6s\tremaining: 22s\n",
      "643:\tlearn: 0.0655822\ttotal: 39.6s\tremaining: 21.9s\n",
      "644:\tlearn: 0.0655544\ttotal: 39.6s\tremaining: 21.8s\n",
      "645:\tlearn: 0.0655241\ttotal: 39.7s\tremaining: 21.7s\n",
      "646:\tlearn: 0.0655028\ttotal: 39.9s\tremaining: 21.8s\n",
      "647:\tlearn: 0.0654764\ttotal: 40.1s\tremaining: 21.8s\n",
      "648:\tlearn: 0.0654460\ttotal: 40.2s\tremaining: 21.7s\n",
      "649:\tlearn: 0.0654302\ttotal: 40.2s\tremaining: 21.7s\n",
      "650:\tlearn: 0.0654156\ttotal: 40.3s\tremaining: 21.6s\n",
      "651:\tlearn: 0.0653929\ttotal: 40.3s\tremaining: 21.5s\n",
      "652:\tlearn: 0.0653499\ttotal: 40.4s\tremaining: 21.5s\n",
      "653:\tlearn: 0.0653414\ttotal: 40.4s\tremaining: 21.4s\n",
      "654:\tlearn: 0.0653181\ttotal: 40.5s\tremaining: 21.3s\n",
      "655:\tlearn: 0.0652767\ttotal: 40.5s\tremaining: 21.3s\n",
      "656:\tlearn: 0.0652621\ttotal: 40.6s\tremaining: 21.2s\n",
      "657:\tlearn: 0.0652513\ttotal: 40.7s\tremaining: 21.1s\n",
      "658:\tlearn: 0.0652145\ttotal: 40.7s\tremaining: 21.1s\n",
      "659:\tlearn: 0.0651600\ttotal: 40.8s\tremaining: 21s\n",
      "660:\tlearn: 0.0651594\ttotal: 40.8s\tremaining: 20.9s\n",
      "661:\tlearn: 0.0651350\ttotal: 40.9s\tremaining: 20.9s\n",
      "662:\tlearn: 0.0651177\ttotal: 40.9s\tremaining: 20.8s\n",
      "663:\tlearn: 0.0650928\ttotal: 41s\tremaining: 20.7s\n",
      "664:\tlearn: 0.0650103\ttotal: 41s\tremaining: 20.7s\n",
      "665:\tlearn: 0.0649723\ttotal: 41.1s\tremaining: 20.6s\n",
      "666:\tlearn: 0.0649468\ttotal: 41.1s\tremaining: 20.5s\n",
      "667:\tlearn: 0.0649189\ttotal: 41.2s\tremaining: 20.5s\n",
      "668:\tlearn: 0.0648730\ttotal: 41.2s\tremaining: 20.4s\n",
      "669:\tlearn: 0.0648423\ttotal: 41.3s\tremaining: 20.3s\n",
      "670:\tlearn: 0.0648050\ttotal: 41.3s\tremaining: 20.3s\n",
      "671:\tlearn: 0.0647963\ttotal: 41.4s\tremaining: 20.2s\n",
      "672:\tlearn: 0.0647737\ttotal: 41.4s\tremaining: 20.1s\n",
      "673:\tlearn: 0.0647457\ttotal: 41.5s\tremaining: 20.1s\n",
      "674:\tlearn: 0.0647113\ttotal: 41.5s\tremaining: 20s\n",
      "675:\tlearn: 0.0646894\ttotal: 41.6s\tremaining: 19.9s\n",
      "676:\tlearn: 0.0646492\ttotal: 41.6s\tremaining: 19.9s\n",
      "677:\tlearn: 0.0646212\ttotal: 41.7s\tremaining: 19.8s\n",
      "678:\tlearn: 0.0646104\ttotal: 41.7s\tremaining: 19.7s\n",
      "679:\tlearn: 0.0645485\ttotal: 41.8s\tremaining: 19.7s\n",
      "680:\tlearn: 0.0645151\ttotal: 41.8s\tremaining: 19.6s\n",
      "681:\tlearn: 0.0644799\ttotal: 41.9s\tremaining: 19.5s\n",
      "682:\tlearn: 0.0644429\ttotal: 42s\tremaining: 19.5s\n",
      "683:\tlearn: 0.0644148\ttotal: 42s\tremaining: 19.4s\n",
      "684:\tlearn: 0.0643738\ttotal: 42s\tremaining: 19.3s\n",
      "685:\tlearn: 0.0643442\ttotal: 42.1s\tremaining: 19.3s\n",
      "686:\tlearn: 0.0643175\ttotal: 42.2s\tremaining: 19.2s\n",
      "687:\tlearn: 0.0642851\ttotal: 42.2s\tremaining: 19.1s\n",
      "688:\tlearn: 0.0642659\ttotal: 42.3s\tremaining: 19.1s\n",
      "689:\tlearn: 0.0642333\ttotal: 42.3s\tremaining: 19s\n",
      "690:\tlearn: 0.0641910\ttotal: 42.4s\tremaining: 19s\n",
      "691:\tlearn: 0.0641669\ttotal: 42.6s\tremaining: 18.9s\n",
      "692:\tlearn: 0.0641400\ttotal: 42.6s\tremaining: 18.9s\n",
      "693:\tlearn: 0.0641086\ttotal: 42.7s\tremaining: 18.8s\n",
      "694:\tlearn: 0.0640815\ttotal: 42.7s\tremaining: 18.8s\n",
      "695:\tlearn: 0.0640580\ttotal: 42.8s\tremaining: 18.7s\n",
      "696:\tlearn: 0.0640196\ttotal: 42.8s\tremaining: 18.6s\n",
      "697:\tlearn: 0.0640010\ttotal: 42.9s\tremaining: 18.6s\n",
      "698:\tlearn: 0.0639807\ttotal: 42.9s\tremaining: 18.5s\n",
      "699:\tlearn: 0.0639468\ttotal: 43s\tremaining: 18.4s\n",
      "700:\tlearn: 0.0639150\ttotal: 43.1s\tremaining: 18.4s\n",
      "701:\tlearn: 0.0638902\ttotal: 43.1s\tremaining: 18.3s\n",
      "702:\tlearn: 0.0638711\ttotal: 43.2s\tremaining: 18.2s\n",
      "703:\tlearn: 0.0638360\ttotal: 43.2s\tremaining: 18.2s\n",
      "704:\tlearn: 0.0638084\ttotal: 43.3s\tremaining: 18.1s\n",
      "705:\tlearn: 0.0637834\ttotal: 43.3s\tremaining: 18s\n",
      "706:\tlearn: 0.0637811\ttotal: 43.4s\tremaining: 18s\n",
      "707:\tlearn: 0.0637522\ttotal: 43.4s\tremaining: 17.9s\n",
      "708:\tlearn: 0.0637278\ttotal: 43.5s\tremaining: 17.9s\n",
      "709:\tlearn: 0.0636794\ttotal: 43.6s\tremaining: 17.8s\n",
      "710:\tlearn: 0.0636582\ttotal: 43.6s\tremaining: 17.7s\n",
      "711:\tlearn: 0.0636326\ttotal: 43.7s\tremaining: 17.7s\n",
      "712:\tlearn: 0.0635780\ttotal: 43.7s\tremaining: 17.6s\n",
      "713:\tlearn: 0.0635506\ttotal: 43.8s\tremaining: 17.5s\n",
      "714:\tlearn: 0.0635254\ttotal: 43.8s\tremaining: 17.5s\n",
      "715:\tlearn: 0.0635130\ttotal: 43.9s\tremaining: 17.4s\n",
      "716:\tlearn: 0.0634982\ttotal: 43.9s\tremaining: 17.3s\n",
      "717:\tlearn: 0.0634791\ttotal: 44s\tremaining: 17.3s\n",
      "718:\tlearn: 0.0634553\ttotal: 44s\tremaining: 17.2s\n",
      "719:\tlearn: 0.0634483\ttotal: 44.1s\tremaining: 17.1s\n",
      "720:\tlearn: 0.0634101\ttotal: 44.1s\tremaining: 17.1s\n",
      "721:\tlearn: 0.0633594\ttotal: 44.2s\tremaining: 17s\n",
      "722:\tlearn: 0.0633492\ttotal: 44.2s\tremaining: 17s\n",
      "723:\tlearn: 0.0633235\ttotal: 44.3s\tremaining: 16.9s\n",
      "724:\tlearn: 0.0632948\ttotal: 44.3s\tremaining: 16.8s\n",
      "725:\tlearn: 0.0632722\ttotal: 44.4s\tremaining: 16.8s\n",
      "726:\tlearn: 0.0632518\ttotal: 44.5s\tremaining: 16.7s\n",
      "727:\tlearn: 0.0632493\ttotal: 44.5s\tremaining: 16.6s\n",
      "728:\tlearn: 0.0632185\ttotal: 44.6s\tremaining: 16.6s\n",
      "729:\tlearn: 0.0631905\ttotal: 44.6s\tremaining: 16.5s\n",
      "730:\tlearn: 0.0631578\ttotal: 44.7s\tremaining: 16.4s\n",
      "731:\tlearn: 0.0631396\ttotal: 44.7s\tremaining: 16.4s\n",
      "732:\tlearn: 0.0631102\ttotal: 44.8s\tremaining: 16.3s\n",
      "733:\tlearn: 0.0630842\ttotal: 44.8s\tremaining: 16.2s\n",
      "734:\tlearn: 0.0630566\ttotal: 44.9s\tremaining: 16.2s\n",
      "735:\tlearn: 0.0630449\ttotal: 44.9s\tremaining: 16.1s\n",
      "736:\tlearn: 0.0630294\ttotal: 45s\tremaining: 16.1s\n",
      "737:\tlearn: 0.0630161\ttotal: 45s\tremaining: 16s\n",
      "738:\tlearn: 0.0630001\ttotal: 45.1s\tremaining: 15.9s\n",
      "739:\tlearn: 0.0629829\ttotal: 45.2s\tremaining: 15.9s\n",
      "740:\tlearn: 0.0629731\ttotal: 45.2s\tremaining: 15.8s\n",
      "741:\tlearn: 0.0629558\ttotal: 45.3s\tremaining: 15.8s\n",
      "742:\tlearn: 0.0629169\ttotal: 45.4s\tremaining: 15.7s\n",
      "743:\tlearn: 0.0629038\ttotal: 45.4s\tremaining: 15.6s\n",
      "744:\tlearn: 0.0628785\ttotal: 45.5s\tremaining: 15.6s\n",
      "745:\tlearn: 0.0628438\ttotal: 45.5s\tremaining: 15.5s\n",
      "746:\tlearn: 0.0628318\ttotal: 45.6s\tremaining: 15.4s\n",
      "747:\tlearn: 0.0628233\ttotal: 45.7s\tremaining: 15.4s\n",
      "748:\tlearn: 0.0628168\ttotal: 45.7s\tremaining: 15.3s\n",
      "749:\tlearn: 0.0628029\ttotal: 45.8s\tremaining: 15.3s\n",
      "750:\tlearn: 0.0627976\ttotal: 45.8s\tremaining: 15.2s\n",
      "751:\tlearn: 0.0627465\ttotal: 45.9s\tremaining: 15.1s\n",
      "752:\tlearn: 0.0627347\ttotal: 45.9s\tremaining: 15.1s\n",
      "753:\tlearn: 0.0627029\ttotal: 46s\tremaining: 15s\n",
      "754:\tlearn: 0.0626773\ttotal: 46s\tremaining: 14.9s\n",
      "755:\tlearn: 0.0626430\ttotal: 46.1s\tremaining: 14.9s\n",
      "756:\tlearn: 0.0625906\ttotal: 46.2s\tremaining: 14.8s\n",
      "757:\tlearn: 0.0625838\ttotal: 46.2s\tremaining: 14.8s\n",
      "758:\tlearn: 0.0625763\ttotal: 46.3s\tremaining: 14.7s\n",
      "759:\tlearn: 0.0625685\ttotal: 46.3s\tremaining: 14.6s\n",
      "760:\tlearn: 0.0625595\ttotal: 46.4s\tremaining: 14.6s\n",
      "761:\tlearn: 0.0625460\ttotal: 46.4s\tremaining: 14.5s\n",
      "762:\tlearn: 0.0625192\ttotal: 46.6s\tremaining: 14.5s\n",
      "763:\tlearn: 0.0624984\ttotal: 46.7s\tremaining: 14.4s\n",
      "764:\tlearn: 0.0624825\ttotal: 46.7s\tremaining: 14.3s\n",
      "765:\tlearn: 0.0624620\ttotal: 46.7s\tremaining: 14.3s\n",
      "766:\tlearn: 0.0624148\ttotal: 46.8s\tremaining: 14.2s\n",
      "767:\tlearn: 0.0623810\ttotal: 46.9s\tremaining: 14.2s\n",
      "768:\tlearn: 0.0623650\ttotal: 46.9s\tremaining: 14.1s\n",
      "769:\tlearn: 0.0623472\ttotal: 47s\tremaining: 14s\n",
      "770:\tlearn: 0.0623207\ttotal: 47s\tremaining: 14s\n",
      "771:\tlearn: 0.0622784\ttotal: 47.1s\tremaining: 13.9s\n",
      "772:\tlearn: 0.0622563\ttotal: 47.1s\tremaining: 13.8s\n",
      "773:\tlearn: 0.0622378\ttotal: 47.2s\tremaining: 13.8s\n",
      "774:\tlearn: 0.0621941\ttotal: 47.2s\tremaining: 13.7s\n",
      "775:\tlearn: 0.0621623\ttotal: 47.3s\tremaining: 13.6s\n",
      "776:\tlearn: 0.0621498\ttotal: 47.3s\tremaining: 13.6s\n",
      "777:\tlearn: 0.0621391\ttotal: 47.4s\tremaining: 13.5s\n",
      "778:\tlearn: 0.0621250\ttotal: 47.4s\tremaining: 13.5s\n",
      "779:\tlearn: 0.0621123\ttotal: 47.5s\tremaining: 13.4s\n",
      "780:\tlearn: 0.0620969\ttotal: 47.5s\tremaining: 13.3s\n",
      "781:\tlearn: 0.0620895\ttotal: 47.6s\tremaining: 13.3s\n",
      "782:\tlearn: 0.0620655\ttotal: 47.7s\tremaining: 13.2s\n",
      "783:\tlearn: 0.0620210\ttotal: 47.7s\tremaining: 13.1s\n",
      "784:\tlearn: 0.0619830\ttotal: 47.8s\tremaining: 13.1s\n",
      "785:\tlearn: 0.0619728\ttotal: 47.8s\tremaining: 13s\n",
      "786:\tlearn: 0.0619631\ttotal: 47.9s\tremaining: 13s\n",
      "787:\tlearn: 0.0619489\ttotal: 47.9s\tremaining: 12.9s\n",
      "788:\tlearn: 0.0619373\ttotal: 48s\tremaining: 12.8s\n",
      "789:\tlearn: 0.0619182\ttotal: 48s\tremaining: 12.8s\n",
      "790:\tlearn: 0.0619058\ttotal: 48.1s\tremaining: 12.7s\n",
      "791:\tlearn: 0.0618827\ttotal: 48.2s\tremaining: 12.7s\n",
      "792:\tlearn: 0.0618386\ttotal: 48.2s\tremaining: 12.6s\n",
      "793:\tlearn: 0.0617953\ttotal: 48.3s\tremaining: 12.5s\n",
      "794:\tlearn: 0.0617582\ttotal: 48.4s\tremaining: 12.5s\n",
      "795:\tlearn: 0.0617085\ttotal: 48.5s\tremaining: 12.4s\n",
      "796:\tlearn: 0.0616815\ttotal: 48.5s\tremaining: 12.4s\n",
      "797:\tlearn: 0.0616427\ttotal: 48.6s\tremaining: 12.3s\n",
      "798:\tlearn: 0.0616345\ttotal: 48.6s\tremaining: 12.2s\n",
      "799:\tlearn: 0.0616236\ttotal: 48.7s\tremaining: 12.2s\n",
      "800:\tlearn: 0.0616215\ttotal: 48.7s\tremaining: 12.1s\n",
      "801:\tlearn: 0.0615951\ttotal: 48.8s\tremaining: 12s\n",
      "802:\tlearn: 0.0615716\ttotal: 48.9s\tremaining: 12s\n",
      "803:\tlearn: 0.0615338\ttotal: 48.9s\tremaining: 11.9s\n",
      "804:\tlearn: 0.0615076\ttotal: 49s\tremaining: 11.9s\n",
      "805:\tlearn: 0.0614836\ttotal: 49.1s\tremaining: 11.8s\n",
      "806:\tlearn: 0.0614615\ttotal: 49.1s\tremaining: 11.8s\n",
      "807:\tlearn: 0.0614479\ttotal: 49.2s\tremaining: 11.7s\n",
      "808:\tlearn: 0.0614119\ttotal: 49.2s\tremaining: 11.6s\n",
      "809:\tlearn: 0.0613897\ttotal: 49.3s\tremaining: 11.6s\n",
      "810:\tlearn: 0.0613741\ttotal: 49.4s\tremaining: 11.5s\n",
      "811:\tlearn: 0.0613520\ttotal: 49.7s\tremaining: 11.5s\n",
      "812:\tlearn: 0.0613247\ttotal: 49.8s\tremaining: 11.4s\n",
      "813:\tlearn: 0.0612833\ttotal: 49.8s\tremaining: 11.4s\n",
      "814:\tlearn: 0.0612590\ttotal: 49.9s\tremaining: 11.3s\n",
      "815:\tlearn: 0.0612523\ttotal: 50s\tremaining: 11.3s\n",
      "816:\tlearn: 0.0612287\ttotal: 50s\tremaining: 11.2s\n",
      "817:\tlearn: 0.0612080\ttotal: 50.1s\tremaining: 11.2s\n",
      "818:\tlearn: 0.0611820\ttotal: 50.5s\tremaining: 11.2s\n",
      "819:\tlearn: 0.0611684\ttotal: 50.8s\tremaining: 11.2s\n",
      "820:\tlearn: 0.0611401\ttotal: 51s\tremaining: 11.1s\n",
      "821:\tlearn: 0.0611274\ttotal: 51.1s\tremaining: 11.1s\n",
      "822:\tlearn: 0.0611082\ttotal: 51.1s\tremaining: 11s\n",
      "823:\tlearn: 0.0610945\ttotal: 51.2s\tremaining: 10.9s\n",
      "824:\tlearn: 0.0610913\ttotal: 51.2s\tremaining: 10.9s\n",
      "825:\tlearn: 0.0610668\ttotal: 51.3s\tremaining: 10.8s\n",
      "826:\tlearn: 0.0610311\ttotal: 51.4s\tremaining: 10.7s\n",
      "827:\tlearn: 0.0609926\ttotal: 51.4s\tremaining: 10.7s\n",
      "828:\tlearn: 0.0609617\ttotal: 51.5s\tremaining: 10.6s\n",
      "829:\tlearn: 0.0609527\ttotal: 51.5s\tremaining: 10.6s\n",
      "830:\tlearn: 0.0609286\ttotal: 51.6s\tremaining: 10.5s\n",
      "831:\tlearn: 0.0609074\ttotal: 51.7s\tremaining: 10.4s\n",
      "832:\tlearn: 0.0608649\ttotal: 51.7s\tremaining: 10.4s\n",
      "833:\tlearn: 0.0608375\ttotal: 52s\tremaining: 10.3s\n",
      "834:\tlearn: 0.0608085\ttotal: 52.1s\tremaining: 10.3s\n",
      "835:\tlearn: 0.0607922\ttotal: 52.2s\tremaining: 10.2s\n",
      "836:\tlearn: 0.0607788\ttotal: 52.2s\tremaining: 10.2s\n",
      "837:\tlearn: 0.0607533\ttotal: 52.3s\tremaining: 10.1s\n",
      "838:\tlearn: 0.0607418\ttotal: 52.4s\tremaining: 10s\n",
      "839:\tlearn: 0.0607401\ttotal: 52.4s\tremaining: 9.98s\n",
      "840:\tlearn: 0.0607028\ttotal: 52.5s\tremaining: 9.93s\n",
      "841:\tlearn: 0.0606726\ttotal: 52.6s\tremaining: 9.87s\n",
      "842:\tlearn: 0.0606623\ttotal: 52.7s\tremaining: 9.81s\n",
      "843:\tlearn: 0.0606409\ttotal: 52.8s\tremaining: 9.75s\n",
      "844:\tlearn: 0.0606089\ttotal: 52.8s\tremaining: 9.69s\n",
      "845:\tlearn: 0.0605917\ttotal: 52.9s\tremaining: 9.63s\n",
      "846:\tlearn: 0.0605652\ttotal: 53s\tremaining: 9.57s\n",
      "847:\tlearn: 0.0605319\ttotal: 53s\tremaining: 9.51s\n",
      "848:\tlearn: 0.0605071\ttotal: 53.1s\tremaining: 9.45s\n",
      "849:\tlearn: 0.0604798\ttotal: 53.2s\tremaining: 9.38s\n",
      "850:\tlearn: 0.0604751\ttotal: 53.2s\tremaining: 9.32s\n",
      "851:\tlearn: 0.0604661\ttotal: 53.3s\tremaining: 9.26s\n",
      "852:\tlearn: 0.0604647\ttotal: 53.4s\tremaining: 9.2s\n",
      "853:\tlearn: 0.0604441\ttotal: 53.5s\tremaining: 9.14s\n",
      "854:\tlearn: 0.0604210\ttotal: 53.5s\tremaining: 9.08s\n",
      "855:\tlearn: 0.0603813\ttotal: 53.6s\tremaining: 9.02s\n",
      "856:\tlearn: 0.0603569\ttotal: 53.7s\tremaining: 8.96s\n",
      "857:\tlearn: 0.0603222\ttotal: 53.7s\tremaining: 8.89s\n",
      "858:\tlearn: 0.0602867\ttotal: 53.8s\tremaining: 8.83s\n",
      "859:\tlearn: 0.0602643\ttotal: 53.9s\tremaining: 8.78s\n",
      "860:\tlearn: 0.0602296\ttotal: 54s\tremaining: 8.72s\n",
      "861:\tlearn: 0.0602191\ttotal: 54.1s\tremaining: 8.66s\n",
      "862:\tlearn: 0.0602085\ttotal: 54.2s\tremaining: 8.61s\n",
      "863:\tlearn: 0.0601934\ttotal: 54.3s\tremaining: 8.54s\n",
      "864:\tlearn: 0.0601802\ttotal: 54.4s\tremaining: 8.48s\n",
      "865:\tlearn: 0.0601537\ttotal: 54.5s\tremaining: 8.43s\n",
      "866:\tlearn: 0.0601358\ttotal: 54.6s\tremaining: 8.37s\n",
      "867:\tlearn: 0.0601004\ttotal: 54.7s\tremaining: 8.31s\n",
      "868:\tlearn: 0.0600700\ttotal: 54.7s\tremaining: 8.25s\n",
      "869:\tlearn: 0.0600160\ttotal: 54.8s\tremaining: 8.19s\n",
      "870:\tlearn: 0.0599986\ttotal: 54.8s\tremaining: 8.12s\n",
      "871:\tlearn: 0.0599898\ttotal: 54.9s\tremaining: 8.06s\n",
      "872:\tlearn: 0.0599789\ttotal: 55s\tremaining: 8s\n",
      "873:\tlearn: 0.0599603\ttotal: 55s\tremaining: 7.93s\n",
      "874:\tlearn: 0.0599433\ttotal: 55.1s\tremaining: 7.87s\n",
      "875:\tlearn: 0.0599361\ttotal: 55.2s\tremaining: 7.81s\n",
      "876:\tlearn: 0.0599177\ttotal: 55.2s\tremaining: 7.75s\n",
      "877:\tlearn: 0.0598907\ttotal: 55.3s\tremaining: 7.68s\n",
      "878:\tlearn: 0.0598566\ttotal: 55.3s\tremaining: 7.62s\n",
      "879:\tlearn: 0.0598423\ttotal: 55.4s\tremaining: 7.55s\n",
      "880:\tlearn: 0.0598359\ttotal: 55.5s\tremaining: 7.49s\n",
      "881:\tlearn: 0.0598159\ttotal: 55.5s\tremaining: 7.43s\n",
      "882:\tlearn: 0.0597683\ttotal: 55.6s\tremaining: 7.37s\n",
      "883:\tlearn: 0.0597359\ttotal: 55.7s\tremaining: 7.3s\n",
      "884:\tlearn: 0.0596964\ttotal: 55.7s\tremaining: 7.24s\n",
      "885:\tlearn: 0.0596697\ttotal: 55.8s\tremaining: 7.18s\n",
      "886:\tlearn: 0.0596532\ttotal: 55.8s\tremaining: 7.11s\n",
      "887:\tlearn: 0.0596462\ttotal: 55.9s\tremaining: 7.05s\n",
      "888:\tlearn: 0.0595499\ttotal: 56s\tremaining: 6.99s\n",
      "889:\tlearn: 0.0595287\ttotal: 56s\tremaining: 6.92s\n",
      "890:\tlearn: 0.0594795\ttotal: 56.1s\tremaining: 6.86s\n",
      "891:\tlearn: 0.0594576\ttotal: 56.1s\tremaining: 6.8s\n",
      "892:\tlearn: 0.0594339\ttotal: 56.2s\tremaining: 6.74s\n",
      "893:\tlearn: 0.0594244\ttotal: 56.3s\tremaining: 6.67s\n",
      "894:\tlearn: 0.0593931\ttotal: 56.3s\tremaining: 6.61s\n",
      "895:\tlearn: 0.0593668\ttotal: 56.4s\tremaining: 6.54s\n",
      "896:\tlearn: 0.0593485\ttotal: 56.4s\tremaining: 6.48s\n",
      "897:\tlearn: 0.0593331\ttotal: 56.5s\tremaining: 6.42s\n",
      "898:\tlearn: 0.0593065\ttotal: 56.6s\tremaining: 6.35s\n",
      "899:\tlearn: 0.0592826\ttotal: 56.6s\tremaining: 6.29s\n",
      "900:\tlearn: 0.0592404\ttotal: 56.7s\tremaining: 6.23s\n",
      "901:\tlearn: 0.0592078\ttotal: 56.7s\tremaining: 6.16s\n",
      "902:\tlearn: 0.0591551\ttotal: 56.8s\tremaining: 6.1s\n",
      "903:\tlearn: 0.0591386\ttotal: 56.8s\tremaining: 6.04s\n",
      "904:\tlearn: 0.0590990\ttotal: 56.9s\tremaining: 5.97s\n",
      "905:\tlearn: 0.0590807\ttotal: 57s\tremaining: 5.91s\n",
      "906:\tlearn: 0.0590667\ttotal: 57.1s\tremaining: 5.85s\n",
      "907:\tlearn: 0.0590417\ttotal: 57.1s\tremaining: 5.79s\n",
      "908:\tlearn: 0.0590266\ttotal: 57.2s\tremaining: 5.72s\n",
      "909:\tlearn: 0.0590106\ttotal: 57.2s\tremaining: 5.66s\n",
      "910:\tlearn: 0.0589994\ttotal: 57.3s\tremaining: 5.6s\n",
      "911:\tlearn: 0.0589897\ttotal: 57.3s\tremaining: 5.53s\n",
      "912:\tlearn: 0.0589756\ttotal: 57.4s\tremaining: 5.47s\n",
      "913:\tlearn: 0.0589584\ttotal: 57.5s\tremaining: 5.41s\n",
      "914:\tlearn: 0.0589449\ttotal: 57.5s\tremaining: 5.34s\n",
      "915:\tlearn: 0.0589181\ttotal: 57.6s\tremaining: 5.28s\n",
      "916:\tlearn: 0.0588965\ttotal: 57.7s\tremaining: 5.22s\n",
      "917:\tlearn: 0.0588682\ttotal: 57.7s\tremaining: 5.16s\n",
      "918:\tlearn: 0.0588504\ttotal: 57.8s\tremaining: 5.09s\n",
      "919:\tlearn: 0.0588228\ttotal: 57.8s\tremaining: 5.03s\n",
      "920:\tlearn: 0.0587883\ttotal: 57.9s\tremaining: 4.97s\n",
      "921:\tlearn: 0.0587334\ttotal: 58s\tremaining: 4.9s\n",
      "922:\tlearn: 0.0587115\ttotal: 58s\tremaining: 4.84s\n",
      "923:\tlearn: 0.0586965\ttotal: 58.1s\tremaining: 4.78s\n",
      "924:\tlearn: 0.0586719\ttotal: 58.2s\tremaining: 4.71s\n",
      "925:\tlearn: 0.0586486\ttotal: 58.2s\tremaining: 4.65s\n",
      "926:\tlearn: 0.0586183\ttotal: 58.3s\tremaining: 4.59s\n",
      "927:\tlearn: 0.0586035\ttotal: 58.3s\tremaining: 4.52s\n",
      "928:\tlearn: 0.0585708\ttotal: 58.4s\tremaining: 4.46s\n",
      "929:\tlearn: 0.0585399\ttotal: 58.4s\tremaining: 4.4s\n",
      "930:\tlearn: 0.0585177\ttotal: 58.5s\tremaining: 4.33s\n",
      "931:\tlearn: 0.0584950\ttotal: 58.6s\tremaining: 4.27s\n",
      "932:\tlearn: 0.0584642\ttotal: 58.6s\tremaining: 4.21s\n",
      "933:\tlearn: 0.0584371\ttotal: 58.7s\tremaining: 4.15s\n",
      "934:\tlearn: 0.0584225\ttotal: 58.8s\tremaining: 4.08s\n",
      "935:\tlearn: 0.0584098\ttotal: 58.8s\tremaining: 4.02s\n",
      "936:\tlearn: 0.0583959\ttotal: 58.9s\tremaining: 3.96s\n",
      "937:\tlearn: 0.0583721\ttotal: 58.9s\tremaining: 3.9s\n",
      "938:\tlearn: 0.0583519\ttotal: 59s\tremaining: 3.83s\n",
      "939:\tlearn: 0.0583385\ttotal: 59.1s\tremaining: 3.77s\n",
      "940:\tlearn: 0.0583152\ttotal: 59.1s\tremaining: 3.71s\n",
      "941:\tlearn: 0.0583067\ttotal: 59.2s\tremaining: 3.64s\n",
      "942:\tlearn: 0.0582989\ttotal: 59.3s\tremaining: 3.58s\n",
      "943:\tlearn: 0.0582568\ttotal: 59.3s\tremaining: 3.52s\n",
      "944:\tlearn: 0.0582298\ttotal: 59.4s\tremaining: 3.46s\n",
      "945:\tlearn: 0.0581898\ttotal: 59.4s\tremaining: 3.39s\n",
      "946:\tlearn: 0.0581552\ttotal: 59.5s\tremaining: 3.33s\n",
      "947:\tlearn: 0.0581378\ttotal: 59.6s\tremaining: 3.27s\n",
      "948:\tlearn: 0.0581196\ttotal: 59.6s\tremaining: 3.21s\n",
      "949:\tlearn: 0.0581047\ttotal: 59.7s\tremaining: 3.14s\n",
      "950:\tlearn: 0.0580908\ttotal: 59.8s\tremaining: 3.08s\n",
      "951:\tlearn: 0.0580861\ttotal: 59.8s\tremaining: 3.02s\n",
      "952:\tlearn: 0.0580606\ttotal: 59.9s\tremaining: 2.96s\n",
      "953:\tlearn: 0.0580606\ttotal: 60s\tremaining: 2.89s\n",
      "954:\tlearn: 0.0580371\ttotal: 1m\tremaining: 2.83s\n",
      "955:\tlearn: 0.0580104\ttotal: 1m\tremaining: 2.77s\n",
      "956:\tlearn: 0.0579824\ttotal: 1m\tremaining: 2.71s\n",
      "957:\tlearn: 0.0579539\ttotal: 1m\tremaining: 2.65s\n",
      "958:\tlearn: 0.0579329\ttotal: 1m\tremaining: 2.59s\n",
      "959:\tlearn: 0.0579038\ttotal: 1m\tremaining: 2.54s\n",
      "960:\tlearn: 0.0578819\ttotal: 1m 1s\tremaining: 2.48s\n",
      "961:\tlearn: 0.0578108\ttotal: 1m 1s\tremaining: 2.42s\n",
      "962:\tlearn: 0.0578021\ttotal: 1m 1s\tremaining: 2.36s\n",
      "963:\tlearn: 0.0578007\ttotal: 1m 1s\tremaining: 2.29s\n",
      "964:\tlearn: 0.0577727\ttotal: 1m 1s\tremaining: 2.23s\n",
      "965:\tlearn: 0.0577443\ttotal: 1m 1s\tremaining: 2.17s\n",
      "966:\tlearn: 0.0577310\ttotal: 1m 1s\tremaining: 2.1s\n",
      "967:\tlearn: 0.0577114\ttotal: 1m 1s\tremaining: 2.04s\n",
      "968:\tlearn: 0.0576906\ttotal: 1m 1s\tremaining: 1.98s\n",
      "969:\tlearn: 0.0576743\ttotal: 1m 2s\tremaining: 1.92s\n",
      "970:\tlearn: 0.0576533\ttotal: 1m 2s\tremaining: 1.86s\n",
      "971:\tlearn: 0.0576330\ttotal: 1m 2s\tremaining: 1.79s\n",
      "972:\tlearn: 0.0576146\ttotal: 1m 2s\tremaining: 1.73s\n",
      "973:\tlearn: 0.0575916\ttotal: 1m 2s\tremaining: 1.67s\n",
      "974:\tlearn: 0.0575637\ttotal: 1m 2s\tremaining: 1.6s\n",
      "975:\tlearn: 0.0575354\ttotal: 1m 2s\tremaining: 1.54s\n",
      "976:\tlearn: 0.0575108\ttotal: 1m 2s\tremaining: 1.47s\n",
      "977:\tlearn: 0.0574925\ttotal: 1m 2s\tremaining: 1.41s\n",
      "978:\tlearn: 0.0574663\ttotal: 1m 2s\tremaining: 1.35s\n",
      "979:\tlearn: 0.0574446\ttotal: 1m 2s\tremaining: 1.28s\n",
      "980:\tlearn: 0.0574216\ttotal: 1m 2s\tremaining: 1.22s\n",
      "981:\tlearn: 0.0573955\ttotal: 1m 2s\tremaining: 1.15s\n",
      "982:\tlearn: 0.0573393\ttotal: 1m 3s\tremaining: 1.09s\n",
      "983:\tlearn: 0.0573057\ttotal: 1m 3s\tremaining: 1.02s\n",
      "984:\tlearn: 0.0572662\ttotal: 1m 3s\tremaining: 962ms\n",
      "985:\tlearn: 0.0572462\ttotal: 1m 3s\tremaining: 898ms\n",
      "986:\tlearn: 0.0572225\ttotal: 1m 3s\tremaining: 834ms\n",
      "987:\tlearn: 0.0571970\ttotal: 1m 3s\tremaining: 770ms\n",
      "988:\tlearn: 0.0571834\ttotal: 1m 3s\tremaining: 706ms\n",
      "989:\tlearn: 0.0571558\ttotal: 1m 3s\tremaining: 642ms\n",
      "990:\tlearn: 0.0571273\ttotal: 1m 3s\tremaining: 577ms\n",
      "991:\tlearn: 0.0571128\ttotal: 1m 3s\tremaining: 513ms\n",
      "992:\tlearn: 0.0570872\ttotal: 1m 3s\tremaining: 449ms\n",
      "993:\tlearn: 0.0570630\ttotal: 1m 3s\tremaining: 385ms\n",
      "994:\tlearn: 0.0570406\ttotal: 1m 3s\tremaining: 321ms\n",
      "995:\tlearn: 0.0570179\ttotal: 1m 3s\tremaining: 257ms\n",
      "996:\tlearn: 0.0570078\ttotal: 1m 4s\tremaining: 193ms\n",
      "997:\tlearn: 0.0569862\ttotal: 1m 4s\tremaining: 128ms\n",
      "998:\tlearn: 0.0569674\ttotal: 1m 4s\tremaining: 64.2ms\n",
      "999:\tlearn: 0.0569419\ttotal: 1m 4s\tremaining: 0us\n",
      "CatBoostClassifier f1-score: 0.960\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cb = CatBoostClassifier(\n",
    "    random_state=26\n",
    ")\n",
    "\n",
    "cb.fit(X_train, y_train)\n",
    "y_pred = cb.predict(X_test)\n",
    "\n",
    "print('CatBoostClassifier f1-score: {:.3f}'.format(\n",
    "    metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.12\n",
    "\n",
    "Выведите матрицу ошибок для алгоритма, который получил наилучшие показатели качества модели на обучающей выборке (будем считать, что оцениваем по f1_score). Матрица ошибок выводится в следующем формате:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/8352c460ae8dce14e5f55dfe15ea4c25/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_6_2.png)\n",
    "\n",
    "**Подсказка**. Для того чтобы построить матрицу ошибок в CatBoost, необходимо использовать следующий шаблон:\n",
    "\n",
    "get_confusion_matrix(модель, Pool(признаки обучающей выборки, целевая переменная обучающей выборки))\n",
    "\n",
    "Более подробно построение матрицы ошибок можно изучить [в документации](https://catboost.ai/en/docs/concepts/python-reference_utils_get_confusion_matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46668.,   538.],\n",
       "       [ 1255., 34662.]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost.utils import get_confusion_matrix\n",
    "from catboost import Pool\n",
    "\n",
    "get_confusion_matrix(cb, Pool(X_train, y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.13\n",
    "\n",
    "Оцените важность признаков для модели из предыдущего задания. Отметьте признак, который оказывает наибольшее влияние на значение целевой переменной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imps = pd.DataFrame(\n",
    "    {'feature' : gs.best_estimator_.feature_names_in_,\n",
    "    'importance' : gs.best_estimator_.feature_importances_}\n",
    "    )\n",
    "feature_imps.sort_values(by='importance', ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Inflight wifi service</td>\n",
       "      <td>25.260967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Type of Travel</td>\n",
       "      <td>18.532444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer Type</td>\n",
       "      <td>7.373753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Online boarding</td>\n",
       "      <td>7.331027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Class_Business</td>\n",
       "      <td>5.520561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Checkin service</td>\n",
       "      <td>3.864023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age</td>\n",
       "      <td>3.791612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Baggage handling</td>\n",
       "      <td>3.586852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gate location</td>\n",
       "      <td>3.283956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Seat comfort</td>\n",
       "      <td>2.971680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Inflight service</td>\n",
       "      <td>2.795882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inflight entertainment</td>\n",
       "      <td>2.728494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>2.052656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flight Distance</td>\n",
       "      <td>1.684770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ease of Online booking</td>\n",
       "      <td>1.541662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Departure/Arrival time convenient</td>\n",
       "      <td>1.510603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cleanliness</td>\n",
       "      <td>1.456763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>On-board service</td>\n",
       "      <td>1.397187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Leg room service</td>\n",
       "      <td>1.262636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Arrival Delay in Minutes</td>\n",
       "      <td>0.897675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Departure Delay in Minutes</td>\n",
       "      <td>0.468728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Food and drink</td>\n",
       "      <td>0.326889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Class_Eco Plus</td>\n",
       "      <td>0.139761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Class_Eco</td>\n",
       "      <td>0.135045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.084373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature  importance\n",
       "6               Inflight wifi service   25.260967\n",
       "4                      Type of Travel   18.532444\n",
       "2                       Customer Type    7.373753\n",
       "11                    Online boarding    7.331027\n",
       "22                     Class_Business    5.520561\n",
       "17                    Checkin service    3.864023\n",
       "3                                 Age    3.791612\n",
       "16                   Baggage handling    3.586852\n",
       "9                       Gate location    3.283956\n",
       "12                       Seat comfort    2.971680\n",
       "18                   Inflight service    2.795882\n",
       "13             Inflight entertainment    2.728494\n",
       "0                                  id    2.052656\n",
       "5                     Flight Distance    1.684770\n",
       "8              Ease of Online booking    1.541662\n",
       "7   Departure/Arrival time convenient    1.510603\n",
       "19                        Cleanliness    1.456763\n",
       "14                   On-board service    1.397187\n",
       "15                   Leg room service    1.262636\n",
       "21           Arrival Delay in Minutes    0.897675\n",
       "20         Departure Delay in Minutes    0.468728\n",
       "10                     Food and drink    0.326889\n",
       "24                     Class_Eco Plus    0.139761\n",
       "23                          Class_Eco    0.135045\n",
       "1                              Gender    0.084373"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(   \n",
    "             {'feature' : X.columns,\n",
    "              'importance' : cb.feature_importances_}\n",
    ").sort_values('importance', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ Поздравляем, вы справились с достаточно сложной задачей и добились высокого качества выделения. Советуем не останавливаться на достигнутом и попробовать организовать наиболее посещаемый ансамбль. Тем не менее, будьте готовы: перебор гиперпараметров на большие объёмы данных занимает достаточно много времени.\n",
    "\n",
    "Уже в следующем юните вы изучите ещё один вид ансамблей и пополните свой арсенал алгоритмов →"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Стекинг"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущих юнитах мы разобрались с ансамблями, в которых объединение нескольких моделей одного типа помогает повысить качество предсказания при решении задачи регрессии или классификации. А что, если мы объединим модели двух или трёх типов (например, логистическую регрессию, метод опорных векторов и KNN)? Может быть, это сделает результат ещё лучше? Да, это действительно может помочь. В некоторых случаях очень полезно использовать различные виды моделей, чтобы повысить точность прогнозирования.\n",
    "\n",
    "? Тогда возникает следующий вопрос: как именно мы можем объединить несколько моделей разных типов?\n",
    "\n",
    "Здесь нам на помощь приходит **стекинг** — третий вид ансамблирования моделей. Принцип реализации стекинга мы уже обсудили в одном из предыдущих модулей, а в этом юните мы формализуем всё изученное в чёткий алгоритм и ещё раз закрепим этот материал. Математических выкладок здесь уже практически не будет, так как стекинг является абсолютной эвристикой, под которой нет никакого теоретического фундамента — его эффективность можно наблюдать только на практике.\n",
    "\n",
    "> **Стекинг** —  это агрегация ответов моделей машинного обучения. Подход использует понятие **базовых моделей**, каждая из которых обучается независимо от остальных, и **метамодели**, которая использует предсказания базовых моделей как признаки.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/760fd97b573f90a5da57e5829d6c3bbd/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_7_1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что мы обучили K базовых моделей $a_1 (x), ..., a_K (x)$ на некоторой выборке и теперь хотим использовать их результаты для обучения метамодели $f(x)$.\n",
    "\n",
    "Самый простой вариант — обучить метамодель на той же выборке. Тогда функция потерь будет выражаться следующим образом:\n",
    "\n",
    "$$\\sum_{i=1}^{N} L\\left(y_{i}, f\\left(a_{1}\\left(x_{i}\\right), \\ldots, a_{K}\\left(x_{i}\\right)\\right)\\right) \\rightarrow \\min _{f}$$\n",
    "\n",
    "→ В таком случае метамодель $f$ будет отдавать предпочтение тем базовым алгоритмам, которые сильнее других подстроились под целевую переменную при обучении, так как по их прогнозам проще всего предсказывать правильные ответы. Если среди базовых алгоритмов будет тот, который просто запомнил все ответы на обучающей выборке, то метаалгоритму будет проще всего использовать только прогнозы данного переобученного базового алгоритма, ведь такой подход будет давать максимальный результат. Но, разумеется, высокое качество в таком случае будет только на обучающей выборке — на тестовой оно будет значительно хуже.\n",
    "\n",
    "Поэтому важно отметить, что **базовые алгоритмы и метамодель должны обучаться на разных выборках**. \n",
    "\n",
    "Разобьём выборку на $L$ частей: $X_1, X_2, ..., X_L$. Пусть $a^{-l}_j (x)$ — это базовый $j$-й алгоритм, который обучен на всех подвыборках, кроме первой."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения метамодели мы будем минимизировать следующий функционал:\n",
    "\n",
    "$$\\sum_{l=1}^{L} \\sum_{\\left(x_{i}, y_{j}) \\in X_{l}\\right.} L\\left(y_{i}, f\\left(a_{1}^{-l}\\left(x_{i}\\right), \\ldots, a_{K}^{-l}\\left(x_{i}\\right)\\right)\\right) \\rightarrow \\min _{f}$$\n",
    "\n",
    "Как мы уже выяснили, чтобы избежать переобучения, необходимо обучать базовые модели и метамодель на разных выборках. Это можно делать с помощью **блендинга** или **стекинга**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## БЛЕНДИНГ\n",
    "\n",
    "> **Блендинг** является простейшей реализацией стекинга.\n",
    "\n",
    "Объясним его суть на **примере** ↓\n",
    "\n",
    "Предположим, у нас есть обучающая выборка $X$, которую мы делим пополам: первая часть используется для обучения базовых моделей, а на второй базовые модели делают предсказания — метапризнаки, на которых и обучается в дальнейшем метамодель."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формализовать этот алгоритм можно следующим образом:\n",
    "\n",
    "* Пусть у нас есть обучающая выборка $(X,y)$ и тестовая выборка $(X_{test}, y_{test})$.\n",
    "* Мы хотим использовать $K$ базовых моделей: $a_1 (x), a_2 (x), ..., a_K (x)$.\n",
    "* Делим обучающую выборку на две части: $(X_{train}, y_{train})$ и $(X_{meta}, y_{meta})$.\n",
    "* Введём для удобства обозначения: $(X_{train}, y_{train}) = A, \\ (X_{meta}, y_{meta}) = B, \\ (X_{test}, y_{test}) = C$.\n",
    "* Для каждой модели $a_i (x)$:\n",
    "    * Обучаем модель $a_i (x)$ на подвыборке $A$.\n",
    "    * Для каждого объекта из подвыборки $B$ делаем предсказание с помощью $a_i (x)$ — получаем столбец новых признаков для метамодели.\n",
    "    * Для каждого объекта из подвыборки $C$ делаем предсказание с помощью $a_i (x)$ — получаем ещё один столбец признаков для метамодели.\n",
    "* Итак, получили матрицу метапризнаков $B_{meta}$ из предсказаний $a_i (x)$ для подвыборки $B$ и матрицу метапризнаков $C_meta$ из предсказаний $a_i (x)$ для подвыборки $C$.\n",
    "* Обучаем метамодель на подвыборке $B_{meta}$.\n",
    "* С помощью обученной метамодели делаем предсказания для всех объектов из $C_{meta}$ — это и будут наши ответы."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно отметить, что для блендинга можно и нужно использовать базовые алгоритмы разной природы: например, вы можете объединять KNN, метод опорных векторов, решающие деревья и на результатах этих базовых алгоритмов обучать метамодель.\n",
    "\n",
    "Метамодель тоже может быть разной природы, но часто в качестве неё берут просто линейную модель:\n",
    "\n",
    "$$f(x) = \\sum^K_{i = 1} w_i a_i (x)$$\n",
    "\n",
    "Схематично описанный выше алгоритм можно изобразить следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/2d3283bba09d12ce993a7984cb111036/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_7_2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СТЕКИНГ\n",
    "\n",
    "К сожалению, у блендинга есть проблема: ни базовые модели, ни метамодель не обучаются на полных данных.\n",
    "\n",
    "Эту проблему решает **стекинг**.\n",
    "\n",
    "Чтобы в итоге все модели могли «познакомиться» с полным набором данных, можно использовать подход, аналогичный кросс-валидации: мы можем разделять выборку на $L$ частей, обучать модель на части $L-1$ и делать предсказание на оставшейся. Определённого правила для выбора количества частей нет, но, разумеется, чем больше их будет, тем выше будет качество (времени на обучение также будет потрачено больше)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм стекинга следующий:\n",
    "\n",
    "* Пусть у нас есть обучающая выборка $(X,y)$ и тестовая выборка $(X_{test}, y_{test})$.\n",
    "* Мы хотим использовать $K$ базовых моделей: $a_1 (x), a_2 (x), ..., a_K (x)$.\n",
    "* Делим обучающую выборку на $L$ частей: $A_1, A_2, ..., A_L$.\n",
    "* Для каждой части $A_i$ из $L$ частей обучающей выборки:\n",
    "    * Обучаем все $K$ базовых моделей на всех частях выборки, кроме $A_i$.\n",
    "    * Делаем предсказание для каждого объекта из подвыборки $A_i$.\n",
    "    * В итоге получаем новые признаки для метамодели.\n",
    "* Обучаем базовые модели на всей обучающей выборке $(X,y)$, делаем предсказание на тестовой выборке $(X_{test}, y_{test})$ и получаем метапризнаки для тестовой выборки — матрицу $C_{meta}$.\n",
    "* Обучаем метаалгоритм на новых признаках метамодели из обучающей выборки.\n",
    "* Делаем предсказание с помощью метаалгоритма для $C_{meta}$ — это и будут наши ответы.\n",
    "\n",
    "Схематично можно изобразить это так:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/fa4292a928728baaf9f760df93701a99/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_7_3.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несомненный **плюс стекинга** в том, что использование различных видов алгоритмов может помочь идентифицировать сложные зависимости. Например, ниже можно видеть иллюстрацию задачи классификации, где структура данных довольно сложная, но при использовании нескольких алгоритмов получается её выявить.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/fa8ea006a8565455c1182f447b19dc50/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_7_4.png)\n",
    "\n",
    "Также метод стекинга можно реализовать с более чем двумя уровнями — это называется **многоуровневым стекингом**. В таком случае мы определяем базовые модели, затем обучаем ряд метамоделей на результатах базовых моделей и в итоге обучаем конечную метамодель. Рассматривать и реализовывать такой подход мы не будем, так как улучшение качества будет незначительным, а вычислительные затраты — невероятно высокими.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/85b7891b4e235ec1c465f824a20e84e0/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_7_5.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, вы заметили, что принцип многоуровневого стекинга очень похож на принцип работы искусственных нейронных сетей, о которых мы говорили ранее в модуле про оптимизацию, и это действительно так.\n",
    "\n",
    "Давайте вспомним **плюсы и минусы стекинга**, которые мы уже рассматривали в предыдущих модулях:\n",
    "\n",
    "### Плюсы\n",
    "\n",
    "* хорошо параллелится (модели обучаются параллельно);\n",
    "* хорошо подходит для использования различных по природе базовых моделей.\n",
    "\n",
    "### Минусы\n",
    "\n",
    "* качество сильно зависит от качества базовых моделей;\n",
    "* плохо интерпретируемые результаты."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда теоретические основы изучены, наступает время **практики**: потренируемся в решении задач с использованием стекинга ↓\n",
    "\n",
    "Мы будем работать с [данными](https://lms.skillfactory.ru/assets/courseware/v1/a21a8975fee2a747c0a0f335a4a9e0f4/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/Frogs_MFCCs.zip), которые содержат информацию о звуках, издаваемых лягушками, и характеристики этих звуков.\n",
    "\n",
    "Необходимо **классифицировать семейства лягушек** в зависимости от особенностей их кваканья и прочих звуковых эффектов.\n",
    "\n",
    "Будем решать задачу бинарной классификации по выявлению лягушек, которые относятся к семейству 'Dendrobatidae' (признак 'Family'). Семейство 'Dendrobatidae' будет классом 1, все остальные семейства — классом 0.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/31b83e2f555ad8e55b31e3bb88f0ec58/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_7_6.jpg)\n",
    "\n",
    "Источник изображения\n",
    "В качестве признаков, которые мы будем использовать для предсказания, необходимо взять все, кроме:\n",
    "\n",
    "* 'Family' — семейство лягушек;\n",
    "* 'Genus' — род лягушек;\n",
    "* 'Species' — вид лягушек;\n",
    "* 'RecordID' — ID записи."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все остальные признаки относятся к акустическим особенностям кваканья — они-то нам и понадобятся, чтобы определить, к какому семейству относится лягушка.\n",
    "\n",
    "Разделите выборку на обучающую и тестовую в соотношении 80/20, параметр random_state = 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data/Frogs_MFCCs.zip')\n",
    "\n",
    "data.Family = data.Family.apply(\n",
    "    lambda x: 1 if x == 'Dendrobatidae' else 0)\n",
    "\n",
    "X = data.drop(columns = ['Family', 'Genus', 'Species', 'RecordID'])\n",
    "y = data.Family\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=31)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.5\n",
    "\n",
    "Для начала обучите на наших данных случайный лес с десятью решающими деревьями. Воспользуйтесь параметрами по умолчанию. В качестве значения random_state возьмите число 42.\n",
    "\n",
    "Оцените значение $F1$-меры и введите его в качестве ответа, предварительно округлив до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest F1-score: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print('RandomForest F1-score: {:.2}'.format(f1_score(y_pred, y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.6\n",
    "\n",
    "Теперь попробуем улучшить качество нашего предсказания за счёт использования стекинга.\n",
    "\n",
    "В качестве базовых моделей выберите следующие:\n",
    "\n",
    "* **случайный лес** с десятью деревьями, random_state = 31;\n",
    "* **KNN**, количество соседей = 11;\n",
    "* **наивный байесовский классификатор** с параметрами по умолчанию, в качестве метода возьмите GaussianNB().\n",
    "\n",
    "В качестве метамодели выберите логистическую регрессию.\n",
    "\n",
    "Обучите модели и сделайте предсказание целевой метки для тестового набора данных.\n",
    "\n",
    "Рассчитайте $F1$-меру для тестового набора данных и введите её в качестве ответа, предварительно **округлив до двух знаков после точки-разделителя**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking F1-score: 0.99\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=10,\n",
    "        random_state=31)),\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=11)),\n",
    "    ('nb', GaussianNB())\n",
    "]\n",
    "\n",
    "stacking = StackingClassifier(    \n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    ")\n",
    "\n",
    "stacking.fit(X_train, y_train)\n",
    "y_pred = stacking.predict(X_test)\n",
    "print('Stacking F1-score: {:.2}'.format(f1_score(y_pred, y_test)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, мы увидели, как сильно улучшает качество применение стекинга. Несмотря на недостатки этого метода (долгое обучение, необходимость подбора параметров, редкое использование на практике — зачастую лишь для того, чтобы добыть дополнительные баллы на Kaggle), в определённых ситуациях он может быть очень полезен. Если у вас достаточно вычислительных ресурсов, вы готовы потратить время на подбор моделей и параметров, а точность модели крайне важна, стекинг сослужит вам хорошую службу.\n",
    "\n",
    "Теперь, когда в вашем арсенале есть все ансамблевые методы, нам осталось лишь подвести итоги этого модуля →"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Итоги"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В этом модуле мы рассмотрели ансамблевые методы машинного обучения. Мы не только повторили основные концепции, но и разобрались с математическими основами алгоритмов.\n",
    "\n",
    "Давайте ещё раз посмотрим на те ансамбли, которые мы изучили:\n",
    "\n",
    "БЭГГИНГ\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/e62f9c293fb2c6ffd7e438197bf03e90/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_8_1.png)\n",
    "\n",
    "Параллельное обучение одинаковых алгоритмов. Результирующий прогноз формируется как среднее арифметическое моделей (случай регрессии) или по большему количеству голосов (случай классификации).\n",
    "\n",
    "БУСТИНГ\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/51c72308fa8d6dad07bd9a5f09a83ab6/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_8_2.png)\n",
    "\n",
    "Последовательное обучение одинаковых алгоритмов, каждый из которых исправляет ошибки предыдущих до достижения необходимого качества.\n",
    "\n",
    "СТЕКИНГ\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/7c28d960b938cd73e5908b9746548738/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md9_8_3.png)\n",
    "\n",
    "Параллельное и независимое обучение моделей (не обязательно одной природы), использование их как факторов для обучения метамодели, которая и формирует итоговый результат."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь для каждого ансамбля вы можете:\n",
    "\n",
    "* объяснить его суть и рассказать про стоящую за ним математическую составляющую;\n",
    "* применить его для решения задачи классификации и регрессии;\n",
    "* настроить гиперпараметры ансамбля так, чтобы получить наилучшее качество модели.\n",
    "\n",
    "Если вы хотите ознакомиться с дополнительными материалами, чтобы ещё больше углубить свои знания, рекомендуем обратить внимание на следующие статьи:\n",
    "\n",
    "* [О тонкостях настройки гиперпараметров в ансамблях](https://habr.com/ru/post/672486/)\n",
    "* [О развитии ансамблевых методов машинного обучения](https://www.researchgate.net/publication/278019662_Istoria_razvitia_ansamblevyh_metodov_klassifikacii_v_masinnom_obucenii)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ Поздравляем, вы справились со всеми заданиями, и теперь можно считать, что вы прекрасно разбираетесь в ансамблях моделей, а главное — понимаете их математические основы и сможете ответить даже на самые сложные вопросы на собеседовании при приёме на работу.\n",
    "\n",
    "Вы ещё встретитесь с ансамблями при выполнении проекта, а в следующих модулях вас ждёт увлекательное изучение математических тонкостей алгоритмов кластеризации →"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "950b5653ccfc34417735dd321d006fd482b31f7611416c3d8236dc5b17587d3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ML-2. Обучение с учителем: регрессия**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍В этом модуле мы начинаем знакомство с моделями машинного обучения. Как вы уже знаете, существует множество алгоритмов, позволяющих решать различные прикладные задачи.\n",
    "\n",
    "В первую очередь класс модели определяется категорией обучения. В этом модуле мы поговорим о тех алгоритмах, которые относятся к категории обучения с учителем, а именно — к задаче регрессии.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/2c3b5a00129b4dbedff6ed9fd2995cdb/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml1-3_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В категории обучения с учителем модели можно условно разделить на следующие основные типы:\n",
    "\n",
    "* Линейные модели: линейная регрессия (для задачи регрессии) и логистическая регрессия (для задачи классификации) и производные от них.\n",
    "* «Древесные» модели: дерево решений и производные от него. \n",
    "* Метрические алгоритмы: метод ближайших соседей и производные от него.\n",
    "* Байесовские методы: метод наивного Байеса и производные от него.\n",
    "* Ансамблевые методы: композиции из методов (бэггинг, стекинг, бустинг).\n",
    "\n",
    "В этом модуле мы поговорим о линейных моделях (но на самом деле ими не ограничимся), которые позволяют решать задачу регрессии.\n",
    "\n",
    "> **Линейные модели** — это модели, отображающие зависимость целевого признака от факторов в виде линейной взаимосвязи.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/a9936e92fb1b93f7dd5515bb546fbdcc/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-1_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном графике мы видим зависимость цены товара от его размера. Из диаграммы рассеяния видно, что в среднем точки расположены на одной прямой линии. То есть зависимость линейная.\n",
    "\n",
    "Подкласс линейных моделей в свою очередь содержит множество конкретных моделей. В библиотеке sklearn, которую мы будем использовать, все линейные алгоритмы содержатся в модуле [linear_model](https://scikit-learn.ru/1-1-linear-models/). \n",
    "\n",
    "### ЦЕЛИ ДАННОГО МОДУЛЯ:\n",
    "\n",
    "1. Познакомиться с принципами работы модели линейной регрессии для решения задачи регрессии.\n",
    "2. Рассмотреть аналитическое (метод наименьших квадратов) и численное (градиентный спуск) решение задачи поиска параметров модели.\n",
    "3. Познакомиться с метриками регрессии.\n",
    "4. Изучить понятия bias и variance и понять причины недообучения и переобучения линейной регрессии.\n",
    "5. Рассмотреть полиномиальную регрессию как метод усложнения модели.\n",
    "6. Познакомиться с регуляризацией и рассмотреть её основные методы.\n",
    "7. Научиться решать задачи регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Линейная регрессия: аналитическое решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Для начала давайте вспомним, что такое задача регрессии в машинном обучении.\n",
    "\n",
    "> **Регрессия** — это класс задач обучения с учителем, когда по определённому набору признаков объекта необходимо предсказать числовую целевую переменную.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/7feb9c1039cfe25f8efb02994733047f/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml1-3_5.png)\n",
    "\n",
    "**Цель обучения** — построить модель, которая бы отражала зависимость между признаками и целевой числовой переменной.\n",
    "\n",
    "Когда зависимость принимается линейной, такая модель называется **линейной регрессией**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ОБЩЕЕ ПРЕДСТАВЛЕНИЕ О ЛИНЕЙНОЙ РЕГРЕССИИ\n",
    "\n",
    "> **Линейная регрессия (Linear Regression)** — одна из простейших моделей для решения задачи регрессии. Главная гипотеза состоит в том, что рассматриваемая зависимость является линейной.\n",
    "\n",
    "Общий вид модели в случае, когда целевая переменная зависит от  факторов, будет иметь следующий вид:\n",
    "\n",
    "$$\\hat{y} = w_{0} + w_{1}x_{0} + w_{2}x_{2} + ... + w_{m}x_{m}$$\n",
    "\n",
    "Давайте разбираться, что в этом выражении значит каждая из переменных. Начнём с простого — с двумерного случая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D-СЛУЧАЙ\n",
    "\n",
    "Для начала поговорим о самом простом случае, когда у нас есть один фактор и зависящий от него целевой признак. Геометрически такая зависимость представляет собой координатную плоскость, где мы отмечаем точки по оси x и соответствующие им точки на оси y.\n",
    "\n",
    "Рассмотрим задачу из нефтяной отрасли. Есть набор данных, где представлены данные о средней пористости скважин (в процентах) и добыче газа на этих скважинах в сутки (в миллионах кубических футов). \n",
    "\n",
    "Нам бы хотелось построить модель, которая опишет зависимость и позволит по известной пористости скважин предсказывать неизвестную выработку газа.\n",
    "\n",
    "Зависимость целевого признака от фактора представлена на диаграмме рассеяния (см. ниже). Пористость скважины отложена по оси абсцисс — Porosity (%), а добыча газа — по оси ординат, Gas production (Mcf/day).\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5aac4f0c35432b4d259b26227fe41e59/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-2_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из диаграммы отчётливо видно, что с ростом пористости скважины растёт добыча газа. Причём растёт она преимущественно линейно: основная масса точек находится на одной прямой.\n",
    "\n",
    "Идея! Давайте проведём через точки прямую линию так, чтобы она максимально хорошо описывала зависимость.\n",
    "\n",
    "Для этого сначала вспомним уравнение прямой из школьного курса математики:\n",
    "\n",
    "$$y=kx+b$$\n",
    "\n",
    "где:\n",
    "\n",
    "* $x$ — это некоторый фактор, от которого зависит целевая переменная $y$. В нашем случае, $x$ — это пористость скважины, а $y$ — добыча газа.\n",
    "* $k$ — коэффициент наклона прямой (тангенс угла наклона). Если $k>0$, это означает, что угол наклона прямой острый и прямая возрастает. Если $k<0$, угол наклона тупой и прямая убывает.\n",
    "* $b$ — коэффициент смещения прямой по оси $y$. Он будет соответствовать значению $y$ при $x=0$. То есть это точка пересечения прямой и оси Y.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/efff3f61af4a7ba5499bb204d8c61aeb/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-2_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном графике изображены две прямые с разными коэффициентами наклона. Зелёная прямая соответствует положительному значению $k_1>0$, и геометрически $k_1$ равен тангенсу острого угла $\\alpha_1$ наклона прямой по отношению к оси x: $k_1=tg(\\alpha_1)$. Синяя прямая соответствует отрицательному значению $k_2<0$, и геометрически $k_2$ равен тангенсу тупого угла $\\alpha_2$ наклона прямой по отношению к оси x: $k_2=tg(\\alpha_2)$. Каждая из прямых пересекается с осью y в точках $b_1$ и $b_2$ — это и есть **коэффициент смещения прямых**.\n",
    "\n",
    "Это уравнение и есть двумерная модель линейной регрессии. Зная коэффициенты $k$ и $b$, мы можем подставить в него любую пористость скважины x и получить предсказание добычи газа y.\n",
    "\n",
    "Однако в машинном обучении приняты немного другие обозначения. Фактическое значение целевой переменной обозначается как $y$, а вот предсказанное моделью — $\\hat{y}$. Также для удобства коэффициенты $k$ и $b$ приведём к единому обозначению: $w_0=b$ и $w_1=k$. Тогда уравнение модели линейной регрессии запишется в виде:\n",
    "\n",
    "$$\\hat{y} = w_{0} + w_{1}x$$\n",
    "\n",
    "**Примечание**. Коэффициенты $w_0$ и $w_2$ называются **параметрами линейной регрессии**.\n",
    "\n",
    "Остаётся только один вопрос: откуда, собственно, взять параметры $w_0$ и $w_1$? Обсудим этот вопрос чуть позже.\n",
    "\n",
    "А пока представим, что параметры мы нашли. В таком случае можно построить прямую, которая опишет нашу зависимость. Пусть коэффициенты составляют (мы их нашли сами по методу наименьших квадратов, о котором поговорим ниже):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_{0} = -2.94$$ \n",
    "$$w_{1} = 287.7$$\n",
    "\n",
    "Тогда модель будет иметь следующий вид:\n",
    "\n",
    "$$\\hat{y} = 287.7x - 2.94$$\n",
    "\n",
    "Если подставлять значения конкретные значения пористости $x$ в модель, можно построить прямую, которая описывает исходную зависимость. Это и будет графическая интерпретация нашей модели:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/68be2a900a484a12681d3e6d5be5fc3b/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-2_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D-СЛУЧАЙ\n",
    "\n",
    "Теперь представим, что у нас не один фактор, а два. Например, помимо пористости скважины, мы дополнительно знаем ещё и о её хрупкости в процентах. То есть у нас теперь есть два фактора: $x_1$ — пористость и $x_2$ — хрупкость.\n",
    "\n",
    "Можно отобразить такую зависимость добычи газа от этих факторов в трёхмерном пространстве в виде диаграммы рассеяния:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/241e1620934df4bea3c70cd4d37ac1d7/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-2_4.png)\n",
    "\n",
    "В таком случае в выражение для модели добавится ещё одна переменная $x_2$ и соответствующий ей коэффициент $w_2$:\n",
    "\n",
    "Опять же, представим, что параметры модели мы нашли и они равны:\n",
    "\n",
    "$$w_{0} = -2003$$\n",
    "$$w_{1} = 302.3$$\n",
    "$$w_{2} = 31.38$$\n",
    "\n",
    "Тогда модель будет иметь следующий вид:\n",
    "\n",
    "$$\\hat{y} = 302.3x_{1} + 31.38x_{2} - 2003$$\n",
    "\n",
    "Это была алгебра — теперь перейдём к геометрии. Геометрически данное уравнение описывает плоскость в трёхмерном пространстве с осями $x_1$ и $x_2$, $w_0$ — смещение плоскости по вертикальной оси, а коэффициенты $w_1$ и $w_2$ — коэффициенты наклона этой плоскости к осям $x_1 и $x_2$. \n",
    "\n",
    "То это это будет плоскость, которая подстроена под точки в трёхмерном пространстве:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5e86dbff46a7bda35c15bf2c88738e67/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-2_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ОБЩИЙ СЛУЧАЙ\n",
    "\n",
    "А что если факторов не два, а больше: 3, 15, 100? Тут-то мы и приходим к общему виду модели линейной регрессии, который вводили в самом начале. Пусть у нас есть $m$ факторов $\\left \\{ x_{1}, x_{2}, ..., x_{m} \\right \\}$, от которых зависит целевая переменная .\n",
    "\n",
    "В геометрическом смысле данное уравнение описывает плоскость в $(m+1)$-мерном пространстве ($m$ факторов + $1$ целевой признак отложены по осям координат). Такую плоскость называют гиперплоскостью.\n",
    "\n",
    "Абстрактное $(m+1)$-мерное пространство, конечно же, невозможно отобразить графически и сложно даже представить, как оно выглядит. Но нам это и не нужно. Все операции в таком пространстве аналогичны операциям в двумерном или трёхмерном пространстве.\n",
    "\n",
    "→ Для понимания принципа работы мы будем рассматривать только прямую в двумерном пространстве, а результат уже обобщать на случай с большей размерностью.\n",
    "\n",
    "Стоит отметить, что в DS мы, как правило, работаем с большим количеством факторов (больше двух), которые описывают данные, поэтому отобразить модель в геометрическом пространстве не получится, но важно понимать, что представляет собой сама модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПОИСК ПАРАМЕТРОВ ЛИНЕЙНОЙ РЕГРЕССИИ: МЕТОД НАИМЕНЬШИХ КВАДРАТОВ\n",
    "\n",
    "Теперь мы знаем, как выглядит модель линейной регрессии в общем случае: это простое линейное выражение, подставляя в которое значения факторов, можно найти целевую переменную. Это линейное выражение соответствует прямой, плоскости или гиперплоскости в зависимости от количества признаков.\n",
    "\n",
    "Остаётся вопрос: **откуда взять коэффициенты, которые стоят при $x$**?\n",
    "\n",
    "Прямую же можно провести как угодно. Вот например несколько прямых, построенных с различными случайными коэффициентами:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/6540d6365f43f4ee183feaa68b9a46c2/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-2_6.png)\n",
    "\n",
    "Какие параметры будут наилучшими?\n",
    "\n",
    "Для ответа на этот вопрос давайте вспомним схему обучения моделей машинного обучения по принципу минимизации эмпирического риска, которую мы рассматривали в предыдущем модуле:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5fac5fe11d423f674949523e3db643c9/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml1-2_1.png)\n",
    "\n",
    "Согласно данной схеме обучения, поиск параметров производится путём минимизации некоторой функции ошибки. Математически мы пытаемся с помощью методов оптимизации найти такие параметры, чтобы ошибка была наименьшей из возможных.\n",
    "\n",
    "Осталось только понять: где взять эту функцию ошибки? Ответ кроется в картинке ниже. Давайте представим, как могла бы выглядеть прямая в двумерном пространстве, проведённая, например, через пять точек:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5fec239cc84df5a5cd29cab48650641d/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-2_7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Что вообще есть ошибка? В самом простом понимании это расхождение между истиной и предсказанием.\n",
    "\n",
    "Чтобы не учитывать знак расхождения, можно взять модуль разницы между истинным значением и предсказанным (тем, что лежит на прямой). Рассчитать ошибки   (на рисунке они отмечены красными отрезками) для всех пяти точек можно следующим образом:\n",
    "\n",
    "$$e_{i} = \\left | y_{i} - \\hat{y_{i}} \\right |,$$\n",
    "\n",
    "где $y_i$ — это результат подстановки $i$-ого значения  в модель линейной регрессии.\n",
    "\n",
    "Вычислим среднее по всем ошибкам. Такая ошибка называется **средняя абсолютная ошибка (Mean Absolute Error, MAE)** и записывается следующим образом (в двумерном случае):\n",
    "\n",
    "$$M A E=\\frac{\\sum_{i=1}^{n} e_{i}}{n} = \\frac{\\sum_{i=1}^{n}\\left|y_{i}-\\hat{y}_{i}\\right|}{n}=\\frac{\\sum_{i=1}^{n}\\left|y_{i}-w_{0}-w_{1} x_{i}\\right|}{n}$$\n",
    "\n",
    "Осталось только найти такие  и , при которых MAE была бы минимальной. В математике это записывается следующим образом:\n",
    "\n",
    "$$M A E=\\frac{\\sum_{i=1}^{n} e_{i}}{n} = \\frac{\\sum_{i=1}^{n}\\left|y_{i}-\\hat{y}_{i}\\right|}{n}=\\frac{\\sum_{i=1}^{n}\\left|y_{i}-w_{0}-w_{1} x_{i}\\right|}{n} \\rightarrow \\min _{w}$$\n",
    "\n",
    "→ Тут-то математики и столкнулись с проблемой. Оказывается, если пытаться решить эту оптимизационную задачу классическими способами (через условия [экстремума функции](https://ru.wikipedia.org/wiki/%D0%AD%D0%BA%D1%81%D1%82%D1%80%D0%B5%D0%BC%D1%83%D0%BC)), то поиск решения будет противоречить основным законам математического анализа. Почему? Обсудим это в модулях по математике, когда будем решать оптимизационные задачи.\n",
    "\n",
    "ОТВЕТ ДЛЯ ЛЮБОЗНАТЕЛЬНЫХ\n",
    "\n",
    "Функция модуля является недифференцируемой в точке 0, то есть не имеет производной. Классическая оптимизационная задача решается через равенство производной функции нулю. Поиск производной может обернуться математическим противоречием.\n",
    "\n",
    "Проблему с MAE можно решить, но всё же она используется гораздо реже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но математикам, конечно, удалось найти выход. Вместо модуля можно использовать квадрат — он тоже убирает знак ошибки и по сути аналогичен модулю. Получим **среднеквадратичную ошибку (Mean Square Error, MSE)**:\n",
    "\n",
    "$$M S E=\\frac{\\sum_{i=1}^{n} e_{i}^2}{n} = \\frac{\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^2}{n}=\\frac{\\sum_{i=1}^{n}(y_{i}-w_{0}-w_{1} x_{i})^2}{n}$$\n",
    "\n",
    "Это и будет наша функция ошибки, которую мы будем минимизировать, управляя параметрами  и :\n",
    "\n",
    "$$M S E=\\frac{\\sum_{i=1}^{n} e_{i}^2}{n} = \\frac{\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^2}{n}=\\frac{\\sum_{i=1}^{n}(y_{i}-w_{0}-w_{1} x_{i})^2}{n} \\rightarrow \\min _{w}$$\n",
    "\n",
    "**Примечание**. В общем случае, когда X — это таблица из  наблюдений и  признаков, постановка задачи оптимизации MSE выглядит следующим образом:\n",
    "\n",
    "$$M S E=\\frac{\\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i})^2}{n}=\\frac{\\sum_{i=1}^{n}(y_{i}-w_{0}-\\sum_{j=1}^{m}w_{j}x_{ij})^2}{n} \\rightarrow \\min _{w},$$\n",
    "\n",
    "где $x_{ij}$ — это значение, которое находится в $i$-ой строке и $j$-ом столбце таблицы наблюдений.\n",
    "\n",
    "Математике известно решение данной задачи оптимизации. Метод поиска параметров линейной регрессии называется **методом наименьших квадратов** (сокращённо — **МНК**) и был изобретён Гауссом ещё в 1795 году. В английской литературе часто можно встретить аббревиатуру *OLS (Ordinary Least Squares)*.\n",
    "\n",
    "→ Решать саму задачу поиска минимума функции мы сейчас не будем, так как пока что не владеем достаточными для её решения знаниями о частной производной и условиях экстремума функции многих переменных, но приведём финальный ответ, полученный для общего случая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, пусть у нас есть матрица X, в которой по строкам собрано  наблюдений, а по столбцам отложено  факторов — по сути, это обычный, привычный нам DataFrame. К каждому примеру из таблицы X есть ответ y.\n",
    "\n",
    "Зависимость между факторами и целевым признаком принята линейной, то есть рассматривается обучение модели линейной регрессии:\n",
    "\n",
    "$$\\hat{y} = w_{0} + w_{1}x_{1} + w_{2}x_{2} + ... + w_{m}x_{m} = \\bar{w} \\cdot \\bar{x}$$\n",
    "\n",
    "$\\bar{w} = (w_{0}, w_{1}, w_{2}, ..., w_{m})$ — вектор параметров\n",
    "\n",
    "$\\bar{w} = (w_{0}, w_{1}, w_{2}, ..., w_{m})$ — вектор ризнаков\n",
    "\n",
    "Мы хотим найти наилучшую оценку для $w_{0}, w_{1}, w_{2}, ..., w_{m}$.\n",
    "\n",
    "**Примечание**. Для того чтобы конечная запись формулы была короче и можно было включить в вектор  коэффициент смещения прямой , в матрицу X первым добавляют столбец, полностью состоящий из единиц. Это связано со спецификой матричного умножения, о котором мы поговорим далее в курсе.\n",
    "\n",
    "Согласно методу наименьших квадратов, аналитическое выражение для поиска вектора коэффициентов уравнения линейной регрессии имеет вид:\n",
    "\n",
    "$$\\bar{w} = (X^{T}X)^{-1} X^{T}y = QX^{T}y$$\n",
    "\n",
    "Данная матричная формула позволяет найти неизвестные параметры линейной регрессии в виде вектора $w=(w_{0}, w_{1}, w_{2}, ..., w_{m})$. Найденные коэффициенты называют решением задачи линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Верхний индекс T у матрицы X означает **транспонирование матриц** — смену строк и столбцов местами (поворот таблицы). Пример:\n",
    "\n",
    "$$\\begin{pmatrix} -2 & 3 & 1 \\\\ 0 & -1 & -3 \\end{pmatrix} = \\begin{pmatrix} -2 & 0\\\\ 3 & -1\\\\ 1 & -3 \\end{pmatrix}$$\n",
    "\n",
    "> Операция возведения матриц в степень -1 называется **обращением матриц**. Полученная в результате матрица называется **обратной** к исходной. Так, матрица $(X^TX)^{-1}$ является обратной к матрице $X^TX$.\n",
    "\n",
    "Саму процедуру обращения матриц мы будем рассматривать в модуле по линейной алгебре. Сейчас же для проведения этой операции мы будем использовать библиотеку *numpy*, которая позволяет очень быстро и просто обращать матрицы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## АНАЛИТИЧЕСКОЕ РЕШЕНИЕ С ПОМОЩЬЮ NUMPY\n",
    "\n",
    "Перейдём к практической части. Давайте научимся строить аналитическое решение линейной регрессии по МНК в Python.\n",
    "\n",
    "Вот какие этапы нам предстоит пройти, чтобы построить свою модель:\n",
    "\n",
    "1. Загрузить данные и проанализировать датасет на предмет пропусков.\n",
    "2. Подготовить данные для подачи в модель: избавиться от пропусков, если они есть, и перекодировать категориальные признаки, если они представлены текстом.\n",
    "3. Построить модель. Будем строить несколько моделей линейной регрессии: первую — на одном признаке, вторую — на всех доступные признаках.\n",
    "4. Оценить качество модели.\n",
    "\n",
    "Для начала импортируем необходимые вспомогательные библиотеки:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') #установка стиля matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с датасетом из библиотеки sklearn о домах в Бостоне. Этот набор данных содержит информацию, собранную службой переписи населения США и касающуюся жилья в районе Бостона, штат Массачусетс.\n",
    "\n",
    "Данный датасет содержится в модуле datasets библиотеки sklearn. Давайте загрузим датасет с помощью функции load_boston() и выведем его описание, обратившись по ключу 'DESCR':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston \n",
    "boston = load_boston()\n",
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном описании говорится, что у нас есть 506 участков с жилыми домами, которые описываются 13-ю признаками. На каждом из участков находится несколько домов. Измерены общие показатели по каждому из участков, в том числе медианная стоимость.\n",
    "\n",
    "Задача — научить модель предсказывать медианную стоимость дома на участке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Краткое описание признаков набора данных\n",
    "\n",
    "* CRIM — уровень преступности на душу населения по городам.;\n",
    "* ZN — доля земли под жилую застройку, разделённая на участки площадью более 25 000 кв. футов;\n",
    "* INDUS — доля акров, которые принадлежат предприятиям, не связанным с розничной торговлей, на город;\n",
    "* CHAS —фиктивная переменная реки Чарльз (1 — если участок прилегает к реке; 0 — в противном случае);\n",
    "* NOX —концентрация оксидов азота (в десятимиллионных долях);\n",
    "* RM —среднее количество комнат в доме;\n",
    "* AGE —доля зданий, построенных до 1940 г. и занимаемых владельцами;\n",
    "* DIS — взвешенные расстояния до пяти бостонских центров занятости;\n",
    "* RAD — индекс доступности радиальных автомобильных дорог;\n",
    "* TAX — полная ставка налога на имущество за каждые 10 000 долларов стоимости;\n",
    "* PTRATIO — соотношение учеников и учителей по городам;\n",
    "B — 1000 (Bk — 0.63) , где Bk — доля граждан афроамериканского происхождения по городам;\n",
    "* LSTAT — процент населения с низким статусом;\n",
    "* MEDV — медианное значение стоимости домов, занимаемых владельцами, в тысячах долларов США (целевой признак)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим DataFrame из наших данных. Для этого обратимся по ключу 'data' к загруженным данным и получим numpy-массив, в котором содержится информация обо всех признаках, а по ключу 'feature_names' содержатся названия признаков. Обратившись по ключу 'target', можно получить numpy-вектор со значениями целевой переменной — медианной стоимости занимаемых домов (MEDV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создаём DataFrame из загруженных numpy-матриц\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "#добавляем в таблицу столбец с целевой переменной\n",
    "boston_data['MEDV'] = boston.target\n",
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем информацию о таблице boston_data с помощью метода info():\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "boston_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Модель линейной регрессии требует, чтобы в подаваемых ей на вход данных не было пропущенных значений. Поэтому если в ваших данных окажутся пропуски, обязательно заранее позаботьтесь о них (способы мы изучали в модуле по очистке данных).\n",
    "\n",
    "Итак, в наших данных нет пропусков, а значит их можно подавать в модель, чтобы обучить её предсказывать целевой признак (признак MEDV).\n",
    "\n",
    "Также модель не умеет работать с категориальными признаками, представленными в виде типа object. Прежде чем подавать в модель линейной регрессии категориальные признаки, необходимо произвести кодировку категорий с помощью уже знакомых вам методов кодирования.\n",
    "\n",
    "→ Давайте начнём с простого. Построим линейную регрессию на одном признаке. Выберем признак, который имеет наиболее высокую линейную взаимосвязь. Для этого рассчитаем корреляцию признаков с целевой переменной и выберем наиболее влиятельный.\n",
    "\n",
    "Для лучшего восприятия давайте построим столбчатую диаграмму для модульного значения корреляций:\n",
    "\n",
    "**Примечание**. Мы могли визуализировать матрицу корреляций, однако сейчас нас интересует только связь факторов с целевым признаком, поэтому нагляднее будет воспользоваться столбчатой диаграммой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Вычисляем модуль корреляции\n",
    "corr_with_target = boston_data.corr()['MEDV'].abs().sort_values()\n",
    "#Удаляем корреляцию целевой переменной с самой собой\n",
    "corr_with_target = corr_with_target.drop('MEDV')\n",
    "#Строим столбчатую диаграмму корреляций\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) #фигура+координатная плоскость\n",
    "ax.bar(corr_with_target.index, corr_with_target.values) #столбчатая диаграмма\n",
    "ax.set_title('Correlations with target') #название графика\n",
    "ax.set_xlabel('Feature') #название оси x\n",
    "ax.set_ylabel('Сorrelation coefficient'); #название оси y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, самый коррелированный по модулю с медианной ценой (MEDV) признак — процент населения с низким статусом (LSTAT). Давайте построим линейную регрессию, используя этот признак.\n",
    "\n",
    "**Примечание**. Построить линейную регрессию = обучить линейную регрессию = найти её параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспоминаем нашу формулу аналитического решения по методу наименьших квадратов:\n",
    "\n",
    "$$\\bar{w} = (X^{T}X)^{-1} X^{T}y = QX^{T}y$$\n",
    "\n",
    "Что есть $X$ и $y$? Это матрица из примеров (матрица наблюдений) и вектор правильных ответов к ним соответственно. У нас матрица $X$ — это таблица, состоящая из одного столбца (LSTAT), а $y$ — столбец с медианными ценами (MEDV):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LSTAT\n",
       "0   4.98\n",
       "1   9.14\n",
       "2   4.03\n",
       "3   2.94\n",
       "4   5.33"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston_data[['LSTAT']] #матрица наблюдений\n",
    "y = boston_data['MEDV'] #вектор правильных ответов\n",
    "X.head()\n",
    "#y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Двойные квадратные скобки ```boston_data[['LSTAT']]``` позволяют выбрать признак из DataFrame, сохранив его в виде таблицы. Это важно, так как в формуле МНК $X$ — это матрица.\n",
    "\n",
    "У нас есть все компоненты формулы, чтобы найти параметры модели. Давайте напишем функцию linear_regression(), в которой реализуем вычисления коэффициентов. Аргументами функции будут матрица наблюдений X и вектор ответов y, а возвращать она будет вектор параметров w.\n",
    "\n",
    "Матричные вычисления легче всего реализовать через библиотеку numpy.\n",
    "\n",
    "Для начала вспомним, что для вычисления свободного члена $w_0$ необходимо добавить в таблицу столбец, полностью состоящий из единиц. Такой столбец можно создать с помощью знакомой нам функции ones() из библиотеки numpy, а присоединить его к таблице X поможет функция column_stack().\n",
    "\n",
    "Матричное умножение в numpy реализуется с помощью оператора @. Транспонирование осуществляется через .T, а обратная матрица вычисляется с помощью функции inv() из модуля linalg (модуля для линейной алгебры)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y):\n",
    "    #Создаём вектор из единиц\n",
    "    ones = np.ones(X.shape[0])\n",
    "    #Добавляем вектор к таблице первым столбцом\n",
    "    X = np.column_stack([ones, X])\n",
    "    #Вычисляем обратную матрицу Q\n",
    "    Q = np.linalg.inv(X.T @ X)\n",
    "    #Вычисляем вектор коэффициентов\n",
    "    w = Q @ X.T @ y\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось только вызвать нашу функцию и передать в неё нашу таблицу примеров X и столбец правильных ответов y. Вычислим вектор параметров и выведем его на экран:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector w: [34.55384088 -0.95004935]\n",
      "w0: 34.55\n",
      "w1: -0.95\n"
     ]
    }
   ],
   "source": [
    "#Вычисляем параметры линейной регрессии\n",
    "w = linear_regression(X, y)\n",
    "#Выводим вычисленные значения параметров в виде вектора\n",
    "print('Vector w: {}'.format(w))\n",
    "#Выводим параметры с точностью до двух знаков после запятой\n",
    "print('w0: {:.2f}'.format(w[0]))\n",
    "print('w1: {:.2f}'.format(w[1]))\n",
    "# Vector w: [34.55384088 -0.95004935]\n",
    "# w0: 34.55\n",
    "# w1: -0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили значения коэффициентов уравнения прямой. С точностью до сотых они равны:\n",
    "\n",
    "$$w_{0} = 34.55$$\n",
    "$$w_{1} = -0.95$$\n",
    "\n",
    "А значит сама модель будет иметь вид:\n",
    "\n",
    "$$\\hat{y} = 34.55 - 0.95x_{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое приятное в модели линейной регрессии — то, что её коэффициенты можно проинтерпретировать. \n",
    "\n",
    "Коэффициент $w_0=34.55$ имитирует влияние сторонних факторов, которые не учтены в модели. Это значение медианной цены домов на участке, если бы значение процента населения с низким статусом было равно 0. \n",
    "\n",
    "Коэффициент $w_1=-0.95$ означает, на сколько в среднем изменится медианная цена (в тысячах долларов) при увеличении низкостатусного населения на 1 единицу. То есть если количество низкостатусного населения увеличится на 1 %, то медианная цена зданий на участке упадёт на 0.95 тысяч долларов. Можно сказать, что каждый новый процент низкостатусного населения уменьшает медианную цену на 0.95 тысяч долларов.\n",
    "\n",
    "Теперь, если в данных появится новый участок Бостона с известной долей низкостатусного населения, мы сможем предсказать значение медианной стоимости домов простой подстановкой значений в модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 29.63\n"
     ]
    }
   ],
   "source": [
    "#Задаём процент низкостатусного населения\n",
    "x_example = 5.18 \n",
    "#Делаем предсказание\n",
    "y_predict = w[0] + w[1] * x_example\n",
    "print('Predicted value: {:.2f}'.format(float(y_predict)))\n",
    "# Predicted value: 29.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы работаем с одним фактором, то можем построить визуализацию нашей модели.\n",
    "\n",
    "Давайте напишем функцию plot_regression_2d(), у которой будет три обязательных аргумента (матрица наблюдений X, столбец правильных ответов y и столбец с предсказаниями модели y_pred) и два аргумента по умолчанию (xlabel — подпись оси абсцисс и ylabel — подпись оси ординат)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_2d(X, y_true, y_predict, xlabel='LSTAT', ylabel='MEDV'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 4)) #фигура + координатная плоскость\n",
    "    ax.scatter(X, y_true, alpha=0.7, label='Sample data') #диаграмма рассеяния\n",
    "    ax.plot(X, y_predict, color='black', label='Regression model') #линейный график\n",
    "    ax.set_xlabel(xlabel) #название оси абсцисс\n",
    "    ax.set_ylabel(ylabel) #название оси ординат\n",
    "    ax.legend(facecolor='white', fontsize=11) #легенда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предсказание для всех объектов из таблицы X, подставив её в модель линейной регрессии с найденными параметрами, и построим график:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Делаем предсказание для всех объектов из таблицы\n",
    "y_predict = w[0] + w[1] * X\n",
    "#Строим визуализацию\n",
    "plot_regression_2d(X, y, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, прямая является убывающей (коэффициент $w_{1}<0$), и, если её продолжить влево, она пересечётся с осью ординат в точке $w_{0}=34.55$. \n",
    "\n",
    "Итак, мы воспользовались формулой для МНК алгоритма и нашли параметры модели линейной регрессии «вручную», реализовав формулу в виде функции. Отметим, что наша функция универсальна: в неё можно подавать не только матрицу $X$ с одним признаком (LSTAT), но и таблицу, содержащую все признаки, описывающие участки.\n",
    "\n",
    "Конечно же, никто не строит линейную регрессию «руками», используя формулу МНК. Все дата-сайентисты пользуются библиотеками, такими как sklearn. Давайте посмотрим на реализацию ↓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## АНАЛИТИЧЕСКОЕ РЕШЕНИЕ С ПОМОЩЬЮ SKLEARN\n",
    "\n",
    "Алгоритм построения модели реализован в библиотеке машинного обучения sklearn и находится в модуле linear_model. Давайте импортируем этот модуль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модуле находится класс [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), который реализует аналитическое решение линейной регрессии. Для обучения модели необходимо просто вызвать метод fit(), передав в него матрицу наблюдений X и вектор правильных ответов y.\n",
    "\n",
    "Данный метод реализует формулу метода наименьших квадратов и рассчитает параметры модели самостоятельно. Чтобы получить свободный член $w_0$ нужно обратиться по атрибуту intercept_, а вектор параметров $w_{1}, w_{2}, ..., w_{m}$ будет храниться в атрибуте coef_ (так как у нас один фактор в матрице X, то и коэффициент будет только один):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: 34.5538408793831\n",
      "w1: [-0.95004935]\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса LinearRegression\n",
    "lr_lstat = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr_lstat.fit(X, y)\n",
    " \n",
    "print('w0: {}'.format(lr_lstat.intercept_)) #свободный член w0\n",
    "print('w1: {}'.format(lr_lstat.coef_)) #остальные параметры модели w1, w2, ..., wm\n",
    " \n",
    "# w0: 34.55384087938311\n",
    "# w1: [-0.95004935]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Обратите внимание, что мы получили ровно те же самые значения для параметров модели, что является вполне ожидаемым, ведь метод fit() у объекта *LinearRegression* реализует ту же самую формулу МНК, которую мы прописали в функции linear_regression(). Интерпретация коэффициентов остаётся той же.\n",
    "\n",
    "Модель обучена. А как сделать предсказание? Вручную записывать выражение для модели и подставлять коэффициенты? Конечно же, нет. Для этого есть метод predict(). В него необходимо передать матрицу наблюдений, для которых нужно сделать предсказание.\n",
    "\n",
    "Давайте сделаем предсказание для всех наших наблюдений из таблицы X и визуализируем результат с помощью нашей функции plot_regression_2d():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predict = lr_lstat.predict(X)\n",
    "#Строим визуализацию\n",
    "plot_regression_2d(X, y, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем тот же самый график, что мы видели ранее, когда реализовывали линейную регрессию вручную.\n",
    "\n",
    "А что, если мы хотим построить линейную регрессию, используя всю предоставленную информацию, то есть все 13 признаков? Не проблема! Нужно только расширить матрицу наблюдений $X$, добавив в неё остальные признаки и снова обучить модель LinearRegression.\n",
    "\n",
    "Давайте выберем из таблицы boston все столбцы, исключая столбец с целевой переменной (MEDV). Полученную матрицу X и вектор правильных ответов y отправляем в метод fit(), чтобы произвести подгонку и найти параметры модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Составляем список факторов (исключили целевой столбец)\n",
    "features = boston_data.drop('MEDV', axis=1).columns\n",
    "#Составляем матрицу наблюдений X и вектор ответов y\n",
    "X = boston_data[features]\n",
    "y = boston_data['MEDV']\n",
    "#Создаём объект класса LinearRegression\n",
    "lr_full = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr_full.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства составим DataFrame из коэффициентов $w_{1}, w_{2}, ..., w_{13}$ обученной модели, не забыв добавить к нему строку со свободным членом $w_0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.108011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.046420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.020559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>2.686734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-17.766611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.809865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.475567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.306049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.012335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.952747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.009312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.524758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INTERCEPT</td>\n",
       "      <td>36.459488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients\n",
       "0        CRIM     -0.108011\n",
       "1          ZN      0.046420\n",
       "2       INDUS      0.020559\n",
       "3        CHAS      2.686734\n",
       "4         NOX    -17.766611\n",
       "5          RM      3.809865\n",
       "6         AGE      0.000692\n",
       "7         DIS     -1.475567\n",
       "8         RAD      0.306049\n",
       "9         TAX     -0.012335\n",
       "10    PTRATIO     -0.952747\n",
       "11          B      0.009312\n",
       "12      LSTAT     -0.524758\n",
       "13  INTERCEPT     36.459488"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Составляем таблицу из признаков и их коэффициентов\n",
    "w_df = pd.DataFrame({'Features': features, 'Coefficients': lr_full .coef_})\n",
    "#Составляем строку таблицы со свободным членом\n",
    "intercept_df =pd.DataFrame({'Features': ['INTERCEPT'], 'Coefficients': lr_full .intercept_})\n",
    "coef_df = pd.concat([w_df, intercept_df], ignore_index=True)\n",
    "display(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили таблицу с признаками из нашего набора данных и коэффициентами, которые им соответствуют.\n",
    "\n",
    "Каждый из коэффициентов в модели показывает, на сколько в среднем (согласно модели) изменится медианная цена (в тысячах долларов) при увеличении параметра на единицу. Например, если уровень преступности увеличится на один пункт, то медианная цена зданий на участке упадёт на 0.1 тыс. долларов. А вот увеличение среднего количества комнат на участке (RM) на одну единицу повысит медианную цену на 3.8 тыс. долларов.\n",
    "\n",
    "→ Свободный член (INTERCEPT) всё так же имитирует влияние внешних факторов и носит смысл «поправки» модели относительно медианной стоимости.\n",
    "\n",
    "Итак, мы с вами построили две модели линейной регрессии: lr_lstat на одном признаке (LSTAT) и lr_full — на всех признаках в данных. Хотелось бы сравнить эти модели по их качеству. Может, нам достаточно только знаний о проценте низкостатусного населения, чтобы предсказать медианную цену?\n",
    "\n",
    "Самая простая идея — визуализировать ошибки. Давайте построим коробчатые диаграммы ошибок моделей. Ошибки будем считать по формуле:\n",
    "\n",
    "$$error_{i} = y_{i} - \\hat{y_{i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Визуализируем ошибки\n",
    "fig, ax = plt.subplots(figsize=(12, 6)) #фигура + координатная плоскость\n",
    "#Ошибки модели на одном факторе LSTAT\n",
    "y_errors_lstat = y - lr_lstat.predict(boston_data[['LSTAT']])\n",
    "#Ошибки модели на всех факторах\n",
    "y_errors_full = y - lr_full.predict(boston_data[features])\n",
    "#Для удобства визуализации составим DataFrame из ошибок\n",
    "errors_df = pd.DataFrame(\n",
    "    {'LSTAT_predict': y_errors_lstat, \n",
    "     'Full_factors_predict': y_errors_full\n",
    "    }\n",
    ")\n",
    "#Строим boxplot для ошибок\n",
    "sns.boxplot(data=errors_df, orient='h', ax=ax)\n",
    "ax.set_xlabel('Model errors') #название оси абсцисс\n",
    "ax.set_ylabel('Model'); #название оси ординат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из построенных диаграмм ошибок видно, что разброс ошибок для модели, построенной на всех признаках, ниже (ящик уже и усы короче), и медиана ошибки также более приближена к 0. То есть можно сказать, что визуально качество второй модели выглядит лучше.\n",
    "\n",
    "На обеих диаграммах присутствуют точки, сильно выбивающиеся за пределы усов. Это наблюдения, для которых модель допустила очень большую ошибку, по сравнению с основной группой.\n",
    "\n",
    "Можно предположить, что это объекты, для которых гипотеза о линейной зависимости несправедлива, и линейной модели не хватает для предсказания целевой переменной для таких объектов. О том, как справиться с этой проблемой, мы поговорим чуть позже.\n",
    "\n",
    "Визуализация — это, конечно, хорошо, но, согласитесь, не очень удобно: визуализация не даёт конкретики — только общие представления об ошибках.\n",
    "\n",
    "Может быть, есть способ описать качество модели каким-то конкретным числом? Да. Этот показатель называется метрикой. \n",
    "\n",
    "✍ О метриках регрессии мы поговорим в следующем юните."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 29.63\n"
     ]
    }
   ],
   "source": [
    "#Задаём процент низкостатусного населения\n",
    "x_example = 5.18 \n",
    "#Делаем предсказание\n",
    "y_predict = w[0] + w[1] * x_example\n",
    "print('Predicted value: {:.2f}'.format(float(y_predict)))\n",
    "# Predicted value: 29.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.7\n",
    "\n",
    "В ваших данных появился новый участок со следующими параметрами:\n",
    "\n",
    "CRIM         0.35114  \n",
    "ZN           0.00000  \n",
    "INDUS        7.38000  \n",
    "CHAS         0.00000  \n",
    "NOX          0.49300  \n",
    "RM           6.04100  \n",
    "AGE         49.90000  \n",
    "DIS          4.72110  \n",
    "RAD          5.00000  \n",
    "TAX        287.00000  \n",
    "PTRATIO     19.60000  \n",
    "B          396.90000  \n",
    "LSTAT        7.70000  \n",
    "\n",
    "Сделайте предсказание медианной стоимости (MEDV) для данного участка c помощью модели lr_full. Введите результат предсказания в тысячах долларов. Ответ округлите до второго знака после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.87]\n"
     ]
    }
   ],
   "source": [
    "new = pd.DataFrame({\n",
    "    'CRIM': [0.35114], \n",
    "    'ZN': [0.0], \n",
    "    'INDUS': [7.38],\n",
    "    'CHAS': [0.0], \n",
    "    'NOX': [0.493], \n",
    "    'RM': [6.041],\n",
    "    'AGE': [49.9], \n",
    "    'DIS': [4.7211], \n",
    "    'RAD': [5.0],\n",
    "    'TAX': [287.0], \n",
    "    'PTRATIO': [19.6], \n",
    "    'B': [396.9],\n",
    "    'LSTAT': [7.7]\n",
    "    })\n",
    "\n",
    "print(np.round(lr_full.predict(new), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.8\n",
    "\n",
    "Дан [набор данных]() о стартапах и их прибыли (в долларах) в трёх различных штатах США.\n",
    "Столбцы:\n",
    "\n",
    "* R&D Spend — расходы на исследования.  \n",
    "* Administration — административные расходы.  \n",
    "* Marketing Spend — расходы на маркетинг.  \n",
    "* State — штат.  \n",
    "* Profit — прибыль (**целевой признак**).  \n",
    "\n",
    "Для обучения линейной регрессии используйте R&D Spend, Administration и Marketing Spend. Отделите факторы от целевой переменной.\n",
    "\n",
    "Обучите модель линейной регрессии методом наименьших квадратов с помощью библиотеки numpy (воспользуйтесь формулой из модуля).\n",
    "\n",
    "Чему равны коэффициенты линейной регрессии при признаках R&D Spend, Administration и Marketing Spend? Ответ введите с точностью до второго знака после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startups = pd.read_csv('data/50_Startups.csv')\n",
    "startups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend\n",
       "0  165349.20       136897.80        471784.10\n",
       "1  162597.70       151377.59        443898.53\n",
       "2  153441.51       101145.55        407934.54\n",
       "3  144372.41       118671.85        383199.62\n",
       "4  142107.34        91391.77        366168.42"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Profit\n",
       "0  192261.83\n",
       "1  191792.06\n",
       "2  191050.39\n",
       "3  182901.99\n",
       "4  166187.94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profit = startups[['Profit']]\n",
    "startups = startups.drop(labels=['State', 'Profit'], axis=1)\n",
    "display(startups.head())\n",
    "display(profit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Составляем список факторов (исключили целевой столбец)\n",
    "features = startups.columns\n",
    "#Составляем матрицу наблюдений X и вектор ответов y\n",
    "X = startups[features]\n",
    "y = profit['Profit']\n",
    "#Создаём объект класса LinearRegression\n",
    "lr_full = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr_full.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R&amp;D Spend</td>\n",
       "      <td>0.805715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Administration</td>\n",
       "      <td>-0.026816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marketing Spend</td>\n",
       "      <td>0.027228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTERCEPT</td>\n",
       "      <td>50122.192990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Features  Coefficients\n",
       "0        R&D Spend      0.805715\n",
       "1   Administration     -0.026816\n",
       "2  Marketing Spend      0.027228\n",
       "3        INTERCEPT  50122.192990"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Составляем таблицу из признаков и их коэффициентов\n",
    "w_df = pd.DataFrame({'Features': features, 'Coefficients': lr_full .coef_})\n",
    "#Составляем строку таблицы со свободным членом\n",
    "intercept_df =pd.DataFrame({'Features': ['INTERCEPT'], 'Coefficients': lr_full .intercept_})\n",
    "coef_df = pd.concat([w_df, intercept_df], ignore_index=True)\n",
    "display(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Метрики регрессии. Недостатки аналитического решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Итак, ранее мы с вами пришли к тому, что нам необходимо научиться оценивать качество модели с помощью какого-то показателя (или нескольких показателей). Такой показатель в машинном обучении называется метрикой. И для каждого класса задач машинного обучения существуют свои метрики.\n",
    "\n",
    "Метрика — это численное выражение качества моделирования.\n",
    "\n",
    "Для оценки качества решения задачи регрессии существует множество метрик. Давайте рассмотрим самые основные и часто используемые.\n",
    "\n",
    "МЕТРИКИ РЕГРЕССИИ\n",
    "\n",
    "Будем рассматривать метрики для задачи регрессии на следующем примере. Возьмём первые пять наблюдений из нашей таблицы и предсказанные для них моделью lr_full ответы:\n",
    "\n",
    "$$y=(24.0, \\ 21.6, \\ 34.7, \\ 33.4, \\ 36.2)$$\n",
    "\n",
    "$$\\hat{y}=(29.82, \\ 25.87, \\ 30.73, \\ 31.76, \\ 29.49)$$\n",
    "\n",
    "На этих значениях мы будем рассматривать следующие метрики:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Средняя абсолютная ошибка — MAE (Mean Absolute Error)\n",
    "\n",
    "Это самый простой и уже знакомый вам показатель. Чтобы посчитать данную метрику, нужно найти все остатки (разницы между предсказанным значением и реальным), взять от каждого из них модуль, сложить их и поделить на количество. Иными словами, нам нужно найти среднее арифметическое модуля отклонения предсказанного значения от реального.\n",
    "\n",
    "$$MAE = \\frac{\\sum_{i=1}^{n}\\left | y_{i} - \\hat{y_{i}} \\right |}{n}$$\n",
    "\n",
    "Данная метрика интерпретируется очень легко: это число показывает, насколько в среднем наша модель ошибается. Чем меньше значение метрики, тем лучше.\n",
    "\n",
    "$$MAE = \\frac{\\left | 24.0-29.82 \\right |+\\left | 21.6-25.87 \\right |+\\left | 4.7-30.73 \\right |+\\left | 33.4-31.76 \\right |+\\left | 36.2-29.49 \\right |}{5} = 4.482 \\left [ тыс. \\$ \\right ]$$\n",
    "\n",
    "То есть для нашего примера из пяти наблюдений в среднем модель ошибается на 4.482 тысячи долларов.\n",
    "\n",
    "Много ли это? Хороший вопрос, на который без эксперта-оценщика недвижимости будет сложно дать ответ. Однако можно попробовать посчитать ошибку в процентах, ведь в процентах всё воспринимается легче, и для этого нам пригодится следующая метрика — MAPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Средняя абсолютная ошибка в процентах — MAPE (Mean Absolute Percent Error)\n",
    "\n",
    "Для её вычисления мы делим модуль разницы между предсказанием алгоритма и истинным значением на истинное значение. Затем складываем все результаты (для каждого объекта), делим на количество и умножаем на 100 %.\n",
    "\n",
    "$$MAPE = \\sum_{i=1}^{n} \\frac{\\left | y_{i} - \\hat{y_{i}} \\right |}{\\left | y_{i} \\right |} \\frac{100\\%}{n}$$\n",
    "\n",
    "Эта метрика показывает, на сколько процентов в среднем наше предсказание отклоняется от реального значения. Эта метрика отлично показывает себя в задачах, когда неизвестно, какое значение целевого показателя считать приемлемым.\n",
    "\n",
    "Например, средняя ошибка — 2 тысячи долларов. Это много или мало? Смотря для чего... А вот средняя ошибка, равная 80 % — это много или мало? Определённо много.\n",
    "\n",
    "$$M A P E=\\left(\\frac{|24.0-29.82|}{|24.0|}+\\frac{|21.6-25.87|}{|21.6|}+\\frac{|34.7-30.73|}{|34.7|}+\\frac{|33.4-31.76|}{|33.4|}+\\frac{|36.2-29.49|}{|36.2|}\\right) \\frac{100 \\%}{5}=15.781 \\%$$\n",
    "\n",
    "Таким образом, на первых пяти наблюдениях модель в среднем ошибается на 15.781 %. Это довольно неплохой результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Средняя квадратическая ошибка — MSE\n",
    "\n",
    "Данный показатель мы используем в линейной регрессии в качестве функции потерь, но ничто не мешает нам также использовать его и в качестве метрики.\n",
    "\n",
    "Логика вычисления данной ошибки очень похожа на предыдущую. Разница лишь в том, что вместо модуля разности между предсказанным и реальным значениями мы берём квадрат этого модуля:\n",
    "\n",
    "$$MSE = \\frac{\\sum_{i=1}^{n}(y_{i} - \\hat{y_{i}})^{2}}{n}$$\n",
    "\n",
    "Данная метрика хуже поддаётся интерпретации, чем предыдущая, так как измеряется не в единицах, а в квадратах единиц. Она чаще используется для внутреннего обсуждения между дата-сайентистами, заказчику такая метрика может быть непонятна.\n",
    "\n",
    "$$M S E=\\frac{(24.0-29.82)^{2}+(21.6-25.87)^{2}+(34.7-30.73)^{2}+(33.4-31.76)^{2}+(36.2-29.49)^{2}}{5}=22.116\\left[(\\text { тыс. } \\$)^{2}\\right]$$\n",
    "\n",
    "Таким образом, для нашего примера квадрат отклонения составляет 22.116 тысяч долларов в квадрате.\n",
    "\n",
    "Согласитесь, не очень понятно, о чём идет речь. Однако данная метрика является популярной, так как позволяет «штрафовать» модель за очень большие ошибки.\n",
    "\n",
    "**Что значит «штрафовать»?** \n",
    "\n",
    "Например, расхождение в 200 единиц в метрике MSE воспринимается как $200^2$, а в метрике MAE это расхождение воспринимается как 200. Поэтому, если у нас есть две модели, но одна из них допускает большие ошибки, эти ошибки становятся ещё больше при расчёте метрики MSE, и нам легче сравнить модели между собой.\n",
    "\n",
    "Но в то же время это и проклятие MSE. Если в данных присутствуют выбросы, метрика может быть необъективной. Если модель будет утверждать, что цена здания — 30 тысяч долларов, а в наборе данных ему соответствует цена в 3 миллиона долларов, то при возведении такой ошибки в квадрат получится 9 миллионов, что может сбить с толку исследователя. Необходимо скептически относиться к данной метрике, если вы не проводили исследование данных на предмет наличия выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Корень из средней квадратической ошибки — RMSE (Root Mean Squared Error)\n",
    "\n",
    "Для получения RMSE надо просто извлечь квадратный корень из MSE:\n",
    "\n",
    "$$RMSE = \\sqrt{MSE} = \\sqrt{\\frac{\\sum_{i=1}^{n}(y_{i} - \\hat{y_{i}})^{2}}{n}}$$\n",
    "\n",
    "Корень извлекается для того, чтобы привести размерности ответов и ошибок в соответствие и сделать метрику более понятной.\n",
    "\n",
    "$$RMSE = \\sqrt{22.116} = 4.702 \\left [ тыс. \\$ \\right ]$$\n",
    "\n",
    "Преимущества и недостатки этой метрики такие же, как и у MSE, к преимуществам добавляется только понятная размерность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Коэффициент детерминации ($R^2$)\n",
    "\n",
    "Все рассматриваемые ранее метрики имели масштаб от 0 до +∞. Чем это плохо?\n",
    "\n",
    "А что если нам скажут, что MSE для модели составляет 32? Должны ли мы улучшить модель, или она достаточно хороша? А что если MSE = 0.4?\n",
    "\n",
    "На самом деле, трудно понять, хороша модель или нет, не сравнив её показатели с теми же показателями других моделей.\n",
    "\n",
    "Коэффициент детерминации, или $R^2$, является ещё одним показателем, который мы можем использовать для оценки модели. Он тесно связан с MSE, но его преимущество в том, что $R^2$ всегда находится в промежутке между -∞ и 1.\n",
    "\n",
    "$$R^{2} = 1 - \\frac{MSE}{MSE_{mean}},$$\n",
    "\n",
    "где\n",
    "\n",
    "$$MSE_{mean} = \\frac{\\sum_{i=1}^{n}(y_{i} - \\bar{y})^{2}}{n},$$\n",
    "\n",
    "где $\\bar{y}$ — среднее по вектору правильных ответов.\n",
    "\n",
    "То есть $R^2$ показывает, насколько наша модель лучше, чем если бы все предсказания были средним по правильным ответам.\n",
    "\n",
    "Посмотрим, как считается $R^2$. Сначала рассчитаем среднее по правильным ответам:\n",
    "\n",
    "$$\\bar{y} = \\frac{24.0+21.6+34.7+33.4+36.2}{5} = 29.98$$\n",
    "\n",
    "Теперь рассчитаем $MSE_{mean}$:\n",
    "\n",
    "$$M S E_{\\text {mean }}=\\frac{(24.0-29.98)^{2}+(21.6-29.98)^{2}+(34.7-29.98)^{2}+(33.4-29.98)^{2}+(36.2-29.98)^{2}}{5}=35.72$$\n",
    "\n",
    "И, наконец, сам $R^2$:\n",
    "\n",
    "$$R^{2} = 1 - \\frac{22.116}{35.72} = 0.38$$\n",
    "\n",
    "Есть ещё одна интерпретация данной метрики. Статистически показатель $R^2$ описывает, какую долю информации о зависимости (дисперсии) смогла уловить модель.\n",
    "\n",
    "Удовлетворительным  считается показатель выше 0.5: чем ближе к 1, тем лучше. Отрицательные значения $R^2$ говорят о том, что построенная модель настолько плоха, что лучше было бы присвоить всем ответам среднее значение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обобщим всё вышесказанное в виде таблицы:\n",
    "\n",
    "![](pics/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАСЧЁТ МЕТРИК НА PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настало время проверить качество построенных нами ранее моделей линейной регрессии: lr_lstat и lr_full.\n",
    "\n",
    "Весь набор функций для вычисления метрик в *sklearn* находится в модуле [metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). Давайте его импортируем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции, которые нам понадобятся:\n",
    "\n",
    "* mean_absolute_error() — расчёт MAE;\n",
    "* mean_square_error() — расчёт MSE;\n",
    "* mean_absolute_percentage_error() — расчёт MAPE;\n",
    "* r2_score() — расчёт коэффициента детерминации $R^2$.\n",
    "\n",
    "В каждую из функций достаточно передать правильные ответы и предсказания, и функция вернёт рассчитанную метрику.\n",
    "\n",
    "Примечание. Для расчёта метрики RMSE нет специальной функции, однако мы знаем, что для её расчёта достаточно извлечь квадратный корень из MSE.\n",
    "\n",
    "Из-за особенностей реализации функция ```mean_absolute_percentage_error()``` возвращает результат не в процентах, а в долях. Чтобы отобразить результат в процентах, необходимо умножить его на 100.\n",
    "\n",
    "Давайте вычислим метрики и выведем их на экран, округлив до третьего знака после запятой. Начнём с модели lr_lstat: сделаем предсказание на основании признака LSTAT и передадим истинные и предсказанные медианные цены в функции для расчёта метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Составляем список факторов (исключили целевой столбец)\n",
    "features = boston_data.drop('MEDV', axis=1).columns\n",
    "#Составляем матрицу наблюдений X и вектор ответов y\n",
    "X = boston_data[features]\n",
    "y = boston_data['MEDV']\n",
    "#Создаём объект класса LinearRegression\n",
    "lr_full = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr_full.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 4.505 thou. $\n",
      "RMSE score: 6.203 thou. $\n",
      "MAPE score: 21.352 %\n",
      "R2 score: 0.544\n"
     ]
    }
   ],
   "source": [
    "#Делаем предсказание по признаку LSTAT\n",
    "y_predict_lstat = lr_lstat.predict(boston_data[['LSTAT']])\n",
    "#Рассчитываем MAE\n",
    "print('MAE score: {:.3f} thou. $'.format(metrics.mean_absolute_error(y, y_predict_lstat)))\n",
    "#Рассчитываем RMSE\n",
    "print('RMSE score: {:.3f} thou. $'.format(np.sqrt(metrics.mean_squared_error(y, y_predict_lstat))))\n",
    "#Рассчитываем MAPE\n",
    "print('MAPE score: {:.3f} %'.format(metrics.mean_absolute_percentage_error(y, y_predict_lstat) * 100))\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict_lstat)))\n",
    " \n",
    " \n",
    "# MAE score: 4.505 thou. $\n",
    "# RMSE score: 6.203 thou. $\n",
    "# MAPE score: 21.352 %\n",
    "# R2 score: 0.544"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделываем ту же самую операцию для второй модели линейной регрессии, lr_full:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 3.271 thou. $\n",
      "RMSE score: 4.679 thou. $\n",
      "MAPE score: 16.417 %\n",
      "R2 score: 0.741\n"
     ]
    }
   ],
   "source": [
    "#Делаем предсказание по всем признакам\n",
    "y_predict_full = lr_full.predict(boston_data[features])\n",
    "#Рассчитываем MAE\n",
    "print('MAE score: {:.3f} thou. $'.format(metrics.mean_absolute_error(y, y_predict_full)))\n",
    "#Рассчитываем RMSE\n",
    "print('RMSE score: {:.3f} thou. $'.format(np.sqrt(metrics.mean_squared_error(y, y_predict_full))))\n",
    "#Рассчитываем MAPE\n",
    "print('MAPE score: {:.3f} %'.format(metrics.mean_absolute_percentage_error(y, y_predict_full) * 100))\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict_full)))\n",
    " \n",
    "\n",
    "# MAE score: 3.271 thou. $\n",
    "# RMSE score: 4.679 thou. $\n",
    "# MAPE score: 16.417 %\n",
    "# R2 score: 0.741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним полученные результаты:\n",
    "\n",
    "* ***MAE***: в среднем первая модель ошибается на  4.505 тыс. долларов, а вторая — на 3.271 тыс. долларов.\n",
    "* ***RMSE***: среднеквадратичное отклонение первой модели от истинных ответов составляет 6.203 тыс. долларов, а второй — 4.679.\n",
    "* ***MAPE***: первая модель ошибается на 21.352 %, а вторая — на 16.417 %.\n",
    "* ***$R^2$***: доля объясняемой информации (дисперсии), которую улавливает первая модель, — 0.544, а вторая — 0.741.\n",
    "\n",
    "Очевидно, что по всем метрикам вторая модель, построенная на основе всех признаков в данных, превосходит первую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.2\n",
    "\n",
    "У вас есть истинные ответы y_true = [1.23, 2.35, 2.75] и предсказания модели y_pred = [1.01, 12.3, 2.74]. Посчитайте метрику RMSE, ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.75"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [1.23, 2.35, 2.75]\n",
    "y_pred = [1.01, 12.3, 2.74]\n",
    "\n",
    "round(np.sqrt(metrics.mean_squared_error(y_true, y_pred)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.3\n",
    "\n",
    "Чему равен коэффициент детерминации на следующих данных?\n",
    "Истинные ответы: y_true = [22.4, 20.6, 23.9, 22.0, 11.9]\n",
    "\n",
    "Предсказанные ответы: y_pred = [20.5, 20.2, 20.3, 19.0, 11.0]\n",
    "\n",
    "Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [22.4, 20.6, 23.9, 22.0, 11.9]\n",
    "y_pred = [20.5, 20.2, 20.3, 19.0, 11.0]\n",
    "\n",
    "round(metrics.r2_score(y_true, y_pred),2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## НЕДОСТАТКИ АНАЛИТИЧЕСКОГО РЕШЕНИЯ\n",
    "\n",
    "Ранее мы с вами рассмотрели, что такое модель линейной регрессии, и научились рассчитывать её параметры с помощью аналитического подхода — метода наименьших квадратов.\n",
    "\n",
    "$$\\bar{w}=\\left(X^{T} X\\right)^{-1} X^{T} y=Q X^{T} y$$\n",
    "\n",
    "Метод наименьших квадратов позволяет очень просто получить коэффициенты , подставив таблицу в формулу. Вот, собственно, и всё «обучение». \n",
    "\n",
    "→ Существует [теорема Гаусса-Маркова](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%93%D0%B0%D1%83%D1%81%D1%81%D0%B0_%E2%80%94_%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D0%B0), которая говорит о том, что, если выполнены все условия теоремы, МНК всегда находит оптимальные оценки параметров. Мы ещё вернемся к этой теореме, когда будем говорить об МНК в модулях по линейной алгебре.\n",
    "\n",
    "Казалось бы, относительно простая математика: надо всего лишь перемножить матрицы между собой и получить ответ. Особенно простой эта задача должна быть для компьютера. Но нам так кажется, поскольку мы ранее не сталкивались с матричным умножением и будем говорить о нём только в модулях по линейной алгебре.\n",
    "\n",
    "Оказывается, у такого простого подхода есть один большой минус — это работа с большим количеством признаков.\n",
    "\n",
    "Давайте внимательно посмотрим на операцию обращения матриц (возведение в степень -1):\n",
    "\n",
    "$$Q = (X^{T}X)^{-1}$$\n",
    "\n",
    "Таблица $X$ имеет размер $n,m$, то есть у неё $n$ строк и $m$ столбцов. Таблица $X^T$ — это результат транспонирования матриц (замены строк и столбцов местами), то есть её размерность — $(m,n)$. Забегая вперёд, отметим, что по правилам умножения матриц результат умножения будет иметь размерность $(m,n)x(n,m)=(m,m)$, где $m$ — это число столбцов.\n",
    "\n",
    "А теперь представим, что у нас не 13 признаков, а 1300. То есть матрица $Q$ имеет размерность $(m,m)=(1300,1300)$. Но мы делаем вычисления на компьютере, так ведь? Сложностей быть не должно, но... В модулях по линейной алгебре мы увидим, что обращение матриц — очень ресурсозатратная операция. У неё кубическая сложность, то есть если размер матрицы — $(m,m)$, то на её обращение понадобится $m^3$ операций. Для нашего примера это $1300^3=2197000000$!\n",
    "\n",
    "Обращение матриц больших размеров может стать очень трудоёмким процессом при работе с большими объёмами данных.\n",
    "\n",
    "Второй недостаток МНК — это невозможность инкрементального обучения, или обучения в режиме реального времени.\n",
    "\n",
    "**Что это такое?**\n",
    "\n",
    "Представьте, что мы построили модель, но собираемся её уточнять в процессе эксплуатации. К нам приходят всё новые данные, и мы должны изменять параметры модели, подстраиваясь под новые зависимости.\n",
    "\n",
    "Если мы используем метод fit() для модели LinearRegression и передадим в него новые данные, то коэффициенты модели будут рассчитаны по новым данным, а прошлые наблюдения будут забыты. То есть придётся добавлять данные в таблицу и переобучать модель на всех доступных данных ещё раз.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая и вторая проблемы решаются с помощью замены аналитического МНК на численные методы, такие как градиентный спуск.\n",
    "\n",
    "Третий недостаток МНК больше теоретический и заключается в том, что матрица $Q = (X^{T}X)^{-1}$ в результате вычислений может не существовать. Это связано с математическими особенностями вычисления обратной матрицы, которые мы рассмотрим далее в курсе. \n",
    "\n",
    "Причина этой проблемы — мультиколлинеарность факторов (сильная корреляционная связь). Из-за этого коэффициенты линейной регрессии становятся слишком большими и модель становится неустойчивой. \n",
    "\n",
    "Проблема решается с помощью регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Линейная регрессия: численное решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Ранее мы с вами установили, что аналитическое решение линейной регрессии — метод наименьших квадратов — имеет несколько недостатков. Основной из них — большая вычислительная сложность обращения матриц.\n",
    "\n",
    "Хотелось бы получить метод, который справляется с этим недостатком. Для этого давайте вернёмся на шаг назад и вспомним, как вообще звучит постановка задачи поиска параметров модели.\n",
    "\n",
    "В самом простом двумерном случае мы пытаемся найти такие коэффициенты  уравнения прямой  и , чтобы средний квадрат ошибки (MSE) был минимален.\n",
    "\n",
    "$$M S E=\\frac{\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{n}=\\frac{\\sum_{i=1}^{n}\\left(y_{i}-w_{0}-w_{1} x_{i}\\right)^{2}}{n} \\rightarrow \\min _{w}$$\n",
    "\n",
    "Гауссу удалось найти общее решение для этой оптимизационной задачи и вывести формулу метода наименьших квадратов для поиска коэффициентов.\n",
    "\n",
    "Но можно пойти другим путём, не аналитическим (вывод формулы «в лоб»), а численным (итерационное приближение функции к минимуму).\n",
    "\n",
    "Самым популярным численным методом оптимизации, используемым в машинном обучении, является **алгоритм градиентного спуска**.\n",
    "\n",
    "**Градиентный спуск (Gradient descent)** — самый используемый [алгоритм](https://neurohive.io/ru/osnovy-data-science/gradient-descent/) минимизации функции потерь. Он применяется почти в каждой модели машинного обучения и является наиболее простым в реализации из всех методов численной оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С градиентным спуском мы будем детально знакомиться в модулях по оптимизации и даже реализуем его своими руками. Сейчас же нам важно усвоить принцип работы, чтобы понимать, какими параметрами алгоритма мы можем управлять при его использовании в коде.\n",
    "\n",
    "Начнём обзор алгоритма немного издалека.\n",
    "\n",
    "Представим, что мы находимся на некоторой холмистой местности и нам надо добраться до самой низкой точки, но делаем мы это вслепую, то есть не знаем сам ландшафт. Назовём эту точку целью.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/955db3eb396297eabf11b61019fb49d5/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_1.png)\n",
    "\n",
    "Давайте опишем, как мы будем искать эту точку. Для начала необходимо задать начальную точку, из которой мы, собственно, стартуем. Далее мы двигаемся в сторону крутизны склона. Если склон круче справа, надо сделать шаг вправо, если склон круче слева, надо сделать шаг влево. Повторяем шаги до тех пор, пока не достигнем самой низкой точки.\n",
    "\n",
    "У вас мог возникнуть вопрос: как определить, что мы достигли цели — самой низкой точки? В этой точке крутизна склона с обеих сторон равна 0 или близка к нему (ровная поверхность). Можно использовать эту информацию как точку остановки нашего алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описанный нами алгоритм можно перевести на язык математики. Он то и будет называться алгоритмом градиентного спуска.\n",
    "\n",
    "Наша функция потерь, которая зависит от параметров модели, — это аналогия ландшафта местности. Пространство, в котором находится ландшафт, — это пространство параметров  нашей модели. То есть это система координат, в которой по осям отложены все возможные значения параметров.\n",
    "\n",
    "В двумерном случае, когда есть только один параметр, от которого зависит функция потерь, можно построить график функции потерь. Например, для MSE, зависящей от одного параметра, график будет иметь вид параболы:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/2031eae68e1cfcfbfa6642928a844ef8/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_2.png)\n",
    "\n",
    "Если параметров не один, а два, то функция потерь будет графически представлена в виде поверхности в трёхмерном пространстве. Ниже приведён пример такой поверхности и её вид сверху в виде концентрических кругов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lms.skillfactory.ru/assets/courseware/v1/86c47a39251c3d192a314187ec8d9043/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_3.png)\n",
    "\n",
    "→ В общем случае, когда у нас больше параметров модели, мы будем работать в многомерном пространстве. Но в этом нет ничего страшного. Суть поиска минимума от этого не меняется, меняется только сложность функции — структуры ландшафта.\n",
    "\n",
    "Для линейной регрессии необходимо найти в этом пространстве такие координаты $w_0, w_1, ... , w_m$, в которых находится минимум функции потерь.\n",
    "\n",
    "Как же нам понять, в какую сторону двигаться? Что будет отвечать за направление крутизны склона? На этот вопрос нам ответит математический анализ. В теории анализа функций, зависящих от нескольких переменных, существует понятие [градиента](https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82).\n",
    "\n",
    "> Математически градиент — это вектор, который состоит из частных производных по параметрам функции.\n",
    "\n",
    "Он записывается следующим образом:\n",
    "\n",
    "$$\\nabla L(w)=\\left(\\frac{\\partial L(w)}{\\partial w_{0}}, \\frac{\\partial L(w)}{\\partial w_{1}}, \\frac{\\partial L(w)}{\\partial w_{2}}, \\ldots, \\frac{\\partial L(w)}{\\partial w_{m}}\\right),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "где $L(w)$ — функция потерь, зависящая от параметров модели, функция может быть любой (например, MSE). $\\nabla$ — символ набла — символьное сокращение градиента, читается как «градиент функции $L(w)$». \n",
    "\n",
    "Пусть пока что математическая формализация градиента нам непонятна, но нам важно отметить его ключевую особенность.\n",
    "\n",
    "→ Градиент — это вектор, который показывает направление наискорейшего роста функции, а его длина — это само значение скорости функции в точке.\n",
    "\n",
    "Если вновь обратиться к примеру с холмами, градиент показывает, с какой скоростью и в каком направлении нужно двигаться из текущей точки, чтобы достичь более высшей точки.\n",
    "\n",
    "> А теперь время фокусов. Если поставить перед градиентом знак минус $-\\nabla L(w)$, то мы получим вектор **антиградиента**, который показывает в сторону наискорейшего убывания функции потерь!\n",
    "\n",
    "В случае одного параметра:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c28fb31ed69592e3b38db4d47492aeb3/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_4.png)\n",
    "\n",
    "В случае двух параметров:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/4a12d561ec2f0938cfd2838ffc9dce62/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А это и есть то, что нам нужно. С помощью этого знания мы сможем вычислять следующую координату в пространстве — следующую точку, которую нам нужно посетить, чтобы дойти до цели — минимума функции.\n",
    "\n",
    "Формально это записывается следующим образом (формулу запоминать не нужно):\n",
    "\n",
    "$$w^{(k+1)} = w^{(k)} - \\eta \\nabla L(w^{(k)}),$$\n",
    "\n",
    "где $w$ — это вектор параметров модели, координаты в пространстве, а индекс в круглых скобках сверху означает номер точки в пространстве. Запись $\\nabla L(w^{(k)})$ означает, что градиент вычисляется в текущей точке под номером $k$.\n",
    "\n",
    "Согласно приведённой формуле, новая координата $w^{(k+1)}$ в пространстве параметров определяется как текущая координата $w^{(k)}$ минус скорость роста в текущей точке $\\nabla L(w^{(k)})$, помноженная на коэффициент «скольжения».\n",
    "\n",
    "Отдельное внимание стоит уделить коэффициенту $\\eta$ (читается как «эта»). Это поправочный коэффициент, который носит название **темп обучения (learning rate)**.\n",
    "\n",
    "> **Темп обучения** — это основной параметр алгоритма. Он определяет то, насколько сильно мы будем двигать точку. В аналогии с нашим примером с движением по холмам можно сказать, что это коэффициент, обратный сопротивлению ландшафта, по которому мы движемся.\n",
    "\n",
    "Управляя данным параметром (уменьшая и увеличивая его), мы управляем скоростью движения к точке минимума. Чем больше темп обучения, тем длиннее наши шаги и тем быстрее мы движемся, и наоборот. О том, зачем этот параметр нужен и как выбирать значение , мы поговорим чуть позже.\n",
    "\n",
    "**Примечание**. Темп обучения является примером внешнего параметра алгоритма, которым может управлять пользователь. Такие параметры ещё называют **гиперпараметрами**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ещё одно важное свойство градиента: теоретически в точке минимума длина вектора равна 0, то есть движения не происходит. Это свойство мы можем использовать в качестве критерия остановки нашего алгоритма.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c06a98caf800ce3fb0f82a6a26235f05/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_6.png)\n",
    "\n",
    "Теперь у нас есть все компоненты, чтобы составить алгоритм для обучения модели линейной регрессии методом градиентного спуска. Для простоты возьмём случай, когда мы строим регрессию на основе только одного признака.\n",
    "\n",
    "Для начала вспомним, как выглядит вид модели линейной регрессии, когда у нас есть только один фактор:\n",
    "\n",
    "$$\\hat{y} = w_{0} + w_{1}x$$\n",
    "\n",
    "У нас есть набор значений фактора $x=(x_{1}, x_{2}, ...x_{n})$ и столбец с правильными ответами $y=(y_{1}, y_{2},..., y_{n})$. Мы пытаемся найти такие коэффициенты прямой, чтобы ошибка предсказания была минимальной. \n",
    "\n",
    "Алгоритм градиентного спуска для такой модели будет выглядеть следующим образом: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Проинициализировать значения параметров $w_0$, $w_1$.\n",
    "\n",
    "    На аналогии наших холмов это будет означать выбор начальной точки в пространстве, из которой мы будем двигаться.\n",
    "\n",
    "    Правильная инициализация параметров — это отдельная история. Например, можно инициализировать все параметры нулями или случайными значениями.  \n",
    "\n",
    "2. Повторять до тех пор, пока длина градиента не приблизится к 0.\n",
    "\n",
    "    На практике полного равенства градиента нулю достичь невозможно из-за численных вычислений, поэтому в качестве остановки задают минимальную границу, ниже которой длина градиента считается достаточной, чтобы остановиться (например, 0.1, 0.01 или 0.001). Если длина будет меньше заданной, то алгоритм можно останавливать.\n",
    "\n",
    "    Существуют и другие критерии остановки: например, остановиться, если текущее значение функции потерь < 1.5. Но они используются гораздо реже.\n",
    "\n",
    "    2.1 Вычислить градиент функции потерь $\\nabla L(w)$.  \n",
    "\n",
    "    Это будет означать нахождение направления и вектора скорости роста нашего ландшафта. \n",
    "\n",
    "    Грубо говоря, нужно взять вектор-столбец с примерами  и подставить его в формулу для вычисления градиента функции потерь. Формулы вычисления градиента для наиболее часто используемых функций потерь уже вычислены и заложены в библиотечные реализации.\n",
    "\n",
    "    Далее приведены формулы вычисления градиента для MSE для двух параметров.\n",
    "\n",
    "    $$L(w)=M S E=\\frac{\\sum_{i=1}^{n}\\left(y_{i}-w_{0}-w_{1} x_{i}\\right)^{2}}{n}$$\n",
    "\n",
    "    $$\\frac{\\partial L(w)}{\\partial w_{0}}=-\\frac{2}{n} \\sum_{i=1}^{n}\\left(y_{i}-w_{0}-w_{1} x_{i}\\right)$$\n",
    "\n",
    "    $$\\frac{\\partial L(w)}{\\partial w_{1}}=-\\frac{2}{n} \\sum_{i=1}^{n} x_{i}\\left(y_{i}-w_{0}-w_{1} x_{i}\\right)$$\n",
    "\n",
    "    $$\\nabla L(w)=\\left(\\frac{\\partial L(w)}{\\partial w_{0}}, \\frac{\\partial L(w)}{\\partial w_{1}}\\right)$$\n",
    "\n",
    "    2.2. Обновить параметры модели, сдвинув их в сторону антиградиента.\n",
    "\n",
    "    Из текущей точки необходимо перейти в новую точку, в сторону убывания высоты ландшафта.\n",
    "\n",
    "    Для обновления координат точки используем формулу:\n",
    "\n",
    "    $$w^{(k+1)}=w^{(k)}-\\eta \\nabla L\\left(w^{(k)}\\right)$$\n",
    "\n",
    "    Далее приведены формулы вычисления градиента для MSE для двух параметров.\n",
    "\n",
    "    $$w_{0}{ }^{(k+1)}=w_{0}{ }^{(k)}+\\eta \\frac{\\partial L\\left(w^{(k)}\\right)}{\\partial w_{0}}=w_{0}{ }^{(k)}+\\eta \\frac{2}{n} \\sum_{i=1}^{n}\\left(y_{i}-w_{0}{ }^{(k)}-w_{1}{ }^{(k)} x_{i}\\right)$$\n",
    "\n",
    "    $$w_{1}{ }^{(k+1)}=w_{1}{ }^{(k)}+\\eta \\frac{\\partial L\\left(w^{(k)}\\right)}{\\partial w_{1}}=w_{1}{ }^{(k)}+\\eta \\frac{2}{n} \\sum_{i=1}^{n} x_{i}\\left(y_{i}-w_{0}-w_{1} x_{i}\\right)$$\n",
    "\n",
    "    Индекс в круглых скобках сверху означает номер итерации.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анимация работы градиентного спуска для двух параметров:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/4e5a14da749976ec2770eaded04098d4/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_7.gif)\n",
    "\n",
    "А как будет меняться само уравнение прямой при минимизации функции ошибок? Коэффициенты прямой будут адаптироваться под зависимость в данных и приближаться к оптимальным значениям. В анимации это будет выглядеть следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/8c7ab69cf4bbdff33c8c2844be1ec0bf/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_8.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. На анимации Error обозначена функция ошибки MSE. С помощью m и b обозначены параметры $w_0$ и $w_1$ соответственно.\n",
    "\n",
    "**Давайте подведём промежуточный итог.**\n",
    "\n",
    "Градиентный спуск — простой и мощный алгоритм оптимизации, который позволяет итеративно находить минимум функции потерь и тем самым находить оптимальные параметры модели.\n",
    "\n",
    "Причём функция потерь не обязательно должна быть MSE. Главное требование к функции потерь — это её гладкость во всех точках.\n",
    "\n",
    "**Примечание**. С математической точки зрения **гладкими** называются функции, которые имеют производную во всех точках.\n",
    "\n",
    "Для нашего пока что обывательского понимания это значит, что функция должна иметь плавный переход из точки в точку. Примеры:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/9df85ced8c7494fe39787b61a74459b3/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Благодаря своей простоте алгоритм обладает минимальной вычислительной сложностью и работает быстрее, чем метод наименьших квадратов, даже на огромных наборах данных с тысячами признаков.\n",
    "\n",
    "Однако у градиентного спуска есть одна большая проблема — это сходимость алгоритма к точке истинного минимума. Алгоритм может попросту не сойтись к истинному минимуму.\n",
    "\n",
    "Сходимость зависит от многих факторов, главные из которых:\n",
    "\n",
    "* сложности зависимости и сложности функции потерь;\n",
    "* выбранный темп обучения;\n",
    "* выбранная начальная точка (инициализация параметров);\n",
    "* масштабирование признаков.\n",
    "\n",
    "Из-за сложной зависимости и сложности самой функции потерь она может иметь несколько видов минимумов: **локальные** и **глобальные**.\n",
    "\n",
    "> **Локальный минимум** — это минимум на какой-то локальной области. \n",
    "\n",
    "> **Глобальный минимум** — это минимум на всей области определения функции (на всём ландшафте).\n",
    "\n",
    "Например, ваши минимальные расходы в онлайн-банке за весь период пользования приложением — это глобальный минимум. А минимальные расходы в приложении за последние шесть месяцев — это локальный минимум. Эти значения могут существенно отличаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы говорим о функции потерь, нас интересует именно глобальный минимум, то есть тот минимум, которого вообще возможно достичь при управлении параметрами.\n",
    "\n",
    "Функция потерь с локальным и глобальным минимумом в случае одного параметра:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/63595c20c0e55a9c4b38854d17a9f37c/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_10.png)\n",
    "\n",
    "Функция потерь с локальным и глобальным минимумом в случае двух параметров:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/416726975e8665ec14562e0c12d73294/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема градиентного спуска заключается в том, что алгоритм может «застрять» в локальном минимуме и не выйти из него.\n",
    "\n",
    "Застряв в локальном минимуме, мы не найдем настоящие оптимальные значения параметров.\n",
    "\n",
    "Чтобы частично решить эту проблему используется не классический градиентный спуск, а его модификации. Существует множество модификаций градиентного спуска, и мы будем знакомиться с большей их частью далее в курсе.\n",
    "\n",
    "В этом модуле мы будем использовать **стохастический градиентный спуск (Stochastic Gradient Descent, SGD)**. \n",
    "\n",
    "В классическом алгоритме мы используем всю выборку и прогоняем её несколько раз через алгоритм, вычисляя градиент функции ошибки, плавно приближаясь к минимуму.\n",
    "\n",
    "> Стохастическая модификация предполагает, что один шаг градиентного спуска производится на основе градиента, рассчитанного не по всей выборке, а только по случайно выбранной части.\n",
    "\n",
    "То есть мы случайно выбираем несколько строк из таблицы и подставляем их в алгоритм, делаем шаг в сторону минимума и повторяем это множество раз, пока алгоритм не сойдётся к приемлемому значению или пока не закончатся итерации (в реализации всегда задаётся максимум итераций на случай, если алгоритм не сойдётся и будет «блуждать по холмам» вечно).\n",
    "\n",
    "Благодаря этому вектор градиента всё время колеблется, и мы прыгаем из точки в точку, а не идём вдоль ровной линии, как это было в классическом градиентом спуске.\n",
    "\n",
    "На рисунке ниже приведены графики «блуждания» точки в пространстве функции потерь (вид сверху).\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/62f07879b1a6d4d1140675a84bce3566/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В чём выгода?**\n",
    "\n",
    "Благодаря таким случайным колебаниям у нас появляется больше возможностей «выкарабкаться» из локальных минимумов и дойти до глобального минимума.\n",
    "\n",
    "Однако из-за таких скачков есть шанс пропустить и глобальный минимум функции потерь, если скачки будут слишком большими.\n",
    "\n",
    "Чтобы управлять шагами, как раз и существует параметр **темпа обучения**. Он позволяет управлять размером шага градиентного спуска.\n",
    "\n",
    "→ Даже для обычной выпуклой функции, такой как парабола, градиентный спуск может сходиться медленно, если выбран слишком маленький темп обучения, или не сходиться вообще, если темп слишком большой. Поэтому темп обучения — это один из самых важных внешних параметров, на который мы можем повлиять.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/71750df0fdd1e154d7eab05413a92d0f/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-4_13.png)\n",
    "\n",
    "Наиболее распространённые значения :  0.01, 0.001 и т. д.\n",
    "\n",
    "Но есть идея получше! Будем брать большой шаг в начале обучения и уменьшать его постепенно, приближаясь к минимуму, чтобы не «выпрыгнуть» из точки минимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реализации стохастического градиентного спуска в sklearn, с которым мы будем работать, именно такая идея и используется по умолчанию. Параметр  регулируется в процессе обучения — он уменьшается с ростом числа итераций по формуле:\n",
    "\n",
    "$$\\eta_{t} = \\frac{\\eta_{0}}{t_{p}},$$\n",
    "\n",
    "где $\\eta_0$ — начальное значение темпа обучения, $p$ — мощность уменьшения темпа (задаётся пользователем).\n",
    "\n",
    "Ещё один важный момент, на который стоит обратить внимание при работе с градиентным спуском — это обязательное **масштабирование факторов** (приведение факторов к единому масштабу или к единым статистическим характеристикам), если их несколько.\n",
    "\n",
    "Например, в нашем наборе данных о домах в Бостоне есть признак NOX (концентрация оксидов азота): он изменяется в диапазоне от 0 до 1. Также есть признак LSTAT (процент низкостатусного населения), который изменяется в диапазоне от 0 до 100 %. \n",
    "\n",
    "Для градиентного спуска (особенно стохастического) важно, чтобы все факторы были приведены к единому масштабу с помощью нормализации/стандартизации (мы изучали их в модуле EDA-3. «Проектирование признаков»). Иначе в пространстве параметров функция ошибки становится очень растянутой по одной оси, но очень сжатой по другой, и найти её минимум будет очень сложно.\n",
    "\n",
    "На самом деле про градиентный спуск и особенности каждой из его модификаций можно говорить очень долго. Мы с вами разобрались в основных принципах работы этого метода оптимизации для поиска параметров линейной регрессии и обсудили самое главное, на что стоит обратить внимание. А теперь — время практики на Python ↓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЧИСЛЕННОЕ РЕШЕНИЕ НА PYTHON\n",
    "\n",
    "Как и раньше, будем работать с датасетом о домах в Бостоне из библиотеки sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston \n",
    "boston = load_boston()\n",
    "#создаём DataFrame из загруженных numpy-матриц\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "#добавляем в таблицу столбец с целевой переменной\n",
    "boston_data['MEDV'] = boston.target\n",
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим с помощью градиентного спуска линейную регрессию на одном факторе — LSTAT (процент низкостатусного населения) — и сравним результат с полученным ранее результатом МНК."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_data[['LSTAT']] #матрица наблюдений\n",
    "y = boston_data['MEDV'] #вектор правильных ответов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать реализацию стохастического градиентного спуска для линейной регрессии из библиотеки sklearn — [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html). Она находится в том же модуле linear_model.\n",
    "\n",
    "У класса SGDRegressor есть множество параметров. Например, параметр random_state отвечает за число, на основе которого происходит генерация  случайных чисел. Напомним, в SGD случайность присутствует в инициализации параметров и выборе части из набора данных. Установив значение параметра random_state равным определённому числу, мы можем гарантировать одинаковые результаты работы метода при разных запусках. Пусть это будет число 42.\n",
    "\n",
    "Для обучения используется метод fit(): он запускает работу градиентного спуска для поиска параметров, в него необходимо передать данные и правильные ответы.\n",
    "\n",
    "**Примечание**. К сожалению, в sklearn нельзя посмотреть то, как происходит поиск оптимальных параметров с помощью SGD. Поэтому нет возможности продемонстрировать историю изменения функции потерь. В модулях по оптимизации мы самостоятельно реализуем алгоритм и посмотрим на поэтапную минимизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(random_state=42)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_lstat = linear_model.SGDRegressor(random_state=42)\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "sgd_lr_lstat.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение завершено, параметры найдены. Давайте выведем их на экран. Для этого используются уже знакомые вам атрибуты coef_ и intercept_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: [34.33010969]\n",
      "w1: [-0.96193242]\n"
     ]
    }
   ],
   "source": [
    "print('w0: {}'.format(sgd_lr_lstat.intercept_)) #свободный член w0\n",
    "print('w1: {}'.format(sgd_lr_lstat.coef_)) #остальные параметры модели w1, w2, ..., wm\n",
    "\n",
    "# w0: [34.33010969]\n",
    "# w1: [-0.96193242]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Обратите внимание, что значения параметров немного отличаются от полученных ранее с помощью МНК значений. Для МНК коэффициенты были равны:\n",
    "```\n",
    "# w0: [34.55384087938311]\n",
    "# w1: [-0.95004935]\n",
    "```\n",
    "В этом нет ничего удивительного, ведь МНК — это аналитический метод, он выдаёт точное решение, а SGD — численный, и вычисления останавливаются, когда достигается приемлемая точность.\n",
    "\n",
    "Давайте с помощью метода predict() сделаем предсказание цены для всех объектов из нашей выборки и построим визуализацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAEFCAYAAADOo78UAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACJe0lEQVR4nO2dd5hcZfXHP7dM277Z9N4JSQgQAgFM6CHSQZEqSJUqYvtRpClgQJqi0lEUBAREIHQIxNAMhDTSSd9N2ZZt0295f3/cmZuZ3dnek/fzPD6SvTP3vu/cmXvec95zvkcRQggkEolEIpH0eNTuHoBEIpFIJJKWIY22RCKRSCS9BGm0JRKJRCLpJUijLZFIJBJJL0EabYlEIpFIegl6dw+gKcrL6ygszKKqKtzdQ+k05Px6N3J+vRs5v97Nnjq/fv1yGz3W4z1tXde6ewidipxf70bOr3cj59e72dPnl4keb7QlEolEIpE4SKMtkUgkEkkvQRptiUQikUh6CdJoSyQSiUTSS+jR2eMdjWHahKIGXl0jblpk+z149KbXLYZpU1kTIRwzKcoLYFgWhmnj0VXys314dJVw1KSiJkLf/ABZ/oYfaXPXTR5vyXjaQ3uv09T7u2oOEolEsjezVxht2xZ8vLiEtcXVFJcFiRs2Po/K0AE57DO0gKOnDkVVlQbv+fDrYt5duJVgOI5pO39XAUUBXVfpl+9HURSCEYOYYePzaIwZksePT5mErqvNXvfIA4bw5qcbWby6lFDEIDvgYfzQ/Izj6Yj5ryupadN1mno/0K5zSyQSiaTldKrRPv3008nNderNhg4dypVXXsmNN96IoiiMGzeO22+/HVXtfK/s48UlLN9YSWVNlHDUQFEUQjGbHRVhYnELgGOnDWvwnre/2EIwYqT93QYQgCXYVhFGAH6PhtejYtk2a7ZW8cTclVx9xn7NXndtcTVCUTANC4+uEjcslm+szDiejpi/qihtuk5T7wfadW6JRCKRtJxOs5ixWAyAZ599lmeffZY5c+YwZ84crr/+ep5//nmEEMybN6+zLu9imDbrimsACEVNFMXx/hRIGGSFdcU1GElXOvGelVuqCMec19sZmpfatiD5Z9Oy3f9WFYUN22qpCcabvK4tYMO2WpR6zqiqNBxPR8xfrXehll6nqfevLq5mzZbqNp9bIpFIJK2j0zztNWvWEIlEuOSSSzBNk5///OesXLmSQw45BIAjjjiCzz77jFmzZjV6jsLCLKBpdZjm2FUbxbAFqqYiBCgpIVshQNNVDFvgz/bRJ8/vviccM3FajTcf4hWAoiiuATYsm7q41eR1UZzXmZbA60u/DYZhp42nPSTnX/8aLb1OU++PRJ3PKCvgafTc0L771xuQ8+vdyPn1bvb0+dWn04y23+/n0ksv5Qc/+AGbN2/m8ssvRwjhepzZ2dnU1dU1eY6qqjD9+uVSXt7065rCMG08mkI0bqEoIFLcZkVRsEwbv0cjGopRHjPc92T7dBRFcQxsMyjgGPjEaz2aSq5Xa/K6COd1uqYQj5lp5/Pq6eNJjqktiV7J+de/RmPXadX7PSqKoMlzk+dv1/3r6bT3+9nTkfPr3bRmfjt2bOfcc7/HyJGjARDCJhQKccIJJ3PppVd05jBbzKef/pc1a1Zz2WVXAj3j/t199x0ceOBBnHjiKY2+ZsaMaXz66aIWn7OphUinGe1Ro0YxYsQIFEVh1KhRFBQUsHLlSvd4KBQiLy+vsy7v4tFVxg/NZ/nGSrL9OnXhuGOMgdyABxCMH5afZgg9usrEEYVs2FZDMGKgKjQIkauq4obIdc15ry0c4z1+WB75Od4mr6sqMGZIXoNFgS3Sx9PeJLLU+aeGsetfpy3vnzysAKDN55ZIJD2Lvn378cwzz7v/rqgo55xzzuDYY49n5MhR3TgyhxkzjmTGjCO7exjdSqcZ7VdeeYV169Zxxx13UFpaSjAY5Dvf+Q4LFy5k+vTpLFiwgEMPPbSzLp9GMst57dZqSoQgFrfxeVUGFWWxz7AC93j991hC8O7CrdSF464XrQCqArqm0K9PABSorI0RjhqgKOT6PQztl00sbjV73SMPGMLXGypZvKqUcMwgy+dh/LD8tPG0N4ksdf7rimsavU5739/Wc0skEoc77riFuXNf69BzJp2LU045nTvuuKvV76+oqHC2wLKcrcpnn32Gjz/+AMuymT79UK666joUReHll1/k3//+Fzk5uYwYMYLBg4dy6aVXcPLJx7HPPhOprKzgqaf+wQsvPNfg/eFwiDvu+DWVlc5z7ZJLLmfGjCN58cXneOedt1BVhX33ncT//d+vefvtuSxZ8jW//vUdrFjxDY888hChUISCggJ+9aubGTp0GNde+2MmTpzEsmVLqa6u4vrrf8Vhh30nbV53330Hfn+AdevWEAzW8eMfX8N7773N+vXrmDnzKH7yk59h2zYPP/wAixZ9haLA7Nkn8sMfXoQQgj//+SE+++xT+vbti23bHHjgQQC8886bvPzyC9i2YJ99JvDzn9+Az+dr511Mp9OM9plnnslNN93Eueeei6Io/O53v6OwsJBbb72VBx98kNGjRzN79uzOunwaqqpw7LRhHHHAkBbXaauqwvEHD+foA4c2Wae9YOk2Fq+vwDAsQhGDcMzig0UlLF5Xwcwpgzh66tAmr3vyjNFMHVOUMfTdXBLZEQcMaZE3W3/+rQ2xN/f+9pxbIpH0HCoqyrnoovOIx2PU1FQzYcIkfve7++nffwD/+9/nrF27mief/AeKonDnnbfx/vvvMGbMOF599SWefvpZdN3DT35yBYMHO4v26upqzj//QqZOndbo+23bZuDAwdx33x/59tu1vP/+uxx22Ayee+4ZXnvtXVRV5Z577qS8vMwdp2EY3HHHzfzpTw8zaNAoPvroQ+6449c89dQ/EsdNHn/8b3z66QKefPLRBkY7OdfHH/8b77zzJnPm/IYXXngVn8/H6aefyMUXX877779DaWkpf//7CxiGwU9+8mNGjx5LLBZl3bq1PPfcS9TV1XHRRecAsHHjBubOfY1HH/0rPp+Pxx77My+88CwXXXRZh96jTjPaXq+XBx54oMHfn3vuuc66ZLN4dJWCHGfVk9XCqXt0lYFF2RmPJY2qV1OpqYsRjDhlXZqqUBOKs3TDbo+4qeumjiuVUNQgFDUyGsFwzDmW6X1NzaU1r2/N+9t7bolkb+eOO+5qkzfcFK3d802Gx23b5s9/fojNmzdx8MHTAVi06EtWrVrBpZdeAEAsFmXAgIFUVe3i8MNnkp2dA8Bxx82mrq7WPeekSZObfP9JJ53K44//hYqKMg47bAYXXXQpmqYxefIULrvsQmbOPJJzzjmffv36u+csLt5Cbm4uU6ZMoby8jmOOOY7f//5ugsEgANOnHwbA6NFj0saSyqGHHg7AgAEDGTVqDIWFfQDIy8ujrq6WxYu/4sQTT0bTNDRNY9asE/j66y8xDIMjjzwaXdcpLCzk0EOdBcGSJYsoKSnmiisuBsA0DcaPn9Diz76l7BXiKp1F0qhqmpJW1gVg2QIhRKs84vpk+z1kBzzEDavBsSyfh2x/w6xtiUQiaS+qqnL11T/l4ovP44UXnuX883+EbVucdda5nHPODwGoq6tD0zTefPN1hGi8vNPnc6pTGnt/VlYWzz//Cv/73xd89tkCXnzxOZ577mXmzHmAlSu/4X//+5xf/OI6brvtTvecdqY6XAS27TwrvV4vQCKZOHM2scez+/mpaQ1bfDa8hsCyrAYJysn3WpbNMcccx/XX/wqAcDiMZTV8drcXGcdsB0mjalkCy0r/0mqqgqaqrkfcFpJJYHa9L51M9JJIJJ2Nrutcc831PPPM01RWVjB16sG8997bhMNhTNPkppt+wfz585g27WC++OIzQqEghmHw3/9+lObAJGns/f/+9794+unHOeaY4/jFL26kqqqKmpoafvjDHzB69Fguu+xKDj54Ohs2fOuea/jwEdTU1LB8+XIA5s37gAEDBpGXl99h8z/ooGm8885bWJZFNBrl/fff5cADpzFt2iF89NEHxONxamtrWbjwCwAOPPAgFiyYT1XVLoQQPPDAHF566flmrtJ6pKfdDpJGdemGCjRNdVd0qRni/nZ6xO1NIpNIJJK2cuihhzN58n489dRj3HDDLaxfv44f//gibNti+vTDOeGEk1EUhTPPPIcrrriEQCBAQUFBxuSrGTOOyPj+ZCLahReejaZpXHPNdRQWFnLqqWdw+eUX4vP5GT58BCeddBoff/wh4HjSv/3tHO68807q6oLk5eXz29/O6dC5n3ba9yku3spFF52LaZocf/wJHHnk0QCsXr2KCy88mz59itwSuXHjxnPxxZdz3XVXIoRg7Njx/PCHF3XomAAU0VjsoAdQXl7XI+rwmiJZkvXJ8h1U1kbQVJWcgIe+BQGEEEwZXdRklndL59dbG3L09PvXXuT8ejdyfu1n69YtfPHFp5x99vkA3Hjjzzn55NOZMeOITr0u7Ln3r1vqtPcWVFXh6KlDiVs2n3+zk9qQk5CmawozpgzuMI9YJnpJJJKeyMCBg1i9ehUXXHAWiqJwyCGH8Z3vzOzuYe2xSKPdAprzcj9eXMKaLVX0zffTJ8+HZQkUNVHTLTtdSSSSPRiv18sdd9zd3cPYa5BGuwlaokZWv5ZaVRRU3fnv9mSOSyQSiURSH2lNmiCpRhav1zrz48Ul7muSZV+ZaE/muEQikUgk9ZFGuxFa2tIy2+8h4NMxTLtBaZaspZZIJBJJRyLD443QEjWyvCwvC5Zuo7w6QmVtFF1Tyfbr9M33I0DWUkskEomkQ5EWpRGSwimZSHrQyfB5Qa7PzeyuCcWpDsaZOLIPB47v53rkEolEIpG0F2m0G6E5NTLADZ8rQN98P8MH5DJ8QC4CwfqSGv761mqeenMV8xYVNyK7J5FIJK3HMG2qg7EOdwo+/vhDLrnkh/zoR+dy4YVn8/zz/+jQ89fn7bfncvfdd7TpvTt2bOeYY45p8jWrVq3gkUcebtP5eyoyPN4ETamR1YbjDcLnqgK1oTg1wRi5AW+bW2lKJBJJJlpS0dJWysvL+POf/8Bf//oc+fkFhMNhrr32xwwfPqLX9rDevHkTVVW7unsYHYo02k2Q2pKyJhgDBfKzfaiqkrGZhy0gGDHQNBVN2/0Dam0rTYlEIslEcktOVZQOdwqqq6sxTZNoNEp+PmRlZXHLLXfg9Tpbfx999CEvvvgcsVgMw4hz0023sd9++3PttT9mn30msHz5UuLxOFde+RNefvlFNm/eyNlnn8fZZ5/P008/TmnpTjZv3kRNTTWnnfY9zjvvwrTrr169kocffpBYLEp+vtMfe/DgIWmvWbduDffc4zQOGTt2vPv3jRvX89BD9xGJRKiq2sUFF1zEscfO5qmnHiMSifD3vz/NmWeezZw5TovPiopypk07hBtvvDWjTnpPRhrtZrBtwYKl2zKubEcPzmPZhgo8moaqgGXbmJZNfra3QdZ5W1ppSiQSSZLmKlra6xSMGzeemTOP5KyzTmP8+H048MBpzJr1XYYOHYZt27z++r/5/e//QEFBAW+++TrPPvsMv//9QwAIIXjyyX/w178+wR/+cB9///uLVFdXcdFF57nypmvXrubRR/+KbdtceukPOeigQ3bPzTC45567uPfehxg4cCALF37BvffezR//+EjaGO+663Z+8pOfcfDBh/LMM0+xbNliAObOfZ0f/ehSpk07hG3bSrjoovM4/fQzueyyK1my5Gt+9KNL+eCDdxk3bjx33XUvhmHwwx/+gLVr1zBhwr5t/sy6A2m0myF1ZatpCqGIwZINFawtrgagqjZG3LDxeVUG982mKM9PQY63wXlk+ZdEImkPLaloaa9T8Mtf3sSPfnQpX375P7788guuuOJibr/9To488hh+97v7+OyzT9i6dQtLlnyNqu4eR7Kn9MCBg5g0aT/8fj8DBw4iGNytC37ccbPJysoCnOYhX3/9FQUFBYDTH3v79hJuvPHnu+cbCqWNrbq6moqKCg4++FAATjjhZN55Zy4A1157PQsXfsGzz/6NDRvWE4mEG8xt1qzvsmrVCl566fmEx1+T8XU9HWm0myC5slWA8uoIoaiJZdmYtgAEY4fkM7BPFrYQGKbN+KH57Du8kOUbK0ldC3d3K83e2mxEIpHsJtOWXJKOcAo+//xTIpEwxx57PCeddConnXQqb7zxH95883UOPvhQLr/8Rxx//Ansv/+BjBkzln//+yX3vbq+25Rk6k1d/++2LdD13f+2LJvBg4fwzDPPJ/5tNdiLVhTSemNr2u5r3nbbjeTm5vGd78zk2GOP58MP32tw/VdeeZH58z/i1FPP4MwzD2HTpg2N9truycgneBMkV7YVNVHqwnGEECiqgmnZxA2b8uoo4ISnfB6NDdvqmDFlMFNGF+HVNUzLxqtrTBld1C2tNG1bMG9RMU+9uYqn5q6SmewSSS+muYqW9i7I/X4/jz32F3bs2A44BvLbb9cxbtw+FBdvRVEULrzwEqZOncZ///sxtt26zPUFC+a7Pag/+2yB6zEDjBgxktraWpYtWwLAW2+9wR13/Drt/fn5BQwcOJDPP/8UgA8+eNc99tVXX3LZZVcyc+ZR/O9/nwOO4dc0DcuyEq9ZyKmnfo/jjz+BeDzOt9+ua/UcegLS026CpNrZtoqQm6wghPM/VVWIxE1iCYlTVVEIxwwicdNNXutu77Yzk1YkEknX01RFS3uZOnUal1xyOf/3f9djmiYA06cfxkUXXYamaYwdO57zzjsTVXU6eS1fvrRV5/f5fFxzzWWEQiEuuOBiRo0azerVKwGn6cidd97DH/94P/F4nKysbG655TcNznHrrXcyZ85vePLJR5g0aYr790suuZyrrroMn8/LmDHjGDRoMDt2bGfffSfx178+waOP/omzzjqP+++fw3PP/Y3s7BwmT57iLlB6E7KfdjO8+dkm3vuqGFVVEMLp3BWJOV9ogcDn0fDoGtl+ncFF2Vx+6qRWGenOmp9h2jw1dxVxs2EozatrXHbKxC5ZTHT3/ets5Px6N711fi3d8uop83v66ccBuPTSKzr0vD1lfh1NU/20ZXi8GY49aBheXSUas4jETKJxCxTHYKMoaKqCEILacBwUesyesWxkIpHsuXh0lYIcX4953ki6Dhkeb4bPV+wg4NMwLBsS6WXRuONpezQVgYKqKORnORnjhmn3iB9SZyetSCQSSUvpaA97b0Ya7RTqh5yS2eN98wOAQihqYpo2Qgg8usaYwXkIQFNVVMUJm/eUWuxk0kpyTztJd2eySyQSiaTtSKNN49KAB47v59ZF9isIUJQo7dpeEcIWIHC87STNebBdXXrVmUkrEolEIul6pNGm8Sxr0xZpIeZkaVdOwOPIlaaICzTlwTalF9yZpMqwdncmu0QikUjaz17/BG9KGnDjtlrGDM5tUBfZJ8/H+GEF+D0tq8VOLgriifKw5KLg48UlnTavVGTSikQikewZ7PWednPSgNMmDEBT1Xoh5j4cPXUoli2a9WCb0ws2MpRkSSQSiUSSib3eaDeXZZ2b5W00xKyqSrNJZ80tCurCsvRKIpFIJC1jr4+XtlQasK0h5uSiIBPOokCWXkkkEomkZXSq0a6srOTII49kw4YNbNmyhXPPPZfzzjuP22+/vUdpvh49dWin6YU3vyjILK7fWRimTXUwhmH2nM9fIpFIJC2j08LjhmFw22234ff7AZgzZw7XX38906dP57bbbmPevHnMmjWrsy7fKjo7y7onlF41lcGuqr2rCbxEIpHsrXSa0b733ns555xzeOKJJwBYuXIlhxziND0/4ogj+Oyzz3qM0U6SDIF3ND2h9Eo2D5FIJJLeT6cY7VdffZU+ffowc+ZM12gLIdxOWdnZ2dTVNS/yXljoNExvSjx9T6Cz52eYFlvKQvgzCL9sKQtRUJjVqWF6ef96N3J+vRs5vz2LTjHa//73v1EUhS+++ILVq1dzww03sGvX7obmoVCIvLy8Zs9TVRXu1V1cWqKA1hXzqw7G2FUTyZzBHo6zubiq06RXe/P9awlyfr0bOb/ezZ46v6YWIp1itP/5z3+6/33BBRdwxx13cN9997Fw4UKmT5/OggULOPTQQ5s4Q++mp+0fy+YhEolEsmfQZRurN9xwA3/60584++yzMQyD2bNnd9Wlu5zuVkCrT0vL2iQSiUTSs+l0cZVnn33W/e/nnnuusy/X7TSngHbEAUMA3LB5V9ETMtglEolE0j72ekW0ltLSDl1NKaCFonHeXbiFkvKQGzafuu8ADh7Xt9PD5j0hg10ikUgk7UMa7WZoan86k/Z4U/vHwYjJupIadHV32dWi1aUE66JdVnbVWWVtEolEIul8pNFuhkz1zcs2VLC2uBpFURoY8uT+cfI9SUzbBgR6PY9aCMGSbyuYNmEA+TneLp6dRCKRSHoT0mg3QWP707tqYwQjQUYMzMsoVJJp/3hM/zzWbK12z2ELwdbSIOGYgWUJ7njmS8YNyefHp0xCl2FriUQikWRAGu0myLQ/bQtBKGpiC7BsG1VLdPxKSTTz6GqD/WOA4vKQGzbfWhqkLhxHVRVUVcG2BWu2VvHE3JVcfcZ+XT7Xlu7ZSyQSiaT7kEa7CbL9HgJ+nUjMRFNVVAUsS2BZNpqmoqnpxi0cc4x8cs+4/v5xMmxuC2dBkPTgNVVBARRFYcO2WsJRkyx/19yanlZTLpFIJJLGkS5VI9i2YMHSbZRXRdiys46tpXVU1ERRNQVNU8gJeKhv05oTKkl2ExO2wLYFKKBrKl6PIyEqgKhhsrMy1K6xt7STl2HavPXFZpZuaF9NuewcJpFIJF2D9LQbIZmAVpDjxbRsQlGTmmAMTYVxQwuI1ssOb4lQSbLsatqEAdzxzJfYtnBD43HDxrRtBPDWF1uYOLKw1d5uS73m5OvWbK1mXUk1quIsQory/Sg0DPW393oSiUQi6Rikp52B1AQ0RVHoVxBg+IAchg/IpV9+FpeeNJH929F/Oz/Hy7gh+YiEQplh2BiWjW0Lsn06thBtUlBrqRJb8nWRmImwBUIIasNxKmui7muSof6OuJ5EIpFIOgbpaWcgUwKaqiioukLUMInEzTYJlSSTvby6xllHj+WFed+ytayOoGWhKArZfg8jBuS412uJt5s8b00oxuri6iaV2Dy6mp4Rr4GmqU4HNiAYMeiT50dVmg/1t0T5TSa0SSQSScey1xrtprKlW9pgo6VCJbYt+GBRMWu2VrGzMkTcEHh0lYFFAY46aChfryolO+BBV1VsITBMG01TGiS2ZTpvMjxdXRejtCpMbpbXDXMnST1P6oJEVRSy/Tp14TiKomDZAsu2QVWaDfU3pfzW3LglEolE0jb2OqPdkn3YxgRSWrJvXX8xYNuCx15fwbriamKGhWU5IXGBoDoYY2tpEIDcgIfy6gihqOlmp+dnewl4G79FqcIvfp+GoijUhuMA9M33u69LXWjUX5AkXxeKmqgI/D6dfYcVNBvql53DJBKJpOvZ64x2JoWzVGGUJK1tsNHYYsC0bb4tqUYAli2whcAWOOVjwvl3LG6xeafTE1ZREnXbQmBaNp8u355R4jQ1PO3UjAvXa04Nc9dfaNRfkCT37Attm32GFjB7+ogWhbXbs7CRSCQSSdvYq4x2a/ZhW9tgI9NiYOmGCqpro453rSgIAYlKL4QARQiEcMq+DEvg1VVs4dRt5yayuRvbH06Gp2tCjpG2bIGqgJoIsccMk/wsX8aFRqYFyeRhfVqd9S07h0kkEknXslcZ7bbsw7Zk37qxxYCwoTZsoGlqg17Wzr8UFMUx0kIIBvfNQVVxhVyaGle230MwYlAbjifKtJy/20JQkO3hspMmkp/jyzjXjur4JTuHSSQSSdeyVz1hk/uwmWjPPmxyMVAfTXPCz36fBkKga0pagpimKSg4NdI+j45HV/BoappoS7PjqrcYQAgURW3UYKeSXJC019CmLmykyIpEIpF0HnuVp92WfdiWaHLXT8qyhcCyBJqmUJDjIyfLg6YohKImphXHskFTwe/RyM/1kZflwe/RiLVCsMUZk45heghGTGzbRtc1cgIecgJ6l2ZvN5XcJ5FIJJKOY68y2tDyfdjWqH0lFwPLNlSwqzbmGGfTQlUVxg7JZ9+Rffi2uIZgNI5Hy3HKq4QgGjPpX5jNqIE5HHnAEP67dFuT40qt844bFsGoQThmYQuBqqlk+zX65vvxefQuzd5uKrnvnBMmdtk4JBKJZE9nrzPaLd2HbWmWeZKjpw5lbXE1deE6YoaNLQSaqrBhRy2KAmcdPQ5VU8gNePl0+XbWJErAkhsUTY0ruYBYW1JNSWmQmGFjWhbxRBja69FQgLqwE6I/+sChrQ55t7XLV3PJfYbZsCRMIpFIJG1jrzPaSZpKMGuL2pdlCxQUcrO82KG4643H4hbLN+xiW/kyhg/MRQhB1LDQFIUsr45h2mmLAY+uku33pBnQ5AJiV22MUMwEIQjHTPREW1DDtNETXcd0TWXGlMEt/hzaqx/eXHJfciEhkUgkkvaz1xrtpmhplnmqdxqKGtRF4oSiJlrSYBsWZkJMJRw3CccMSsqC5AS8aeInycXAjCmD+XT5dteABvw6Q/tls7UsCCgEIwYKkEzzsmxBwKejKgqD+2ajayq2bROJm/i8Wovm2tqIQn2aE1nJzfJQHZOGWyKRSDoCabQz0FRiWZbPQ8CrM29RcZp3OnpwHl6PimXZqKriiqkoAAoIWxCP21iWSBM/SRKOGbz/1VbWb6tBURRqQnG2VYRYvXkXli0ozPW550723hbCSR63Ehnklm3j97V8PzscNVmxaVeDv7dGP7z55L6WLR4kEolE0jx7TclXVdUu+vfPo3//PPbddxTz53/U6GuThsiybcqrI2wtDbK11OmpLRAsWLatQXerVZt3oasqmuYYrqRBFZD4u4rX6/y/q/Gdgt+js6UsiKooVNZEqQ3HEUK4r68LG5h2orpbURLevLMoMC2b7RUhtuyso6IqwoKl25x+3Y1g24J5i4p56s1VfFtSw9bSIOXVEbfrGLSsy1eSZJ/wtnY9k0gkEknL2Gs87UAgy/3vyspKzjrrdAD8fj+PPvo0J510Strrk4llwUjQUSnTVHICHiJxk8++2Ulh7u798KSMqEeHUYPy2LCtBiEcj1VTFXTdacyhq06Gd13YaOCVDumfzeqtVfh0zQ2Dg6OepimOgU5eS1XAoyn4PDoxw0oYW438bC8FOd5mw9vJkDg4IXEhBHUJzfJ+BQGgdXXrUmRFIpFIuoa95snq9/spK6vl88+/Zvr0w9y/R6NRLr74fNcLf+mlFxBCuIllIwbmub20++b7EQKqgjFsIRBARU004YUHWblpF2W7wgR8Orqm4vc63nVelpeiPB9lVWHXg95WHqK0KoxHV/F5NErKguysDLO1tI5I3CTVT/b7NPKyvHh0lSyfhqY6oi1OiFzg8+hk+ZxyL0VRUjK3G4qcpCbZqQrkBDwIHO89FDUT2uht0w/vKLEWiUQikWRmr3u6jh07jrlz36OsrJavv17BMcccl3b82muvYMCAfIYMLuDTD19GEXaaSpmmqiiAZYm0MLZp2pi2oDYcR9dUhg/IYXDfbMYOzmdwUTabd9ZRXhPFMAWaphHwOV28LMsmGDUwLEFuwOMYTUu4++lCCLL9HvoXZjF+SAG/POdAjp02jCH9cxjcNwevR0dRnF7YFTVRdx6Nhbfrq7cV5fvJy/KiKAqmaaMqSreHtg3TlspqEolEkoG9JjyeiWHDhvPii68CUFpays03/4q5c19zj3/w8kN88PJDABxz+lVMP+YsVE2nIMeLSBjKZODasCx0TUVVVUJRk6J88Ht1UBX6FwZYU1xFwKcnmoUIasMGwYjJph11eHSnVCvbr5OX5cW0Yhimhd+ruZnmthBMGFFAfo6PLTvq8Oma21xECOF6ykVCoCpKo+Ht+kl2Ck57zmRi3OWnTCLL3z1fi/aWn3UVqVUDEolE0pXs1UY7lQEDBvD00/8AnKS122//NS+++E/3+EevPcpHrz0KwBnnXsnsMy6lpCyIsAWKqqCpKt5EWNiybExLUBuKURuKsXbzLmKGU0vt8agI4Tz4TctGCPB6EvvKEYO8LC9jh+ZTuivMwD5Z2LYT/k6qo9WG4245WjK8nWwaYllOdjoajYa3G8v2BsHkUUXdZrCh/eVnnU2mRcXUfQdw8Li+PWpRIZFI9lwUkZoy3MMoL6+jX79cysvruuX6ti14+9O1PPbn3/Pl/FcyvmbaUT9g5smXUVZjudnXiuIkntVFDBAkWmVabka3oijuf2sqjgeeMKCKojB8QC5+j8aPTphA3LTSErsM0+apN1ftDp8DlTVRghEDIQTjhhQwYURBk96pa3wySKbWf09bldKStPT+GabNU3NXEc+goObVNS47ZWK375XPW1TcYLGjezQmDM3vEYuKzqA7f39dgZxf72ZPnV+/frmNHpOedhOoqsLJR0xg9uFPEYo+iipMHv7jfTz88IPuaxbNf5lF818GYMyBszngmEso6lNIKOool+UEPIRjFtGYSbIKS1NwE82SqmZJLFtgWBZTRvchy6+TVe8W1feUk+Htglwf44fm893pIzBMm5LyIH3zAw0856QRPuKAIU1me3d1qLotbVO7kkZV8tSW17RLJBJJe+k0o21ZFrfccgubNm1C0zTmzJmDEIIbb7wRRVEYN24ct99+O6ra8x90uyVPfdxyyx3ccssdGIbBn//8B+bMudN93YYl77FhyXsAjJh0JEecdg198wewpbQOKyWeYaV42T6vllBUM7EsG4+usf+Yvk0mgmVqejJ5WD4zpwzmybkr2bCtlphh4fNojBmSx49PmYSqKq0ywl0dqm5OWc2ra1QHY91WTtbTFxUSiWTvoNPC4x9++CHz5s1jzpw5LFy4kGeeeQYhBBdffDHTp0/ntttuY+bMmcyaNavRc3R3eLw5kl6rpsDfnnmSu35zc8bXDRxzMJOOuYJAbl/ASf7y6CpeXUHVNIb2y0ZTFWKGzYThBZx02MgWGab6oetH/vMNa7ZWNagBnzC8kH2GFWRULZsyuqiBEe7IUHVr7l+m8LNl2/i9zvZBez3+9oT6629LJPH6dLBEjwjfdwY9+ffXEcj59W721Pl1S3j8uOOO46ijjgJg+/bt9O3bl/nz53PIIYcAcMQRR/DZZ581abR7KplCx5Omn8bOndegKPDii//kpz+92n39zg1fsXPDVwAUDZvMgbOvxdd3CLlZXuKWQNiCmnAcUPi2uJqnKle1yDClNj0JR002bKttEL5VgHVbq4knyrlSaUyutLu8ykwRBIHqNlhpq8ffEaH+RuVabcGENtS0SyQSSVvo1D1tXde54YYb+OCDD3j44Yf5+OOP3YSr7Oxs6uqaXiEVFjoqZk2tOrqDNz/dyJqSGlRVITvbC8Cakhpycv2cPGM01113FVdefQV3//UL3pz7OkvefhBhOx5aZfEKPnzqSgD6DxnLL27+HSPGj2Tlhkr0lAd/6vlawsZtNRiWnSKjKogbNqZtY1uCjdtr6JMXoH+fgHsPAAzDxp/tIzfLQ13YIDfLQ0FhFn0KAk7r0Hrk6hojhxW2SlO8NffvnBMmYpgWdWEDv1flT/9ahqI1NIhbykIUFGa1aBzN3a+W8oPZ+5Lz+SZWbqgkGDHICXiYNKaIEw4f5TaJ2RPpab+/jkbOr3ezp8+vPp2eiHbvvffyy1/+krPOOotYLOb+PRQKkZeX1+R7q6rCPS78YZg2i1eVYmYIHS9eVcrUMUV4dJV5i4oJRgyGT/gOwybMAGD7+q9Y+s5DGLEQAGXb1nPDNWe57z/j8t8xYf+ZrpDLV6t2MmZgDvnZDVXG6od6NdsRgUlqmscMC9O0HYU01flfVW0E07RcqVIAj6by9icb2Li9Ns0LHdY3ixWbdjVsAjI6j+qqcJOfT+q42nP/tlXG2FUTyezxh+NsLq5q1uNv6f1qKdP36cfUMUXuHAcPyu9R38+Opqf9/joaOb/ezZ46v24Jj7/22muUlpZyxRVXEAg43t3kyZNZuHAh06dPZ8GCBRx66KGddflOI9mCU1UUNE1JM2rJ0HG238O64hp8uo6uaxiGhQAGjJ7Gd6/5J4oCNTtW8d/n0/fA//Pk7n8fdeb/MXjCkTz5xio3MzwZPs4U6p0xZTDDBmQnQuRg2o7gigBy/B63njtVgMUWAhRYtXlXg4Sz/UYXMWV0UVqoesyQXA4c3w/DtFucbf6D2fu2+bNuLjmtJeImnRHqb6oXu0QikXQmnWa0jz/+eG666SbOP/98TNPk5ptvZsyYMdx66608+OCDjB49mtmzZ3fW5TsF2xYsXFVK6a4IhmmhJVTMkprfSUOSaij65PqoqIkST0hyChzvdp9J05jxl0+ojRgsW/gRC16+K+1a81/5PfB7AGadeR3Ro850j6VmdccMi4+XbOOT5TvI8ml4dJVo3ETYAlV1xjdiQC7JDiS1oRihiEFhjp9xw/JYn2EfXFUUvi2u4bJTJnLEAUOoC8f5ak0ZG7bXsnzDrrQ9YcsWhKIGC1eVZjT+OZ9vYvo+/dr0eTff9rN5D7kjDL9EIpH0FDrNaGdlZfHHP/6xwd+fe+65zrpkp/Px4hJWbd5Fll+nNmyndccqyve7hiTVUPQtCGALQVlVBABFgcJcH0X5fmwBu2pjjJsykyHj3wRFYcfGZcyv54F/8MrDfPDKwwAccdLFzDjhYvdYZU2UuojTNSw/J4cRA3KJmiY1dXH65gfcvVYhhNvqU9NUUCFm2IQiBl5Pw33hVC90ybryBgZ52cZK1hZXoygKdeE4pbsiZPl1ivL9bocyVVFYuaGy1SHoVDIlpyWFYFqSDd4Rhl8ikUh6ClJcpYWkimsU5fsBR3vcFhCJWUwaWegamPqGol9BgHDMJBq3UBMa4VtLgwR8GghB33wfxTGTcMwkb9BETv75a2gq5No7ee7BK9PGseCtv7Hgrb8BMPWI7zHhiEvTJExVXcGv60R0C0sIbFOgabt7dOdn+8jy6Zim7YSyo2ZGo530QhsTFamqjRGMxBk+IBdQiBkWhuVEE/omPh9bCKrqotSEYvTND9S/RIvI1PZTa2XNeVOGX9IQqa0ukfRcpNFuIakh79QmG5bteNyHTByYZjDqGwpVUUAIPB7NbRriZEhrVNU5ncICXg1bCKJxCwWFrKLR/PovnwBQsXMzj995QdqYFi94lcULnIYnIyYdyYgf3w44OuYxw8IKOpEAgcA0hevhJ9FVp92JadvoKSI3qV5odTDWYE/YFs6CxbIE5dURwlHTCT8rYFo2hbledtXGHFU4ReFfH61nwrCmpVWbI3UfObWeuyVlYLLfd8uQ2uoSSc9HGu0WkmlvVFVA1VS8utbAK0k1FDWhGC/M+5bSyrCrfKZpKvnZHrxejV01EbcMS1MUVNVGSRjGovwAqgJ9BozghbdXAvDJopU8/tsfYplx93pbVv6Xe396DABDx03jO9+/hdFDi+iT5ydmmJSUBbGEQAgnRJ8kJ+Bln6EFFJeFMnqhmeZt2TaWLTBtQTARmtc0p7WnIWy27ExkcyoKhbk+TNPuMDW1RuVEG6k5T0UmkO0m09ZCJhW8RatLCdZF91htdYmktyGNdgtp695osu1mLOaUWhUJgWUJN/PctAWhsEE80fXLsgWaqiJsQThmsnNXiBH9c9lneEFaOHfAX+YTjhmUlpby0sNXEq7b5R4r+XYR/7rndAAGDZ/Ady+6F8NUqKiOEoma5GZ53b3nbL+H2dNHAGT0QjPNW1N39xdP/i3Z4cwwbcIxk+yAh9yAl/6FWRhxs0VGtSVIOdH20ViW/4wpg6W2ukTSC5BGuxW0dW801VtVFQVVV7AFGJZNXo4Pv0cjbtqUVYcJJTxXcDp+9cnzM3JwHgdN6I9lCzy6mhbq1dXJzJz2MVvKgtRUVfH8H39C+Y5N7rV3bF3D3357GgBZ+QOYfclD2CIfy7Ypyg8wOWXB0ZixyzTvkYNyWV9Sk/Y6IcCjKY7KWwZx3I4wqjIbvH00pikfiZlyMSSR9AKaNNr33nsvZ555JmPGjOmq8fRo2ro3muqtKorittI0LZsBfSz65PqwhE00ZrkG26mv1qkLxZm3qISVGyvJyfK6CVeaqvD1mjLWldRQF47j1VUmjxvKwi8W8ez7awmFQrzw519SvGGZO45wTSn/eeg8AHRfNuf9/CmmjO6DbYtG9ywb6wpm24I5z31NTSju9A+3BeDs2VvCMai14ThaVZjChApZRxjVzs4Gb28r0p5MU1sLW3YGCfidBMX6yMWQRNJzaNJoZ2dnc/XVV1NQUMCZZ57JiSeeSHZ2dleNrcfSlr3RpLf6yfLt1ARjiT1tL33y/USjBrqqIITAFqCpCrkBj1tSJlBQVCUt4Qpg2YYKN+HLsmy2lNaxrSLE+GEFfLPR5NyfPszW0iDCNvjs3/dQsu5/7nvNWIh/zDmXfwDjJuzPqy+/woABA9zjLdHrnjllEEs3VGBZgh2VIYRQEZAw6o4aW10oTn6WF+i4EqvOyAbv6lak3UFTWwtRw2T8sALWb0s36lJbXSLpWbSoy9eSJUt47bXXmD9/Pocffjjf//73mTZtWqcPrqd3+WothmnzxOsricRNd0/b69OJx0x0VcXGyfrWVBUQjsEVjrLZ8AG57j6ypqsoNuzYFaIuHE/TEgeYPX04Xk1ldXE16xO11Nl+3SlRsy2+fOtPbFz2QcYxHnXUMTzwwMOsK1Wa7QqWNHQrNu1ifUkNuq6SE/DQJ89HZU3UWUzYgjGD85g8qk+HG8CO9IozdRhrrAtaKr3p+9lYpzJwurddctK+fLp8e9piaOrEPTt7vDfdv7Yg59c7aUrGtFWtOQ3DYP78+bz55pusXbuWd999t0MG2Bh7mtGuDsZ4au6qNAOTNNqmZad5OoZps7W0DkVVyMvyurXPAJG4iW0Lyquj1L99toAxg/O4+oz9AHhv4RbWllQjBGwtDaIqTrlZbuKcC+e9yLz/PJJxvENHT+bkH95E0YDhu8eboTVnOGry1JursGxB6rPdFoKAz8OFs/chy99z0yfa04q0t30/W7I4SV0MSW313o2cX++kKaPdKvdkyZIlLFiwgFWrVrktNiUtJ5lElYksn4fjDx7OlNFFeHUNgcCja+QGPORle7FTbHNOlpeAX8dKiJk4YfWE4pmqEDctNwx64mEjOWBMX/w+HVVxktuSBltRFA497lx+8/jnbNtezTPPPE8gsFsEpWTjCh777fncfc1MnvzdRews/tZNSkobu19n0shCnJ34dA6c0L9HG2zYHTbORKb59maOnjrU/Y6Zlo1X15gyuihtayG5/SND4hJJz6PZp+mqVauYO3cu77zzDiNHjuR73/set9xyCz6fzCRtLU0lUY0ZkkskbroJX3XhOM9/sJb122qpDRtoqkJOwENBrpeRfXOxbMHmHbWOiIot3DB6tl8l2+fBq2tUB2Nk+z1u8lzS604KqdhCYJg2+44ocAz8iSezZUsphmlz0++f4ZWn7iAcrAagbNsGnr7nEgBefGAkjzzyJAcfPB0gcY5CKmojlFZFicVNvLrGxJF9OOHwUeyqDHbtB91K9qaMdCk0I5H0bpo02ieccALxeJzTTz+df/7znwwZMqSrxtVraO2+aoMkKkVBUWBdSU1aMw5bCOKmTU5Apy7ihM8raiJU1kbYsqMOFIjGTEzbSVxTFMXxsg2TnVVh/v7umgYJVbMOHo4ANpfWsaMiRCxu4/OorN9ei7ao2N1z9ugqJxw/iyFjp6IqCiUbv+H1v99FdcV2ALZs2cxJJ80CIK+gDwef/AtyBk5C2KCokO3TGdQ3m43ba3nn800cMKoPkbjZYw3E3qhPLoVmJJLeSZN72l988QWHHXZYV44njZ68p93ebONY3OL9r7aydEMlZbvC6CkdwywBtcFYooOWSTxuEDWEG3xOnj4ZMtc1p1+2sMEWNgrQvzCLvgUBR5dcCPweDUVRCEUM6sJxYoZFnzw/Hl1DVRpPMqufod3Pu4vrrruKVatWNJiTpvs48MSfM3DsdPKyPIwclEdVMIYiICfgafIz6q5Sq+R1A169QRJWMiM9dawd2S+8NyDn17uR8+udtCsR7YsvvuCFF15g48aN+Hw+xo4dy3nnncf+++/f4QOtT0822m3NNk59/9INlWyvCKXtTedmecnL8bJhWw0eTcG0BHGz+VxBr666bTlBwe/VKMjx0TffT0VNlGAkztD+OZimUxpmWs7+t9+rkxPwUJTvx5ch6aoxYxqOmtz1+Fv8+293U7V9TcYxHX3mDQyacEQi+z3H7eGdcXHQzOKno416U8pgmaICTfUL7+nh//bQU39/HYWcX+9mT51fU0a7yfD422+/zT333MOFF17I97//fRRFYe3atfzsZz/jxhtv5Pjjj+/wwfYG2qN/nfp+2xYYluMZJ8+0qy5GXcTAMAVGC4x1krhpuz27QRCLWwQjBrlZHqqCMUzTYuvOING4iWGJFG9dUJtoL1qQ401TvspkKJPGa+XmKnaZeXznnHsAR7jlmw8fpXzLUndMH79yL3AvALN+8HMOPuI0VFVN+4w+XlzC0g0VCBs0TSEat/j623JMWzD7kOFNGvVkL++2GPLGlMEgsz56Y69vT79wiUQiaS1NGu2nnnqKf/7znwwbtvshdsQRRzBr1ix+9atf7bVGu73613XhOMVldUTiFtGYCcIxWAIwTRulA0piTVtQE4pTG4q7YfW4uTsL2hYgLIFtOx53MGIwoCjLVTtrzFB+vLiEJesrqKyJYlm7FxVZ+QOY/v07AIgGd7HioyfYuX63mMsHLz/IBy8/CMBRp13FD46+jdwsP58s31FPVc3Zoy+tjKAgUFWVb+oZy9Re3m3Zmmjtoqup17e3X7hE0hHsyUp+knSaNNqGYaQZ7CQjR47ENM1OG1RPpz3ZxoZp88my7YTjpqvPneyYlSQaa3jettKUry5w9tY1zUliG9E/B4+uuqF7IQSatturNC2bL1bupKw6StywGj23P6cP0069Ea+uoNgRls97im+XfOgen//6o0x8/VEAJs04l8kzz8ayNacftxCIRPvTxd9WEI2ZFOb6086f2su7JV5yfZKLLk1TsWw7rQFKpkVXU4u0YETqcku6j71ByU+STpNGW9d7dn1td9GWbOPkj2tNcTXfFlcTN20Mw0JJZI+nZhYISCSHdf5cbEBYNgGfl+MPHk4sbjlSqyEj0XFMcfe8P12+k111kUR43YkMWI2kRCg45UV9C4v4/iW3Ytu3Eo+Hmf/64yz99DX3dSs/fYGVn74AwJiDTmPCjPNB8eHzOIpx1cE4+Tn+tOS7ZC9vyxKounOgNV3EdFWlJhR3zlNvjvUXXYZpY5o2AZ+OadnYgjRDnxPo2pKwtnhU0gvbc2ntNo+k99OkVa6urua1115r8HchBDU1NQ3fsBfRWv3rDxdtZen6SkgYY12FmAAFgaI4Kje22G2sFUVBEaJJT7kj0DUFr66Tl+XBsgVvfbGJytoYmqq46mm14XhCB91AVVUwnWS35F586hhVBXRNpSDHS2Guj9xcH99uqSIUdSIzY75zCZOOvhxhxVk07znWLfy3+94NX7/Ohq9fB2DU/rM58tQrEXixbBtVc4xNspe3pqloWronEYzG2VEZYlBRdpMLp0+W76C8OoJl2+iaiuLR3DkefaBj9Ot7MMGIQXUw5pwnoQ+f7dc5ZL/BXWII2+JRSS9sz6Yl2zySPY8mjfb06dNZuHBho8f2ZloqUmHbgg8WFfP+lyUYpoWmqZiWjaaCojhGz+fVUFCIRE3Xu7ZsQWc/VhUFhA15WR5ihs0Tc1ewaXttQv9cwevRXMNcFzawhSA3oBOL794aUVXFGWti4eH3aeRne+mbH6CqLkYoZhIzHEOLANNyBF2EUBj/nQvYd+aFCMtk7Zevsvazf7rn3bTsPTYtew+ACVOPY9YPriOQne+0NlUg26+ndUSrrIkSjpq8OO9bsv0eRgzI4agDh2LatntvnKS3SmpCcXwelbgJpmWDAL9PR9dUZkwZDDT0YEzbJho3UVUVXU1drnRBOCTDeOp7VJm8aemF7dm0JLdGsufRpNG+5557umocvZbmRCo+XlzCsg0VGJbt1FILgW3bGKZwDXQ87hxTFFDEbjOQ/H8Fx8DqmorXoxGMdMyPUVcVfF4VWwiicZO4aSNw9reNRCa616MRNywM0/FKwzELXdcwTAtQEuNKeN2KgrAFdWET2w4RNYSbIZ86n9Swv2PwNcZN/wHjpv8AYVtsXf4O33z0lPuaNYs/ZM1iZ0986PhDOfr7P6Uwb7B7vLImSk0oRm7AQ23I8bZXbKzgnS+LycvyMKx/DmOH5LF+Wy1CiIRGuoLPo+HVVUBhaP9sEI6uu6oqaR6MLSAUMfF7dRQF15NXFYXVG3cxbWzfFnnbbQ1TN+VRrS2uxrJtNmyva1C61p4KB0nPZ29S8pPspkmjffPNN/O73/0OgP/85z+cccYZ7rFzzz2XF154oXNH18tJPmw9moaWMNjgGDc74UkLSNR7CRRVQbEFugqKomJZNpZwjuuaU4ctRMP97tQ98eQ5W7InbtqCgKIQiprkBjyJwQgnk12omLZAxJ1OXV6PRmGOl2DESITUPQicSIJXVzFMi7gpiJk2mDZxw/FOAz4dbEFTagCphxRVY8QBJzPygJOxhaBk5Ycse/8v7vGSdf/j2TlOVvqofQ7iuLN+QVQpJC/R/rMuHCdu2pg2KLZFXRi2VwSd8HZdjH6FWRnvhbATD0G/J82DsQXEDKf1qaoqzj66orjGsCWJaO0NUzflUZWUO3PzebQ0bzoSM9tV4SDp+eyNSn6SZoz2qlWr3P/+xz/+kWa0I5FI541qDyH1YZsT8Lj10JYtUFXweXXXEFuWTSRmEvA5Iem4mbKfLZwwbmMh8/pJbEmaM9xCgMBx7StqIuyoDDcI9tqAR1fok+ejb57TZCQUNRFCMGZIPsP6ZbHk2woqaixMy+mhrWsKuqYSizq140r9je96aK7hEiSccgSOQR02eRbDJs9CU6Bi0//4/D+/RwjnRZvWfs2Td54HwKAREzjohOvJ7TsMyxJub/KoYVFW7UQKjMTfAz6NYMTc3epUU1FUGD8sH3A+64BPY+euCMGIgWnZxA0bTVXwebW0vfSmEtGSnvXCVaWs2ryrzWFqr67h9WgZuqhBLG43eDirisKWnUECfh3Trd3fTVd6YTIJrnPpjN7ykp5Ni9PD6wun1e/hLGlIaviqKNFasy4cRyQSzQqyvQzun0s0alBeHSEWtxBCwUoYpYBPIxyzSNhVpwQrkbXdHMmkNq+uNKqo5tUVcvweKmsjxBup4EsaTycUrtCvIECREERiJicfNoJvNlSyqzbmhP8TYzNM2w2vxw2b5pxJJ7yuEM0Q5ktiCRg47nDOuvF1crK8rF/xOV+8fj/xaAiAHVvW8OZjVwKQ02coB3z3egoHjgUhMG0or4mhAJFodWKPOlkTDkV5AaaMLkIAT725imA4zvbKMJGYgc+rO0l5KsRNC59XSwmbCyZlqNFO9azrwnFKd0XI8usU5fvdRVdLwtSp59lRGSISM8nN8rrnMSwLj6469fIaad5W1DDTWr265+wiL0wmwXUNsgHM3keTRjvVMEsj3Xrqh6/65vspzPWxZWctuVle+hUEUBTYVRslHDXQddUxDnGBsAUoakq4e3dIN2m1dU1JdPhKv66ugq5rIIRzTsUmZjpe8O67KPB5NMqro2RwxgAn7K6qCl5dJRQx6JPrw7IFNcEYkZjFSx+vp6wqkkgyEwgU18NNvl+IJp1s53PSVFRNwbAs19POhGk5CW+hqMGQ8dP56b1vo2sq3yz5Hx+9dA/hOsd7De4q4dPnfwmAP6eIA0/8OUVDJzklarYN1u5rjhyYy1Wn7ceny7ezbGNlogbcIBiOO+VdwiTg0fB7NXyJxLyYYeHzNN7FLDUBzOmNblEbdiaW2he9uTB16nkGFAZcOVrLthnaLwdVVYgbYbaW1qGlaNcriuK2es3yZdZT72xkElzXIhvA7D00K66yY8cOJ3Eq8d9Jw2EYMjOxJWQKX+0zvDChEe54JKGoCYoTgrZt2xFXUZREDTEoqupmX/t9Gn6vTihqoGtOaVJSbxwAIfB5dUYOysW2BSMH5rF5Zx2bdtRiWnbCwDu9uhOnbFC2lUQBNMWpxY7FTDbtqMUwbaxERrYCbpKanThvKh5ddbxUBKGYnSghSwwz5XUBv06fXB8l5SGicbNRw23bAiGcJDlFEWwtrUPXFPIHT+Kka57Bsm3KS9ay+J0/EKpyOpJFg5V88dKvnfH4sp2GJqMPIi/Ly4A+AXy6jmUL1hXXUFUbS5R+AYqCpjjXzPLrDOiThQKUVoXRVJWYYbldzA4e19f1HusnjWmagqapCCEIRgz65O2uOW8qTF3/PLujHH5URWHkoDzWbq0iO7Ht4pTkOdsvRfl+xg/Lx+fVusULa6/Mr0QiaZwmjXY4HOaHP/wh4IRmU/9bet4tI1P4SlOVlA5azv5wXiLsKQREYrt7ZKuu+IpjXocPdBpvbC0NYlrJrHPFDaGjgLBthA05fi+nfmcUny7fTigSp7I2hpqoLw5HTbdUqzGDrSYaioSiBpaNq22u4LQF3byzjriR2cIqgFdT6ZMfQNdg0/Y6/D5nj9VMhNLBCdeGoyaqouDVNacOO575nB7dWV5YFoDAwPlcROJaowblU5AzhYJBjyAE1FZsYdl7D1NTugEAIxbiy//c6YxP1Tj27Js48NDj2LSjhtqII7biXMEp5XK2MZz7AVBREyUSs1BVBV1zsuoXrS4lWBd1vcf6SWOq4nzedUnPPVFz3lyYurHkM1VRiJsW3xZXoyqKu+0SjBjYie/OpJGFad50V3th7ZX5lUgkjdOk0f7JT37S6DFptFtH/Qdn0pBrPg+PvrLUTRhSEipbNaE4qqqQ49cJJoRJcrM86KrzwB89OI8N2xyBG01VnHIt4RjLuCXYVRdl/7FFrrc1Y8pgPvhqK1t2BqmLxAlFDFQF938NEtYUR/glajieb7LsLOmdxy2BJpzEuKSJVVWwE/9QFGe8trDZVuYkuIUT80jd0tRUhREDc/FoKmOG5PPhomJMM13WVQGyfCpHHDiU+Yu3YWK7Yf5k+N2wbHTdSYDTFDAF5PUdwczzHwAgVLWD5R/8hcoSp6WosC0+fOEuPnzhLu4DDjv1egbscxSq6kQvbHt3FMKyLDehKjfLmzb+ZHlYUsgiVT0tSTIkHolZCCHw6lqzYeqmynm8urNg8Ho0hID8hJCNLZyF3iETB3brvrEsRZJIOo8mjfZNN91EUVERhx12GB5Pwx/a6aef3lnj2ivw6Cr9+mQxYViBu/+XlOtw6qAhiGPYcgNecrM87gP/yAOG8MTclXxbUu1qfCSf07qmJjz03Q9un1fj5O+MIha3ePfLLZRWhR3PUnF6cWOLNMMthGOgLUOk/S2V+mFs23bGoKnOPqZlC8oqQg1fJ3afTNcUaoJx8rO9TB7Vh8++2eF4t1EDw07MSwXTdmqlk/vnya4qqbXf4ahT5uTzapjRdIORXTiIw866C4BIXQXfzHuMso2L3ONfvPEH4A8ATD76MkYccCKK4mT2m7ZzrwJeJ5nMFo6EajKLPBQ1eG/hForLQ656mmlZ9M0POLXrQF62l+/s14fDJg9qUZi6qXKeSSMLWb+9lh0V4QZSrIMSTV+6E1mKJJF0Hk0a7f/85z+8/fbbfPbZZ0yYMIETTzyRww8/3JGylHQYqfvexeV1RGImRXl++uQ5BkJRFCaP6sP0iQPSHvhXnjaZ977cwvtflqDrNpqmkuXT6FcQQFUUvi2u4ch6+4efLt/Oxu21BHy6I9Iidie6oQh01dl/1XXn/+14ujBKYyQ9cZ/HCR0bpk15dbTJ92mqQsCrUxuOo6nQvzCL4QNyicZNyqqcciuBUw5n2/DV6p0Ypo2q7s6mT2XzDqevrkdX0BNKbZmuH8jtyyGn3wKAHatl7YK/suGb+e7xFR8/xYqPHXGXCTN+yPhDzmDs0AK8HpUdFSHqIia2LdA1lfwcH8K2WFtSja46tfQFuT4qqiNU1TlZ9bG4jc+jsmlnHV5d4+ipQ1tUCtVUOc/611dQE4q5CnFCCGpCMQYVZfUIo9jRpUiydEwicVBE/SdfI3zzzTe8/fbbLFy4kMmTJ3PSSSc1KmVqGAY333wz27ZtIx6Pc9VVVzF27FhuvPFGFEVh3Lhx3H777c0a//Lyuj22yXmS1PmFoyZPzl2JndjLTsWra1x2ysQGD6zqYIwn31iJoipp3arAqTe+9OSJaf2xn5q7irhpYQnB+pIaNznNtgVej4pHUwnHnD1mW4gm67xTURVQVIUsr9OtKyfgYVdtrMn3ez0qfo+GEILCXD+/vnAaC5ZuY8mGCjZucxLn7EQEQFcV/In6atjdfzxTXbqS8PZNq+nBJ2VkvR6NYf1zWLtxG9/M/zvFKz7I+PrJM85m5LTvo+k+9xpej4qmqowY0LBpfWVdlGy/Ex1x9uIFKIIsn6dVbUXrGyzDtHnyjZVsrwwRijrCL8ns8cFF2Vx+6qQOM2yt/f1lGmt7jG1nl47tTc+XPZE9dX79+jV8niRpcZ32fvvtx3777ceiRYu4//77mTt3LkuWLMn42jfeeIOCggLuu+8+qqqqOOOMM5gwYQLXX38906dP57bbbmPevHnMmjWr9bPZg4mbzt5paxJ4sv0ecrK8Ldo/TE0Q0hSFPrleqoMGKBCNm3h0jVjccGu8k4a7JdgCvImQvG0LcgIeqmpjTb7HsmwUr0ZOwEtOwEl4O3rqUL7ZVOnKpCYV4ATCTQiDzJ5/coHgiNU0P+7k1KJxi5LyOlRvDvsffw37H38NphFl7Wf/ZNPiue7rV3z6L1Z8+i8ARh14EpNmXoDfl+dEAlIWWrZwaqhrgjFy/B7KqsNEY5bbM1wIwahBeXh0jWjc4utvyzFtwexDhmccZ/18iFDUIBwz3Zr5ZKheVRQicTPte9JVHmpTxrU9SWeydEwiSadZoy2E4KuvvuLdd99lwYIF7LvvvlxwwQUcffTRjb7nu9/9LrNnz3b/rWkaK1eu5JBDDgHgiCOO4LPPPpNGux5tSeBpzf5h8vyxuJmo+TUT7SYdGU9FEU5DDLF7E1pTndpusxmXW9cgP8eDguOpNxca9yaSxgYVZSc0wDWy/U6nMY+qkRPwYFqCaNxy59PCoBCQCPmrjhZ68t+NvQ7AqJcFr3v8TDrqUiYddSmWabB+4Ut8u/Bl9/imJW+xaclbAIyachz9zr2enLx8KmuiBCMGcdMiGrNYv60G2xaoaqJmOxHZ2LC91lWC0zWV0soICoLjpg1v1oNM/Z6oioKqO4srw7QJeHWy/Z4uFzepb1xbshhpjraUjskwumRPp0mjffvtt/PJJ58wceJETjjhBH71q18RCASaPWl2djYAwWCQ6667juuvv557773XTYzKzs6mrq75kEZhYRbQdKhgTyB1flP3HcCi1aVpD1bbFkzddwCDB+VnfP8PZu9LzuebWLmhkmDEICfgYdKYIk44fFSKROju87/92SaCUQNFVQj4ddewZQd0QljEFQvDdHp9e3QVn8fZo44ZFgjhZoin1Vr7dIJhE1VNhqbtJo22LRwZ1+wsrzuuwYPy2VUbxQLyc/xUB6MJvW/b9YpTs9ibQgE8moIv4Cx0QpF408ItTRzTdA/7fOd8Js08n4BfY/UXr7J03t/c45uWf8jDy52GJsP3ncG0E64CTw4CRxAmuQtkmHZKRrqzT68kYvSqqrBqazX5+VmcPGM0AOFonJ2VEQYWBcjyexPnsKgLG+w/vh9L1pWjKFC2K0JdOI5p2fQrzGLxhkpsIVhTUuOU+GU7711TUkNOrt89f0tp7vdnmBZbykL4/R6EgLKqMHXhOJYlKK8uITfHx8kzxzT4LjbHrtoohi3w+ho+pgzDxp/to0+ek5lv2YJ3Pt/Eyo2VBMMGOVkeJo3O/Bto7fx6O3J+exZNGu1//etfFBQUsGrVKlatWsWDDz6YdnzevHmNvnfHjh1cc801nHfeeZxyyincd9997rFQKEReXl6zg6uqCu+xexZJ6s/v4HF9CdZF0xJ4JgzL5+BxfZv8HKbv04+pY4rSvIz6Sl0AB4zqwzufbURBwTSdeuncLI/TSjMYRVWctpzoGgB6opC7INtL3LSoDRmOqlg9DNMmGrdb1KgEHGMWN0ywBBNGFLjzM0wbj6ZQkO3BNC3iho2RIrGaTDxPbZKSCTWxp63ELfREJ6/m0umae0XApxOP2ww/4DSG7n8aCJst37zHNx8+7r5m6+pP2br6UwAGjJrK5GOvIiuvH0JN794m3Ix/gWnY+HQNYQsWryplyohC/vbOatZvq3HV18YMzmPcsAI2bKslFDHICugoAkorw+yqi6FrKnlZXnL8Op8u3UZdKE5hbsOw9OJVpUzNIL3aGC35/VUHY+yqieDRVSpqotSG427OQSxm8unSbUTC8VaHs5PfhXisocauV9eIhmKUxxyRp3mLitOiTXXBGJ8v25ZWQ9/W+fVm5Px6J23e027KKDdFRUUFl1xyCbfddhuHHXYYABMnTmThwoVMnz6dBQsWcOihh7bp3Hs67dESbomIRiRuku13Qs91EWO3IhsRCnK8HDiuH+tKqvFou5OnFBX2G9WH9dtr2V4eonRXGCvF89U0Zx8bHM9REZmztuvj7PGmLwBSw/39CgLkZnvZtL3GaQJCItEMJ0RqNWG1Az4nOmDaNprYPb6mSPYGz3g+r0Z2QCdqpCTXKSpjDjyR6Ud+j4JcH5989AYL39i9sC3dtJjSpy4HoM+QfZly/LXkFA5JO68tnNC/1+Pc43DM4PE3VrBmaxXJ6jbDtFn6bQXrSqoZPcjZ8jAMZ25CgREDc9OSEIVw6vSz/LrbQjRJZ4ibJMP10bjlCtQk0RLd6dqihNbSrR+pwCbZm2jSaA8ZMqSpw43y2GOPUVtbyyOPPMIjjzwCwK9//WvuuusuHnzwQUaPHp225y1pSGepWDmtJ03qwnEURXHbVNaGnIYaxx00jNyAx/X0s/27S3W0xSXEEg/mZI03OOHwWMqecFPSqKlEDcHG7TWUV4exhWDWwc7e59FTh2LagjVbqgAn29oWTm/uYNR0W4Im0RLGNvnI9no1DMPGErv7ebdkEdHYnvngPn5uOG8aD7y0FL/HwrKMtBr4ipoo4bjJ0H2PYsbRp6AoCgs/fZ/PXrsf23SkRXdtW838v10DQF6/URzw3Z+S12+ke45QxGBraZCcLJ3Kmmhi8eDkEwjhNEwJRUxMW6AnrLOwoTYYpzBntzSqAKrrYkRjFltL6/DoWgNN8o6u404a16+/LU/rRCaEk5CoKkqbFwstKR2TCmySvYkWZ4+3hltuuYVbbrmlwd+fe+65zricpNWkiJMIQdx02n4atVH+/t4aJgwr4JKT9nW98uTD8OipQ7Fsm5KyoNNr2naETzya6kqcCpG5fWhjxE2burDBZ9/s5KgDh7oSrxu31xIzLPxenZwsnepgHEV12n4KkTAIfh1VVQlFnRCpqkJOwEvAp7KrLu6G0a3EZnZjofvkwiV5zOdR8SQkVfOyvM68cQxQbraHraVB4obllpQ5iwgnWW/zzlo8mkbRqOmceN1LqApUbFnKorceJB6pBaC2fBMLnr0egKyCQUw94XpyRk/Gsmx21USJxpNysY7MbHJ9YAsny9+nawlNc+dAUhoVoLImSm3YSPREF9gZNMk7w+tMLrRKKyMYpoWmOe1ok2pwbV0stCTytCcpsMlEunTk59GQTjHakp5LKGqQE/Bi2Y5edTRuYdk2Hk1D11UiMbPRkhpVVThk4kCWra9ESWRDJ0vCvi2uwRa2Wx/dkn1tBSeBCEWhOhijJhRj2bcVbjjU59GwbeEYoUQ2V9Kr1jUVVVUYPiDHVUmzAEUobK8I4vdo2LaN3+chHDXcRYWmgGUKV3pVUxUCPp0cv0ZVMJ7oB+40OsnP9lOU72ddcQ2HTR5EwKcTipr4vRrhqIHC7s5rsbgzxqTCnEh4/qqqMHz8NEZOeIGYYVFevJKv3/oDoZpSAMLVO/j0hRsA8GUVMPXEn1M0fAqQsn+f8pmV7gqDwK3Lzs/2ul6/LQSVtVFiiYx7FFAM2+lvHjMbaJJ3JKqqMPuQ4SgIlq6vTAvLd4QSWlORpz1BgU22Mk1Hfh6NI432XkbSK0kqd20trQO0RFb2boGWxvYC69eFawmTkuXXCUbi+DwaPo9CzLScRDdVQVMUYhnSsx21MyeEralKxr1JyxLYiTrkYf1z3NagoajpJtJNHtMHIeDzFTsTbU5NPB6VwhwvfQsCFJfZWJYTJvd7NVQlETK3HYGXnIBO/8IAoNCvMJCQBd29RxyMxHnzi41s2F7j9kNP7WqmAEIBXcFVdtthh5xmLsDgvtlOYmBtDI+2H4f85iUs22bFimV8Ofchasq3ABALV/PFK7c5n6vu48CTfsGgMYekJdwpKQ1kasNx9hlWwIThhawrrmFLaa1rsFXFea2daDTj9Whdokl+3LThCBTWbKkiblrk+L1d0g60oxTYWuPZdaQXKOvR05GfR+NIo72XkeqVCNvp262qjj52bsDjGqrG9gIb82qG9c+hJhQjGDaJGxbZPg9Dh2Zj2k7JU0lZkHDUxKgneuLorNsU9Qng0dUGe5PJ1paW7YR6vbqaEBVxDNPlp0ziixU7WL6pkrxsJxkqGjcxTJvqkIGqKti2005UCCccryqOctvoIflcdtIkTNvGq2v8/d01Tu2ztlvXvLImyq66KOu3VWMLBVBQFJHW09zn0YjErUTXNQ2fV0NPtOO0beH21S7K96OpkO3TCccNBg7dh7Ovf5JQ1GRX2Rb+98YfqNqxFgDLjLHo9d+5n8NBJ/2M8Qcc6yTgJRY5+VmOl33EAUM4bPIgHnt9BbvqCdokE/ZicSuhzJaZjjBASe8oubXh82qMGZLbJd5RexI4oXWeXUd7gTKRLh35eTSNNNp7IUnvY82Ware1Z27A47Z5hKb3ApvyaqJxi4qaCH3zHSP87AfrqAvGyEpondcv1VITNcqHTR5Ifravwd5ksrVlMLI7RO4gmDzKKV1au7U6YVxj7nsFTsetipoo4Bh+pwuY4/2OHVrANWfsl/aQrb8YqayJUlUXxbZtTCvZsjM9XO30M7ewE+Fww7JREvvfteE4mqa6e89CCGZOGewaloWrSlm2voLaUJyCfsOZed69TnvN2lKWvf8IFVuXudf5+q2H+PqthwA4/uxfMHXGaWiqQiRmunv6MdNZcFhWel6BsASq5iSDZfnTf/IdaYBSvSOfRwMBKzdXoalql3lHbU3gbI1n19FeoEykS0d+Hk0jjfZeSKpX8u7CLawrqXEzkiF9LzCTB9aUV5Pl1xnu311jOGl0EZ8v20ZBjo9dtTEsW2AlEqx0VcXv08jy6Rw8YUCjXnyfPB+D+2ajoDRYJNSG4xSXBwlF4hiJPt1O5FpgCYGwHc+4f36Aony/G/rWVcd7TzVMqYuRukiMXbVRbCGIGQ2jA7s/K9xViACELSivjjKgT5bTeEVzWn36fbo7ZlVVKMjxcdQBQ4jGDHZWhp3St4QWek7BQGac9VuEAnasmm/mPcHmlZ+513z/Xw/w/r+clqOzz/wJ/jPuQNM08rK8BLw60bjTDc3NsFcgblg89/469h1RyKxpw9x5d5QB6s3eUWvG3hnz7KxEOsO0HYGaRqSReyp7UmJhZyCN9l6MR1c56bCRZC0uaeA1H3nAEOYtKm7SA2uJV3PC4aMI1kVZs6Uan1dDURQCPo2ivAACx4D6PRq5CWW0+l6836MzZnAesw525D3rLxKc3tJ2itqK4u7Pozh71iqOkVQVxQ19Z1qxpy5GXvtkI1tLg3g0La2cLRNJxa1kUlo4auBRVY4+cAgzpgxukIVf37vNyfYSjRtuH2/TdhqleHWNPgMGMfayu5g4vJAV3xbz0X/+wjcL33Wv/d4rf2L4K38C4PvnX0PB+BOxhRMGjyVD9oqTHLhxey2bd9SyYVsNV542GcsWzRogw7SoDsaaDTf3Zu+oNWPvjHl2dCJd6vfLsAQeTelVSVx7QmJhZyKN9l5OY15zqsJUezwwrUmvXmnwQ0yOZ8aUwbz/1Va2lgVZs7Wa4vJQ2oMnGQEwLaftpWE5sqvs3m5GUxT0REZ3MkSdpLkVe2l1BI+uNRB/yYRIaRbi8WgMKMri7GPH0rfAkfz1edP3kut7t31yfZRXWQiR2CP3ehIJcxCKmtSG4/h1jfz8Qr5/ya2ceP5NqHacRR88zQdvveie99///AvwFwAmHPo9xhx6Dh6Pz+1vnvwEvi2p5sNFWzlk4sBGDVCyR3hZbYxd1ZFmw+a92Ttqzdg7a54d2co09fvl9enEm6gI6al0dGvXPQlptCVAutfcGSHAprz6TD/ET5dvZ/22mgaLhmQ3raSXGvDreDwqeaoX04q52dNJx1sgyPbprVqxh6IG0ahJdsBDRXWk2bnZAhTVafyhKZDt85DfiLeV6bNVcDLOdV0l4NPxeTR21TolcHHDycDftKMWTVMYMziPi0/cl9wsL57zpgNPEIlEuO++Ofz5z39wz7nmf6+y5n+vAjB26okceOzFeHyOlr9lCVZvqWbGlCGNGqBgJM7akmqyAt4WLdp6s3fUmrG3ZZ4tSfJrbyJd6rV66zZFKh31eeyJSKMtaUBnhTpb+kNs6sHz2Tc7yc32oie8R9O0E204BYU5XiprY468qS1cgY/BRdmoitriFXvSm6oOxVCaiSY6bUMdQRbHq4d9RxQ0uSAIRY1ERrztlpbZAvw+nX2HF1BcEU40AHHm5dE0V8J1/bZavlpTltY5KxAIcNttv+W2235LPB7nT396iHvvvds9vn7x26xf/DYAIycfzUGzf0zczCFuWhkNkJlQY9Pr9btv7sGfyTsaPSSPA8f36/H7qq3x7JJ/W11cTTAcJyfLy+RhBQ1e25Ykv/YqIfbmbYpMdJYyZG9GGm1JAzo71NncD7GxB48tBNXBGDlZHpzQuqMGVpTvpyoYIxgy8OqO6ErAp9OvwJ8wiio/OmECcdNq0Yrdo6uMHpzH2q1VThY0TqlYaqcxVcUJxSdajsXiNpYmmDyqD8dNa7wVZcDrZMLXhOJu6Vbq/PICXob1z6amNkpZTYSY4WSIC5zogaYqrN5Sxcwpg9Pmk+rN/eIXN/CLX9zAO19s4o9//jOLP3jSvcbmFR+zecXHACx/+0TuvfdBoCjd0PbPTkjINqSpB3/qoqwuHGfRmlI2bK/lmw2VPV4coy2enSIcKVmlESGh7qg17s3bFJKWIY22pAEdHepsbQ1wYw8eK1HjralKoh+44Ro+n0elb4Efb0Lis36TjLhppRma5sZ08IT+zF+yjWjcwqM5++Km5Xj1quI0EImbNrYATVfxeh2N7/HDCpo0Sp8u307cTNZ0K0TjJqbl6IkX5fsxLZtvS2oor4kSDJuujrszHSehbNP2Wp58cyXxuIXXozkCNppCOGKmGcdZB4/gg8POYPB+JyGEYOs3H/DNh4+4Y3nvvbd57z3HA58x40h+c/cDTBg3FoCS8lDGB7/Pp2NadpOes0dXWbKunJWbq3qdOEZLPLtUY5zldz6P+nPrrjB1b96mkLQMabQlGemIRBDbFrz56UYWry5tVQ1wYw8eRcUtHUu2f1QT6mBRw8IXtzJ6EqkeRktDlrlZXoYPyHXKpxKKbAKoqI4QiZrYCAI+D3k5XnL8HvTEQmF9SS1HHZjZoMXiFp8s3+GIzJg2tnC6qKkqKKrq9oaurosRje822LvlTJ0FSjhuUrYrTDhmEYmZmJZNdsDDyIG5acbRsCwicaetpaIojJhyPKP2P55sv0689Gv+/dTt7tg+/fS/HHvkNAAOOmga515+G1FR4B5Pzl3XVJ55e02T93JP2VfNREvn1tVh6tRFaOpv1zAc4SCZxLXnII22JCMdkQjy8eIS1pTUYBpWq72tTIuGycP6YFo27yzcmi4eIgS5AUcdLLULFjgexughee4cFizd1qKQZerCIXXe/QoCjBqUx+qtVfg9On6/ntbvuakH8vtfbaWyNoqqOrKitm0TsZz+5bqmYguBIpyMcSdz3SQ1eV0IXCNfEzZQcORYEVAXNvi2pIaiPD998nx8s2kX5btCGIaNnlC8S35WhiUYvd+RrNtYTkGOj/fee4crr7yUUMjpv/7114v4+utTAeg/eBQnnHcT2X1HAYKCHOdzbupe7mn7qqm0dG5dFaZuahF6xAFD8Gf7iIZijf52e0NDjt4wxq5EGm1Jk7Q1EcT1SLS2eVuNLRp21UaZv3S70+jEstO6SZmWzfih+ZSUhQjHDAI+5+u9YVsN32yoJODTKa8OU5DrT79WI2NqLNowY8pgdlSGm30gpz5sALaU1mHZgphhuR3IFAW3naWmqliW7c7Lo6nE7fS2ogKwbMdrt+30vuVx06a8JkJlbdQRVInvVodzi+wUp1xO11R3XLNnn8CmTdsB+Pjj+fz4ykupqSoHoGz7Jv5+/48ByCscwOkX3cawsVOa/Nz25H3Vls6tq8LUze2b98nzUx4zGryvNzTk6A1j7A6k0ZZ0CkmPJDvb2+BYa7yt+ouGTGHr5EMx2+/lu9NHuNf/ctXOtH3VSMx0sstt3JaRTY2pqWhD8oEMuGFuRYXJw/qgqUoDYZph/bLZVh5CCLG7c5fY3dYz4NMd3fdEy81sv+7ooKu7dV9TZduFSDfY4Dzk4gkVtGy/k0AnEq/V0sK5glGD8tIMR/IB+cmmLL571d/QNZVQ+bd88p8HqCzdCkBtVSn/eMjpCR7IzuO0i25jxD4HN/jcOtNgtdTr6izvrDVza26Lqb1jbEmovjF6Q0OOxsZo2TaHTBzYYxZ/XR0JkEZb0ikkPZJMtMfbaixsXf+hme33sGFbXdoDTdOcMHQwYtAnz0/qYr2pMWWKNhw9dSi2ECxcXebWchfk+BDAR4tL+Kbew2Z1cRW14Thej4aC7aqeJS1vNGZQWhVmaL8cxgzOpyYcRwvGEJqCZeMmwDmeefOfUyTmbEmYlnCU2hK2X1EgL+DlhMTiJsnHi0tYuqGSmlDc7S8eKBrD2T//G/nZXr755hu+evsPlBavc84fquXFv/wSgId+6eXRR5/muyecknFftSPEMVrqdXWFd9bSuTW26LNt0azaYEtoSag+E70h5yDTGIUQVNZEee/LEpatryQny8vUfQdw8Li+3eJ5d1ckQBptSaeQNK5rSmrS/t4R3lZLHpqZHmjJ5iNOuZWNqqltHpOa6CdekOvD79XceutlGyqoC8UprBeCV4TihLNVgdejIgyRcKAFHk1lUN+cRFcwZ1x1YYO4ZaOgkOXT8Hp0p4e3AtG4ldZ0JRO2AK+ugrCxbPB6NHTVmf/RU4emqbQlH5BCCDdUD04ovS4cJy9LJ7fvcI6+8EEQEKrewaK3H2bH5m8AiMfjXHrpBe75TvvRrznplO9z+H6DOWzyoBaX2jVF0uuyhcAwbcIxI6Nn6Cw+KhC2s0jrDA+yqQhMJq+r/qKvo7zctm5D9Iacg0xjrKiJOq1xUVBU594uWl1KsC7aLdGB7opWSKMt6TSOnjqUnFw/i1eVdqgUYUuS5Bp7oPXN96NrKn6fTixmtqvv8rriGnfvOYmwoToYJz8n3ZPXNAWvrpLl9xBOZHyjKHg0FZ9Hw6OrVNZE2VEZZsTAPAb1yUJTFaqDMQJ+D5oC1aaNEAKPruHRFCJxE7Ph89rFFoI+eT4icYt+BQFys73sW08ExDBtdlSGqIvE8eia62UnsRINUJKd4EJRk+zCwRz9w3sYP6yAU6YVcOmVV7H0qwXue17/+928/ndH3GXmaT/hx5ddzqyD0z371n7Wa7ZUsWVnHeGY6bQ7VRWyfDpeTXUXBrqq8snyHc6iLJEXkO3X6Zvv7xQPMtUYt9TrSn5vQMGwdovrtMXLbes2RG/IOag/RlsIQlETJdHmNtnxT1W7JzrQndEKabQlnYaqKpw8YzRTxxR12v5iYx5BYw80AcycMqjd8oiN7dknNc5TPXkgoX/u7KtbliPUoqvOOHMS2wihqIktwLRsakNxwlHHQJVXRdBU0DUtYbRVEI4CXHlNvNExRqIWOQGYfcgwpif2AJNzTTUywXCc0l0RAj6n1rwuYriJa6qiEIkZ5Gb56JvvpyghaKOpKgoKRf0GccZl93DSRRZbS7bz8X/+RMmaT90xfPL6n/jkdaehyS233MHVV1+Hrrf8sZNcVKwtriIcs9ze5AgIRgy+2bSLp95cRdywqAnFKasO4/fqTo94IagLO59PYa6vUz3IlnpddeE4xWV1ROKWqzGQk2iL2xYvty3bEL2hlrv+GC1LYFk2iuosHlMXxN0RHejOaIU02pJOp7ukCJt6oCXbY7aVxvbsVcU5r1JvBV5RHSHgVVEUlVDUJGZYmJbAozvecPKhpGkqNcGYazi9Hg3TstE9GgXZTqeyYMTAEhA3HPnUxrqQKSqoinDHBLvDt8kkPRKhxoBPozYcJy/LS16Wl2DEacZSkOslHjfdXuuqgrsYCccMKmoiCVlWBVvPYdopv2Layb8iHg2yYv7f2LriQ3c8d911B3fddQcAP/vZL/n5z2/A50u/B8nxBbw6ny7fzrqSGmpCMUJRK1GzLtI+27hpEzMtdM35XITttCFNKtkpikIoajKoT3aneZCt8boWrSklEjcRYrfGQG1iYTG4qPVjbGtpZm9oyJE6xrhp4dE1svy6+11M0h3Rge6MVkijLdlj6cymA03t2X9nv4HuAzscM/D5dHRNpSDHedjYdphgxNl3DkUt1m+roTDHi5rIGg9FTdfTTUaqdUUhHDUZPiCXPnl+LNvGsm18Hp11xdVE47sfHknRmf4FfvoXZrO+pJYj9rdcIxgMx9m5K4wtHKNhC0dlTlOdSMDAoiwGFGUxon8OZx2/Dw/+c3GjD6e++QGyAx5CEQPD3J0Z7/XnMPWEn/Cd039GPBpm48IXWfLJv933PvTQ/Tz00P0A/PjHV3HDDbfy5doqN7ycXDQkO6WR0GdXE8l0uwVnwDRsFN0pl9M1FTNRJpf8DC3LZmj/rE7L8G2p12WYNhu21ZHt91AXjruLDwXHAx89ZVCbx9bahXFvaMhRf4wLV5WyavOuNI0G2xZM6IboQHdGK6TRluzxdJan39Sevaoq7sPGtGyeeXsNiqJQXh1hV108xdNyvMVddXH6FwbI8nuoDRsp4T9nD1tRFCxbYNk2Hk1F1VSyEw05bOGE0CtqIiQ11LL9HvoVOF29wjGD97/a6nZNU1SFcMx0pUh9Hs0tIfN7Nc4+ZhyDirKd0H2WL628LVlmBzB+WD5Zfp3xQ/NZuqECj64QN3FL2Tyq0w7UH8jm1PN+zpv/ehrLjPOHP9zHgw/e536OTzzxKE888SgA+x92EkefcTU1Iadtq6IoFOb60FVn/nbCWquKgqI4D3avV3X2OTUVRRUIQ6CAuxjx6ArF5SGemrvK3WtO9jkvKMxq9/egpV5X0rgnyw1DUdONrgR8GgdP6N/usbSW3tCQIznGWdOGoatKWnQgmT3eHXRXtEIa7b0cqTbUdpJ79vuNKKSiJkLf/ABZ/t0/qeTDxjAdmdFo3EyEtnf330bF3YPtWxBg7OB8ynZFMEwLTVPJC+iYliAcM9FU1U3ASa7oj546FF1VWF1cTThqggK5AZ2++QHXk/N7dLaUBd1rqoqCbTv/b9oCb8I4KkDcEPTND6R9F448YAhri6vZsK2WuOHonY8ZkseRiTrg5EOqLmQQiTn78h5NxeNREUKQE9CZkOh85tH93Hjjrdx4460YhsGjj/6Zu+7aLae67Iu3WPbFWwAMnziTg797FX3yhpHl9xCMGGiKwOfVUYBozCTLp7vdyLL9OrXhOD6PxtD+OQBU1UadMjnLyQWIxU0+XlLCJ8t3kBPw0KcgwIh+2e0q02mp15Vq3PsVBChK1PdrmoLfo5Ob1VDToCn2tt9upujA4EH5lJfX9ZjxyDptSach1YbaT0u11ZMP9a/XlTtZ48IJ3ia9UVVxzhWKGBw2eSCaCku+raA2FCcUtTBNC0s4pWGWZeP3p3v0yQfHewu3sLakOq2lpi0EIwbmsGZr9e4kNOEIwdgWkPCwFZxQuc+rEjctslIeDf9duo2YYTG0f46bhBYzLP67dBvHThuGZQsOmtCf6RMH8tGSYhatLac26OzTFuT6+c5+AzN6Hx6Ph+uu+xkXXnI1T76+guVfvMF7Lz3kHt+66hO2rvoEgDGTDmW/Y6/C9uQTjZkoCSnYLJ/qZrsLITATSX4lZUHycrzomkph7m5P0ikbMlBVi/wcH7EOKtNpiddV37irioKqK60Oqe7tv92eFh3o6vFIo72X0hsUkXo6rdFWP3rqUCzbZmdlmLhhg+IYbI/HeVBrqkJOlpdsv4fjpg1n/bZadlQ6+866rlEQ8JCf62XC0AJmTx/R4AHv0VVOPGwkgcUlGWVXi1O6dmmqSsCrO6pyNghboOi7e4+nJtEYppWWZLU7I15hbXE1lm2zYXtdmvH49Q+nOVnbCuRn+5o1Rtl+DznZPqYd+T2mHfk9hBB8/vEbzP/3/e5rNqz8HxtW/g+AIaOncOL5N9Bv4HDKq8JU1ESxbEEkZlKUF6Awz4dtCUxhU1O3e+84tWwoudUAHVOm01KvqyNCqvK3u3cjjfZeSG9QROpp1A9FtlZbXVUVjj9kBAKFj5dsIxw13M9fADl+nX2HFbjnVlAYMTDP9WyTDlRxWajRMbZEdtXx8CAn4HF6kWd5KMjxu/vU+wwvSBt3XbjxJKuS8iDBiOHWmUfjFl9/W45pC2YfMtz93KqDsSZDh/U9UEVROPzoUxk/dRa6prJ93RfM/cedWKaj8LVt43KevPN8AAoHjmH6yddTNGiMWzqlAJquoAmVuBHFTmxHJDP0VVVxE++SdFSZTnNeV3tDqvK3K5FGey+kNygi9RQaC0UeOL5fm7TVZ00bhqrAZ9/spDoYA6Awx8uMKYNdbyv1/qTWejd37iSNya7Cbg9vUFEWg4qyQEAkbuL36Bk9vtyszElWtoBY3ElkE0BlSn/z0soIQtjomsa3LQzhZvJAjz5waCJh7AB+d9MVPPP2Grau/YrX//5bIqFaAKp2buDdp34CQE6fwRx31o1M2u9AwEn083mdRZDP4/RZ1xLd1OrX+nZ12VBbQ6rytyuRRnsvpDcoIvUUmmpa0BZtdVVVmHXwcI46cCg1oRgIyM9JDyGn3h87RcxEVdp+fxrz8JpLZvLoWsYkK8Oy8HqcrO2Kmmhaf3PDtJi/ZAe6ptCvINBoCLf+tRvzQH1ezU3mGzNpOtff+xZbS+so3fINn792P+FapyNZcNd2XnvsOl4DcvKLOP2i2xk78SDGDsljw7Y6wjGD/GwvpmWn1fp2ZSOT9p5H/nYl0mjvhfQGRaSeQFOhyA3b6hg9JI/122vTjqV+hk09gD26St/8QMbrenSVcUPzmb9km1MWlFDOyvbrHHVg+8Kf9T28lnh8mbzgCSMK2bCthphhE0xRUANngRAzTGKGQlGitM1BYcWmXUyfOJCFq3ZmTKRqbDyp31lnP1rQf/hkvnvl04CgunQDX735EHWVxQAEayp57o/XAZCdncNfHnmKw2cdu1u0JTGXXF1j/Oi8Tm9k0lHn6ajf7t6Web4nIY32XkpvUETqbpoLRR48oT8F+YEGddpHHjCk3V2cnIxokfwHyfrrVF3wrqIxL33eomK+/rY8rcmIEIIsvyO2guJECRRNdcPnpmlzz/Nfg4C+TXjhmUh+N1cXV7vXU1UFj64xYOh4jr/sL06/8uptfPX2H6nYthaAUCjIRT86xz3P44//lUtPPoNwzGTksEKqq8Jt/mw6KimsNedpz293b8883xPoVKO9bNky7r//fp599lm2bNnCjTfeiKIojBs3jttvvx1VlSu87qI3KCJ1N82FInOzvBm11ectKm7Xg9wwbdaX1NKvICutlldVFNaX1HLUgXbaveoqr6m+F3z01KGYiT3sZF15TsBDnzyfq9CmqY7BTobPNU0hFDGwhSMx2teVR20+kap+eduKzbvYXh5yvHzFKQHLDXgoGDqJyZMf5/JTJlFTuYNf/OKnLFjwsXueK664BLgEgCeeeILTTju7gewsNP+5dlRSWGvP057frsw87/102i/8ySef5JZbbiEWc5Jt5syZw/XXX8/zzz+PEIJ58+Z11qUlrSD5IJYGuyHJUKRdz7utH4pM/QybewAbZvPNsJMefvJ9Hl11z5faJznZl/mpN1fx1NxVPPXmKuYtKnb6dHcBqqow+5DhzD5kKEP75zB8QA79CgJoqkq232k+ArjhcyEEAZ+OZTmKZcGE8U7SVA/oVJLlbVPH9cWja+4CIC/LS9+CAJqm4tU1vLrGiBEjeeWV1ykrq2X58rWccMLJaef68Y9/zIAB+fTvn8djj/0Zy7Ja/Lmm3qf6tHQu7TlPa3+7HfHdlHQ/nfakHj58OH/605/cf69cuZJDDjkEgCOOOILPP/+8sy4tkXQYR08dypTRRXh1p3GHV9eYMrqo0VBkRzzIG2tGAunJRkmvKV6vTvzjxSUtnF3HcNy04Rw0vh9+j+5+RkceMISjDhyCqoBp2k5rzywv/Qr8aImM+NRa6fpza45kCd3xhwxjaP9shg/IpSjfT2VNlC07a9m5K8zf312TZmwHDhzE3//+PGVltaxevYkzzzw77Zy33XYzgwYVMnBgPo/85UEikWiTn2tL71NzdNR5mqOjFhmS7qXTwuOzZ8+mpGT3l1yI3d15srOzqatrXnquMKEL3K9fbucMsocg59ezOeeEiRimRV3YIDfLg0fX0o6nzq+gMIs+BQFiGULqubrGyGGFDd6fian7DmDR6tK0fUbbFkzddwCDB+VjmBZbykL4MzzQt5SFKCjMatF1WkKm+1f/82jsMwpH4zzwz8XOvndiLvk5JtXBKB5NJSvgQVGUtLm1hnNPmEjB55tYuaGSzTtrCUVNCnL99O8TAEVhTUkNObl+Tp4xusGcXn75ReBFamtrueGGG3jsscfc45+89TSfvPU0AN/57g85+tRLM36uzd2nltJR58lE8v6lfjcd9TiBrjl18a35bvY0evvzpbV0WSJa6v51KBQiLy+v2fdUVYXp1y+327RluwI5v95FdSzdG8k0vxH9sjNn947Oa3HS08Hj+hKsi6ZnbA/L5+BxfSkvr6M6GGNXTSRzklw4zubiqnbV6yb3c+snarUkkan+ZzRucF7a51GQ7cE0TXRNJRJpOLfWMn2ffuw3opAn5650uqUpCkZK17PFq0qZOqYo42fVr18usZjCb3/7e37729+zo7yKy39yA19+9KL7ms/efY7P3n0OgOUfXsxdv72LnBzHUBwwqg/lFUG27AwSNcxG59Lc/nhz97ut1P9+Du+X3WhVQnsS8rqLPe35kqSphUiXGe2JEyeycOFCpk+fzoIFCzj00EO76tISSZfSEZn5zSUbdVa9rm0LPly0ldVbq4nFLfoWZqU11GhLIlPTwilmRkPW2uS6uGm5XcvS5iOgJhyjJhjb3eazCfoW5nPSOdcx6/vXYJkGn7//HAve+qt7/Pnn/sbzz/0NgJnHnsrhJ12F0LII+HXGDyvg+IOH4/Pu9lZbmq3dVYmhPakqIROyFK15usxo33DDDdx66608+OCDjB49mtmzZ3fVpSWSLqUjH8AtqVvuqFp72xY89voKvi2pTmSsq4RjFtW1EQCOOGBIm7Klm/o8Ug1ccgxtKUmqv4hJVWmzheBfH61nwvCCZs+T+rlquoeZJ17MzBMvxrRMti1/m+ee2t1S9JN5b/DJvDcA2Gf/Izj+rOvJ8ulpi5fWLnLa23yiKaPX2qqErkSWorWcTjXaQ4cO5aWXXgJg1KhRPPfcc515OYmkR9HZ3X86utb+g0XFrCuuBhxDK4SgOhjFND2sK65h/7F92yWh2ZLPo60lSfUXMckyM4QgN8tRQWtpaVOmz3XyqD787KxbePB3txKLm1x9wz3M/efv3fesXbaAtcsW8Cdg5syjeOihPzFo8LAu0wlvzOj9YPa+7mvS5HETHcaSdLcEqixFazlSXEUi6aV0pEdvmDZrtlRhpymYOaVUoahJMOp07epMCc321j2niq/UheOoikJ2wNOqWnBI/1xTpWaTHl8kbrHvIScx5fBTEEKw6ut5vPa337jv/+ST+Uybth8Ag0dO5JQLbqbvwBFp1+hoI9mY0cv5fBPT9+kH9FwJVNkEpXVIoy2R9HI6wqMPRQ3ihoWW8LBTsRJlXFk+D0P7ZbOupAZd7ZiQfP0xtMeTTxrb/cf15ck3VuH3aQ0MQUuNpW0LFizdljFcm2r8FEVh0rTjmDTtOAA2rvycN/5+J6FQEIDtm1fx+J0/BKDf4NGceuGvGThsfLuMZKMd5zIYvZUbKt0kvExbKrYQGKbNviMKWnX/OnLvWTZBaR3SaEskEqendZaXnLDhqpclUTWnleXf311DMBwnFDUBQU7A6f/dUfK3HeEJGqYNAvISjUHaep7mwrWN5ROcevLJ/PGOqwBYsGA+l11+CdVVFQCUb9/I0/dcCkC/AUOYOvhvTJ/e8oTc5jrOZTJ6wUi60Uvep7VbqympCBKL2/g8Kuu316ItKm52D7kz9p57WgSgpyfDSaMtkUhcLywSNwHcNps6jgGMWzaaLfB6NLweDdO22WdoAbOnj+iwB1t7kuvqG5NgxMC0LPrmB1x9iJZGBFoSrm1JPsERRxzFmtUb+HhxCfP++xn//utvqCrfBkB56TZOOeV4APr06cOjjz7N0Ucf2+S4mus4l8no5QTSjV4yGmHagmDMwKNpTmc2o2V7/p2x99xTGhj1lmS4nreMkEgk3cLRU4ey/+giBhdlM7hvFmMG53HGUWMZUJCFVs+A6apKcVmoU8bQGgW6JPXV4QpyfYBCdTDeqvNAy5TDksbvslMmcunJE7nslIkcO21Yg4d78nW/+elZLFy4lG3bq/noo8+YPHmK+5pdu3Zx9tln0L9/HsOG9eOtt+Y2uG6zHecG52WU252UoT7dMG02bqvFp2tp+QvNyZl2pgxqW+97R9JTFAabQ3raEokEyJzY5s/2sfCbHV2239iW5LpMxkQBRwddVznnmLHkZ7dco7s14dqW5hOkvm7y5P346KNPAdiw4Vuuv/5aFi78AoBYLMbFF5/vvu/Pf36cH/zgnBZ1nNNVJc3zHz0kj0MnDyIeiae9r617yJ2599zdDYx6UzJczxiFRCLpMaQ2osjN6hpd7KbG0BxNecaxmKO81poHbksbxXQEY8aMY+7c9ygrq2Xx4pUcc8xxacevvfYKBgzIZ/zofqxc+AbCzrxPn5vldT3/i0/clzFDctm4vZY/vrikQcOTtmqdd4VGenc1MOpNuuzSaEskkkbx6FqXGbC20hnGpC3hWsO0qQ7G2hwmHjp0GC+++CplZbWsWLGeU089I+34W88/wO9+ciR3XzOTLz74J7ZlZuw4t2RdOSs3VzlhXk/DMG9bFyVduZjparqqaUtHIMPjEomkSTpaxKWj6YxEptaEazsjgal///489dTfgb9TXV3F7bf/mhde2C1O9dFrj/HRa06Dk5/97FfM2O//8Pl8LQ7ztvWe9vTvQlvpKclwLUERPUV0NgPl5XV7rCB8Ejm/3s3eNL+eXArjGs4MxqQpw9kR92/eouKMD/spo4s6XM0rGAxy992/4emnH894/KKLr6Bg3zPIzs4GwOvTicecigDTsrn05Ilp+85tvac95bvQkb+/tn6HOoOmGoZIo93NyPn1buT8Op/WGIjWGpP2zs8wbZ6au4q42TBpzatrXHbKxE4zatFolAcf/D1/+MP9GY8fcPjJfPec69C0QIPx9BSj21464/vZEz6bHtHlSyKRSFpDW8LOna33Xp/uVPPy+/3cfPNt3HzzbRiGwSOPPMzdd++WU136+Zss/fxNAPY96Fiu/+UdaKrCvEXFPb4WuTvp6u9Qa+m9SyyJRLJH0xvqZntKApPH4+GnP/0FZWW1bNu2ix9deXPa8dVfz+OKc2cycGA+t/7f5VSU7eixn6mkaaTRlkgkPY7OFPLoSHpiRrXHo3Pfb29k2/ZqKqrDPPjQX9KOr1/xOX+65fvcfc1MnvvDddRUbO9Rn6mkaaTRlkgkPY7eVDfbE9S8MuHRVYryA/zw/AsoK6tl3cZyTrv4N6jq7h7mW75dwiN3nMPtVxzO7OOPZPXqVd04YklLkHvaEomkx9HTmkg0RXerebWUbL+HqYfNYvK0YwBYv+ILXn/mt0QjTkeyFSuWceSRTgOTMWPG8pe/PMHUqdO6bbySzPS8b5ZEItnr6Ylh5+boLjWvllL/Mx07+TB+cf873PTnBdx2798ZMmR3ZGDDhvV897vH0L9/HlOm7MNnn33SXcOW1KNnfrskEsleT08NO/dmGvtMr/7R6SxZsoqyslref38+++wzwX3Pzp07OOOMk+jfP48xY4bywQfvduMMJLJOu5uR8+vdyPl1Pp1ZN9sT5teZNDa/ln6ma9as5vrrr2bx4q8bHFNVlccee5rTTvue2/60q9lT719TddrS05ZIJD2anh527o209DOdMGFf3n33Y8rKavnyy2XMnHmke8y2bX7844sZMCCf/v3z+Oc//0EP9gH3GOSvQCKRSCTNMnLkKP7977mUldWybNkavvvdE9OO/+xn17oG/IknHsGyGiYRStqPNNoSiUQiaRWDBg3mH/94kbKyWlav3sT3v39W2vFbbrmRQYMK6d8/j4ceug/D6Dkler0dabQlEolE0maKiop49NGnKCurZf36Yi688JK043Pm3MmQIUX075/HXXfdQSQS6aaR7hlIoy2RSCSSDiEvL5/77/8DZWW1bN68k6uu+kna8YcffpARIwbQv38eN974C4LBPS+JrLORRlsikUgkHU5WVha/+c3dlJXVUlxczi9/eWPa8b/+9UlGjx5C//55XHvtFVRV7eqmkfYupNGWSCQSSafi8/n4v/+7mbKyWrZv38Udd9yddvyll15gn31G0r9/Hhdf/ENKS0u7aaQ9H2m0JRKJRNJl6LrO1Vf/hLKyWnburOa++/6Qdvytt95gv/3G0b9/HmeddTrFxVu7Z6A9FGm0JRKJRNItqKrKj350CWVltZSW1vDII0+mHZ8//yMOOmgy/fvncdJJs1i//ttuGmnPQRptiUQikXQ7iqJw5plnU1ZWS1lZLc888zxZWVnu8a++Wsjhhx9E//55HHXU4XzzzfJuHG33IY22RCKRSHocJ554Mps376SsrJaXX36dvn37ucdWrVrBscfOQFEUDj54Cl99tbAbR9q1dKnRtm2b2267jbPPPpsLLriALVu2dOXlJRKJRNILOfLIo1m1agNlZbW89dYHjBw5yj22ZctmTjppFv375zFx4mj++9+Pu3GknU+XGu0PP/yQeDzOv/71L37xi19wzz33dOXlJRKJRNLLOfjg6Xz55TLKympZunQpkybt5x6rqKjgBz84jf798xgxYgDvvPNWN460c+hSo/31118zc+ZMAA444ABWrFjRlZeXSCQSyR7E/vvvz8cff0ZZWS2ff/41hxxyqHssEonwox+dS//+efTvn8fLL7+4RzQ06dLWnL/+9a85/vjjOfJIp1PMUUcdxYcffoiu6xlfb5oWuq511fAkEolEsgewZcsWrrjiCt57772Mxx955BGuuOIKVLX3pXVltpadRE5ODqFQyP23bduNGmyAqqrwHtsvNYmcX+9Gzq93I+fXu2lsfllZfXj22ZcBKC0t5eabf8Xcua+5x6+++mquvvpqAG677U6uvPKaJm1RV9Nj+mlPnTqVBQsWALB06VLGjx/flZeXSCQSyV7GgAEDePrpf1BWVsvatZs555zz047/9re3MnhwH/r3z+Pee+8mFot100hbRpca7VmzZuH1ejnnnHOYM2cON910U1deXiKRSCR7MYWFfXj44UcpK6tl48ZtXHrpj9OOP/DAvQwb1o/+/fO47babCYfD3TTSxunSPe3WUl5et9eGd/YU5Px6N3J+vRs5v5YRiUR44IF7efjhBzMev+CCi7n99t+Sl5ff7mu1hB4THpdIJBKJpKcRCAS45ZY7KCurZdu2Sm6++ba0488++zfGjh1G//55XHnlpVRUVHTTSKXRlkgkEonExePxcP31v6SsrJYdO6q4++57046/+urLTJw4mv7987jggrPZsWN7l45PGm2JRCKRSDKgaRqXX36V29DkD3/4S9rx9957h/33n8Cjj/65y8YkjbZEIpFIJM2gKArnnXeBa8CfeurvbpnY0KHDumwcPacwTSKRSCSSXoCiKJx66hmceuoZXX5t6WlLJBKJRNJLkEZbIpFIJJJegjTaEolEIpH0EqTRlkgkEomklyCNtkQikUgkvQRptCUSiUQi6SVIoy2RSCQSSS9BGm2JRCKRSHoJPbrLl0QikUgkkt1IT1sikUgkkl6CNNoSiUQikfQSpNGWSCQSiaSXII22RCKRSCS9BGm0JRKJRCLpJUijLZFIJBJJL0EabYlEIpFIegl6dw+gMWzb5o477mDt2rV4vV7uuusuRowY0d3D6lBOP/10cnNzARg6dChz5szp5hF1DMuWLeP+++/n2WefZcuWLdx4440oisK4ceO4/fbbUdXevVZMnd/KlSu58sorGTlyJADnnnsuJ554YvcOsI0YhsHNN9/Mtm3biMfjXHXVVYwdO3aPuX+Z5jdw4MA95v5ZlsUtt9zCpk2b0DSNOXPmIITYY+5fpvnV1dXtMfevpfRYo/3hhx8Sj8f517/+xdKlS7nnnnt49NFHu3tYHUYsFgPg2Wef7eaRdCxPPvkkb7zxBoFAAIA5c+Zw/fXXM336dG677TbmzZvHrFmzunmUbaf+/FatWsXFF1/MJZdc0s0jaz9vvPEGBQUF3HfffVRVVXHGGWcwYcKEPeb+ZZrfNddcs8fcv48//hiAF198kYULF7pGe0+5f5nmd8wxx+wx96+l9Ngl19dff83MmTMBOOCAA1ixYkU3j6hjWbNmDZFIhEsuuYQLL7yQpUuXdveQOoThw4fzpz/9yf33ypUrOeSQQwA44ogj+Pzzz7traB1C/fmtWLGC+fPnc/7553PzzTcTDAa7cXTt47vf/S4//elP3X9rmrZH3b9M89uT7t9xxx3HnXfeCcD27dvp27fvHnX/Ms1vT7p/LaXHGu1gMEhOTo77b03TME2zG0fUsfj9fi699FKefvppfvOb3/DLX/5yj5jf7Nmz0fXdARwhBIqiAJCdnU1dXV13Da1DqD+/KVOm8H//93/885//ZNiwYfzlL3/pxtG1j+zsbHJycggGg1x33XVcf/31e9T9yzS/Pen+Aei6zg033MCdd97J7Nmz96j7Bw3nt6fdv5bQY412Tk4OoVDI/bdt22kPy97OqFGjOPXUU1EUhVGjRlFQUEB5eXl3D6vDSd0/C4VC5OXldeNoOp5Zs2YxefJk979XrVrVzSNqHzt27ODCCy/ktNNO45RTTtnj7l/9+e1p9w/g3nvv5b333uPWW291t+Fgz7h/kD6/GTNm7HH3rzl6rNGeOnUqCxYsAGDp0qWMHz++m0fUsbzyyivcc889AJSWlhIMBunXr183j6rjmThxIgsXLgRgwYIFTJs2rZtH1LFceumlLF++HIAvvviCSZMmdfOI2k5FRQWXXHIJv/rVrzjzzDOBPev+ZZrfnnT/XnvtNR5//HEAAoEAiqIwefLkPeb+ZZrftddeu8fcv5bSY7t8JbPH161bhxCC3/3ud4wZM6a7h9VhxONxbrrpJrZv346iKPzyl79k6tSp3T2sDqGkpISf//znvPTSS2zatIlbb70VwzAYPXo0d911F5qmdfcQ20Xq/FauXMmdd96Jx+Ohb9++3HnnnWnbOr2Ju+66i3feeYfRo0e7f/v1r3/NXXfdtUfcv0zzu/7667nvvvv2iPsXDoe56aabqKiowDRNLr/8csaMGbPH/P4yzW/QoEF7zO+vpfRYoy2RSCQSiSSdHhsel0gkEolEko402hKJRCKR9BKk0ZZIJBKJpJcgjbZEIpFIJL0EabQlEolEIukl7DlqJRKJJI2FCxfy5z//uYG+/bvvvssTTzyBaZoIITjttNO47LLL+OSTT7j//vsB2Lp1K3379iUrK4uhQ4fyl7/8BdM0Oeqoo5g9eza33norAD/4wQ+Ix+PU1NQQDocZNGgQAL///e/ZZ599unbCEslegDTaEsleRGlpKffeey+vvvoqhYWFhEIhLrjgAkaNGsWxxx7r6v1fcMEFXHvttUyfPt1973//+1/2228/3nnnHX75y18SCAR4+eWXAXj11Vf58ssvXcEgiUTSOcjwuESyF1FVVYVhGESjUcDRo77nnnsYO3Zss+999dVXmTVrFlOmTOGtt97q7KFKJJIMSKMtkexFTJgwgWOPPZbjjjuOM888k/vuuw/btpvtVb9r1y4+//xzjj32WE444QT+9a9/ddGIJRJJKtJoSyR7Gb/5zW/46KOPOPfcc9m+fTtnnXUW77//fpPveeONNzj00EPJz8/n2GOPZe3atXtFcwaJpKchjbZEshcxf/583n77bQYMGMD3v/99HnroIW655RZeeeWVJt/36quvsmTJEo455hhOPfVUVFXlxRdf7KJRSySSJNJoSyR7EX6/nwceeICSkhLA6Xe+evVq9t1330bfs2LFCnbu3Mn8+fP56KOP+Oijj3j88ceZO3cuwWCwq4YukUiQ2eMSyR7NokWLOPDAA91/n3LKKVx77bVceeWVGIYBwMyZM7nmmmsaPcerr77K9773Pfx+v/u36dOnM2rUKObOncu5557beROQSCRpyC5fEolEIpH0EmR4XCKRSCSSXoI02hKJRCKR9BKk0ZZIJBKJpJcgjbZEIpFIJL0EabQlEolEIuklSKMtkUgkEkkvQRptiUQikUh6Cf8PSp7XAA2tgWMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#функция для визуализации регрессии\n",
    "def plot_regression_2d(X, y_true, y_predict, xlabel='LSTAT', ylabel='MEDV'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 4)) #фигура + координатная плоскость\n",
    "    ax.scatter(X, y_true, alpha=0.7, label='Sample data') #диаграмма рассеяния\n",
    "    ax.plot(X, y_predict, color='black', label='Regression model') #линейный график\n",
    "    ax.set_xlabel(xlabel) #название оси абсцисс\n",
    "    ax.set_ylabel(ylabel) #название оси ординат\n",
    "    ax.legend(facecolor='white', fontsize=11) #легенда\n",
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "y_predict = sgd_lr_lstat.predict(X)\n",
    "#Строим визуализацию\n",
    "plot_regression_2d(X, y, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно рассчитать метрики регрессии для полученной модели. Давайте для примера посчитаем $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.542\n"
     ]
    }
   ],
   "source": [
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))\n",
    "# R2 score: 0.542"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый $R^2$ для линейной регрессии, обученной с помощью градиентного спуска, составил 0.542. Напомним, для той же модели, обученной с помощью МНК, метрика была равна 0.544. То есть доля информации, которую объяснила модель, обученная с помощью градиентного спуска, ниже примерно на 0.002. Очевидно, в реальных задачах такая разница не имеет значения. \n",
    "\n",
    "Теперь попробуем обучить многомерную линейную регрессию с помощью SGD. Как и раньше составим полную матрицу наблюдений $X$ из всех факторов, которые нам даны. Обучим модель и выведем значения коэффициентов в виде DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>1.540729e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>-5.382789e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>3.091632e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>1.485638e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>2.393660e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>1.134434e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>9.343666e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.241329e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>2.584134e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-3.359744e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>9.818128e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>4.723602e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>2.999564e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INTERCEPT</td>\n",
       "      <td>1.298221e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients\n",
       "0        CRIM  1.540729e+11\n",
       "1          ZN -5.382789e+08\n",
       "2       INDUS  3.091632e+11\n",
       "3        CHAS  1.485638e+10\n",
       "4         NOX  2.393660e+10\n",
       "5          RM  1.134434e+10\n",
       "6         AGE  9.343666e+10\n",
       "7         DIS -1.241329e+11\n",
       "8         RAD  2.584134e+11\n",
       "9         TAX -3.359744e+11\n",
       "10    PTRATIO  9.818128e+10\n",
       "11          B  4.723602e+10\n",
       "12      LSTAT  2.999564e+11\n",
       "13  INTERCEPT  1.298221e+10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Составляем список факторов (исключили целевой столбец)\n",
    "features = boston_data.drop('MEDV', axis=1).columns\n",
    "#Составляем матрицу наблюдений X и вектор ответов y\n",
    "X = boston_data[features]\n",
    "y = boston_data['MEDV']\n",
    " \n",
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_full = linear_model.SGDRegressor(random_state=42)\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "sgd_lr_full.fit(X, y)\n",
    " \n",
    "#Составляем таблицу из признаков и их коэффициентов\n",
    "w_df = pd.DataFrame({'Features': features, 'Coefficients': sgd_lr_full.coef_})\n",
    "#Составляем строчку таблицы со свободным членом\n",
    "intercept_df =pd.DataFrame({'Features': ['INTERCEPT'], 'Coefficients': sgd_lr_full.intercept_})\n",
    "coef_df = pd.concat([w_df, intercept_df], ignore_index=True)\n",
    "display(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все коэффициенты имеют запредельные значения (9-11 степени числа 10). Это типичная картина расходящегося градиентного спуска: алгоритм не достиг точки минимума по каким-то причинам. Такие высокие значения коэффициентов означают, что модель является неустойчивой.\n",
    "\n",
    "Давайте сделаем предсказание и выведем $R^2$ для обученной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -155407065857466568600977408.000\n"
     ]
    }
   ],
   "source": [
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "y_predict = sgd_lr_full.predict(X)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))\n",
    "\n",
    "# R2 score: -10590303862129977211224064.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2$ отрицательный. Да ещё какой! Напомним, отрицательный $R^2$ говорит о том, что модель абсолютно не описывает зависимости в данных.\n",
    "\n",
    "В чём же причина? Неужели SGD не справился с поиском 14 параметров (свободный член + 13 коэффициентов при факторах)?\n",
    "\n",
    "→ Ответ очень простой — отсутствие масштабирования. Как мы уже говорили ранее, при использовании градиентного спуска и его модификаций очень важно масштабировать данные с помощью нормализации или стандартизации. Иначе алгоритм теряется в таком растянутом пространстве из-за неравномерных градиентов.\n",
    "\n",
    "Давайте стандартизируем наши данные. Воспользуемся классом StandardScaler из модуля preprocessing библиотеки sklearn, который реализует стандартизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    " \n",
    "#Инициализируем стандартизатор StandardScaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#Производим стандартизацию\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "#Составляем DataFrame из результата\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попытка №2. Обучим модель и составим таблицу из её параметров:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.870552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.947112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.116802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.730289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-1.894276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>2.757578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.027846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-3.049237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>1.957066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-1.305271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-2.012984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.843065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-3.697319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INTERCEPT</td>\n",
       "      <td>22.541417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients\n",
       "0        CRIM     -0.870552\n",
       "1          ZN      0.947112\n",
       "2       INDUS     -0.116802\n",
       "3        CHAS      0.730289\n",
       "4         NOX     -1.894276\n",
       "5          RM      2.757578\n",
       "6         AGE     -0.027846\n",
       "7         DIS     -3.049237\n",
       "8         RAD      1.957066\n",
       "9         TAX     -1.305271\n",
       "10    PTRATIO     -2.012984\n",
       "11          B      0.843065\n",
       "12      LSTAT     -3.697319\n",
       "13  INTERCEPT     22.541417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_full = linear_model.SGDRegressor(random_state=42)\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "#Подаём стандартизованные данные\n",
    "sgd_lr_full.fit(X_scaled, y)\n",
    " \n",
    "#Составляем таблицу из признаков и их коэффициентов\n",
    "w_df = pd.DataFrame({'Features': features, 'Coefficients': sgd_lr_full.coef_})\n",
    "#Составляем строчку таблицы со свободным членом\n",
    "intercept_df =pd.DataFrame({'Features': ['INTERCEPT'], 'Coefficients': sgd_lr_full.intercept_})\n",
    "coef_df = pd.concat([w_df, intercept_df], ignore_index=True)\n",
    "display(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот теперь результат более схож с реальностью. Сделаем предсказание и посчитаем результирующий $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.740\n"
     ]
    }
   ],
   "source": [
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "#Передаём стандартизованные данные\n",
    "y_predict = sgd_lr_full.predict(X_scaled)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))\n",
    "\n",
    "# R2 score: 0.740"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь метрика имеет приемлемое значение, а значит градиентный спуск смог сойтись.\n",
    "\n",
    "**Важно!** Если вы обучили модель на стандартизованных данных, то и для предсказания необходимо передавать их в стандартизованном виде.\n",
    "\n",
    "Например, если попытаться сделать предсказание с помощью построенной модели, передав в качестве матрицы наблюдений нестандартизованную таблицу, то ошибки мы не получим, однако значение метрики будет неадекватным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -1856.503\n"
     ]
    }
   ],
   "source": [
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "#Передаём стандартизованные данные\n",
    "y_predict = sgd_lr_full.predict(X)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))\n",
    "\n",
    "# R2 score: -1856.503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У класса SGDRegressor, помимо random_state, есть ещё множество различных внешних параметров, которые можно настраивать. Со всем списком вы можете ознакомиться в документации. А мы приведём несколько самых важных:\n",
    "\n",
    "* loss — функция потерь. По умолчанию используется squared_loss — уже привычная нам MSE. Но могут использоваться и несколько других. Например, значение \"huber\" определяет функцию потерь Хьюбера. Эта функция менее чувствительна к наличию выбросов, чем MSE.  \n",
    "* max_iter — максимальное количество итераций, выделенное на сходимость. Значение по умолчанию — 1000.\n",
    "* learning_rate — режим управления темпом обучения. Значение по умолчанию — 'invscaling'. Этот режим уменьшает темп обучения по формуле, которую мы рассматривали ранее: $\\eta_{t} = \\frac{\\eta_{0}}{t^{p}}$.\n",
    "Есть ещё несколько режимов управления, о которых вы можете прочитать в документации.\n",
    "\n",
    "    Если вы не хотите, чтобы темп обучения менялся на протяжении всего обучения, то можете выставить значение параметра на \"constant\".\n",
    "\n",
    "* eta0 — начальное значение темпа обучения $\\eta_{0}$. Значение по умолчанию — 0.01.\n",
    "Если параметр learning_rate=\"constant\", то значение этого параметра будет темпом обучения на протяжении всех итераций.\n",
    "\n",
    "* power_t — значение мощности уменьшения $p$ в формуле $\\eta_{t} = \\frac{\\eta_{0}}{t^{p}}$. Значение по умолчанию — 0.25.\n",
    "\n",
    "Давайте посмотрим, что будет, если выставить константный режим управления темпом обучения и задать ему более высокое значение, например 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -335415038359.635\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_bad = linear_model.SGDRegressor(\n",
    "    learning_rate='constant', #режим темпа обучения — константа\n",
    "    eta0=0.1, #начальное и постоянное значение темпа обучения\n",
    "    random_state=42\n",
    ")\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "#Подаём стандартизованные данные\n",
    "sgd_lr_bad.fit(X_scaled, y)\n",
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "#Передаём стандартизованные данные\n",
    "y_predict = sgd_lr_bad.predict(X_scaled)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))\n",
    "\n",
    "#R2 score: -335415038359.635"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2<0$, то есть SGD разошёлся из-за слишком высокого темпа обучения. \n",
    "\n",
    "Вот ещё один плохой пример. Что будет, если поставить слишком маленькое значение параметра eta0? Например, 0.000001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -1.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1225: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_bad2 = linear_model.SGDRegressor(\n",
    "    learning_rate='constant', #режим темпа обучения — константа\n",
    "    eta0=1e-6, #начальное и постоянное значение темпа обучения\n",
    "    random_state=42\n",
    ")\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "#Подаём стандартизованные данные\n",
    "sgd_lr_bad2.fit(X_scaled, y)\n",
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "#Передаём стандартизованные данные\n",
    "y_predict = sgd_lr_bad2.predict(X_scaled)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))\n",
    " \n",
    "# R2 score: -1.578\n",
    "# warnings.warn(\"Maximum number of iteration reached before \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Так как модель линейной регрессии является довольно простой и исследованной, то значения параметров, которые обладают наибольшей эффективностью, уже установлены по умолчанию (аргументы по умолчанию), но бывают ситуации, когда поэкспериментировать с параметрами может быть полезно, чтобы попытаться повысить качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.735\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_bad2 = linear_model.SGDRegressor(\n",
    "    random_state=42,\n",
    "    tol=0.1\n",
    ")\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "#Подаём стандартизованные данные\n",
    "sgd_lr_bad2.fit(X_scaled, y)\n",
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "#Передаём стандартизованные данные\n",
    "y_predict = sgd_lr_bad2.predict(X_scaled)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))\n",
    " \n",
    "# R2 score: -1.578\n",
    "# warnings.warn(\"Maximum number of iteration reached before \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СРАВНЕНИЕ АНАЛИТИЧЕСКОГО И ЧИСЛЕННОГО РЕШЕНИЙ\n",
    "\n",
    "У вас наверняка возник вопрос: что лучше использовать — LinearRegression (аналитическое решение через метод наименьших квадратов) или SGDRegressor (численное решение через стохастический градиентный спуск)?\n",
    "\n",
    "Приведём сравнение двух реализаций в виде таблицы:\n",
    "\n",
    "![](pics/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По приведённой таблице можно выделить примерные области применения каждого из методов:\n",
    "\n",
    "* Если стоит задача одноразового обучения на всех данных, которые есть, и признаков немного (меньше 1 000), наш выбор — LinearRegression, так как МНК обеспечивает простое решение и гарантированную сходимость.\n",
    "* Если стоит задача непрерывного обучения модели в процессе её эксплуатации или количество признаков очень велико, наш выбор — SGDRegressor с возможностью корректировки параметров на новых данных.\n",
    "\n",
    "Однако существенной разницы между двумя подходами нет, так как используется одна и та же модель. Наиболее распространённым является классический метод наименьших квадратов (LinearRegression), им в прикладных задачах пользуется большинство дата-сайентистов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Дилемма смещения и разброса. Полиномиальные признаки. Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Центральной проблемой всего обучения с учителем (не только линейных моделей) является дилемма смещения и разброса модели. Давайте узнаем, что это такое.\n",
    "\n",
    "До этого момента мы обучали модели на всех имеющихся данных. С одной стороны, это имеет смысл, ведь мы хотим минимизировать ошибки модели, используя как можно больше данных для обучения.\n",
    "\n",
    "С другой стороны, из-за такого подхода становится труднее оценивать, насколько хорошо работает модель. Причина этого в том, что, если мы продолжим рассчитывать метрики, используя тренировочные данные, мы можем обнаружить, что при применении модели на незнакомых ей данных она работает довольно плохо.\n",
    "\n",
    "→ Таким образом, модель может детально подстроиться под зависимость в обучающей выборке, но не уловить общей сути.\n",
    "\n",
    "> Такая проблема называется **переобучением (overfitting)**. По сути, такая модель работает намного лучше с обучающими данными, чем с новыми. Она была чрезмерно натренирована на обнаружение уникальных характеристик обучающего набора данных, которые не являются общими закономерностями.\n",
    "\n",
    "> **Недообучение (underfitting)** — проблема, обратная переобучению. Модель из-за своей слабости не уловила никаких закономерностей в данных. В этом случае ошибка будет высокой как для тренировочных данных, так и для данных, не показанных во время обучения.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/24d0e131092f71d843db3a5fe85cdbf5/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-5_1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* На первом рисунке изображена простая модель линейной регрессии, не способная уловить сложную зависимость в данных.\n",
    "* На втором рисунке изображена оптимальная модель, которая хорошо описывает зависимость и при этом не имеет переобучения (полином четвёртой степени).\n",
    "* На последнем рисунке изображен полином 27-й степени, который подстроился под каждую точку в тренировочном наборе, но не смог уловить общие закономерности.\n",
    "\n",
    "С теоретической точки зрения недообучение и переобучение характеризуются понятиями смещения и разброса модели.\n",
    "\n",
    "> **Смещение (bias)** — это математическое ожидание разности между истинным ответом и ответом, выданным моделью. То есть это ожидаемая ошибка модели.\n",
    "\n",
    "$$bias(\\hat{y}) = M\\left [ (y - \\hat{y}) \\right ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. В зарубежной литературе математическое ожидание часто обозначается как $E$:\n",
    "\n",
    "$$bias(\\hat{y}) = E\\left [ (y - \\hat{y}) \\right ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем больше смещение, тем слабее модель. Если модель слабая, она не в состоянии выучить закономерность. Таким образом, налицо недообучение модели.\n",
    "\n",
    "**Разброс (variance)** — это вариативность ошибки, то, насколько ошибка будет отличаться, если обучать модель на разных наборах данных. Математически это дисперсия (разброс) ответов модели.\n",
    "\n",
    "$$variance(\\hat{y}) = D\\left [ (y - \\hat{y}) \\right ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. В зарубежной литературе дисперсия часто обозначается как $Var$:\n",
    "\n",
    "$$variance(\\hat{y}) = Var\\left [ (y - \\hat{y}) \\right ]$$\n",
    "\n",
    "Чем больше разброс, тем больше ошибка будет колебаться на разных наборах данных. Наличие высокого разброса и есть свидетельство переобучения: модель подстроилась под конкретный набор данных и даёт высокий разброс ответов на разных данных.\n",
    "\n",
    "Теоретически на составляющие смещения и разброса модели можно разложить любую функцию потерь. Например, разложение квадратичной ошибки (её математическое ожидание) будет выглядеть следующим образом:\n",
    "\n",
    "$$M\\left[(y-\\widehat{y})^{2}\\right]=\\operatorname{bias}(\\hat{y})^{2}+\\operatorname{variance}(\\hat{y})+\\sigma^{2}$$\n",
    "\n",
    "**Примечание**. Здесь математическое ожидание от квадрата ошибки — это теоретическая аналогия MSE, которую мы с вами рассматривали:\n",
    "\n",
    "$$M S E=\\frac{\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{n}$$\n",
    "\n",
    "Математическое ожидание — это среднее значение во всей генеральной совокупности (на бесконечной выборке), а не на конкретных значениях. Это исключительно теоретическая величина.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Вывод формулы — [здесь](https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D0%BB%D0%B5%D0%BC%D0%BC%D0%B0_%D1%81%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D1%8F%E2%80%93%D0%B4%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D0%B8%D0%B8#%D0%92%D1%8B%D0%B2%D0%BE%D0%B4).\n",
    "\n",
    "* $\\sigma^{2}$ — неустранимая ошибка, вызванная случайностью.\n",
    "* $bias(\\hat{y})^{2}$ — смещение модели (в квадрате).\n",
    "* $variance(\\hat{y})$ — разброс модели.\n",
    "О чём нам говорит эта теоретическая формула?\n",
    "\n",
    "Ошибка модели складывается из смещения модели (в квадрате) и её разброса, а также случайной ошибки. \n",
    "\n",
    "→ Если с последним слагаемым $\\sigma^{2}$ мы ничего не сможем сделать, то вот на первые два (bias и variance) мы можем как-то повлиять. В идеале мы должны свести их к 0. Однако уменьшение одного слагаемого повлечёт увеличение другого. На практике часто приходится балансировать между смещёнными и нестабильными оценками.\n",
    "\n",
    "[Дилемма смещения-дисперсии](https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D0%BB%D0%B5%D0%BC%D0%BC%D0%B0_%D1%81%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D1%8F%E2%80%93%D0%B4%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D0%B8%D0%B8) является центральной проблемой в обучении с учителем. В идеале мы хотим построить модель, которая точно описывает зависимости в тренировочных данных и хорошо работает на неизвестных данных. К сожалению, обычно это невозможно сделать одновременно.\n",
    "\n",
    "Усложняя модель, мы пытаемся уменьшить смещение (bias), однако появляется риск получить переобучение, то есть мы повышаем разброс (variance). \n",
    "\n",
    "С другой стороны, снизить разброс (variance) позволяют более простые модели, не склонные к переобучению, но есть риск, что простая модель не уловит зависимостей и окажется недообученной, то есть мы повышаем смещение (bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если провести аналогию, что модель — это игрок в дартс, то самый лучший игрок будет иметь небольшое смещение и разброс: его дротики ложатся кучно «в яблочко». Если у игрока большое смещение, то дротики сгруппированы около другой точки, а если большой разброс — дротики разлетаются по всей мишени.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c9e31e930c613a02ef6abd7c363158d6/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-5_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересный факт. По [теореме Гаусса-Маркова](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%93%D0%B0%D1%83%D1%81%D1%81%D0%B0_%E2%80%94_%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D0%B0), оценки линейной регрессии, полученные методом наименьших квадратов, обладают наименьшим разбросом. То есть если существует другая линейная модель, обученная способом, отличным от МНК (например, градиентным спуском), то теорема гарантирует, что эта модель будет обладать большим либо равным разбросом (variance), чем МНК-модель. То есть у линейной регрессии, обученной с помощью МНК, меньше всего риск переобучения. \n",
    "\n",
    "Однако это не значит, что его не существует вовсе.\n",
    "\n",
    "Теперь, когда мы знаем о теоретических основах проблемы переобучения и недообучения, что мы можем сделать, чтобы лучше судить о способности модели к обобщению на практике? Как диагностировать высокие bias и variance?\n",
    "\n",
    "Типичным решением является разделение данных на две части: обучающий и тестовый наборы. На тренировочном наборе данных мы будем обучать модель, подбирая параметры. Тестовый набор данных, который модель не видела при обучении, мы будем использовать для оценки истинного качества моделирования. Схематично можно представить это следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/6b3371e3f1d290f0c216ac1e826005ff/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-5_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как это работает на практике. Работать будем с уже знакомыми нам данными — данными о домах в Бостоне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston \n",
    "\n",
    "boston = load_boston()\n",
    "#создаём DataFrame из загруженных numpy-матриц\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "#добавляем в таблицу столбец с целевой переменной\n",
    "boston_data['MEDV'] = boston.target\n",
    " \n",
    "#Составляем список факторов (исключили целевой столбец)\n",
    "features = boston_data.drop('MEDV', axis=1).columns\n",
    "#Составляем матрицу наблюдений X и вектор ответов y\n",
    "X = boston_data[features]\n",
    "y = boston_data['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn для разделения выборки на тренировочную и тестовую есть функция train_test_split() из модуля model_selection. Данная функция принимает следующие аргументы:\n",
    "\n",
    "* X и y — таблица с примерами и ответами к ним.\n",
    "* random_state — число, на основе которого генерируются случайные числа. Тренировочная и тестовая выборка генерируются случайно. Чтобы эксперимент был воспроизводимым, необходимо установить этот параметр в конкретное значение.\n",
    "* test_size — доля тестовой выборки. Параметр определяет, в каких пропорциях будет разделена выборка. Стандартные значения: 70/30, 80/20.\n",
    "\n",
    "Функция возвращает четыре объекта в следующем порядке: тренировочные примеры, тестовые примеры, тренировочные ответы и тестовые ответы. \n",
    "\n",
    "Итак, давайте разделим нашу выборку на тренировочную и тес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (354, 13) (354,)\n",
      "Test: (152, 13) (152,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Разделяем выборку на тренировочную и тестовую в соотношении 70/30\n",
    "#Устанавливаем random_state для воспроизводимости результатов \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)\n",
    "#Выводим результирующие размеры таблиц\n",
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)\n",
    " \n",
    "# Train: (354, 13) (354,)\n",
    "# Test: (152, 13) (152,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После разделения в тренировочной выборке оказались 354 наблюдения, а в тестовой — 152.\n",
    "\n",
    "Затем обучим линейную регрессию (с помощью МНК) на тренировочных данных и рассчитаем $R^{2}$ для тренировочных и тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.743\n",
      "Test R^2: 0.722\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса LinearRegression\n",
    "lr_model = linear_model.LinearRegression()\n",
    "#Обучаем модель по МНК\n",
    "lr_model.fit(X_train, y_train)\n",
    " \n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict = lr_model.predict(X_train)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict = lr_model.predict(X_test)\n",
    " \n",
    "print(\"Train R^2: {:.3f}\".format(metrics.r2_score(y_train, y_train_predict)))\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict)))\n",
    "\n",
    "# Train R^2: 0.743\n",
    "# Test R^2: 0.722"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, $R^{2}=0.743$ на тренировочной выборке и $R^{2}=0.722$ на тестовой выборке. То есть показатели довольно близки друг к другу (низкий разброс ответов модели для разных выборок).\n",
    "\n",
    "Это одно из свидетельств отсутствия переобучения. Это не удивительно, ведь линейная регрессия, построенная на 13 факторах, является довольно простой моделью: всего лишь 14 параметров, что очень мало по меркам машинного обучения. Риск переобучения возрастает с количеством факторов, которые участвуют в обучении модели.\n",
    "\n",
    "Но что насчёт смещения? Самый простой способ оценить смещение и недообученность модели — посмотреть на значение метрики и интуитивно оценить её.\n",
    "\n",
    "Может, наша модель слишком слабая?  $R^{2}=0.722$ — не слишком уж высокий показатель (напомним, максимум — 1). Возможно, стоит попробовать обучить более сложную модель. Например, можно построить модель **полиномиальной регрессии**.\n",
    "\n",
    "**Примечание**. Существуют более совершенные визуальные способы оценить наличие смещения и разброса, такие как кривая обучения и кросс-валидация. О них мы ещё поговорим далее в курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПОЛИНОМИАЛЬНЫЕ ПРИЗНАКИ\n",
    "\n",
    "> **Полиномиальная регрессия (Polynomial Regression)** — это более сложная модель, чем линейная регрессия. Вместо уравнения прямой используется уравнение полинома (многочлена). Степень полинома может быть сколь угодно большой: чем больше степень, тем сложнее модель.\n",
    "\n",
    "В простом двумерном случае, когда мы рассматриваем зависимость целевого признака от одного фактора, полиномом второй степени будет уравнение параболы:\n",
    "\n",
    "$$\\hat{y} = w_{0} + w_{1}x + w_{2}x^{2}$$\n",
    "\n",
    "Геометрически полином в двумерном пространстве — это некоторая кривая, которая пытается описать зависимость в данных. Выглядит это следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/01a58ba6150976bb3c408323a9b5fbcf/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-5_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда факторов больше одного, например два, то, помимо возведения фактора в квадрат, появляются ещё и комбинации из $x_1$ и $x_2$:\n",
    "\n",
    "$$\\hat{y}=w_{0}+w_{1} x_{1}+w_{2} x_{2}^{2}+w_{3} x_{2}+w_{4} x^{2}_{2}+w_{5} x_{1} x_{2}$$\n",
    "\n",
    "Такая модель будет описывать сложную поверхность в трёхмерном пространстве, которая проставлена на рисунке:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/10616697357bc2252dd39b8fa419ffc0/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-5_6.png)\n",
    "\n",
    "Заметьте, как быстро растёт количество коэффициентов, а с ним и сложность модели. А ведь это только два фактора — $x_1$ и $x_2$. Мы не будем приводить уравнение для общего случая, как делали это с линейной регрессией, так как оно будет содержать слишком много слагаемых.\n",
    "\n",
    "Например, рассматривая построенный ранее график зависимости медианной цены домов от процента низкостатусного населения, вы могли заметить, что между данными показателями существует не линейная, а скорее полиномиальная связь.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/4b02bf0809fb707c3950ce0aa275368e/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-5_7.png)\n",
    "\n",
    "На рисунке изображены модели линейной и полиномиальной (вторая степень) регрессий.\n",
    "\n",
    "Заметим, что степени $x$ можно тоже считать своего рода искусственными признаками в данных. Они называются полиномиальными признаками.\n",
    "\n",
    "Поэтому полиномиальная регрессия — это та же линейная регрессия, просто с новыми признаками. Полиномиальные признаки — один из самых распространённых методов FeatureEngineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c9664ed6fac637130e49aa29ebfb67e9/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-5_8.png)\n",
    "\n",
    "→ Благодаря степенным слагаемым модель становится сложнее и начинает улавливать более сложные зависимости и выдавать меньшее смещение. Но, как вы понимаете, резко повышается риск переобучения модели — увеличивается разброс предсказаний на разных данных из-за количества факторов.\n",
    "\n",
    "Давайте проследим за этим.\n",
    "\n",
    "Построить полиномиальную регрессию в sklearn очень просто. Для начала необходимо создать полиномиальные признаки с помощью объекта класса PolynomialFeatures из модуля preprocessing. Это преобразователь, который позволит сгенерировать полиномиальные признаки любой степени и добавить их в таблицу. У него есть два важных параметра:\n",
    "\n",
    "* degree — степень полинома. По умолчанию используется степень 2.\n",
    "* include_bias — включать ли в результирующую таблицу столбец из единиц (x в степени 0). По умолчанию стоит True, но лучше выставить его в значение False, так как столбец из единиц и так добавляется в методе наименьших квадратов.\n",
    "\n",
    "**Примечание**. Как правило, дата-сайентисты останавливаются на полиноме второй (максимум третьей) степени. Чем выше степень полинома, тем больше слагаемых, а значит, тем больше признаков и тем сложнее становится модель.\n",
    "\n",
    "Для того чтобы подогнать генератор и рассчитать количество комбинаций степеней, мы используем метод fit(), а чтобы сгенерировать новую таблицу признаков, в которую будут включены полиномиальные признаки, используется метод transform(), в который нужно передать выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 104)\n",
      "(152, 104)\n"
     ]
    }
   ],
   "source": [
    "#Создаём генератор полиномиальных признаков\n",
    "poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit(X_train)\n",
    "#Генерируем полиномиальные признаки для тренировочной выборки\n",
    "X_train_poly = poly.transform(X_train)\n",
    "#Генерируем полиномиальные признаки для тестовой выборки\n",
    "X_test_poly = poly.transform(X_test)\n",
    "#Выводим результирующие размерности таблиц\n",
    "print(X_train_poly.shape)\n",
    "print(X_test_poly.shape)\n",
    " \n",
    "# (354, 104)\n",
    "# (152, 104)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы сгенерировали новые тренировочные и тестовые наборы данных. В каждой таблице в дополнение к 13 изначальным признакам добавилась 91 полиномиальная комбинация степени 2.\n",
    "\n",
    "В результате мы получили два numpy-массива:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_poly))\n",
    "print(type(X_test_poly))\n",
    "# <class 'numpy.ndarray'>\n",
    "# <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем скормить наши данные модели линейной регрессии, чтобы найти коэффициенты полинома по МНК-алгоритму:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.929\n",
      "Test R^2: 0.268\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса LinearRegression\n",
    "lr_model_poly = linear_model.LinearRegression()\n",
    "#Обучаем модель по МНК\n",
    "lr_model_poly.fit(X_train_poly, y_train)\n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict_poly = lr_model_poly.predict(X_train_poly)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict_poly = lr_model_poly.predict(X_test_poly)\n",
    " \n",
    "#Рассчитываем коэффициент детерминации для двух выборок\n",
    "print(\"Train R^2: {:.3f}\".format(metrics.r2_score(y_train, y_train_predict_poly)))\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict_poly)))\n",
    "\n",
    "# Train R^2: 0.929\n",
    "# Test R^2: 0.268"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потрясающе! На тренировочной выборке коэффициент детерминации $R^{2}=0.929$, то есть наша модель описывает почти 93 % зависимости в данных.\n",
    "\n",
    "Смотрим на показатели тестовой выборки и сразу «спускаемся с небес на землю»: $R^{2}=0.268$. Метрика значительно ниже, чем на тренировочном наборе. Это и есть переобучение модели. Из-за своей сложности (количества факторов) модель полностью адаптировалась под тренировочные данные, но взамен получила высокий разброс в показателях на данных, которые она не видела ранее. \n",
    "\n",
    "**Примечание**. Модель линейной регрессии может быть неустойчивой, даже если показатели на тренировочной и тестовой выборках довольно близки, однако все коэффициенты уравнения имеют огромные значения.\n",
    "\n",
    "Такая модель никому не нужна, так как она не отражает действительности.\n",
    "\n",
    "Однако не стоит расстраиваться — есть один замечательный метод, который сможет спасти нашу модель от переобучения, и это **регуляризация**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РЕГУЛЯРИЗАЦИЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Регуляризация** — способ уменьшения переобучения моделей машинного обучения.\n",
    "\n",
    "Идея регуляризации состоит в том, что мы намеренно пытаемся увеличить смещение модели, чтобы уменьшить разброс. Закон баланса в действии!\n",
    "\n",
    "Но как можно увеличить смещение модели? Мы можем «наказывать» модель за обучение сложным взаимосвязям. \n",
    "\n",
    "Математически это будет очень простая операция — добавление к функции потерь некоторого штрафа.\n",
    "\n",
    "> **Штраф** — это дополнительное неотрицательное слагаемое в выражении для функции потерь, которое специально повышает ошибку.  За счёт этого слагаемого метод оптимизации (OLS или SGD) будет находить не истинный минимум функции потерь, а псевдоминимум.\n",
    "\n",
    "Есть несколько способов добавления штрафа к функции потерь:\n",
    "\n",
    "* **L1-регуляризация (Lasso)** — добавление к функции потерь суммы модулей коэффициентов, умноженных на коэффициент регуляризации $\\alpha$:\n",
    "\n",
    "$$L_{1}(w)=M S E+\\alpha \\sum_{j=1}^{m}\\left|w_{j}\\right|$$\n",
    "\n",
    "* **L2-регуляризация (Ridge)**, или регуляризация Тихонова — добавление к функции потерь суммы квадратов коэффициентов, умноженных на коэффициент регуляризации $\\alpha$:\n",
    "\n",
    "$$L_{2} (w) = MSE + \\alpha \\sum_{j=1}^{m} (w_{j})^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Коэффициенты** $\\alpha$ (альфа) — это коэффициенты регуляризации. Они отвечают за то, насколько сильное смещение мы будем вносить в модель: чем оно больше , тем сильнее будет штраф за переобучение.\n",
    "\n",
    "А что по геометрии? Рассмотрим, как будет выглядеть минимум функции потерь в трёхмерном пространстве (вид сверху). Первый метод, $L_{1}(w)$, заставляет искать минимум функции потерь на пересечении его с ромбом, а второй, $L_{2}(w)$, — с окружностью. Визуализация представлена ниже:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/b62125f402f9f7558e5eab24cf3964bd/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml2-5_9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунках выше изображено решение задачи поиска минимума функций.\n",
    "\n",
    "**Для левого рисунка:**\n",
    "\n",
    "$$L_{1} (w) = \\frac{\\sum_{i=1}^{n} (y_{i} - w_{0} - w_{1} x_{1})^{2}}{n} + \\alpha (\\left | w_{0} \\right | + \\left | w_{1} \\right |) \\rightarrow min_{w}$$\n",
    "\n",
    "**Для правого рисунка:**\n",
    "\n",
    "$$L_{2} (w) = \\frac{\\sum_{i=1}^{n} (y_{i} - w_{0} - w_{1} x_{1})^{2}}{n} + \\alpha ((w_{0})^{2} + (w_{1})^{2}) \\rightarrow min_{w}$$\n",
    "\n",
    "Красными концентрическими кругами (линиями равного уровня) изображена функция потерь $MSE = \\frac{\\sum_{i=1}^{n} (y_{i} - w_{0} - w_{1} x_{1})^{2}}{n}$. Дополнительное регуляризационное слагаемое $\\lambda_{1} = \\alpha (\\left | w_{0} \\right | + \\left | w_{1} \\right |)$ задаёт уравнение ромба, а слагаемое $\\lambda_{2} = \\alpha ((w_{0})^{2} + (w_{1})^{2})$ — уравнение окружности.\n",
    "\n",
    "Таким образом, в результате добавления смещения $\\alpha_i$ мы находим не настоящий минимум, а **псевдоминимум**, который лежит на пересечении с ромбом при L1 (окружностью — при L2). Такая оптимизация называется **условной**, или **оптимизацией с ограничениями**. Решение такой задачи строится на основе [метода множителей Лагранжа](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BC%D0%BD%D0%BE%D0%B6%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%B9_%D0%9B%D0%B0%D0%B3%D1%80%D0%B0%D0%BD%D0%B6%D0%B0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. В реализации sklearn для решения задачи оптимизации используется итеративный алгоритм [координатного спуска](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BE%D1%80%D0%B4%D0%B8%D0%BD%D0%B0%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA) (аналог градиентного спуска, но не использующий производную).\n",
    "\n",
    "Отличительной особенностью L1-регуляризации является то, что коэффициенты, которые соответствуют «ненужным», по мнению модели, факторам, обнуляются, то есть факторы просто не будут участвовать в предсказании. Это очень важно для сложных моделей, в обучении которых используются множество факторов (как в нашей модели выше — 91 фактор). Тем самым мы уменьшим сложность модели, сократим её разброс и, как следствие, уменьшим переобучение.\n",
    "\n",
    "В заключение теоретической части хочется отметить, что на практике никогда не ясно, какой из методов регуляризации сработает лучше всего. Выход — пробовать оба метода и сравнивать результаты.\n",
    "\n",
    "А теперь пора приниматься за практику!\n",
    "\n",
    "Практика показывает, что обучение линейной регрессии с большим количеством признаков рекомендуется производить на стандартизованных (нормализованных) данных.\n",
    "\n",
    "**Примечание**. Часто возникает вопрос: как правильно проводить стандартизацию/нормализацию при наличии тренировочной и тестовой выборки?\n",
    "\n",
    "Вы обучаете (fit()) преобразование на тренировочной выборке и используете его с одними и теми же параметрами на тренировочной и тестовой выборке (transform()). Если производить подгонку на каждой из выборок в отдельности, вы внесёте смещение в модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартизацию (нормализацию) полезнее проводить перед генерацией полиномиальных признаков, иначе можно потерять масштаб полиномов.\n",
    "\n",
    "Давайте предобработаем наши данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 104)\n",
      "(152, 104)\n"
     ]
    }
   ],
   "source": [
    "#Инициализируем стандартизатор StandardScaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#Подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "scaler.fit(X_train)\n",
    "#Производим стандартизацию тренировочной выборки\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "#Производим стандартизацию тестовой выборки\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    " \n",
    "#Создаём генератор полиномиальных признаков\n",
    "poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit(X_train_scaled)\n",
    "#Генерируем полиномиальные признаки для тренировочной выборки\n",
    "X_train_scaled_poly = poly.transform(X_train_scaled)\n",
    "#Генерируем полиномиальные признаки для тестовой выборки\n",
    "X_test_scaled_poly = poly.transform(X_test_scaled)\n",
    "#Выводим результирующие размерности таблиц\n",
    " \n",
    "print(X_train_scaled_poly.shape)\n",
    "print(X_test_scaled_poly.shape)\n",
    "# (354, 104)\n",
    "# (152, 104)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ В sklearn методы регуляризации реализованы в классах Lasso (L1-регуляризация) и Ridge (L2-регуляризация). Оба метода осуществляют поиск параметров с добавлением регуляризации. Процесс обучения и предсказания не отличается от обычной линейной регрессии.\n",
    "\n",
    "Давайте построим модель линейной регрессии с L1-регуляризацией на сгенерированных нами ранее полиномиальных признаках.\n",
    "\n",
    "Главный параметр инициализации Lasso — это alpha, коэффициент регуляризации. По умолчанию alpha=1. Практика показывает, что это довольно сильная регуляризация для L1-метода. Давайте установим значение этого параметра на 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.879\n",
      "Test R^2: 0.882\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с L1-регуляризацией\n",
    "lasso_lr_poly = linear_model.Lasso(alpha=0.1)\n",
    "#Обучаем модель\n",
    "lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "#Рассчитываем коэффициент детерминации для двух выборок\n",
    "print(\"Train R^2: {:.3f}\".format(metrics.r2_score(y_train, y_train_predict_poly)))\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict_poly)))\n",
    "\n",
    "# Train R^2: 0.879\n",
    "# Test R^2: 0.882"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на то, как изменились значения метрик. Да, на тренировочной выборке $R^{2}=0.879$. Метрика упала (до стандартизации + регуляризации значение $R^2$ было $0.929$). Однако метрика ощутимо выросла на тестовой выборке: $R^{2}=0.882$ (ранее она была равна $0.268$). Мы смогли преодолеть переобучение.\n",
    "\n",
    "Давайте выведем значения коэффициентов модели, округлив их до третьего знака после запятой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.     0.    -0.038  0.    -0.523  2.766 -0.355 -0.605  0.    -0.595\n",
      " -0.763  0.    -3.259 -0.    -0.     0.     3.132 -0.141  0.     0.\n",
      "  0.    -0.     0.     0.    -0.015 -0.     0.063 -0.    -0.     0.\n",
      "  0.159 -0.    -0.    -0.     0.     0.07  -0.    -0.     0.017  0.\n",
      "  0.    -0.     0.     0.     0.     0.    -0.    -0.     0.     0.46\n",
      " -0.808 -0.643  0.    -0.    -0.     0.    -0.     0.    -0.43  -0.348\n",
      " -0.511 -0.     0.    -0.14  -0.    -0.277  0.    -0.     0.223 -0.\n",
      " -0.    -0.836 -0.054 -0.421  0.019 -0.784  0.    -0.     0.706  0.\n",
      " -0.    -0.335 -0.198  0.    -0.     0.     0.205 -0.     0.531 -0.\n",
      "  0.     0.048 -0.    -0.292  0.677  0.81  -0.    -1.151 -0.    -0.\n",
      " -0.    -0.288 -0.356  0.429]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(lasso_lr_poly.coef_, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание: большая часть коэффициентов обнулилась. Это значит, что признаки, которые соответствуют этим коэффициентам, не используются в прогнозе модели Lasso-регрессии.\n",
    "\n",
    "Теперь давайте на тех же данных обучим модель линейной регрессии с L2-регуляризацией. Для L2-регуляризации параметр alpha по умолчанию равен 1. Давайте попробуем использовать значение параметра alpha=10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.907\n",
      "Test R^2: 0.848\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с L2-регуляризацией\n",
    "ridge_lr_poly = linear_model.Ridge(alpha=10)\n",
    "#Обучаем модель\n",
    "ridge_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict_poly = ridge_lr_poly.predict(X_train_scaled_poly)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict_poly = ridge_lr_poly.predict(X_test_scaled_poly)\n",
    "#Рассчитываем коэффициент детерминации для двух выборок\n",
    "print(\"Train R^2: {:.3f}\".format(metrics.r2_score(y_train, y_train_predict_poly)))\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict_poly)))\n",
    " \n",
    "\n",
    "# Train R^2: 0.907\n",
    "# Test R^2: 0.831"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрики $R^2$ на тренировочной и тестовой выборках для L2-регуляризации получились немного выше. В первую очередь мы всегда ориентируемся на тестовую выборку — это данные, которые модель ещё не видела.\n",
    "\n",
    "Давайте выведем значения коэффициентов модели, округлив их до третьего знака после запятой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.128 -0.049  0.084  0.117 -0.932  2.848 -1.008 -1.464  0.909 -0.908\n",
      " -0.653  0.971 -2.605  0.085 -0.032  0.466  2.721 -0.507  0.986  0.309\n",
      " -0.391 -0.714  0.376 -0.379  0.072  0.287  0.143 -0.138 -0.014  0.315\n",
      "  0.05  -0.409 -0.316  0.075  0.702  0.08  -0.281 -0.37   0.511  0.175\n",
      "  0.72   0.282  0.477  0.888 -0.012  0.074 -0.052  0.166 -0.263  0.414\n",
      " -1.129 -0.852  0.273  0.227 -0.106  0.368 -0.137 -0.241 -0.697 -0.177\n",
      " -0.326 -0.524  0.882 -0.637  0.344 -0.439 -0.006  0.386  0.233 -0.535\n",
      "  0.111 -0.802 -0.662 -0.56   0.22  -1.001  0.123  0.144  0.889 -0.114\n",
      " -0.086 -1.022 -0.71   1.08  -0.446 -0.178 -0.07  -0.496  0.874 -0.926\n",
      "  0.717  0.601 -0.49  -0.723  0.308  1.086 -0.448 -1.256  0.057  0.354\n",
      " -0.059 -0.433 -0.791  0.177]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(ridge_lr_poly.coef_, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте организуем процесс перебора параметров модели: создадим цикл, в котором будем перебирать 20 различных значений alpha в диапазоне от 0.001 до 1. Такой список проще всего создать с помощью функции linspace() из библиотеки numpy.\n",
    "\n",
    "В цикле будем обучать модель линейной регрессии и L1-регуляризацией (Lasso), вычислять значения метрики $R^2$ на тренировочной и тестовой выборках и заносить результаты в списки train_scores и test_scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём список из 20 возможных значений от 0.001 до 1\n",
    "alpha_list = np.linspace(0.001, 1, 20)\n",
    "#Создаём пустые списки, в которые будем добавлять результаты \n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for alpha in alpha_list:\n",
    "    #Создаём объект класса линейной регрессии с L1-регуляризацией\n",
    "    lasso_lr_poly = linear_model.Lasso(alpha=alpha, max_iter=10000)\n",
    "    #Обучаем модель\n",
    "    lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "    #Делаем предсказание для тренировочной выборки\n",
    "    y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "    #Делаем предсказание для тестовой выборки\n",
    "    y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "    #Рассчитываем коэффициенты детерминации для двух выборок и добавляем их в списки\n",
    "    train_scores.append(metrics.r2_score(y_train, y_train_predict_poly))\n",
    "    test_scores.append(metrics.r2_score(y_test, y_test_predict_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате выполнения данного кода в списках train_scores и test_scores появятся 20 различных значений $R^2$ на тренировочной и тестовой выборках.\n",
    "\n",
    "Давайте построим линейные графики, которые покажут, как меняется метрика $R^2$ на тренировочной и тестовой выборках в зависимости от alpha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Визуализируем изменение R^2 в зависимости от alpha\n",
    "fig, ax = plt.subplots(figsize=(12, 4)) #фигура + координатная плоскость\n",
    "ax.plot(alpha_list, train_scores, label='Train') #линейный график для тренировочной выборки\n",
    "ax.plot(alpha_list, test_scores, label='Test') #линейный график для тестовой выборки\n",
    "ax.set_xlabel('Alpha') #название оси абсцисс\n",
    "ax.set_ylabel('R^2') #название оси ординат\n",
    "ax.set_xticks(alpha_list) #метки по оси абсцисс\n",
    "ax.xaxis.set_tick_params(rotation=45) #поворот меток на оси абсцисс\n",
    "ax.legend(); #отображение легенды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью графика мы можем подобрать оптимальное значение параметра alpha. Нам нужна такая точка на оси абсцисс, при которой на тестовой выборке наблюдается максимальная метрика и при этом разница между метриками на тренировочной и тестовой выборках минимальна.\n",
    "\n",
    "Видно, что $R^2$ на тестовой выборке достигает наибольшего значения в точке 0.0536. Причём в этой точке наблюдается примерное равенство метрик на каждом наборе данных. Далее метрика на тестовой выборке начинает падать.\n",
    "\n",
    "Обратите внимание, что на тренировочной выборке $R^2$ непрерывно падает с ростом alpha. Оно и понятно, ведь чем больше alpha, тем сильнее регуляризация и тем меньше модель подстраивается под обучающую выборку.\n",
    "\n",
    "Давайте подставим значение alpha=0.0536 в модель Lasso и получим результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.894\n",
      "Test R^2: 0.890\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с L1-регуляризацией\n",
    "lasso_lr_poly = linear_model.Lasso(alpha=0.0536)\n",
    "#Обучаем модель \n",
    "lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "#Рассчитываем коэффициент детерминации для двух выборок\n",
    "print(\"Train R^2: {:.3f}\".format(metrics.r2_score(y_train, y_train_predict_poly)))\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict_poly)))\n",
    "\n",
    "# Train R^2: 0.894\n",
    "# Test R^2: 0.890"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, метрика $R^2$ выросла благодаря тому, что мы смогли подобрать оптимальное значение параметра alpha.\n",
    "\n",
    "**Примечание**. Помимо основных методов регуляризации L1 и L2, существует комплексный метод.\n",
    "\n",
    "> **Эластичная сетка (Elastic Net)** — это комбинация из двух методов регуляризации. Функция потерь в таком методе выглядит следующим образом:\n",
    "\n",
    "$$L_{2}(w)=M S E+\\alpha \\cdot \\lambda \\sum_{i=1}^{m}\\left|w_{i}\\right|+\\alpha \\cdot(1-\\lambda) \\sum_{i=1}^{m}\\left(w_{i}\\right)^{2} \\rightarrow \\min _{w}$$\n",
    "\n",
    "В sklearn реализация эластичной сетки находится в объекте класса [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html).\n",
    "\n",
    "Параметры  и  позволяют регулировать вклад L1- и L2-регуляризации. На практике данный метод используется гораздо реже, так как нужно подбирать оптимальную комбинацию из двух параметров.\n",
    "\n",
    "**Примечание**. Регуляризация присутствует и в модели SGDRegressor, причём она используется по умолчанию. В инициализаторе данного класса есть параметр penalty, который позволяет управлять методом регуляризации. Параметр может принимать значения 'l1', 'l2' и 'elasticnet'. По умолчанию используется L2-регуляризация (penalty='l2'). Коэффициент регуляризации (alpha) по умолчанию равен 0.0001 (относительно слабая регуляризация). Управляя двумя этими параметрами, вы можете настраивать тип регуляризации в SGD-методе и её «силу»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В этом юните мы:\n",
    "\n",
    "* рассмотрели понятия переобучения и недообучения и связанные с ними смещение (bias) и разброс (variance);\n",
    "* научились генерировать полиномиальные признаки и обучать модель линейной регрессии на этих признаках;\n",
    "* познакомились с основными методами регуляризации и их реализациями в sklearn;\n",
    "* научились подбирать внешний параметр (коэффициент регуляризации alpha) на основе значений на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Линейная регрессия. Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Настало время попрактиковаться применять модель линейной регрессии и её модификации в задачах регрессии.\n",
    "\n",
    "В этот раз мы коснёмся мира медицинского страхования. Нашей целью будет предсказать индивидуальные медицинские расходы граждан США, оплачиваемые медицинской страховкой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работать будем с популярным датасетом [Medical Cost Personal Datasets](https://www.kaggle.com/mirichoi0218/insurance).\n",
    "\n",
    "[→ Скачайте файл с данными](https://lms.skillfactory.ru/assets/courseware/v1/12aeb6a8af2d5cdf500e55d3ccbb9f8e/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/insurance.zip)\n",
    "\n",
    "Необходимые нам библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import preprocessing #предобработка\n",
    "from sklearn.model_selection import train_test_split #разделение выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/insurance.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, набор данных содержит следующие столбцы:\n",
    "\n",
    "* age — возраст основного бенефициара;\n",
    "* sex — пол страхового подрядчика;\n",
    "* bmi — индекс массы тела ($кг/м^2$), в идеале — от 18.5 до 24.9;\n",
    "* children — количество детей, охваченных медицинской страховкой;\n",
    "* smoker — является ли человек курящим;\n",
    "* region — жилой район США (северо-восток, юго-восток, северо-запад, юго-запад);\n",
    "* charges (целевой признак) — индивидуальные медицинские расходы, оплачиваемые медицинской страховкой.\n",
    "\n",
    "Размер таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "# (1338, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем информацию о пропусках, так как наличие пропусков не позволит нам построить модель линейной регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски в таблице отсутствуют.\n",
    "\n",
    "Посмотрим на типы данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex          object\n",
       "bmi         float64\n",
       "children      int64\n",
       "smoker       object\n",
       "region       object\n",
       "charges     float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши данные содержат несколько типов признаков:\n",
    "\n",
    "* age, bmi, children — числовые признаки;\n",
    "* sex, smoker — бинарные категориальные переменные (две категории);\n",
    "* region — множественные категориальные переменные (несколько категорий);\n",
    "* charges — числовой целевой признак.\n",
    "\n",
    "Прежде чем приступать к этапу подготовки данных для модели, вы можете произвести небольшое исследование зависимостей в данных, например построить следующие графики и диаграммы:\n",
    "\n",
    "* гистограммы/коробчатые диаграммы числовых признаков;\n",
    "* столбчатые диаграммы медианных медицинских расходов в зависимости от категориальных признаков;\n",
    "* диаграммы рассеяния зависимости целевого признака от других числовых в разрезе категориальных (обратите особенное внимание на зависимость медицинских расходов от признака курения).\n",
    "Мы знаем, что модель линейной регрессии не умеет работать с категориальными признаками, поэтому категории необходимо перекодировать.\n",
    "\n",
    "Кодировку будем совершать по следующему принципу:\n",
    "\n",
    "* smoker — переведём в бинарные значения (0 — некурящий, 1 — курящий);\n",
    "* sex — аналогично (0 — female, 1 — male);\n",
    "* region — используем OneHot-кодирование (воспользуемся функцией get_dummies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex     bmi  children  smoker      charges  region_northeast  \\\n",
       "0   19    0  27.900         0       1  16884.92400                 0   \n",
       "1   18    1  33.770         1       0   1725.55230                 0   \n",
       "2   28    1  33.000         3       0   4449.46200                 0   \n",
       "3   33    1  22.705         0       0  21984.47061                 0   \n",
       "4   32    1  28.880         0       0   3866.85520                 0   \n",
       "\n",
       "   region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 1  \n",
       "1                 0                 1                 0  \n",
       "2                 0                 1                 0  \n",
       "3                 1                 0                 0  \n",
       "4                 1                 0                 0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#кодируем бинарные категориальные признаки\n",
    "data['smoker'] = data['smoker'].apply(lambda x: 0 if x == 'no' else 1)\n",
    "data['sex'] = data['sex'].apply(lambda x: 0 if x == 'female' else 1)\n",
    "#оставшиеся категориальные признаки кодируем с помощью OneHot\n",
    "data = pd.get_dummies(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили перекодированную таблицу, в которой все признаки являются числовыми.\n",
    "\n",
    "Выделим факторы и целевой признак в отдельные таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop('charges', axis=1).columns\n",
    "X, y = data[features], data['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем начинать работу над моделью ↓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.1\n",
    "\n",
    "Прежде чем переходить к этапу моделирования, нам необходимо позаботиться о создании выборки для тестирования модели.\n",
    "\n",
    "Разделите набор данных на тренировочную и тестовую выборки в соотношении 80/20. Воспользуйтесь функцией train_test_split.\n",
    "\n",
    "В качестве значения параметра random_state укажите число 42.\n",
    "\n",
    "Чему равно количество наблюдений в тестовом наборе данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1070, 9) (1070,)\n",
      "Test: (268, 9) (268,)\n"
     ]
    }
   ],
   "source": [
    "#Разделяем выборку на тренировочную и тестовую в соотношении 70/30\n",
    "#Устанавливаем random_state для воспроизводимости результатов \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#Выводим результирующие размеры таблиц\n",
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.2\n",
    "\n",
    "Обучите модель линейной регрессии аналитическим методом (LinearRegression) на тренировочном наборе данных. Все параметры оставьте по умолчанию.\n",
    "\n",
    "Чему равен свободный член (intercept) обученной модели? Ответ округлите до сотых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: 34.55\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса LinearRegression\n",
    "lr = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr.fit(X_train, y_train)\n",
    " \n",
    "print('w0: {:.2f}'.format(lr_lstat.intercept_)) #свободный член w0\n",
    "# print('w1: {}'.format(lr_lstat.coef_)) #остальные параметры модели w1, w2, ..., wm\n",
    " \n",
    "# w0: 34.55384087938311\n",
    "## w1: [-0.95004935]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.3\n",
    "\n",
    "С помощью модели, полученной в предыдущем задании, сделайте предсказание на тренировочной и тестовой выборке. Рассчитайте следующие три метрики: $R^2$, $MAE$, $MAPE$. Не забудьте привести значение $MAPE$ к процентам.\n",
    "\n",
    "Значение $R^2$ округлите до трёх знаков после точки-разделителя, а значения $MAE$ и $MAPE$ — до целого числа.\n",
    "\n",
    "Чему равны значения метрик на тренировочной и тестовой выборках?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_train, y_train_predict, y_test, y_test_predict):\n",
    "    print('Train R^2: {:.3f}'.format(metrics.r2_score(y_train, y_train_predict)))\n",
    "    print('Train MAE: {:.0f}'.format(metrics.mean_absolute_error(y_train, y_train_predict)))\n",
    "    print('Train MAPE: {:.0f}'.format(metrics.mean_absolute_percentage_error(y_train, y_train_predict)*100))\n",
    "    print('\\n')\n",
    "    print('Test R^2: {:.3f}'.format(metrics.r2_score(y_test, y_test_predict)))\n",
    "    print('Test MAE: {:.0f}'.format(metrics.mean_absolute_error(y_test, y_test_predict)))\n",
    "    print('Train MAPE: {:.0f}'.format(metrics.mean_absolute_percentage_error(y_test, y_test_predict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.742\n",
      "Train MAE: 4208\n",
      "Train MAPE: 42\n",
      "\n",
      "\n",
      "Test R^2: 0.784\n",
      "Test MAE: 4181\n",
      "Train MAPE: 47\n"
     ]
    }
   ],
   "source": [
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "#Выводим результирующие метрики\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.4\n",
    "\n",
    "Постройте диаграмму boxplot для визуализации ошибок модели линейной регрессии на тренировочной и тестовой выборках. В качестве ошибки возьмите разницу между истинным ответом и предсказанием: $y-\\hat{y}$ (без модуля).\n",
    "\n",
    "Выберите верные ответы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Визуализируем ошибки\n",
    "fig, ax = plt.subplots(figsize=(12, 6)) #фигура + координатная плоскость\n",
    "#Ошибки модели на тренировочной выборке \n",
    "y_train_errors = y_train - lr.predict(X_train)\n",
    "#Ошибки модели на тестовой выборке\n",
    "y_test_errors = y_test - lr.predict(X_test)\n",
    "#Для удобства визуализации составим DataFrame из ошибок\n",
    "predict_df = pd.DataFrame(\n",
    "    {'Train errors': y_train_errors, \n",
    "     'Test errors': y_test_errors\n",
    "    }\n",
    ")\n",
    "#Строим boxplot для ошибок\n",
    "sns.boxplot(data=predict_df, orient='h', ax=ax)\n",
    "ax.set_xlabel('Model errors') #название оси абсцисс\n",
    "ax.set_ylabel('Model'); #название оси ординат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.5\n",
    "\n",
    "Нормализуйте тренировочную и тестовую выборки с помощью min-max-нормализации (MinMaxScaler). Расчёт параметров нормализации (fit) произведите на тренировочной выборке.\n",
    "\n",
    "**Примечание**. Min-max-нормализация не искажает изначальный вид бинарных категориальных признаков, в отличие от стандартизации.\n",
    "\n",
    "На нормализованных данных сгенерируйте полиномиальные признаки степени 2. Воспользуйтесь классом PolynomialFeatures из библиотеки sklearn. Значение параметра include_bias выставите на False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1070, 54)\n",
      "Test shape: (268, 54)\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект для min-max нормализации\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "#Вычисляем параметры для нормализации - min и max для каждого столбца\n",
    "scaler.fit(X_train)\n",
    "#Производим преобразование для каждой из выборок\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Создаем объект для генерации полиномиальных признаков степени 2\n",
    "poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "#Вычисляем параметры генерации - результирующее количество признак\n",
    "poly.fit(X_train_scaled)\n",
    "#Производим преобразование для каждой из выборок\n",
    "X_train_scaled_poly = poly.transform(X_train_scaled)\n",
    "X_test_scaled_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "print('Train shape: {}'.format(X_train_scaled_poly.shape))\n",
    "print('Test shape: {}'.format(X_test_scaled_poly.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.6\n",
    "\n",
    "Обучите модель линейной регрессии на полиномиальных признаках.\n",
    "\n",
    "Чему равно значение метрики $R^2$ на тестовой выборке?\n",
    "\n",
    "Значение $R^2$ округлите до трёх знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.842\n",
      "Train MAE: 2900\n",
      "Train MAPE: 30\n",
      "\n",
      "\n",
      "Test R^2: 0.867\n",
      "Test MAE: 2732\n",
      "Train MAPE: 30\n"
     ]
    }
   ],
   "source": [
    "lr_poly = linear_model.LinearRegression()\n",
    "lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "\n",
    "y_train_predict = lr_poly.predict(X_train_scaled_poly)\n",
    "y_test_predict = lr_poly.predict(X_test_scaled_poly)\n",
    "print_metrics(y_train, y_train_predict, y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.7\n",
    "\n",
    "Выведите значения коэффициентов полученной модели. Посмотрите на степени коэффициентов.\n",
    "\n",
    "Какой вывод можно сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.72324070e+16  1.31146740e+16 -6.07518911e+15  8.68217520e+15\n",
      " -1.01570042e+16 -4.74066016e+16 -1.33580061e+17 -3.47106940e+16\n",
      " -7.38096689e+16  8.48000000e+03  8.98000000e+02  8.58000000e+02\n",
      " -1.57800000e+03  2.32000000e+02  1.72324070e+16  1.72324070e+16\n",
      "  1.72324070e+16  1.72324070e+16  9.88117370e+16  7.42000000e+02\n",
      " -1.29393750e+03  2.14312500e+02 -1.11926411e+17 -1.11926411e+17\n",
      " -1.11926411e+17 -1.11926411e+17 -9.42390625e+03  1.74862500e+03\n",
      "  5.47891016e+04  6.07518911e+15  6.07518911e+15  6.07518911e+15\n",
      "  6.07518911e+15 -1.98400000e+03 -2.28000000e+03 -8.68217520e+15\n",
      " -8.68217520e+15 -8.68217520e+15 -8.68217520e+15  4.62270002e+15\n",
      "  5.53430414e+15  5.53430414e+15  5.53430414e+15  5.53430414e+15\n",
      " -3.72415148e+16  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  4.89319446e+16  0.00000000e+00  0.00000000e+00 -4.99374223e+16\n",
      "  0.00000000e+00 -1.08384475e+16]\n"
     ]
    }
   ],
   "source": [
    "print(lr_poly.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.8\n",
    "\n",
    "Постройте линейную регрессию с L1-регуляризацией (Lasso) на полиномиальных признаках. В качестве параметра alpha используйте значение по умолчанию, параметр max_iter установите в значение 2000.\n",
    "\n",
    "Чему равны метрики $R^2$, $MAE$ и $MAPE$ на тестовой выборке?\n",
    "\n",
    "Значение $R^2$ округлите до трёх знаков после запятой, а значения $MAE$ и $MAPE$ до целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.842\n",
      "Train MAE: 2890\n",
      "Train MAPE: 29\n",
      "\n",
      "\n",
      "Test R^2: 0.867\n",
      "Test MAE: 2719\n",
      "Train MAPE: 30\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с L1-регуляризацией\n",
    "lasso_lr_poly = linear_model.Lasso(max_iter=2000)\n",
    "#Обучаем модель \n",
    "lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "#Рассчитываем коэффициент детерминации для двух выборок\n",
    "\n",
    "print_metrics(y_train, y_train_predict_poly, y_test, y_test_predict_poly)\n",
    "# Train R^2: 0.894\n",
    "# Test R^2: 0.890"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.9\n",
    "\n",
    "Постройте линейную регрессию с L2-регуляризацией на полиномиальных признаках. В качестве параметра alpha используйте значение по умолчанию.\n",
    "\n",
    "Чему равны метрики $R^2$, $MAE$ и $MAPE$ на тестовой выборке?\n",
    "\n",
    "Значение $R^2$ округлите до трёх знаков после запятой, а значения $MAE$ и $MAPE$ до целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.839\n",
      "Train MAE: 2949\n",
      "Train MAPE: 30\n",
      "\n",
      "\n",
      "Test R^2: 0.863\n",
      "Test MAE: 2861\n",
      "Train MAPE: 31\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса линейная регрессия с L2-регуляризацией\n",
    "#Выставляем параметр alpha в подобранное выше значение\n",
    "ridge_lr = linear_model.Ridge()\n",
    "#Обучаем модель предсказывать логарифм целевого признака\n",
    "ridge_lr.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "#Если обучили на логарифме, то от результата необходимо взять обратную функцию - экспоненту\n",
    "y_train_pred = ridge_lr.predict(X_train_scaled_poly)\n",
    "y_test_pred = ridge_lr.predict(X_test_scaled_poly)\n",
    "\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ Поздравляем! Вы познакомились со своими первыми моделями машинного обучения!\n",
    "\n",
    "Напоследок ещё раз обсудим, **что мы сделали в модуле:**\n",
    "\n",
    "* узнали, что такое модель линейной регрессии;\n",
    "* изучили несколько методов поиска параметров этой модели, реализованных в sklearn: метод наименьших квадратов (LinearRegression) и стохастический градиентный спуск (SGDRegressor);\n",
    "* выявили достоинства и недостатки каждого из методов;\n",
    "* научились делать предсказание с помощью модели линейной регрессии;\n",
    "* познакомились с метриками регрессии и научились измерять качество регрессионной модели;\n",
    "* узнали о центральной проблеме обучения с учителем – дилемме смещения и разброса, научились определять переобученность модели;\n",
    "* научились строить полиномиальную регрессию и бороться с переобучением с помощью регуляризации.\n",
    "\n",
    "**Методы решения задачи регрессии, которые мы рассмотрели в модуле:**\n",
    "\n",
    "* LinearRegression и SGDRegressor — модели линейной регрессии с аналитическим и численным решением;\n",
    "* PolynomialFeatures + LinearRegression — модель полиномиальной регрессии (или линейная регрессия на полиномиальных признаках);\n",
    "* Lasso и Ridge — модели линейной регрессии с L1- и L2-регуляризацией соответственно.\n",
    "\n",
    "Стоит отметить, что, помимо рассмотренных, существует ещё множество методов решения задачи регрессии, с которыми мы будем знакомиться дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ДОПОЛНИТЕЛЬНО:**\n",
    "\n",
    "[Десять датасетов для практики работы с линейной регрессией](https://www.telusinternational.com/articles/10-open-datasets-for-linear-regression)  \n",
    "[Базовые принципы машинного обучения на примере линейной регрессии](https://habr.com/ru/company/ods/blog/322076/)  \n",
    "[Регрессионные модели в Python](https://nagornyy.me/it/regressionnye-modeli-v-python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "950b5653ccfc34417735dd321d006fd482b31f7611416c3d8236dc5b17587d3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MATH&ML-15. Рекомендательные системы. Часть II**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущем модуле мы начали знакомиться с рекомендательными системами — кратко разобрали существующие подходы к их построению и научились оценивать качество РС. Более подробно мы пока успели изучить только popularity-based подход. В этом модуле мы рассмотрим остальные алгоритмы и научимся реализовывать их на практике.\n",
    "\n",
    "Для начала давайте кратко повторим материал, изученный в прошлом модуле ↓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Теперь вы точно готовы к дальнейшему изучению рекомендательных систем.\n",
    "\n",
    "Основные цели, которые стоят перед нами в этом модуле:\n",
    "\n",
    "1. Разобрать принципы работы моделей рекомендательных систем:\n",
    "    * content-based-модели,\n",
    "    * коллаборативной фильтрации,\n",
    "    * гибридной модели.\n",
    "2. Познакомиться с основами применения глубокого обучения для построения рекомендательных систем.\n",
    "3. Отработать изученные алгоритмы на решении практических задач.\n",
    "\n",
    "В [юните «Практика»](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DST-3.0+28FEB2021/jump_to_id/9af88f62b92b44559b442bfcc9f4d23d) мы достроим начатую в предыдущем модуле модель рекомендательной системы для статей, а в промежуточных юнитах рассмотрим применение методов построения рекомендательных систем на других датасетах из различных областей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Content-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В этом юните мы рассмотрим систему рекомендаций на основе контента, или, как её чаще называют, **content-based model**.\n",
    "\n",
    "![](https://img.genial.ly/5fdc5ca1853b5759f6e69400/392c8cc2-df07-48b3-88f4-088149cb53fe.png)\n",
    "\n",
    "> Подход **content-based** предполагает, что пользователю рекомендуются товары или контент на основе его предпочтений и вкусов.\n",
    "\n",
    "Профиль интересов пользователя формируется исходя из его оценок, а также неявной обратной связи: лайков, количества просмотров и так далее. В качестве рекомендаций пользователю предлагаются похожие элементы.\n",
    "\n",
    "Сходство или близость элементов измеряется на основе сходства содержания этих элементов. Говоря «содержание», мы имеем в виду такие сущности, как категория, тег, жанр и т. д., то есть метаданные. Далее в этом юните мы познакомимся с некоторыми алгоритмами определения сходства."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/792c9ad6bbaf1201d6cfecf6d816838f/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_2_1.png)\n",
    "\n",
    "Вы наверняка уже сталкивались с content-based-рекомендациями в тех или иных сервисах. Например, на сайте Netflix можно использовать фильтрацию по контенту, чтобы создавать рекомендации из аналогичных элементов, которые размещаются в разделе More Like This.\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/a8a0464a8baddb3f5b705ff2dc2f4945/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_2_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте на примере рассмотрим построение рекомендательной системы на основе контента для конкретного пользователя.\n",
    "Допустим, пользователь Михаил выставил лайки и дизлайки для фильмов на одном из веб-сервисов:\n",
    "\n",
    "**ФИЛЬМ**|**РЕЙТИНГ**\n",
    "-|-\n",
    "«Миссия невыполнима»|Лайк\n",
    "«Джеймс Бонд»|Лайк\n",
    "«Приключения Буратино»|Дизлайк\n",
    "\n",
    "Предположим, что по правилам сервиса лайк прибавляет 4.5 балла к фильмам с таким жанром, а дизлайк вычитает 6 баллов. Теперь создадим вектор пользователя для Михаила на основе трёх его оценок:\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/118b2ca3c07dba4356d56b26cb692aec/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_2_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присваиваем значение 9 боевикам, так как Михаил поставил лайк двум фильмам с жанром «боевик». Михаил не смотрел анимационные фильмы, так что присваиваем 0 анимации, и, поскольку он оставил плохой отзыв фильму в жанре «дети», присваиваем -6 детским фильмам.\n",
    "\n",
    "Таким образом, вектор пользователя для Михаила — это $(9,0,-6)$ для шкал (Боевик, Анимация, Дети).\n",
    "Теперь попробуем предсказать отношение Михаила к фильмам, которые он ещё не смотрел, например «Звёздные войны» и «История игрушек».\n",
    "\n",
    "«Звёздные войны» — это боевик, который не относится к анимации или детским фильмам, поэтому по шкалам (Боевик, Анимация, Дети) у этого фильма будут координаты $(1,0,0)$. У фильма «История игрушек» будут координаты $(0,1,1)$, так как он относится и к жанру детских фильмов, и к анимации.\n",
    "Теперь нам необходимо найти произведения вектора пользователя и вектора фильма: чем больше будет скалярное произведение, тем более подходящим для Михаила будет фильм.\n",
    "\n",
    "Скалярное произведение для «Истории игрушек» равно $-6$, а для «Звёздных войн» оно равно $9$. Следовательно, из этих двух вариантов именно «Звёздные войны» будут рекомендованы Михаилу, что вполне логично, ведь ему больше нравятся боевики.\n",
    "\n",
    "Аналогично можно вычислить скалярные произведения векторов для всех фильмов на сайте и рекомендовать Михаилу десять наиболее подходящих фильмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном примере мы опирались лишь на схожесть фильмов по жанрам: скалярное произведение будет увеличиваться в том случае, если у фильма ненулевая координата для того жанра, который пользователь уже оценил положительно. Однако в реальности всё намного сложнее: например, мы можем использовать одновременно жанр фильма, теги, описание, актёров и т. д. Для этого случая нам нужен способ измерить сходство между набором параметров.\n",
    "\n",
    "Рассмотрим два наиболее популярных метода измерения такого сходства:\n",
    "\n",
    "* **индекс Жаккара**,\n",
    "* **косинусная близость**.\n",
    "\n",
    "### ИНДЕКС ЖАККАРА\n",
    "\n",
    "Индекс Жаккара измеряет сходство между двумя наборами A и B как мощность множества пересечения, делённую на мощность множества объединения каких-то характеристик объекта. Его удобно применять для категориальных признаков.\n",
    "\n",
    "$$J(A,B) = \\frac{\\left|A \\cap B \\right|}{\\left|A \\cup B \\right|} = \\frac{\\left|A \\cap B \\right|}{\\left|A \\right| + \\left|B \\right| - \\left|A \\cap B \\right|}$$\n",
    "\n",
    "Например, с помощью индекса Жаккара мы можем оценить, насколько похожи фильмы, основываясь на наборах ключевых слов (тегов) для них:\n",
    "\n",
    "* фильм А : {фантастика, школа, романтика};\n",
    "* фильм B : {приключения, фантастика, школа};\n",
    "* фильм C : {ужасы, триллер, драма}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем предположить, что фильм A больше похож на фильм B, чем на фильм C, так как фильмы A и B имеют два общих тега (фантастика, школа), в то время как фильмы A и C не имеют ни одного общего тега.\n",
    "\n",
    "Если бы мы рассматривали вычисление этого индекса для фильмов А и В, то получили бы $\\frac{2}{4}$, так как в пересечении два тега, а в объединении — четыре. Для фильмов А и C мы получили бы $0$, так как пересечение множеств их тегов является пустым. Таким образом, показатель близости для фильмов А и В получился бы больше, и это подтвердило бы наши предположения об их большей схожести.\n",
    "\n",
    "### КОСИНУСНАЯ БЛИЗОСТЬ\n",
    "\n",
    "Подход с использованием индекса Жаккара помог нам создать интуитивное представление о том, что означает сходство набора категориальных значений. Подход с **косинусным сходством** немного сложнее и применяется для оценки близости массивов с числами. Он требует, чтобы мы представляли объекты в виде вектора.\n",
    "Например, мы можем представить те же самые фильмы как набор из трёх вещественных чисел:\n",
    "\n",
    "* фильм $A = (1.1, 2.3, 5.1)$;\n",
    "* фильм $B = (1.3, 2.1, 4.9)$;\n",
    "* фильм $C = (5.1, 6.2, 1.1)$.\n",
    "\n",
    "Глядя на эти векторы, кажется, что фильмы А и В похожи друг на друга больше, чем, например, фильмы А и С, так как координаты фильмов А и В очень близки и различаются гораздо меньше, чем координаты фильмов А и С."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы вычислить косинусную близость, нам понадобится следующая формула:\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/19ae75390814099a1aaf8a660888b0d6/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_2_5.png)\n",
    "\n",
    "По сути, мы ищем угол между векторами. Если два вектора совпадут (т. е. будут максимально близкими), то угол между ними будет равен нулю, а значит, косинус будет равен $1$. Если векторы будут направлены в противоположные стороны, косинус будет равен $-1$. Таким образом, мы можем получить для любых двух векторов значение в пределах от $1$ до $-1$ включительно, по которому можно определить, насколько векторы близки друг к другу.\n",
    "Давайте вычислим косинусную близость, чтобы оценить, насколько наши догадки о близости фильмов соответствуют реальности.\n",
    "\n",
    "Косинусная близость для фильмов А и B:\n",
    "\n",
    "$\\operatorname{sim}(A, B)=\\frac{1.1\\cdot 1.3+2.3 \\cdot 2.1+5 \\cdot 1^* 4.9}{\\sqrt{1.1^2+2 .3^2+5.1^2} \\sqrt{1.3^2+2.1^2+4.9^2}} \\approx 0,999$\n",
    "\n",
    "### Задание 2.1\n",
    "\n",
    "Вычислите косинусную близость между векторами А и С. Результат округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.551"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [1.1, 2.3, 5.1]\n",
    "C = [5.1, 6.2, 1.1]\n",
    "\n",
    "sim = (A[0]*C[0] + A[1]*C[1] + A[2]*C[2])/ \\\n",
    "    ((A[0]**2 + A[1]**2 + A[2]**2)**0.5 * (C[0]**2+C[1]**2+C[2]**2)**0.5)\n",
    "    \n",
    "round(sim, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как нам известно, чем выше значение косинусной близости, тем больше сходство между векторами. Таким образом, наши изначальные предположения совпали с реальностью: векторы А и В действительно схожи между собой сильнее, чем векторы А и С. Значит, если человек поставил высокую оценку фильму А, то мы должны порекомендовать ему фильм В.\n",
    "\n",
    "Итак, чтобы построить рекомендательную систему на основе контента, необходимо:\n",
    "\n",
    "1. Для каждого продукта создать характеризующие его признаки.\n",
    "2. Найти показатель близости между всеми продуктами.\n",
    "3. Порекомендовать пользователю продукты, которые показывают наибольшую близость с теми продуктами, которые он высоко оценил.\n",
    "\n",
    "Давайте реализуем подобную рекомендательную систему на практике. Будем работать с [датасетом](https://lms-cdn.skillfactory.ru/assets/courseware/v1/747dae7bf99b18ce3b24bd34aa7bc29b/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/netflix_titles.zip), содержащим информацию об оценивании фильмов на платформе Netflix.\n",
    "\n",
    "**Признаки в данных:**\n",
    "\n",
    "* `show_id` — id фильма,\n",
    "* `type` — его тип (фильм или сериал),\n",
    "* `title` — название,\n",
    "* `director` — режиссер,\n",
    "* `cast` — актерский состав,\n",
    "* `country` — страна,\n",
    "* `date_added` — дата добавления,\n",
    "* `release_year` — год выхода на экраны,\n",
    "* `rating` — рейтинг,\n",
    "* `duration` — продолжительность,\n",
    "* `listened_in` — жанр(-ы),\n",
    "* `description` — описание.\n",
    "\n",
    "В первую очередь нам необходимо определить, на основании чего мы будем рассматривать близость фильмов. Выберем для этой задачи описание фильма, ведь в нём, скорее всего, содержится много информации. Однако описание — это текст. Есть много подходов к преобразованию текста в вектор, и мы будем использовать подход **TF-IDF** (Term Frequency-Inverse Document Frequency)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Показатель TD-IDF** — это индикатор того, насколько релевантно слово в контексте документа.\n",
    "\n",
    "Его можно определить следующим образом:\n",
    "\n",
    "$$\\text{TF-IDF(слова) = TF(слова) * IDF (слова)}$$\n",
    "\n",
    "где:\n",
    "\n",
    "* $\\text{TF слова} = \\frac{\\text{Количество раз, когда слово встретилось в тексте}}{\\text{Количество всех слов в тексте}}$\n",
    "\n",
    "* $\\text{IDF слова} = log \\left (\\frac{\\text{Общее кол-во документов}}{\\text{Кол-во документов, в которых встречается слово}}\\right )$\n",
    "\n",
    "Этот показатель возрастает пропорционально количеству раз, когда слово встречается в тексте, и уменьшается пропорционально количеству слов во всех текстах в целом.\n",
    "\n",
    "Таким образом:\n",
    "\n",
    "* Коэффициент будет выше, если слово характерно именно для этого текста, то есть встречается в данном тексте часто, но не встречается в других текстах.\n",
    "* Коэффициент будет ниже, если слово не встречается почти нигде или встречается одинаковое количество раз во всех текстах, то есть не характеризует никакой текст в отдельности.\n",
    "\n",
    "Если вам интересно подробнее изучить алгоритм создания такого представления, рекомендуем прочитать [статью](https://medium.com/analytics-vidhya/tf-idf-term-frequency-technique-easiest-explanation-for-text-classification-in-nlp-with-code-8ca3912e58c3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы преобразовать текст по этому принципу, нам понадобится соответствующая функция из библиотеки `sklearn` — импортируем её:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее учтём стоп-слова, т. е. предлоги и другие служебные части речи, которые не несут содержательной информации, и с учётом этого определим нашу модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfidfVectorizer(stop_words='english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски пустыми строками:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/netflix_titles.csv')\n",
    "\n",
    "df['description'] = df['description'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трансформируем наши описания в матрицу:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = model.fit_transform(df['description'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.2\n",
    "\n",
    "Сколько столбцов в получившейся матрице?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7787x17905 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 107187 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо вычислить косинусную близость. Можно сделать это так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_sim = linear_kernel(feature_matrix, feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обратите внимание!** Мы используем здесь `linear_kernel()`, а не [`cosine_similarity()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html#sklearn.metrics.pairwise.cosine_similarity), так как в косинусном расстоянии в знаменателе реализуется нормировка векторов, а TF-IDF создаёт уже нормализованные векторы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернём индексацию и уберём дубликаты из данных:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(df.index,index=df['title']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь пропишем функцию для создания рекомендаций:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    #вычисляем попарные коэффициенты косинусной близости\n",
    "    scores = list(enumerate(cosine_sim[idx]))\n",
    "    #сортируем фильмы на основании коэффициентов косинусной близости по убыванию\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    #выбираем десять наибольших значений косинусной близости; нулевую не берём, т. к. это тот же фильм\n",
    "    scores =   scores[1:11]\n",
    "    #забираем индексы\n",
    "    ind_movie = [i[0] for i in scores]\n",
    "    #возвращаем названия по индексам\n",
    "    return df['title'].iloc[ind_movie]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, если мы хотим найти рекомендации по фильму \"Star Trek\", то функция будет выдавать следующий результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5788             Star Trek: The Next Generation\n",
       "5787                      Star Trek: Enterprise\n",
       "5786                 Star Trek: Deep Space Nine\n",
       "5557                     She's Out of My League\n",
       "134                                  7 Days Out\n",
       "6664                        The Midnight Gospel\n",
       "6023                                     Teresa\n",
       "4863    Pinkfong & Baby Shark's Space Adventure\n",
       "5104                                       Rats\n",
       "5970                             Tales by Light\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Star Trek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.3\n",
    "\n",
    "Найдите вторую рекомендацию для детского фильма \"Balto\", вышедшего на экраны в 1995 году:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vroomiz'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Balto').iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы смогли создать рекомендации на основе контента и разобрались с принципом работы этого алгоритма. Теперь давайте посмотрим на преимущества и недостатки данного подхода.\n",
    "\n",
    "**ПРЕИМУЩЕСТВА**\n",
    "\n",
    "* **Для создания рекомендаций не требуются данные от других пользователей.** Как только пользователь выполнил поиск, просмотрел несколько продуктов и/или совершил несколько покупок, система фильтрации на основе контента может начать создавать соответствующие рекомендации. Это делает её идеальной для компаний и сервисов, у которых нет огромного количества пользователей для формирования выборки.\n",
    "* **Рекомендации получаются очень релевантными для пользователя.** Рекомендации на основе контента могут быть в значительной степени адаптированы к интересам пользователя, включая рекомендации по нишевым товарам, поскольку метод основан на сопоставлении характеристик или атрибутов объекта базы данных с интересами пользователя.\n",
    "* **Рекомендации прозрачны для пользователя.** Высокорелевантные рекомендации создают ощущение понятности алгоритмов для пользователя, повышая уровень его доверия к предлагаемым рекомендациям.\n",
    "* **Вы избегаете проблемы «холодного старта».** Хотя фильтрация на основе контента требует первоначального ввода данных от пользователей, чтобы начать давать рекомендации, качество ранних рекомендаций обычно намного выше, чем у других подходов.\n",
    "* **Системы фильтрации на основе содержания обычно проще в создании.** Основная работа заключается в создании характеристик, на основании которых будет вычисляться близость.\n",
    "\n",
    "**НЕДОСТАТКИ**\n",
    "\n",
    "* **Отсутствие новизны и разнообразия.** Вполне возможно, что человеку, который любит боевики, могли бы понравиться и фильмы ужасов. Однако мы не сможем ему их порекомендовать, если он сам не отметит подобные фильмы как понравившиеся.\n",
    "* **Присвоенные характеристики могут быть неверными.** Рекомендации на основе контента хороши настолько, насколько хороши атрибуты (характеристики), при"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы разобрались с первым персонализированным методом для построения рекомендательных систем. В следующих юнитах мы детально изучим другие алгоритмы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Коллаборативная фильтрация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Следующий подход к построению рекомендательных систем, который мы изучим, — это коллаборативная фильтрация. Она основана на поиске сходства между пользователями или между продуктами. Используя этот метод, мы можем прогнозировать рейтинги на основе оценок похожих пользователей или похожих продуктов.\n",
    "\n",
    "![](https://img.genial.ly/5fdc5ca1853b5759f6e69400/8d75cb1e-148b-4ba2-ba3c-aefac1e8a161.png)\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/0641f061288f15ee47c7986bf6c9c0fe/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_3_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако для начала давайте рассмотрим очень часто встречающуюся в рекомендательных системах концепцию — матрицу предпочтений.\n",
    "\n",
    "Чтобы её получить, расположим в матрице клиентов по строкам, а продукты — по столбцам. На пересечении строк и столбцов разместим оценки, поставленные клиентами соответствующим продуктам: первый клиент поставил второму товару 3, третий клиент поставил первому товару 2 и так далее.\n",
    "\n",
    "/|ТОВАР 1|ТОВАР 2|ТОВАР 3|ТОВАР 4|ТОВАР 5\n",
    "-|-|-|-|-|-\n",
    "КЛИЕНТ 1||3||5|\n",
    "КЛИЕНТ 2|1||1|1|\n",
    "КЛИЕНТ 3|2|||3|2\n",
    "КЛИЕНТ 4||4|||5\n",
    "КЛИЕНТ 5|5||2|3|4\n",
    "\n",
    "На основе этих данных мы можем разделить пользователей на кластеры. Чтобы это сделать, можно взять некоторую меру близости для пользователей по их истории оценок и на основе полученных значений объединить пользователей в кластеры таким образом, чтобы похожие пользователи оказались в одной группе, а сильно отличающиеся — в разных. В таком случае оценку пользователя для продукта можно прогнозировать как среднюю оценку пользователей этого кластера, оценивших этот продукт."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, если нам необходимо предсказать, как конкретный пользователь оценил фильм, мы анализируем оценки, поставленные данному фильму пользователями, которые принадлежат к тому же кластеру, что и изучаемый пользователь, и усредняем эти оценки. Так получается предсказание оценки фильма для нашего пользователя.\n",
    "\n",
    "В целом, такой подход можно применять, однако у него есть ряд существенных недостатков:\n",
    "\n",
    "* Нечего рекомендовать новым/нетипичным пользователям. Если появляется пользователь, который ни на кого не похож, мы не знаем, к какому кластеру его отнести. На начальных стадиях мы определяем его в случайный кластер, и рекомендации в таком случае будут плохими.\n",
    "* Не учитывается специфика каждого пользователя. По сути, мы выявляем некоторые паттерны поведения и предпочтений и для каждого паттерна выделяем свои рекомендации. Однако на самом деле даже пользователи из одного кластера немного отличаются друг от друга, поэтому возникают неточности.\n",
    "* Если оценок нет, то среднее арифметическое невозможно вычислить. Если в кластере никто не оценивал объект, сделать предсказание не получится, так как для предсказания нужно вычислить среднее арифметическое для оценок.\n",
    "\n",
    "## КОЛЛАБОРАТИВНАЯ ФИЛЬТРАЦИЯ НА ОСНОВЕ ПАМЯТИ (MEMORY-BASED)\n",
    "\n",
    "Чтобы решить перечисленные выше проблемы, обратимся к коллаборативной фильтрации, а точнее к memory-based-подходу, основанному на близости пользователей (user-based)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним, что при memory-based-подходе хранится полная матрица взаимодействий (лайков, просмотров и т. д .) пользователя с продуктом.\n",
    "\n",
    "### КОЛЛАБОРАТИВНАЯ ФИЛЬТРАЦИЯ НА ОСНОВЕ ПОЛЬЗОВАТЕЛЕЙ (USER-BASED-ПОДХОД)\n",
    "\n",
    "> **Коллаборативная фильтрация на основе пользователей** — это метод, используемый для предсказания продуктов, которые могут понравиться пользователю, на основе оценок, выставленных этому продукту другими пользователями, имеющими схожие с целевым пользователем вкусы.\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/5c33a47165a42a7a6dd473ac39459bfd/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_3_2_ed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом алгоритме мы заменяем жёсткую кластеризацию на следующую формулу и получаем предсказанную оценку пользователя $u$, которую он поставил элементу $i$:\n",
    "\n",
    "$$\\hat{r}_{u i}=\\bar{r}_u+\\frac{\\sum_{v \\in U_i} \\operatorname{sim}(u, v)\\left(r_{v i}-\\bar{r}_v\\right)}{\\sum_{v \\in U_i} \\operatorname{sim}(u, v)}$$\n",
    "\n",
    "Здесь используются следующие обозначения:\n",
    "\n",
    "* $u$ и $v$ — индексы пользователей;\n",
    "* $\\bar{r}_u$ — средняя оценка пользователя ;\n",
    "* $\\bar{r}_v$ — средняя оценка пользователя ;\n",
    "* $sim$ — функция схожести;\n",
    "* $i$ — номер оцениваемого элемента.\n",
    "Средняя оценка пользователя может быть никак не привязана к его интересам. По сути, это просто показатель того, как в среднем пользователь привык оценивать фильмы.\n",
    "\n",
    "Оценка пользователя, которую мы предсказываем для него, состоит **из двух частей**:\n",
    "\n",
    "* Непосредственно его средняя оценка.\n",
    "* Слагаемое, состоящее из разницы в оценках с другими пользователями, т. е. похожести пользователей. Эта разница домножается на похожесть пользователей, то есть в числителе — средневзвешенная разница в оценках, а в знаменателе — сумма показателей схожести."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждому клиенту мы подбираем релевантный для него товар в рамках группы клиентов, но не решаем задачу кластеризации, а усредняем интересы данной группы в дистанции нескольких соседей. По сути, здесь мы руководствуемся идеей, что, например, видео можно порекомендовать человеку, если оно понравилось его друзьям.\n",
    "\n",
    "Давайте разберём пример применения этого алгоритма.\n",
    "\n",
    "В матрице четыре пользователя — Алиса, Рома, Катя и Женя. Они оценивают различные приложения из AppStore. Диапазон оценок — от 1 до 5. Знак '?' означает, что данный пользователь не оценил это приложение.\n",
    "\n",
    "ИМЯ|APP1|APP2|APP3|APP4|APP5\n",
    "-|-|-|-|-|-\n",
    "Алиса|5|4|1|4|?\n",
    "Рома|3|1|2|3|3\n",
    "Катя|4|3|4|3|5\n",
    "Женя|3|3|1|5|4\n",
    "\n",
    "Вычислим сходство как коэффициент корреляции — такой подход также популярен.\n",
    "\n",
    "Для начала найдём среднее значение рейтинга для каждого пользователя:\n",
    "\n",
    "$$\\bar{r}_i=\\frac{\\sum_p r_{i p}}{\\sum p}$$\n",
    "\n",
    "Таким образом получаем:\n",
    "\n",
    "$\\bar{r}_{\\text {Алиса }}=3.5$\n",
    "\n",
    "$\\bar{r}_{Рома}=2.25$\n",
    "\n",
    "$\\bar{r}_{Катя}=3.5$\n",
    "\n",
    "$\\bar{r}_{Женя}=3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вычисляем сходство между Алисой и всеми остальными пользователями:\n",
    "\n",
    "$\\operatorname{Sim}(Алиса, Рома)=\\frac{((1.5 \\cdot 0.75)+(0.5 \\cdot (-1.25))+(-2.5 \\cdot(-0.25))+(0.5 \\cdot 0.75))}{\\sqrt{\\left(1.5^2+0.5^2+2.5^2+0.5^2\\right)} \\sqrt{\\left(0.75^2+1.25^2+0.25^2+0.75^2\\right)}}=0.301$\n",
    "\n",
    "$\\operatorname{Sim}(Алиса, Катя)=\\frac{((1.5 \\cdot 0.5)+(0.5 \\cdot (-0.5))+(-2.5 \\cdot 0.5)+(0.5 \\cdot (-0.5))}{\\sqrt{\\left(1.5^2+0.5^2+2.5^2+0.5^2\\right)} \\sqrt{\\left(0.5^2+0.5^2+0.5^2+0.5^2\\right)}}=-0.33$\n",
    "\n",
    "$\\operatorname{Sim}(Алиса, Женя)=\\frac{((1.5 \\cdot 0)+(0.5 \\cdot 0)+(-2.5 \\cdot(-2))+(0.5 \\cdot 2))}{\\sqrt{\\left(1.5^2+0.5^2+2.5^2+0.5^2\\right)} \\sqrt{\\left(0^2+0^2+2^2+2^2\\right)}}=0.707$\n",
    "\n",
    "Теперь спрогнозируем рейтинг Алисы для приложения App5:\n",
    "\n",
    "$r_{(\\text {Алиса }, I 5)}=\\bar{r}_{\\text {Алиса }}+\\frac{\\left(\\operatorname{sim}(\\text { Алиса, } U 1) *\\left(r_{U 1, I 5}-\\bar{r}_{U 1}\\right)\\right)+\\left(\\operatorname{sim}(\\text { Алиса,U2 }) *\\left(r_{U 2, I 5}-\\bar{r}_{U 2}\\right)\\right)+\\left(\\operatorname{sim}(Алиса, U 3) *\\left(r_{U 3, I 5}-\\bar{r}_{U 3}\\right)\\right.}{\\operatorname{sim}(\\text { Алиса, } U 1)+\\operatorname{sim}(\\text { Алиса,U2 })+\\operatorname{sim}(Алиса, U 3)}$\n",
    "\n",
    "$r_{(\\text {Алиса, I5 })}=3.5+\\frac{(0.301 * 0.75)+(-0.33 * 1.5)+(0.707 * 1)}{|0.301|+|-0.33|+|0.707|}=3.83$\n",
    "\n",
    "Итак, мы смогли реализовать предсказание для user-based-подхода.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### КОЛЛАБОРАТИВНАЯ ФИЛЬТРАЦИЯ НА ОСНОВЕ ЭЛЕМЕНТОВ (ITEM-BASED-ПОДХОД)\n",
    "\n",
    "Если мы транспонируем матрицу предпочтений и будем решать ту же самую задачу не для пользователей, а для объектов (items), то получим аналогичную задачу, которая является item-based-моделью коллаборативной фильтрации и даёт нам возможность предсказывать оценку следующим образом:\n",
    "\n",
    "$$\\hat{r}_{u i}=\\bar{r}_i+\\frac{\\sum_{j \\in I_u} \\operatorname{sim}(i, j)\\left(r_{u j}-\\bar{r}_j\\right)}{\\sum_{j \\in I_u} \\operatorname{sim}(i, j)}$$\n",
    "\n",
    "По формуле можно понять, что этот подход использует идею предыдущего, только теперь похожи не пользователи, а объекты. Возвращаясь к примеру с рекомендациями фильмов, теперь мы рекомендуем пользователю фильм, который похож на те фильмы, которые уже понравились этому пользователю ранее.\n",
    "\n",
    "Кроме того, продуктов обычно больше, чем пользователей, поэтому векторы получатся большей размерности. Это даёт возможность получить более устойчивую модель с большей статистической значимостью.\n",
    "\n",
    "Может показаться, что коллаборативная фильтрация в рамках item-based-подхода очень похожа на модель на основе контента. Однако это не так: item-based-модель рассматривает взаимодействия пользователей с продуктом, а content-based-модель — метаинформацию продукта.\n",
    "\n",
    "Теперь давайте рассмотрим преимущества и недостатки коллаборативной фильтрации, основанной на памяти (memory-based):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ПРЕИМУЩЕСТА**\n",
    "\n",
    "* Может помочь пользователям обнаружить новые релевантные продукты из новых категорий, даже если пользователи не проявляют интерес к новым типам продуктов.\n",
    "* Не требует подробных характеристик и контекстных данных о продуктах. По сути, для реализации нужна только матрица взаимодействий пользователей и продуктов.\n",
    "\n",
    "**НЕДОСТАТКИ**\n",
    "\n",
    "* Нехватка данных может привести к трудностям при рекомендации новых продуктов или при появлении новых пользователей, поскольку предложения основаны на исторических данных и взаимодействии. Таким образом, для этого подхода актуальна проблема холодного старта.\n",
    "* По мере роста пользовательской базы алгоритмы страдают из-за большого объёма данных (очень ресурсоёмкие вычисления) и недостаточной масштабируемости.\n",
    "* Отсутствие разнообразия в долгосрочной перспективе. Это может показаться нелогичным, поскольку смысл коллаборативной фильтрации заключается в том, чтобы рекомендовать пользователю новые товары. Однако поскольку алгоритмы функционируют на основе исторических рейтингов, они не будут рекомендовать товары с небольшим количеством оценок или ограниченным количеством данных. Популярные товары будут более популярны в долгосрочной перспективе, а новых и разнообразных вариантов будет не хватать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы рассмотрели memory-based-подходы коллаборативной фильтрации. Давайте перейдём к следующим подходам, которые относятся к категории model-based и основаны на разложениях матриц. После этого мы сможем сравнить изученные модели при решении практической задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL-BASED-ПОДХОД"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В подходе на основе моделей используются модели машинного обучения для прогнозирования и ранжирования взаимодействий между пользователями и элементами, с которыми они ещё не взаимодействовали. Эти модели обучаются на основе информации, уже имеющейся в матрице взаимодействий, с помощью различных алгоритмов, например матричной факторизации.\n",
    "\n",
    "**Матричная факторизация** используется для генерации **латентных признаков** путём разложения **разрежённой** матрицы взаимодействия пользователя и продукта на две меньшие и **плотные** матрицы особенностей пользователей и продуктов.\n",
    "\n",
    "- Под латентными признаками понимаются некоторые выделенные на основе данных факторы. Например, это может быть фактор приверженности определённому жанру фильмов.\n",
    "\n",
    "- Мы получаем разрежённую матрицу из-за того, что продуктов очень много, и, очевидно, каждый пользователь взаимодействовал только с небольшим их количеством. Поэтому в матрице много пустых ячеек (нулей).\n",
    "\n",
    "- Матрицы плотные, так как нам известны характеристики пользователей и продуктов.\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/d02212cd93a334020c696d2b7835e6eb/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_3_3.png)\n",
    "\n",
    "Слева на иллюстрации мы видим разрежённую матрицу (X), а справа — матрицу пользователей U с их характеристиками (размерности k) и матрицу товаров V с их характеристиками (размерности k).\n",
    "\n",
    "Рассмотрим два варианта матричной факторизации — SVD и ALS.\n",
    "\n",
    "SVD — это сингулярное разложение, с которым вы уже подробно знакомились в [модуле по кластеризации](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DST-3.0+28FEB2021/jump_to_id/de3e2256746440e1a97c14a54697424f). Давайте вспомним суть SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любую прямоугольную матрицу A размера (n, m) можно представить в виде произведения трёх матриц:\n",
    "\n",
    "В этой формуле:\n",
    "\n",
    "* $U$ — матрица размера $n,n$. Все её столбцы ортогональны друг другу и имеют единичную длину. Такие матрицы называются **ортогональными**. Эта матрица содержит нормированные собственные векторы матрицы $AA^T$.\n",
    "* $D$ — матрица размера $n,m$. На её главной диагонали стоят числа, называемые **сингулярными** числами (они являются корнями из собственных значений матриц $AA^T$ и $A^TA$), а вне главной диагонали стоят нули. Если мы решаем задачу снижения размерности, то элементы этой матрицы, если их возвести в квадрат, можно интерпретировать как дисперсию, которую объясняет каждая компонента.\n",
    "* $V$ — матрица размера $m,m$. Она тоже **ортогональная** и содержит нормированные собственные векторы матрицы $A^TA$).\n",
    "\n",
    "Данное разложение используют для того, чтобы представить матрицу предпочтений как разложение на матрицу с характеристиками пользователей и матрицу с характеристиками продуктов. Матрица U представляет связь между пользователями и латентными факторами, D — диагональная матрица, описывающая силу каждого латентного фактора, а V — матрица, описывающая связь между продуктами и латентными факторами.\n",
    "\n",
    "Однако SVD — не единственная возможность для разложения матрицы. Второй популярный алгоритм — ALS (Alternating Least Square)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS — итеративный алгоритм разложения матрицы предпочтений на произведение двух матриц.\n",
    "\n",
    "Чтобы понять лучше суть этого алгоритма, вспомним одну из известных нам функций потерь — RMSE.\n",
    "\n",
    "Предположим, что есть m пользователей и n продуктов. Тогда у нас будут следующие матрицы:\n",
    "\n",
    "* $R$ размерности $m*n$;\n",
    "* $U$ размерности $m*k$;\n",
    "* $P$ размерности $n*k$, где $k$ — количество латентных факторов.\n",
    "\n",
    "Тогда функция потерь, которую мы будем минимизировать, будет следующей:\n",
    "\n",
    "$$\\begin{aligned} \\text { loss } & =\\min (y-\\hat{y})^2 \\\\ & =\\min \\left(R-U * P^T\\right)^2 \\\\ & =\\min \\sum_{m, n}\\left(R_{m, n}-U_m * P_n^T\\right)^2\\end{aligned}$$\n",
    "\n",
    "Здесь:\n",
    "\n",
    "* $R$ — истинные показатели взаимодействия пользователя и продукта;\n",
    "* $U*P^T$ — прогнозируемые показатели взаимодействия пользователя и продукта.\n",
    "\n",
    "Далее мы, по сути, решаем метод наименьших квадратов для разницы матриц, на каждом шаге уменьшая ошибку сначала по факторам пользователей, а затем — по факторам товаров. Чтобы избежать ситуации переобучения, к ошибке добавляются регуляризационные коэффициенты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS — это итерационный процесс оптимизации, в котором мы на каждой итерации пытаемся приблизиться к факторизованному представлению исходных данных.\n",
    "\n",
    "Давайте рассмотрим реализацию ALS на «игрушечном» примере. Допустим, у нас есть некоторая матрица, которая содержит информацию про пользователей и их отношение к фильмам:\n",
    "\n",
    "/|ФИЛЬМ 1|ФИЛЬМ 2|ФИЛЬМ 3\n",
    "-|-|-|-\n",
    "Пользователь 1|0.5|?|4\n",
    "Пользователь 2|1|3|5\n",
    "\n",
    "Однако нам неизвестно, какую оценку поставил Пользователь 1 Фильму 2 — её мы и будем пытаться предсказать с помощью ALS.\n",
    "\n",
    "В соответствии с методом ALS мы хотим получить следующее разложение:\n",
    "\n",
    "$\\left(\\begin{array}{ccc}0.5 & ? & 4 \\\\ 1 & 3 & 5\\end{array}\\right)=\\left(\\begin{array}{l}u_1 \\\\ u_2\\end{array}\\right)\\left(\\begin{array}{lll}p_1 & p_2 & p_3\\end{array}\\right)$\n",
    "\n",
    "Для начала фиксируем матрицу U (вектор-столбец). Для неё можно выбрать любые случайные числа, но для удобства вычислений примем оба значения за единицу:\n",
    "\n",
    "$\\left(\\begin{array}{ccc}0.5 & ? & 4 \\\\ 1 & 3 & 5\\end{array}\\right)=\\left(\\begin{array}{l}1 \\\\ 1\\end{array}\\right)\\left(\\begin{array}{lll}p_1 & p_2 & p_3\\end{array}\\right)$\n",
    "\n",
    "Если мы перемножим матрицы в правой части равенства, то получим пять уравнений, в которых участвуют компоненты из вектора p:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/7cfd0f260ead1de4a75aa302d7108876/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_3_eq4.png)\n",
    "\n",
    "Поскольку существует единственное уравнение, определяющее вторую компоненту P, мы задаём её равной 3. Нам необходимо выбрать оставшиеся две компоненты так, чтобы средняя квадратичная ошибка была минимальной. Таким образом, вычисляем:\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/279fe917219154ac3ca65f2fb52443c0/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_3_eq5.png)\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/8ca933222d3532e8cc93cc2f8b5d79ae/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_3_eq6.png)\n",
    "\n",
    "Разумеется, мы умеем вычислять точки минимума для функции, используя производные. Находим точки минимума для обоих случаев и получаем первую оценку для матрицы:\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/7ed8812fc95a1f755772a90238182c97/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_3_eq7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы оставляем компоненты матрицы P фиксированными и оптимизируем матрицу U. Это аналогично даёт нам следующие уравнения для U:\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/099c4c6f2311990b9a03599c4e81f1f6/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_3_eq8.png)\n",
    "\n",
    "Далее мы можем минимизировать среднеквадратичную ошибку для компонентов матрицы U, как мы это делали ранее для компонентов матрицы P.\n",
    "\n",
    "Повторяя эти итерации, мы в какой-то момент сходимся к оптимальным матрицам U и P. В данном примере после 20 итераций можно определить, что U и P даны в виде:\n",
    "\n",
    "![](https://lms-cdn.skillfactory.ru/assets/courseware/v1/f6ef822ea53016f0a6d20afb87d1d906/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/DST_MATH_ML_15_3_eq9.png)\n",
    "\n",
    "Теперь из этих матриц мы можем получить восстановленную матрицу прогнозируемых взаимодействий пользователей и продуктов, на основе которой мы можем составлять рекомендации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MATH&ML-7. Теория вероятностей в контексте наивного байесовского классификатора**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение. Основные понятия теории вероятностей\n",
    "\n",
    "✍ В этом модуле мы начнём знакомство с новым разделом математики — **теорией вероятностей**.\n",
    "\n",
    "До сих пор мы имели дело с **детерминированными** величинами.\n",
    "\n",
    "Например, если вы играете в игру, в которой вам платят 1 000 рублей каждый раз, когда вы правильно возводите число 5 в квадрат, всё зависит только от ваших арифметических навыков, ведь $5^2$ — это всегда 25. Пока вы будете правильно считать, вы будете выигрывать.\n",
    "\n",
    "> **Детерминированность** — это ситуация, в которой одно и то же действие всегда приводит к одному и тому же результату.\n",
    "\n",
    "Вероятность же имеет дело с **неопределённостями**.\n",
    "\n",
    "Изменим правила игры: теперь вам платят 1 000 рублей, если вы угадаете, что выпадет при подбрасывании игрального кубика. Интуитивно мы понимаем, что, если кубик правильный (т. е. ровный со всех сторон), то шанс угадать — 1 из 6 , так как граней шесть, и каждая выпадает равновероятно. Таким образом, здесь мы попадаем в ситуацию случайности, когда одно и то же действие приводит к разным результатам. Итог такого действия называется **случайной величиной**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но что, если вы бросаете два кубика и делаете ставку на сумму? Какое число выбрать для ставки?\n",
    "\n",
    "Может показаться, что сумма очков на двух равновероятных кубиках также равновероятна, но это не так: 6 и 7 будут выпадать гораздо чаще, чем 2 или 12. Для наглядности можно отобразить все возможные комбинации в таблице:\n",
    "\n",
    "1|2|3|4|5|6\n",
    "-|-|-|-|-|-\n",
    "**1**|(1, 1)|(1, 2)|(1, 3)|(1, 4)|(1, 5)|(1, 6)\n",
    "**2**|(2, 1)|(2, 2)|(2, 3)|(2, 4)|(2, 5)|(2, 6)\n",
    "**3**|(3, 1)|(3, 2)|(3, 3)|(3, 4)|(3, 5)|(3, 6)\n",
    "**4**|(4, 1)|(4, 2)|(4, 3)|(4, 4)|(4, 5)|(4, 6)\n",
    "**5**|(5, 1)|(5, 2)|(5, 3)|(5, 4)|(5, 5)|(5, 6)\n",
    "**6**|(6, 1)|(6, 2)|(6, 3)|(6, 4)|(6, 5)|(6, 6)\n",
    "\n",
    "Как видите, для того, чтобы выпало 12 , нужны две шестёрки, а, например, для 7 есть много вариантов, поэтому шанс угадать больше. Но насколько больше? В целом, поскольку у нас выписаны все варианты, мы можем примерно понять, насколько чаще в сумме будет выпадать 7, а не 12.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/94f287c8fc3dc580b6e00409e671fa90/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_1_1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что, если кубиков не два, а десять?\n",
    "\n",
    "Тогда всё становится ещё сложнее. Выписывать все варианты мы уже не сможем, так как их слишком много.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/aedada64ecb9262068aba7236d07aaea/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_1_2.png)\n",
    "\n",
    "> Здесь нам уже понадобится **теория вероятностей** — наука, которая позволяет сделать предположения о более простых вероятностях (об очках на одном кубике) и на их основе математически вывести гораздо более сложные (об очках на нескольких кубиках). К примеру, теория вероятностей помогает ответить на вопрос: «На что ставить, чтобы увеличить шансы на выигрыш?»\n",
    "\n",
    "Мы не случайно начали юнит с примера про кубики: именно попытки предсказать вероятности выигрыша в такие азартные игры, как игральные кости или орлянка несколько столетий назад дали стимул развитию этой области математики. Но, разумеется, теория вероятностей широко используется и по сей день и может быть полезна не только для того, чтобы оценить свои шансы в казино.\n",
    "\n",
    "Изучение вероятности важно, так как она имеет дело с количественными оценками ситуаций с неопределёнными результатами."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* При **производстве** какого-то продукта всегда неясно, получится ли он с дефектом. Тестирование каждого продукта, который должен выйти в продажу, было бы невероятно дорогим и трудозатратным. Однако понимание вероятности дефекта позволяет заранее заложить её в издержки и проработать политику решения ситуаций с бракованными товарами.\n",
    "\n",
    "* Также всякий раз, когда человек вкладывает деньги в акции, он, осознавая это или нет, занимается оценками вероятностей. Каждая **инвестиция** имеет некоторую степень неопределённости: никто не может быть уверен, какова будет стоимость акций в будущем. Инвестируя деньги в акции, вы, по сути, предполагаете высокую вероятность того, что эти акции вырастут в цене. Продажа же акций означает, что вы оцениваете вероятность падения цены как довольно большую. Профессиональные финансовые аналитики, как правило, уделяют много внимания оценкам вероятности при просчёте своих рисков. Они используют исторические данные и огромный поток ежедневной информации, чтобы определить вероятность увеличения или уменьшения стоимости инвестиций.\n",
    "\n",
    "* Вероятностные модели также постоянно используются в **анализе данных**: в алгоритмах классификации и прогнозирования, а также при построении рекомендательных систем и в стохастических алгоритмах оптимизации.\n",
    "\n",
    "    * Если мы хотим построить алгоритм, который будет рекомендовать фильмы пользователю сервиса, для каждого фильма необходимо рассчитать вероятности, выражающие соответствие фильма предпочтениям человека. После этого можно будет предложить пользователю те фильмы, у которых эти вероятности наибольшие.\n",
    "\n",
    "    * Если вы сможете собрать данные о том, какие вопросы и как часто встречаются на собеседованиях на позицию специалистов по машинному обучению, то сможете предсказать вероятность столкнуться с задачей на тему данного модуля при трудоустройстве."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном модуле мы изучим все основные концепции теории вероятностей, научимся вычислять значения вероятностей для разных случаев и применять теорию вероятностей для решения различных задач.\n",
    "\n",
    "## НАШИ ЦЕЛИ НА ДАННЫЙ МОДУЛЬ:\n",
    "\n",
    "* Узнать **основные понятия** из теории вероятностей.\n",
    "\n",
    "    В каждом юните вы будете знакомиться с новыми терминами, которые встретите ещё не раз при описании различных алгоритмов.\n",
    "\n",
    "* Познакомиться со всеми **теоремами и правилами** для вычисления вероятностей.\n",
    "\n",
    "    Теория вероятности включает множество законов, которые являются основой различных алгоритмов машинного обучения. Например, условная вероятность и теорема Байеса являются фундаментом для байесовского классификатора. Сама по себе теорема Байеса дала начало отдельной ветви статистики, которая включает в себя байесовские методы, очень популярные в последнее время в машинном обучении.\n",
    "\n",
    "* Научиться применять полученные знания для **решения практических задач**.\n",
    "\n",
    "    Разумеется, после разбора каждого правила и понятия мы будем закреплять знания на практике.\n",
    "\n",
    "* Понять принцип работы **байесовского классификатора** и научиться применять его для задач машинного обучения.\n",
    "\n",
    "    Мы с вами решим задачу классификации спама, прописав алгоритм «вручную», и сможем получить достаточно высокое качество модели.\n",
    "\n",
    "* Познакомиться с основными **распределениями случайных величи**н.\n",
    "\n",
    "    Мы узнаем, какие есть распределения и как некоторые из них помогают обработать признаки или сравнить значения, измеренные по разным шкалам (например, результаты международных экзаменов по английскому языку TOEFL и IELTS).\n",
    "\n",
    "* Научиться вычислять **характеристики случайных величин**.\n",
    "\n",
    "    Мы познакомимся с основными характеристиками случайных величин и сможем с их помощью оценивать наборы разных значений."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, в первую очередь нам необходимо познакомиться с главными понятиями, начать говорить на «языке» теории вероятностей.\n",
    "\n",
    "В теории вероятностей всё начинается со случайного эксперимента.\n",
    "\n",
    "> Под **случайным экспериментом** понимается такой эксперимент, результат которого не детерминирован изначально.\n",
    "\n",
    "Предположим, если мы заходим на наш сайт в какой-то случайный момент времени и узнаём количество пользователей, находящихся на сайте в данный момент, мы совершаем случайный эксперимент, ведь заранее никак нельзя предугадать, сколько точно людей будет на сайте в то или иное время.\n",
    "\n",
    "Приведём **ещё несколько примеров случайных экспериментов**:\n",
    "\n",
    "* подбрасывание игральной кости;\n",
    "* вытаскивание карты из колоды;\n",
    "* подсчёт числа людей, находящихся в помещении;\n",
    "* выстрел по мишени;\n",
    "* сдача студентом экзамена;\n",
    "* запуск случайной песни из плейлиста."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все вышеперечисленные эксперименты объединяет то, что каждый раз мы не можем точно знать, что получится в итоге — результаты могут быть разными. Например, если мы открываем плейлист и просим плеер выбрать случайную песню, то в результате слышим одну из песен, которые мы уже выбрали ранее. Или, если мы берём колоду карт и вытягиваем одну из них, то в результате получаем карту какой-то определённой масти и достоинства.\n",
    "\n",
    "> Так появляется понятие **элементарного исхода **— любого возможного исхода случайного эксперимента. Например, если вернуться к примеру про количество пользователей на сайте, то все элементарные исходы — это все возможные количества посетителей на сайте.\n",
    "\n",
    "> Разумеется, по результатам эксперимента обычно может получаться много различных результатов (элементарных исходов). Всё множество таких исходов носит называется **пространством элементарных исходов** и обычно обозначается буквой $\\Omega$ (омега).\n",
    "\n",
    "Ниже можно увидеть примеры случайных экспериментов и пространства элементарных исходов:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "СЛУЧАЙНЫЙ ЭКСПЕРИМЕНТ|ПРОСТРАНСТВО ЭЛЕМЕНТАРНЫХ ИСХОДОВ\n",
    "-|-\n",
    "Сдача экзамена TOEFL|Любое число от 0 до 120\n",
    "Бросок одного шестигранного кубика|1, 2, 3, 4, 5, 6\n",
    "Попытка устроиться на определённую должность|«Устроился» ли «не устроился»\n",
    "Подбрасывание монетки два раза|ОО, ОР, РО, РР, где Р — это решка, а О — орёл"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Классическое определение вероятности. Правила сложения и умножения\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущем юните мы немного познакомились с тем, что такое вероятность и зачем нам необходимо научиться считать вероятности.\n",
    "\n",
    "Теперь давайте рассмотрим формальное классическое определение вероятности.\n",
    "\n",
    "> **Вероятностью** случайного события $A$ называется отношение числа $n$ равновероятных элементарных исходов, составляющих событие $A$, к числу всех возможных элементарных исходов $N$:\n",
    "> \n",
    "> $$P(A)=\\frac{n}{N}$$\n",
    "> \n",
    "> Элементарные исходы, составляющие событие $A$, также очень часто называют **исходами, благоприятными или благоприятствующими для события** $A$.\n",
    "\n",
    "Рассмотрим пример ↓\n",
    "\n",
    "Вы работаете в компании, которая разрабатывает новое лекарство.\n",
    "\n",
    "В клинических испытаниях участвовали 2800 человек. Ухудшение состояния было зарегистрировано у семи из них.\n",
    "\n",
    "Необходимо понять, какова вероятность, что новое лекарство вызовет ухудшение состояния пациента, так как, если она велика, то лекарство требует доработки."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, в данном случае 2800 — это общее количество исходов события, а 7 — количество благоприятных исходов. Согласно определению вероятности, вероятность серьёзных побочных эффектов вычисляется следующим образом:\n",
    "\n",
    "$\\frac{7}{2800} =0.0025$\n",
    "\n",
    "Можно также сказать, что вероятность — это число, которое оценивает степень возможности наступления того или иного случайного события. Вероятности всегда находятся в диапазоне от 0 до 1 включительно:\n",
    "\n",
    "$0 \\leq P(A) \\leq 1$\n",
    "\n",
    "Чем больше полученное значение, тем более вероятно, что событие произойдёт. Вероятность 0 означает, что событие никогда не случится. Такое событие называют **невозможным**:\n",
    "\n",
    "$P(A)=P(\\oslash)=\\frac{n}{N}=\\frac{0}{N}=0$\n",
    "\n",
    "Вероятность 1 означает, что событие произойдёт в любом случае — такое событие называют **достоверным**:\n",
    "\n",
    "$P(A)=P(\\Omega)=\\frac{n}{N}=\\frac{N}{N}=1$\n",
    "\n",
    "Все остальные значения от 0 до 1 представляют различные уровни вероятности."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, мы научились вычислять вероятности случайных событий по определению. Теперь нам важно разобраться с **дополнением события**. Скорее всего, вы помните, что такое дополнение ко множеству, — здесь логика ровно такая же.\n",
    "\n",
    "> **Дополнение события $A$**  — это подмножество таких исходов во всём пространстве исходов, что они не благоприятствуют событию $A$. Дополнение события $A$ само по себе тоже является событием и обозначается как $\\overline{A}$.\n",
    "\n",
    "Важно понимать, что **у события и дополнения к нему нет общих исходов**, то есть они взаимоисключающие или, как это обычно называют в теории вероятностей, **несовместные**. Также событие и дополнение к нему содержат в сумме абсолютно все исходы из пространства исходов. Из этого следует, что сумма их вероятностей равняется одному:\n",
    "\n",
    "$$P(A)+P\\left(\\overline{A}\\right)=1$$\n",
    "\n",
    "Например, если мы знаем, что вероятность того, что пойдёт дождь, равна $0.7$, то вероятность того, что дождя не будет, равна $1-0.7=0.3$. События «пойдёт дождь» и «дождя не будет» являются несовместными, так как не может быть, чтобы одновременно шёл дождь и его не было. Также они покрывают всё пространство исходов, так как никаких других вариантов быть не может."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы узнали, что могут существовать два события, которые содержат в себе все элементарные исходы, и тогда их вероятности в сумме равны 1.\n",
    "\n",
    "На самом деле это верно не только для двух событий. Если у нас есть любое количество взаимоисключающих событий, которые описывают абсолютно все возможные элементарные исходы, то сумма их вероятностей равна 1:\n",
    "\n",
    "$$P\\left(A_{1}\\right)+P\\left(A_{2}\\right)+P\\left(A_{3}\\right)+\\ldots+P\\left(A_{n}\\right)=1$$\n",
    "\n",
    "Теперь нам необходимо изучить ряд правил, которые помогут находить вероятности в более сложных задачах. Начнём с правила суммы и правила умножения."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПРАВИЛО СУММЫ\n",
    "\n",
    "> Вероятностное **правило суммы** используется в ситуациях, когда необходимо найти вероятность наступления объединения событий.\n",
    "\n",
    "К примеру, если есть события «Маша получила за тест 4» и «Маша получила за тест 5», их объединением будет событие «Маша получила за тест 4 или 5», и для вычисления его вероятности нам как раз понадобится правило суммы.\n",
    "\n",
    "Это правило используется для несовместных событий, то есть событий, которые не могут произойти одновременно.\n",
    "\n",
    "Если события $A$ и $B$ являются несовместными, то вероятность для объединения этих событий вычисляется по следующей формуле:\n",
    "\n",
    "$$P(A \\cup B)=P(A)+P(B)$$\n",
    "\n",
    "Знак  здесь имеет тот же смысл, что и в объединении множеств. Мы уже разбирали это в модуле, посвящённом математическому анализу."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разумеется, формулу для вероятности объединения событий можно легко вывести математически. За $S$ обозначим всё пространство исходов:\n",
    "\n",
    "$$P(A \\cup B)=\\frac{\\left|A \\right|+\\left|B \\right|}{\\left|S \\right|}=\\frac{\\left|A \\right|}{\\left|S \\right|}+\\frac{\\left|B \\right|}{\\left|S \\right|}=P(A)+P(B)$$\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/d3338cd8939dde9bbd126e38b76417a4/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_2_1.png)\n",
    "\n",
    "Разберём это правило на примере ↓\n",
    "\n",
    "*В магазине одежды есть в наличии две зеленые юбки, три — красные и четыре — синие. Приходит покупательница и случайным образом выбирает юбку, причём каждая юбка может быть выбрана с одинаковой вероятностью. Точно известно, что она выберет только одну юбку.*\n",
    "\n",
    "*Какова вероятность того, что покупательница выберет зелёную или синюю юбку?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим события $G$ и $B$ следующим образом:\n",
    "\n",
    "* $G$ = клиентка выбирает зелёную юбку;\n",
    "* $B$ = клиентка выбирает синюю юбку.\n",
    "\n",
    "Нельзя купить одновременно зелёную и синюю юбку, так что можно без проблем применить правило для вероятности суммы:\n",
    "\n",
    "$P(G \\cup B)=P(G)+P(B)=\\frac{2}{9}+\\frac{4}{9}=\\frac{2}{3}$\n",
    "\n",
    "Получаем, что с вероятностью $\\frac{2}{3}$ будет выбрана зелёная или синяя юбка."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Пусть нам известно, что среди людей, заходящих в магазин, 70 % ничего не покупают. Остальные с равной вероятностью покупают 1, 2 или 3 бутылки воды.*\n",
    "\n",
    "*Допустим, что в магазин заходят два человека. Если событие $A$ — это «покупка чётного числа бутылок первым человеком», а событие $B$ — «покупка вторым человеком более чем одной бутылки», давайте найдём вероятность события $A \\cap B$, то есть вероятность того, что один человек купил чётное количество бутылок, а второй купил более одной бутылочки.*\n",
    "\n",
    "Рассмотрим элементарные исходы, благоприятные событию $A$, и его вероятность:\n",
    "\n",
    "$A = \\{0,2 \\}, \\ P(A) = 0.8$\n",
    "\n",
    "Сделаем то же самое для события $B$:\n",
    "\n",
    "$B = \\{2,3 \\}, \\ P(B) = 0.2$\n",
    "\n",
    "Тогда вероятность их пересечения ищем следующим образом:\n",
    "\n",
    "$P (A \\cap B) = 0.8 \\cdot 0.2 = 0.16$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ОБОБЩЁННОЕ ПРАВИЛО СУММЫ\n",
    "\n",
    "Применение рассмотренного нами правила суммы несколько ограничено, поскольку требует несовместных событий.\n",
    "\n",
    "Что, если события всё же могут быть совместными, то есть происходить одновременно?\n",
    "\n",
    "Приведём обобщенное правило суммы, которое можно применять и в таких ситуациях:\n",
    "\n",
    "$$P(A \\cup B)=P(A)+P(B)-P(A \\cap B)$$\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/a6b1e755d92f20c415dfebf2a9626e78/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_2_2.png)\n",
    "\n",
    "Давайте рассмотрим, как выводится это правило.\n",
    "\n",
    "Дело в том, что при сложении вероятностей наступления событий $A$ и $B$ мы считаем центральную часть (пересечение) дважды. Поэтому нам необходимо вычесть вероятность пересечения данных событий, чтобы она была вычислена только один раз.\n",
    "\n",
    "$$P(A \\cup B)=\\frac{\\left|A \\right|}{\\left|S \\right|}+\\frac{\\left|B \\right|}{\\left|S \\right|}-\\frac{\\left|A \\cap B \\right|}{\\left|S \\right|}=P(A)+P(B)-P(A \\cap B)$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Пусть 30 % клиентов нашей клининговой компании — женщины. Также мы знаем, что $\\frac{2}{3}$ женщин пользуются нашими услугами еженедельной уборки, а $\\frac{2}{3}$ — нет. Среди мужчин $\\frac{3}{7}$ пользуются услугами еженедельной уборки, а $\\frac{4}{7}$ ими не пользуются.*\n",
    "\n",
    "*Необходимо найти вероятность, что случайно выбранный клиент либо женского пола, либо пользуется нашими услугами еженедельной уборки, либо и то, и другое.*\n",
    "\n",
    "Просто сложить вероятность, что клиент женского пола, и вероятность, что клиент пользуется рассматриваемыми услугами, нельзя, так как в таком случае мы дважды посчитаем женщин, которые используют еженедельную уборку.\n",
    "\n",
    "Можно представить наши данные в виде следующей таблицы:\n",
    "\n",
    "Пол\\услуги|Пользуются услугами|Не пользуются услугами\n",
    "-|-|-\n",
    "Женщины|20 %|10 %\n",
    "Мужчины|30 %|40 %"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы рассчитать все значения, мы воспользовались информацией из условия задачи.\n",
    "\n",
    "Если мы знаем, что всего женщин 30 %, и $\\frac{2}{3}$ из них пользуются нашими услугами еженедельной уборки, а $\\frac{1}{3}$ — нет, то легко рассчитать:\n",
    "\n",
    "* процент женщин, которые используют услугу: $30 \\%* \\frac{2}{3} = 20 \\%$;\n",
    "* процент женщин, которые не используют услугу: $30 \\%* \\frac{1}{3} = 10 \\%$.\n",
    "\n",
    "Аналогичные расчёты можно провести и для мужчин.\n",
    "\n",
    "Если пользоваться формулой, то для начала необходимо сложить вероятности того, что клиент женского пола:\n",
    "\n",
    "Пол\\Услуги|Пользуются услугами|Не пользуются услугами\n",
    "-|-|-\n",
    "Женщины|**20 %**|**10 %**\n",
    "Мужчины|30 %|40 %\n",
    "\n",
    "Затем надо прибавить вероятность того, что клиент пользуется нашими услугами:\n",
    "\n",
    "Пол\\Услуги|Пользуются услугами|Не пользуются услугами\n",
    "-|-|-\n",
    "Женщины|**20 %**|10 %\n",
    "Мужчины|**30 %**|40 %"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда мы получим, что мы посчитали 30 % и 10 % по одному разу, а 20 % — два раза:\n",
    "\n",
    "Пол\\услуги|Пользуются услугами|Не пользуются услугами\n",
    "-|-|-\n",
    "Женщины|***20 %***|**10 %**\n",
    "Мужчины|**30 %**|40 %\n",
    "\n",
    "Поэтому вычитаем 20 % и получаем необходимый нам результат:\n",
    "\n",
    "$50 \\% + 30 \\% - 20 \\% = 60 \\%$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Условная вероятность"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Мы познакомились с простейшими правилами вычисления вероятностей и теперь переходим к алгоритму для поиска условной вероятности.\n",
    "\n",
    "> Как можно понять из названия, **условная вероятность** — это вероятность события при некоторых уже известных условиях.\n",
    "\n",
    "Например, нам может быть необходимо найти вероятность, что человек вернёт ипотеку, если у него уже есть кредит на автомобиль, или вероятность того, что клиент компании уйдёт к конкурентам, если нам известно, что он отклонял все рекламные предложения в течение предыдущего года.\n",
    "\n",
    "> Условная вероятность события $A$ при условии $B$ определяется как вероятность того, что событие $B$ произойдёт после того, как событие $A$ уже произошло, и обозначается следующим образом:\n",
    ">\n",
    "> $$P(B \\mid A)$$\n",
    "\n",
    "Чтобы найти формулу для поиска условной вероятности, запишем, что вероятность того, что произойдёт и событие $A$ и событие $B$ сразу (по сути, это пересечение событий $A$ и $B$) — это вероятность того, что произойдёт событие $A$, умноженная на вероятность того, что произойдёт событие $B$ (при условии, что  уже произошло). Это соотношение получается напрямую из правила произведения, которое вы изучили в предыдущем юните:\n",
    "\n",
    "$$P(A \\ и \\ B)=P(A) \\cdot P(B \\mid A)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделим обе части на $P(a)$:\n",
    "\n",
    "$$\\frac{P(A \\text { и } B)}{P(A)}=\\frac{P(A) \\cdot P(B \\mid A)}{P(A)}$$\n",
    "\n",
    "В правой части сократим $Р(A)$ в числителе и знаменателе и получим формулу для поиска условной вероятности:\n",
    "\n",
    "$$\\frac{P(A \\text { и } B)}{P(A)}=P(B \\mid A)$$\n",
    "\n",
    "Рассмотрим алгоритм вычисления условной вероятности на примере ↓\n",
    "\n",
    "\n",
    "Представим, что некий стажёр пытается устроиться на работу. С вероятностью $0.06$ он успеет вовремя прийти на собеседование и получит работу. С вероятностью $0.2$ он в принципе придёт на собеседование вовремя. Необходимо найти вероятность, что стажёр получит работу, если известно, что он уже пришёл на собеседование в нужное время.\n",
    "\n",
    "Обозначим за $N$ событие, что стажёр пришёл вовремя, а за $T$ — событие, что его взяли на работу. Тогда получаем следующую формулу:\n",
    "\n",
    "$$P(T \\mid N)=\\frac{P(N \\text { и } T)}{P(N)}=\\frac{0.06}{0.20}=0.30$$\n",
    "\n",
    "Получаем, что стажёр получит работу при условии, что он вовремя пришел на встречу, с вероятностью $0.3$.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим ещё несколько примеров. Вспомним пример из предыдущего юнита, но на этот раз усложним его, найдя ответ на менее очевидный вопрос.\n",
    "\n",
    "*Среди людей, заходящих в магазин, 70 % ничего не покупают. Остальные с равной вероятностью покупают 1, 2 или 3 бутылки воды. Найдите вероятность купить 2 бутылки, если точно известно, что было куплено меньше трёх.*\n",
    "\n",
    "Запишем выражение для поиска условной вероятности, согласно рассмотренной ранее формуле:\n",
    "\n",
    "$P(\\{2\\} \\mid\\{0,1,2\\})=\\frac{P(\\{2\\} \\cap\\{0,1,2\\})}{P(\\{0,1,2\\})}$\n",
    "\n",
    "В числителе нам нужна вероятность того, что одновременно было куплено две бутылки и какое-то количество из множества $\\{0,1,2 \\}$. Разумеется, это то же самое, что вероятность покупки просто двух бутылок:\n",
    "\n",
    "$\\frac{P(\\{2\\} \\cap\\{0,1,2\\})}{P(\\{0,1,2\\})}=\\frac{P(\\{2\\})}{P(\\{0,1,2\\})}=\\frac{0.1}{0.7+0.1+0.1}=1 / 9$\n",
    "\n",
    "Получаем, что из тех, кто покупает меньше трёх бутылок воды, ровно две бутылки берёт один человек из девяти покупателей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что, хотя в пересечении один исход, а в условии — три, вероятность не равна $1/3$. Так получилось потому, что модель неравновероятна и ноль (то есть исход, когда человек ничего не купил) имеет существенно больший вес, чем остальные исходы.\n",
    "\n",
    "*В конференции участвуют 1000 человек: 300 мужчин и 700 женщин. Известно, что 240 мужчин и 280 женщин пьют кофе. Необходимо найти, с какой вероятностью случайно взятый человек с конференции:*\n",
    "\n",
    "* *пьёт кофе, если пол неизвестен;*\n",
    "* *пьёт кофе, если это мужчина;*\n",
    "* *пьёт кофе, если это женщина.*\n",
    "\n",
    "Для начала опишем всё пространство элементарных исходов. Для простоты введём следующие обозначения:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Omega=\\{M D, M N, F D, F N\\}$\n",
    "\n",
    "$\\mathrm{M} - male \\ (мужчина)$\n",
    "\n",
    "$\\mathrm{F} - female \\ (женщина)$\n",
    "\n",
    "$\\mathrm{D} - drinks \\ (пьёт)$\n",
    "\n",
    "$\\mathrm{N} - does \\ not \\ drink \\ (не \\ пьёт)$\n",
    "\n",
    "Рассчитаем вероятности для каждого исхода:\n",
    "\n",
    "* вероятность, что это мужчина, пьющий кофе: $P(M D)=\\frac{240}{1000}=0.24$;\n",
    "* вероятность, что это мужчина, не пьющий кофе: $P(M N)=\\frac{300-240}{1000}=0.06$;\n",
    "* вероятность, что это женщина, пьющая кофе: $P(F D)=\\frac{280}{1000}=0.28$;\n",
    "* вероятность, что это женщина, не пьющая кофе: $P(F N)=\\frac{700-280}{1000}=0.42$.\n",
    "\n",
    "Тогда вероятность того, что человек (мужчина или женщина) пьёт кофе, мы можем вычислить, вспомнив правило сложения вероятностей, изученное в прошлом юните:\n",
    "\n",
    "$P(D)=P(\\{M D, F D\\})=0.24+0.28=0.52$\n",
    "\n",
    "Теперь рассчитаем условную вероятность того, что человек пьёт кофе, если мы знаем, что это мужчина:\n",
    "\n",
    "$P(D \\mid M)=P(\\{M D, F D\\} \\mid\\{M D, M N\\})= \\frac{P(\\{M D\\})}{P(\\{M D, M N\\})}=\\frac{0.24}{0.3}=0.8$\n",
    "\n",
    "То же самое делаем для женщин:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое делаем для женщин:\n",
    "\n",
    "$P(D \\mid F)=P(\\{M D, F D\\} \\mid\\{F D, F N\\})=\\frac{P(\\{F D\\})}{P(\\{F D, F N\\})}=\\frac{0.28}{0.7}=0.4$\n",
    "\n",
    "Итак, мы рассчитали условные вероятности для этого примера. Теперь давайте в рамках этой же ситуации рассмотрим разницу между вероятностью пересечения событий и условной вероятностью. Для этого попробуем найти вероятности двух похожих, но всё же принципиально разных событий:\n",
    "\n",
    "* случайно взятый человек с конференции пьёт кофе и является женщиной;\n",
    "* случайно взятый человек с конференции пьёт кофе, если уже известно, \n",
    "что это женщина.\n",
    "\n",
    "Может показаться, что эти события похожи, однако это не так. Давайте рассчитаем вероятность сначала первого, а затем второго события.\n",
    "\n",
    "Для нахождения вероятности первого события используем правило произведения:\n",
    "\n",
    "$P(F \\cap D)=P(F D)=0.28$\n",
    "\n",
    "Для вычисления вероятности второго события используем формулу условной вероятности:\n",
    "\n",
    "$P(D \\mid F)=P(\\{M D, F D\\} \\mid\\{F D, F N\\})=\\frac{P(\\{F D\\})}{P(\\{F D, F N\\})}=\\frac{0.28}{0.7}=0.4$\n",
    "\n",
    "Можно увидеть, что результаты получились разные, так как это две принципиально разные ситуации — пожалуйста, будьте внимательны и не путайте эти случаи при решении задач."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## УСЛОВНАЯ ВЕРОЯТНОСТЬ И МАТРИЦА ОШИБОК"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим, как условная вероятность используется в машинном обучении для оценки качества классификации.\n",
    "\n",
    "Допустим, у нас есть выборка из изображений, которые мы хотим классифицировать на две группы — фотографии чихуахуа и фотографии кексов с ягодами:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/0f63123d6a47458f9ec7e8ae1fec15f7/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_3_1.png)\n",
    "\n",
    "Мы реализовали один из алгоритмов машинного обучения (например, логистическую регрессию или KNN) и получили следующие результаты:\n",
    "\n",
    "-|Чихуахуа (предсказание)|Кекс (предсказание)\n",
    "-|-|-\n",
    "Чихуахуа (реальное изображение)|450|100\n",
    "Кекс (реальное изображение)|150|550"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По столбцам мы видим предсказания алгоритма, а по строкам — реальные изображения. То есть, например, на 450 фотографиях действительно чихуахуа, и модель корректно это отразила, а вот на 100 фотографиях в реальности чихуахуа, но модель приняла собаку за кекс.\n",
    "\n",
    "?\n",
    "Теперь представим, что мы загружаем в алгоритм новую картинку и нам необходимо понять: если модель выдаёт, что на картинке — чихуахуа, то с какой вероятностью это действительно так?\n",
    "\n",
    "Таким образом, мы хотим найти следующую вероятность:\n",
    "\n",
    "$P(на \\ фото \\ действительно \\ чихуахуа \\mid алгоритм \\ предсказал \\ чихуахуа \\ на \\ фото)$\n",
    "\n",
    "Ещё раз взглянем на результаты и будем рассматривать только на первый столбец, поскольку нам уже известно, что алгоритм предсказал, что на фото чихуахуа:\n",
    "\n",
    "-|Чихуахуа (предсказание)|Кекс (предсказание)\n",
    "-|-|-\n",
    "Чихуахуа (реальное изображение)|**450**|100\n",
    "Кекс (реальное изображение)|**150**|550\n",
    "\n",
    "Всего в рассматриваемом пространстве ответов 600 предсказаний.\n",
    "\n",
    "Из 600 сделанных прогнозов 450 верны, а 150 — неверны.\n",
    "\n",
    "Таким образом, условная вероятность составляет $450/600 = 3/4$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятно, вы уже отметили, что, по сути, перед вами уже знакомая вам матрица ошибок, часто используемая в машинном обучении для оценки качества классификации. Вы наверняка умеете вычислять различные метрики, и теперь пришло время осознать, что на самом деле ранее вы постоянно вычисляли условные вероятности, когда рассчитывали качество модели:\n",
    "\n",
    "$Precision = P(X \\ предсказан \\ как \\ класс \\ 1 \\ и \\ действительно \\ им \\ является \\mid X \\ предсказан \\ как \\ класс \\ 1)$\n",
    "\n",
    "$Recall = P(X \\ предсказан \\ как \\ класс \\ 1 \\ и \\ действительно \\ им \\ является \\mid X \\ действительно \\ принадлежит \\ к \\ классу \\ 1)$\n",
    "\n",
    "$Specificity = P(X \\ предсказан \\ как \\ класс \\ 0 \\ и \\ действительно \\ им \\ является \\mid X \\ действительно \\ принадлежит \\ к \\ классу \\ 0)$\n",
    "\n",
    "\n",
    "→ Этот пример хорошо иллюстрирует то, что различные правила и алгоритмы из теории вероятностей пронизывают машинное обучение и анализ данных даже там, где это незаметно с первого взгляда."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## НЕЗАВИСИМОСТЬ СОБЫТИЙ\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В применении теории вероятностей к анализу данных очень важно понятие **независимости**. Нам важно знать, влияет ли одно явление на другое или они не зависят друг от друга. Сейчас мы говорим о вероятности событий, поэтому и независимость рассмотрим тоже для событий.\n",
    "\n",
    "> События $A$ и $B$ называются независимыми, если вероятность их пересечения равна произведению вероятностей\n",
    ">\n",
    "> $$P(A \\cap B)=P(A) \\cdot P(B)$$\n",
    "\n",
    "Основная суть независимых событий заключается в том, что вероятность $A$ не зависит от наличия условия, связанного с $B$, то есть при наступлении события $B$ событие $A$ происходит так же часто, как и без него.\n",
    "\n",
    "* Пример независимых событий — независимые подбрасывания монет. Если при первом броске выпал, к примеру, орёл, то это никак не повлияет на результат второго подбрасывания.\n",
    "\n",
    "* Пример зависимых событий — результаты извлечения разных игральных карт из одной и той же колоды. Когда первая карта вытягивается из колоды, в колоде остаётся меньше карт, поэтому результат влияет на вероятность вытягивания других карт.\n",
    "\n",
    "Давайте рассмотрим пример решения задачи на проверку зависимости и независимости событий ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Дано вероятностное пространство, которое определено следующим образом:*\n",
    "\n",
    "$\\Omega=\\{1,2,3,4,5,6\\}$\n",
    "\n",
    "*Причём появления разных чисел не равновероятны, а соответствуют следующим вероятностям:*\n",
    "\n",
    "$\\begin{array}{lll}P(1)=0.3 & P(3)=0.1 & P(5)=0.1 \\\\ P(2)=0.3 & P(4)=0.05 & P(6)=0.15\\end{array}$\n",
    "\n",
    "$\\begin{array}{lll}P(1)=0.3 & P(3)=0.1 & P(5)=0.1 \\\\ P(2)=0.3 & P(4)=0.05 & P(6)=0.15\\end{array}$\n",
    "\n",
    "*Необходимо проверить на независимость две пары событий:*\n",
    "\n",
    "$A = \\ \"нечётное \\ число$, $B = \\ \"число \\ меньше \\ 3\"$,\n",
    "\n",
    "$A = \\ \"нечётное \\ число\"$, $C = \\ \"число, \\ равное \\ 3 \\ или \\ 4\"$\n",
    "\n",
    "Сначала разберёмся с первой парой — найдём благоприятные исходы для каждого события и для их пересечения:\n",
    "\n",
    "$A=\\{1,3,5\\}, B=\\{1,2\\}$\n",
    "\n",
    "$A \\cap B=\\{1,3,5\\} \\cap\\{1,2\\}=\\{1\\}$\n",
    "\n",
    "Далее рассчитаем необходимые вероятности:\n",
    "\n",
    "$P(A \\cap B)=P(\\{1\\})=0.3$\n",
    "\n",
    "$P(A) \\cdot P(B)=P(\\{1,3,5\\}) \\cdot P(\\{1,2\\})=0.5 \\cdot 0.6=0.3$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем равенство:\n",
    "\n",
    "$P(A \\cap B)=P(A) \\cdot P(B)$\n",
    "\n",
    "Так как выполняется условие о том, что вероятность пересечения событий $A$ и $B$ совпадает с произведением вероятностей событий  и , то можно сделать вывод, что события $A$ и $B$ независимы.\n",
    "\n",
    "Теперь рассмотрим вторую пару событий.\n",
    "\n",
    "$P(A \\cap C)=P(\\{3\\})=0.1$\n",
    "\n",
    "$P(A) \\cdot P(C)=P(\\{1,3,5\\}) \\cdot P(\\{3,4\\})=0.5 \\cdot 0.15=0.075$\n",
    "\n",
    "Получаем, что равенство не выполнено:\n",
    "\n",
    "$P(A \\cap C) \\neq P(A) \\cdot P(C)$\n",
    "\n",
    "Это значит, что события $A$ и $C$ являются зависимыми."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Полная вероятность"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В этом юните мы познакомимся с вычислением **полной вероятности**.\n",
    "\n",
    "Прежде чем разобраться с тем, что это такое, необходимо вспомнить понятие **несовместных**, или взаимоисключающих событий, то есть таких, которые не могут произойти в одно и то же время. Если случится одно, другое не произойдёт.\n",
    "\n",
    "К примеру, если событие $A$ заключается в том, что сегодня выходной день, а событие $B$ — что будний, то данные события являются взаимоисключающими, так как не может быть, чтобы у человека был одновременно и рабочий день, и выходной. Также, например, не может одновременно выпасть нечётное и чётное число очков на кубике, покупатель не может одновременно купить товар и не купить его и т. д.\n",
    "\n",
    "Отсюда вытекает понятие **разбиения**.\n",
    "\n",
    "> **Разбиение вероятностного пространства** — это взаимоисключающие и совместно исчерпывающие события. Проще говоря, это события, которые не пересекаются (т. е. не имеют общих исходов), но в объединении дают все возможные исходы.\n",
    "\n",
    "Давайте рассмотрим **пример** разбиения вероятностного пространства ↓\n",
    "\n",
    "Пусть у нас есть собственная кондитерская, в которой мы продаём пирожные. Каждый клиент обычно покупает равновероятно от 1 до 6 пирожных (получается, что для каждого количества вероятность равна $\\frac{1}{6}$), то есть пространство всех элементарных исходов задаётся следующим образом:\n",
    "\n",
    "$\\Omega=\\{1,2,3,4,5,6\\}$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим следующие события:\n",
    "\n",
    "$A=\\{1,2\\}, \\ B=\\{3\\}, \\ C=\\{4,5,6\\}$\n",
    "\n",
    "* $A$ — клиент купил одно или два пирожных;\n",
    "* $B$ — клиент купил три пирожных;\n",
    "* $C$ — клиент купил от четырёх до шести пирожных.\n",
    "\n",
    "Эти события являются взаимоисключающими, так как у них нет общих исходов:\n",
    "\n",
    "$A \\cap B=\\varnothing, B \\cap C=\\varnothing, A \\cap C=\\varnothing$\n",
    "\n",
    "При этом их объединение даёт все возможные элементарные исходы:\n",
    "\n",
    "$A \\cup B \\cup C=\\{1,2,3,4,5,6\\}=\\Omega$\n",
    "\n",
    "Получается, что эти события образуют разбиение вероятностного пространства.\n",
    "\n",
    "Рассмотрим ещё один **пример** в контексте истории с пирожными. Теперь события будут следующими:\n",
    "\n",
    "$A=\\{1,2\\}, \\ B=\\{3,4\\}, \\ C=\\{4,5,6\\}$\n",
    "\n",
    "Такой набор событий не будет образовывать разбиение, так как у событий есть общие исходы, а значит, они не являются взаимоисключающими:\n",
    "\n",
    "$B \\cap C=\\{4\\} \\neq \\varnothing$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем перейти к **формуле полной вероятности**, которая как раз основана на идее разбиения вероятностного пространства.\n",
    "\n",
    "Теорема полной вероятности очень полезна в случаях, когда мы ищем вероятность возникновения события, которое является суммой двух (или более) событий из разных частей разбиения.\n",
    "\n",
    "Чтобы идея была более понятной, рассмотрим её на примере: если мы хотим найти число пьющих кофе людей, то мы можем сделать это, сложив количество пьющих кофе мужчин и пьющих кофе женщин, если нам известны эти значения.\n",
    "\n",
    "Та же самая идея на языке вероятностей звучит следующим образом: вероятность, что случайно выбранный человек пьёт кофе, равна сумме вероятности, что человек пьёт кофе и является мужчиной, и вероятности, что человек пьет кофе и является женщиной.\n",
    "\n",
    "Искать вероятности отдельно для мужчин и женщин — часто более выгодная стратегия, так как обычно поиск более простых вероятностей (для отдельных элементарных исходов, а не для всего события сразу) намного проще.\n",
    "\n",
    "Давайте рассмотрим применение этой теоремы на примере, а уже после изучим её математическую формулировку ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы являетесь владельцем кафе и знаете, что в дни, когда нет дождя, вы получаете необходимую выручку с вероятностью $0.5$. Если в городе дождь, то люди скорее заказывают еду с доставкой и не приходят к вам в кафе — в такие дни вы получаете нужный доход с вероятностью $0.3$.\n",
    "\n",
    "На основе исторических данных известно, что в случайный день с вероятностью $0.6$ в городе нет дождя.\n",
    "\n",
    "Какова вероятность, что завтра вы получите необходимый доход?\n",
    "\n",
    "Давайте построим схему. У нас есть два варианта: нет дождя или есть дождь с вероятностями $0.6$ и $0.4$ ($1-0.6$) соответственно:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3515273c03aae4ab44ae26c6c7eca4a7/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_4_1.png)\n",
    "\n",
    "Мы знаем, что если дождя нет, то хорошая выручка будет с вероятностью $0.5$. Значит, плохая выручка тоже будет с вероятностью $0.5$:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/8000319baeb8ceda5173f38c4d0eca00/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_4_2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также мы знаем, что если идёт дождь, мы получим хорошую выручку с вероятностью $0,3$. Соответственно, плохая выручка у нас получается с вероятностью $1-0.3=0.7$:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/9446c797dfe172d1ad121c6405d9399f/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_4_3.png)\n",
    "\n",
    "Нас интересуют те комбинации событий, которые приводят к хорошей выручке:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/1922491f5590ca57bdba0e240f427fdf/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_4_4.png)\n",
    "\n",
    "То есть нам необходимо рассчитать вероятности для двух событий:\n",
    "\n",
    "* когда нет дождя и получилась хорошая выручка;\n",
    "* когда есть дождь и получилась хорошая выручка."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из предыдущего юнита вы наверняка помните соотношение, которым мы сейчас и воспользуемся:\n",
    "\n",
    "$$P(A \\ и \\ B)=P(A) \\times P(B \\mid A)$$\n",
    "\n",
    "* Рассчитаем вероятность для «ветки» с отсутствием дождя: $0.6 * 0.5 = 0.3$.\n",
    "* Рассчитаем вероятность для «ветки» с дождём: $0.4 * 0.3 = 0.12$.\n",
    "\n",
    "Так как нам подойдёт либо первый вариант, либо второй, то по правилу сложения мы просто складываем эти вероятности:\n",
    "\n",
    "$0.3 + 0.12 = 0.42$\n",
    "\n",
    "Итак, мы вычислили вероятность получить хорошую выручку — она равна $0.42$ — и решили задачу с помощью теоремы полной вероятности.\n",
    "\n",
    "Наверняка алгоритм решения вам уже понятен, но всё же приведём математическую формулировку теоремы:\n",
    "\n",
    "$$P(B)=\\sum_{i=1}^{n} P\\left(B \\mid A_{i}\\right) P\\left(A_{i}\\right)$$\n",
    "\n",
    "В данной формуле:\n",
    "\n",
    "* $P(B)$ — вероятность наступления события $B$;\n",
    "\n",
    "* $P(A_i)$ — вероятность наступления события $A_i$, которое является условием для события $B$;\n",
    "\n",
    "* $P(B|A_i)$ — условная вероятность наступления события $$, если известно, что произошло событие $A_i$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберём ещё несколько примеров решения задач на использование данной формулы ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что два производителя, А и Б, поставляют двигатели для гоночных автомобилей Formula 1 со следующими характеристиками:\n",
    "\n",
    "* 99 % двигателей завода А служат более 5 000 км;\n",
    "* завод B производит двигатели, которые прослужат более 5 000 км с вероятностью 95 %;\n",
    "* 70 % двигателей произведены заводом А, а остальные — заводом Б.\n",
    "\n",
    "Найдите вероятность того, что двигатель прослужит более 5 000 км.\n",
    "\n",
    "Попробуем снова нарисовать дерево вероятностей, которым мы пользовались в предыдущем примере:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/57cc6ee47cf35dc977c6322951673177/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_4_5.png)\n",
    "\n",
    "Так как нас интересуют те события, где двигатель прослужит более 5 000 км, то нужные нам ветви будут следующими:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/38b09ca6e6f05221da7f608c62587c83/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_4_6.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось только выполнить необходимые расчёты:\n",
    "\n",
    "* Вероятность, что двигатель с завода А и прослужит более 5 000 км, равна $0.7*0.99 = 0.693$.\n",
    "* Вероятность, что двигатель с завода Б и прослужит более 5 000 км, равна $0.3*0.95 =  0.285$.\n",
    "\n",
    "Осталось вычислить итоговую вероятность:\n",
    "\n",
    "$0.693 + 0.285 = 0.978$\n",
    "\n",
    "Получается, что случайно выбранный двигатель прослужит более 5 000 км с вероятностью $0.978$.\n",
    "\n",
    "Разумеется, мы могли бы найти ответ не с помощью дерева вероятностей, а уже с использованием  формулы полной вероятности. Тогда решение выглядело бы следующим образом:\n",
    "\n",
    "$P(двигатель \\ прослужит \\ более \\ 5000 \\ км) =$\n",
    "\n",
    "$P(двигатель \\ прослужит \\ более \\ 5000 \\ км \\ \\mid \\ двигатель \\ с \\ завода \\ А) * P(двигатель \\ с \\ завода \\ А) +$\n",
    "\n",
    "$+  P(двигатель \\ прослужит \\ более \\ 5000 \\ км \\ \\mid \\ двигатель \\ с \\ завода \\ Б) * P(двигатель \\ с \\ завода \\ Б) =$\n",
    "\n",
    "$0.7*0.99 + 0.3*0.95 = 0.693 +   0.285 = 0.978$\n",
    "\n",
    "Давайте рассмотрим ещё один **пример** (более сложный), но его решение уже распишем строго по формуле и не будем пользоваться деревом вероятностей ↓\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 % клиентов постоянно жалуются на сервис — из них 60 % уйдут. Ещё 10 % клиентов периодически жалуются на сервис — из них 10 % уйдут. Оставшиеся 89 % клиентов никогда не жалуются на сервис — из них 3 % уйдут.\n",
    "\n",
    "Найдите:\n",
    "\n",
    "* долю уходящих клиентов каждого типа от всех клиентов;\n",
    "* долю уходящих клиентов от всех клиентов;\n",
    "* долю каждого типа клиентов среди уходящих клиентов.\n",
    "\n",
    "Для удобства введём обозначения событий:\n",
    "\n",
    "* CUC — Constantly Unhappy Customer (постоянно недовольный);\n",
    "* DC — Dissatisfied Customer (недовольный);\n",
    "* CSC — Completely Satisfied Customer (довольный);\n",
    "* C — Churn (ушедший).\n",
    "\n",
    "Рассчитаем вероятности для событий, которые касаются характеристик клиентов:\n",
    "\n",
    "* вероятность того, что клиент постоянно недоволен: $P(C U C)=0.01$;\n",
    "* вероятность того, что клиент периодически недоволен: $P(D C)=0.1$;\n",
    "* вероятность того, что клиент доволен: $P(C S C)=0.89$.\n",
    "\n",
    "Теперь рассчитаем условные вероятности, которые характеризуют то, с какой вероятностью уйдёт клиент в зависимости от его типа:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* вероятность того, что клиент уйдёт, если он постоянно недоволен: $P(C \\mid C U C)=0.60$;\n",
    "* вероятность того, что клиент уйдёт, если он периодически недоволен: $P(C \\mid D C)=0.1$;\n",
    "* вероятность того, что клиент уйдёт, если он доволен: $P(C \\mid C S C)=0.03$.\n",
    "\n",
    "Рассчитаем доли (вероятности)  уходящих клиентов для каждого типа клиентов:\n",
    "\n",
    "* вероятность того, что клиент постоянно недоволен и уйдёт: $P(C \\cap C U C) = P(C \\mid CUC) \\cdot P(CUC) = 0.6 \\cdot 0.01 = 0.006$;\n",
    "* вероятность того, что клиент периодически недоволен и уйдёт: $P(C \\cap D C)=0.1 \\cdot 0.1 = 0.01$;\n",
    "* вероятность того, что доволен и уйдёт: $P(C \\cap C S C)=0.03 \\cdot 0.89 = 0.0267$.\n",
    "\n",
    "Теперь мы можем найти долю уходящих клиентов для всех их клиентов. По сути, доля — это и есть вероятность, так что просто применяем формулу полной вероятности:\n",
    "\n",
    "$P(C) = P(C \\mid CUC) \\cdot P(CUC) + P(C \\mid DC) \\cdot P(DC) + P(C \\mid CSC) \\cdot P(CSC) =$\n",
    "\n",
    "$= 0.01 \\cdot 0.6 + 0.1 \\cdot 0.1 + 0.89 \\cdot 0.03 = 0.0427$\n",
    "\n",
    "Также мы можем найти долю каждого типа клиентов среди уходящих клиентов:\n",
    "\n",
    "* доля постоянно недовольных клиентов среди ушедших: $P(CUC \\mid C) = \\frac{P(C \\cap CUC)}{P(C)} = \\frac{0.006}{0.0427} \\approx 0.14$;\n",
    "* доля периодически недовольных клиентов среди ушедших: $P(DC \\mid C) = \\frac{P(C \\cap DC)}{P(C)} = \\frac{0.01}{0.0427} \\approx 0.23$;\n",
    "* доля довольных клиентов среди ушедших: $P(CSC \\mid C) = \\frac{P(C \\cap CSC)}{P(C)} = \\frac{0.0267}{0.0427} \\approx 0.63$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Теорема Байеса"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Возможно, вы сталкивались с тем, что в ответ на какие-то ваши запросы в интернете выводится не ровно то, что вы ищете, а какие-то ассоциации с поисковым запросом. Например, если вы будете искать информацию про красную и синюю таблетку, то, скорее всего, в выдаче результатов у вас будет фильм «Матрица». Как поисковая система смогла «понять», что вам может быть нужен именно этот фильм? Разумеется, она его не смотрела и не умеет намеренно искать по кратким содержаниям. Однако, имея багаж знаний в виде множества других поисковых запросов, она знает, что вы вероятнее всего ищете. Эта вероятность вычисляется с помощью **теоремы (формулы) Байеса**.\n",
    "\n",
    "Теорема Байеса используется во многих методах машинного обучения, например в спам-фильтрах, чтобы определять, является ли электронное письмо спамом, учитывая слова в этом письме. Кроме того, многие задачи в статистике, например, связанные с интерпретацией медицинских результатов, лучше всего описываются с использованием теоремы Байеса.\n",
    "\n",
    "**Идея теоремы Байеса** заключается в том, что если у нас есть одна условная вероятность (например, $B$ при условии $A$), а мы хотим найти другую ($A$ при условии $B$), то мы можем получить из одной вероятности другую по определённому правилу. \n",
    "\n",
    "Если мы посмотрим на две условных вероятности, то увидим, что они связаны общим числителем:\n",
    "\n",
    "$P(B \\mid A) = \\frac{P(A \\cap B)}{P(A)}$, \n",
    "\n",
    "$P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это значит, что их можно без проблем выразить друг через друга.\n",
    "\n",
    "Давайте попробуем сделать это, то есть, по сути, попробуем **доказать теорему Байеса** ↓\n",
    "\n",
    "Она записывается следующим образом:\n",
    "\n",
    "$$P(A \\mid B)=\\frac{P(B \\mid A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "Запомним это, а теперь запишем формулу для вероятности события $B$ при условии $A$:\n",
    "\n",
    "$$P(B \\mid A)=\\frac{P(A \\cap B)}{P(A)}$$\n",
    "\n",
    "Если мы домножим в этой формуле обе части на $P(A)$, то она примет следующий вид:\n",
    "\n",
    "$$P(A \\cap B)=P(B \\mid A) \\cdot P(A)$$\n",
    "\n",
    "Теперь возьмём формулу условной вероятности для вероятности события $A$ при условии $B$\n",
    "\n",
    "$$P(A \\mid B)=\\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "и подставим в числитель правой части соотношение, выведенное ранее:\n",
    "\n",
    "$$P(A \\cap B)=P(B \\mid A) \\cdot P(A)$$\n",
    "\n",
    "Тогда получим:\n",
    "\n",
    "$$P(A \\mid B)=\\frac{P(B \\mid A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "Это ровно то, что нам нужно. Таким образом, мы только что доказали теорему Байеса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте на конкретном примере рассмотрим, как теорема Байеса помогает в решении задач. Начнём с уже известного по предыдущему юниту кейса про отток клиентов ↓\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1 % клиентов постоянно жалуется на сервис — из них 60 % уйдут. Ещё 10 % клиентов периодически жалуются на сервис — из них 10 % уйдут. Оставшиеся 89 % клиентов никогда не жалуются на сервис — из них 3 % уйдут.*\n",
    "\n",
    "*Найдите долю довольных клиентов среди ушедших.*\n",
    "\n",
    "Мы, зная информацию об ушедших клиентах среди довольных, можем выразить долю довольных клиентов среди ушедших, то есть получить одну условную вероятность через другую.\n",
    "\n",
    "Для начала найдём общую долю оттока клиентов. В целом, мы уже делали это в предыдущем юните, так что просто повторим уже известные вам вычисления:\n",
    "\n",
    "$P(C) = P(C \\mid CUC) \\cdot P(CUC) + P(C \\mid DC) \\cdot P(DC) + P(C \\mid CSC) \\cdot P(CSC) =$\n",
    "\n",
    "$= 0.01 \\cdot 0.6 + 0.1 \\cdot 0.1 + 0.89 \\cdot 0.03 = 0.0427$\n",
    "\n",
    "Если мы говорим про отток довольных клиентов, то в общей формуле можно найти слагаемое, в котором вычисляется именно доля оттока довольных клиентов:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/7b35ae0ed8cddab9add92e87f61a9a72/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_5_1.png)\n",
    "\n",
    "Тогда получаем, что доля довольных клиентов среди всех ушедших равна отношению доли ушедших и довольных клиентов к доле всех ушедших:\n",
    "\n",
    "$P(C S C \\mid C)=\\frac{P(C \\mid C S C) P(C S C)}{P(C)}=\\frac{0.03 \\cdot 0.89}{0.0427} \\approx 0.63$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Получается, что больше всего денег мы потеряем из-за тех клиентов, которые были довольны и не жаловались. Это является контринтуитивным предположением, но теория вероятности в том числе нужна для того, чтобы выстраивать стратегию принятия решений на основе чётких доказательств, ведь наше мышление и интуиция часто нас подводят.\n",
    "\n",
    "Теперь нам необходимо ввести два новых понятия: **априорные вероятности** и **апостериорные вероятности**.\n",
    "\n",
    "> Под **априорными вероятностями** понимаются безусловные вероятности, то есть они фиксированы и не зависят от вероятностей наступления других событий.\n",
    "\n",
    "В нашей задаче это следующие вероятности:\n",
    "\n",
    "* $P(CUC)= 0.01$;\n",
    "* $P(DC) = 0.1$;\n",
    "* $P(CSC) = 0.89$.\n",
    "\n",
    "> **Апостериорные вероятности**, напротив, обусловлены вероятностями наступления каких-то ещё случайных событий.\n",
    "\n",
    "В рамках нашей задачи такой вероятностью является $P(CSC \\mid C)$.\n",
    "\n",
    "Очень часто формулу Байеса применяют для оценки результатов медицинских тестов, поэтому давайте рассмотрим ещё один **пример** в таком контексте ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Редкое заболевание встречается у 1 % людей. Тест ошибочно показывает наличие болезни у здоровых людей с вероятностью 2 % и ошибочно показывает отсутствие болезни у больных с вероятностью 3 %.*\n",
    "\n",
    "*Найдите вероятность, что человек на самом деле болен, если тест на заболевание положителен.*\n",
    "\n",
    "Введём обозначения, чтобы было проще записывать решение:\n",
    "\n",
    "* S — sick (болен);\n",
    "* H — healthy (здоров);\n",
    "* P — positive (тест на заболевание положительный);\n",
    "* N — negative (тест на заболевание отрицательный).\n",
    "\n",
    "Теперь найдём априорные вероятности для событий «человек болен» и «человек здоров»:\n",
    "\n",
    "$P(S) = 0.01$\n",
    "\n",
    "$P(H) = 0.99$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также найдём условные вероятности, которые понадобятся нам при решении задачи:\n",
    "\n",
    "* вероятность того, что тест показывает положительный результат, если человек здоров: $P(P \\mid H) = 0.02$;\n",
    "* вероятность того, что тест показывает отрицательный результат, если человек здоров: $P(N \\mid H) = 0.98$;\n",
    "* вероятность того, что тест показывает положительный результат, если человек болен: $P(P \\mid S) = 0.97$;\n",
    "* вероятность того, что тест показывает отрицательный результат, если человек болен: $P(N \\mid S) = 0.03$.\n",
    "\n",
    "Для удобства обобщим эти результаты в виде таблицы:\n",
    "\n",
    "-|Положительный тест|Отрицательный тест\n",
    "-|-|-\n",
    "Здоров|0.02|0.98\n",
    "Болен|0.97|0.03\n",
    "\n",
    "Пока человек не прошёл медицинский тест, мы считаем его здоровым с вероятностью 99 % и больным — с вероятностью 1 %. Но когда он пройдет тест, у нас появится новая информация и вероятности изменятся.\n",
    "\n",
    "Давайте найдём полную вероятность, которая складывается из вероятности двух событий:\n",
    "\n",
    "* человек болен и получил положительный тест: $P(P \\mid S) P(S)$;\n",
    "* человек здоров и получил положительный тест: $P(P \\mid H) P(H)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем результат:\n",
    "\n",
    "$P(P)=P(P \\mid S) P(S)+P(P \\mid H) P(H)=0.97 \\cdot 0.01+0.02 \\cdot 0.99=0.0295$\n",
    "\n",
    "Теперь вычислим условную вероятность, пользуясь формулой Байеса:\n",
    "\n",
    "$P(S \\mid P)=\\frac{P(P \\mid S) P(S)}{P(P)}=\\frac{0.97 \\cdot 0.01}{0.0295} \\approx 0.3288$\n",
    "\n",
    "→ Итак, вероятность того, что человек болен, если получил положительный тест, — всего . Задумайтесь об этом: этот результат, как и в прошлом примере, может показаться противоречащим интуиции. Это в очередной раз подчёркивает мощность теоремы Байеса: она помогает определять истинные значения вероятностей там, где невозможно оценить их просто по интуиции или из соображений здравого смысла. Теорема Байеса позволяет принимать безошибочные решения на основе вероятностных данных.\n",
    "\n",
    "Рассмотрим ещё один **пример** для закрепления понимания этой теоремы ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ваш друг работает в сервисе, который ремонтирует колёсные диски производителей Seagull и Tosha (диски других производителей сервис в ремонт не принимает). Друг утверждает, что примерно 60 % дисков в ремонте — диски Seagull и лишь 40 % — диски Tosha. На основе этой статистики он не рекомендует вам покупать Seagull. Вы провели небольшое исследование и сделали вывод, что доля Seagull на рынке составляет 40 %, а доля Tosha — 23 %.*\n",
    "\n",
    "*Какие диски действительно чаще ломаются?*\n",
    "\n",
    "Как и ранее, начнём с того, что введём удобные обозначения:\n",
    "\n",
    "* S — диск произведён компанией Seagull;\n",
    "* T — диск произведён компанией Tosha;\n",
    "* B — broken (сломанный диск, сданный на ремонт в сервис).\n",
    "\n",
    "Теперь рассчитаем вероятность того, что случайный диск произведён компанией Seagull. Для этого разделим её долю рынка на суммарную долю двух компаний:\n",
    "\n",
    "$P(S)=\\frac{0.40}{0.40+0.23} \\approx 0.635$\n",
    "\n",
    "Аналогичные вычисления сделаем для компании Tosha:\n",
    "\n",
    "$P(T)=\\frac{0.23}{0.40+0.23} \\approx 0.365$\n",
    "\n",
    "Также нам известны условные вероятности. Вероятность того, что диск произведён компанией Seagull, если он сдан в ремонт:\n",
    "\n",
    "$P(S \\mid B)=0.6$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятность того, что производителем является Tosha, если диск сдан в ремонт:\n",
    "\n",
    "$P(T \\mid B)=0.4$\n",
    "\n",
    "Теперь давайте выразим обратные условные вероятности. Однако у нас есть проблема — нам неизвестна вероятность поломки диска. Обозначим её за неизвестную  и выразим через  по теореме Байеса необходимые вероятности.\n",
    "\n",
    "* вероятность поломки диска, если это производитель — Seagull: $P(B \\mid S)=\\frac{P(S \\mid B) P(B)}{P(S)}=\\frac{0.6 \\cdot p}{0.635} \\approx 0.9448819 \\cdot p$;\n",
    "* вероятность поломки диска, если это производитель — Tosha: $P(B \\mid T)=\\frac{P(T \\mid B) P(B)}{P(T)}=\\frac{0.4 \\cdot p}{0.365} \\approx 1.09589 \\cdot p$.\n",
    "\n",
    "Мы видим, что второе значение больше первого. Чтобы узнать, во сколько раз, поделим вторую вероятность на первую:\n",
    "\n",
    "$\\frac{P(B \\mid T)}{P(B \\mid S)} = \\frac{1.09589 \\cdot p}{0.9448819 \\cdot p} \\approx 1.16$\n",
    "\n",
    "→ Получаем, что вероятность поломки для дисков Tosha в 1.16 раз (или на 16 %) больше, чем вероятность поломки для дисков Seagull. Значит, рекомендация нашего друга неверна и более надёжным вариантом является купить диск компании Seagull.\n",
    "\n",
    "Итак, мы разобрались с тем, как решать задачи с применением теоремы Байеса. На этом наше знакомство с ней не заканчивается: далее вас ждёт краткая экскурсия в **байесовские методы**, а в следующем юните вы потренируетесь в реализации методов классификации, основанных на этой теореме."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## БАЙЕСОВСКАЯ СТАТИСТИКА\n",
    "\n",
    "При разборе задач этого юнита вы могли заметить, что теорема Байеса помогает «пересчитывать» априорные вероятности с учётом каких-то дополнительных обстоятельств. Эта её особенность настолько полезна и часто применима, что дала начало новой ветви математической статистики — **байесовской статистике**.\n",
    "\n",
    "Байесовская статистика предоставляет математические инструменты для обновления представлений о случайных событиях в свете появления новых данных или свидетельств об этих событиях.\n",
    "\n",
    "Это контрастирует с другой формой статистического вывода, известной как **классическая**, или **частотная статистика**, которая предполагает, что вероятности — это частота конкретных случайных событий, происходящих в длительном цикле повторяющихся испытаний.\n",
    "\n",
    "В частотной статистике мы считаем, что случайную величину можно оценить, только если будет проведено большое количество экспериментов. В байесовском подходе случайная величина — это детерминированный процесс, который можно просчитать даже без экспериментов, если знать значение всех влияющих на процесс факторов. Конечно же, узнать их невозможно, поэтому мы будем корректировать оценки после каждой новой порции информации.\n",
    "\n",
    "Например, если нас попросят найти вероятность того, что в день $X$ будет конец света, частотная статистика потребует много раз прожить день $X$, посчитать процент дней, когда конец света случился, и после этого даст оценку вероятности. Байесовский же подход сможет обойтись и без экспериментов, если удастся просчитать все факторы, влияющие на конец света."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы лучше понять различие, рассмотрим ещё один **пример** ↓\n",
    "\n",
    "Пусть у нас есть монетка, которая является «шулерской», то есть одна из её сторон выпадает чаще другой. Рассмотрим различия в оценке вероятностей выпадения решки и орла в классической парадигме и при байесовском подходе.\n",
    "\n",
    "В классическом подходе вероятность получить орёл при подбрасывании «нечестной» монеты — долгосрочная относительная частота появления орла при повторных подбрасываниях монеты. Таким образом, чем больше мы подбрасываем монету, тем больше число выпавших орлов в процентах от общего количества подбрасываний стремится к «истинной» вероятности того, что на монете выпадет орёл.\n",
    "\n",
    "Философия байесовской статистики такова, что до первого подбрасывания мы считаем, что монета «честная», то есть по умолчанию используем априорную вероятность.\n",
    "\n",
    "Допустим, после нескольких бросков монета постоянно выпадает орлом. Тогда мы модифицируем исходную вероятность: добавляем информацию о том, что у нас выпало несколько орлов подряд, и постепенно наши оценки «честности» монеты меняются. Таким образом, предыдущее убеждение о «честности» монеты модифицируется. Апостериорное убеждение в итоге будет сильно изменено по сравнению с априорным убеждением о «честной» монете."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, здесь возникнет вопрос: какая разница, какой подход использовать, если результат будет один и тот же?\n",
    "\n",
    "На самом деле, это не совсем так. Для некоторых задач результаты при применении классической теории вероятности и байесовского подхода получаются разные. Мы не станем их разбирать в силу серьёзной математической сложности, однако если это вас не пугает, то предлагаем вам ознакомиться с ними в дополнительных материалах ↓\n",
    "\n",
    "**ДОПОЛНИТЕЛЬНО**\n",
    "\n",
    "Байесовская статистика, по сути, представляет собой отдельную философию внутри теории вероятностей и математической статистики. Это очень объёмная тема, чтобы говорить о ней сейчас даже с минимальными подробностями. Если она вас заинтересовала, рекомендуем прочитать следующие статьи:\n",
    "\n",
    "* [\"Are you a Bayesian or a Frequentist? (Or Bayesian Statistics 101)\" (о различиях частотной и байесовской статистики)](https://www.behind-the-enemy-lines.com/2008/01/are-you-bayesian-or-frequentist-or.html)\n",
    "* [«Скажи Байесу \"да!\". Забудь про интуицию — просто думай, как Байес завещал»](https://nauka.tass.ru/sci/6815287)\n",
    "* [«Частотный и байесовский подходы к A/B тестированию: подробное сравнение | Урок 7»](https://vc.ru/u/1174886-koptelnya/411293-chastotnyy-i-bayesovskiy-podhody-k-a-b-testirovaniyu-podrobnoe-sravnenie-urok-7)\n",
    "\n",
    "Так как теорема Байеса и байесовская статистика являются важной частью теории вероятностей, вопросы о них могут встретиться вам на собеседовании. Попробуйте ответить на следующие:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как теорема Байеса и байесовская статистика являются важной частью теории вероятностей, вопросы о них могут встретиться вам на собеседовании. Попробуйте ответить на следующие:\n",
    "\n",
    "* Чем байесовская статистика отличается от классического частотного подхода?\n",
    "* Что такое апостериорная вероятность?\n",
    "\n",
    "Но особо важный материал ждёт вас в следующем юните: обратите внимание на все тонкости алгоритма наивного байесовского классификатора, так как вас с большой вероятностью могут попросить рассказать о принципе его работы и о том, в чём же заключается его наивность."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Наивный байесовский классификатор: практика"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Мы уже изучили все основные правила и алгоритмы, с помощью которых можно вычислять вероятности, и познакомились с теоремой Байеса — пожалуй, самой известной теоремой во всей теории вероятностей. Её популярность обусловлена тем, что она активно используется в различных алгоритмах машинного обучения. Мы разберём один из таких алгоритмов — **наивный байесовский классификатор.**\n",
    "\n",
    "> **Наивный байесовский классификатор (НБК, англ. Naive Bayes Classifier, NBC)** решает задачу классификации объектов по типам. Большим преимуществом этого алгоритма является его простота, как идейная, так и алгоритмическая.\n",
    "\n",
    "Наивная байесовская классификация — это достаточно простой вероятностный алгоритм, основанный на том, что все признаки модели независимы.\n",
    "\n",
    "Если, например, мы говорим про задачу классификации спам-писем и обычных писем, то в этом контексте мы считаем, что каждое слово в сообщении не зависит от всех других слов, то есть каждое слово мы учитываем, не обращая внимания на контекст.\n",
    "\n",
    "Алгоритм классификации выдаёт вероятность того, является письмо спамом или нет, основываясь на наборе слов в письме. Расчёт этой вероятности основан на формуле Байеса, а компоненты формулы рассчитываются на основе частот слов во всём наборе сообщений.\n",
    "\n",
    "Давайте разберёмся, как работает алгоритм ↓\n",
    "\n",
    "Прежде всего, возьмём формулу Байеса и применим её к нашей задаче:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(Спам \\mid w_1, w_2, ..., w_n) \\propto P(Спам) \\cdot \\prod^n_{i = 1} P(w_i \\mid Спам)$\n",
    "\n",
    "Вероятность того, что письмо является спамом при условии, что в нём есть определённые слова (которые мы обозначили), пропорциональна произведению двух значений:\n",
    "\n",
    "* вероятности получения спама в целом (по сути, это доля спама в выборке);\n",
    "* произведения вероятностей, что в письме есть некоторое слово , если письмо является спамом, для всех слов выборки.\n",
    "\n",
    "Давайте разберёмся с этим подробнее. Для каждого слова в сообщении мы рассчитываем вероятность того, что это слово окажется в спаме. В рамках нашей задачи рассматриваем следующие значения:\n",
    "\n",
    "$P(spam)$ — вероятность, что случайно взятое письмо будет спамом (также это доля спам-сообщений в нашем наборе данных);\n",
    "\n",
    "$P(w_i \\mid spam)$ — вероятность того, что в сообщении будет определённое слово, если это письмо является спамом.\n",
    "\n",
    "По той же логике можем определить:\n",
    "\n",
    "$P(not \\ spam)$ — доля сообщений, которые не являются спамом;\n",
    "\n",
    "$P(w_i \\mid not \\ spam)$ — вероятность того, что в сообщении будет определённое слово, если это письмо не является спамом.\n",
    "\n",
    "Теперь необходимо понять, как рассчитать вероятности каждого слова. Для этого в алгоритме используется следующая формула:\n",
    "\n",
    "$P\\left(w_{i} \\mid S p a m\\right)=\\frac{N_{w_{i} \\mid S p a m}+\\alpha}{N_{S p a m}+\\alpha \\cdot N_{\\text {Vocabulary }}}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой формуле:\n",
    "\n",
    "$N_{Vocabulary}$ — количество уникальных слов во всём наборе данных;\n",
    "\n",
    "$N_{Spam}$ — общее количество слов в спам-сообщениях;\n",
    "\n",
    "$N_{w_i \\mid Spam}$ — количество повторов слова во всех спам-сообщениях;\n",
    "\n",
    "$\\alpha$ — коэффициент для случаев, когда слово в сообщении отсутствует в нашем наборе данных.\n",
    "\n",
    "Кратко это можно объяснить так: вероятность того, что это слово встретится в спам сообщении, — это частота этого слова в «спамовой части» нашего набора данных (но с добавлением «сглаживания», чтобы учитывать ситуации, когда попадаются слова, которых не было в обучающей выборке).\n",
    "\n",
    "Также эта же формула (но с другими значениями) верна для вероятности того, что слово принадлежит не спам-сообщениям.\n",
    "\n",
    "[→ Скачать ноутбук из скринкаста](https://lms.skillfactory.ru/assets/courseware/v1/c32769d02b0e5c938c98756bdc08de13/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/%D0%9D%D0%B0%D0%B8%D0%B2%D0%BD%D1%8B%D0%B9%D0%91%D0%B0%D0%B9%D0%B5%D1%81.ipynb)\n",
    "\n",
    "[→ Скачать файл данных](https://lms.skillfactory.ru/assets/courseware/v1/a589990d37e715d1e53600022ef89a5d/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/SMSSpamCollection.zip)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы увидели, как работает алгоритм байесовского классификатора в контексте решения прикладной задачи, и теперь самое время рассмотреть его плюсы и минусы:\n",
    "\n",
    "### Плюсы:\n",
    "\n",
    "* Алгоритм не только прост для понимания и реализации, но также даёт достаточно точные оценки и быстро работает.\n",
    "* Наивный Байес имеет низкую вычислительную сложность.\n",
    "Он может эффективно работать с большим набором данных.\n",
    "* Его можно использовать с задачами прогнозирования нескольких классов, то есть в задачах мультиклассовой классификации.\n",
    "* Если выполнено предположение о независимости признаков, то НБК даёт более высокое качество, чем логистическая регрессия и многие другие модели.\n",
    "\n",
    "### Минусы:\n",
    "\n",
    "* Предположение о независимых признаках не выполняется на практике практически никогда.\n",
    "* Если нет обучающего набора данных для какого-то из классов, это приводит к нулевой апостериорной вероятности и модель не может сделать прогноза.\n",
    "\n",
    "Разумеется, при решении реальных задач мы не будем каждый раз самостоятельно прописывать алгоритм  — можно использовать готовые методы. В библиотеке sklearn есть несколько байесовских классификаторов:\n",
    "\n",
    "[GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) — самый простой вариант, работает с непрерывными признаками;  \n",
    "[MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)  — работает с категориальными признаками, текстами и несбалансированными выборками;  \n",
    "[ComplementNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html) — улучшенная версия MultinomialNB, стабильно показывает более высокое качество в задачах классификации текстов;  \n",
    "[BernoulliNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html) — версия для работы с бинарными признаками;  \n",
    "[CategoricalNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB) — работает с категориальными признаками, предполагает кодировку данных через OrdinalEncoder.\n",
    "\n",
    "С точки зрения кода они используются ровно так же, как и те алгоритмы, которые вам уже известны, например логистическая регрессия. Сейчас вы сможете убедиться в этом на практике ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПРАКТИКА\n",
    "\n",
    "Мы посмотрели, как можно полностью самостоятельно, «с нуля» реализовать байесовский классификатор с довольно высокой точностью.\n",
    "\n",
    "Теперь вашей задачей будет реализовать классификацию спам-сообщений уже с использованием готовых функций.\n",
    "\n",
    "Вам будет необходимо не только решить задачу, но и верно оформить её решение перед отправкой на проверку.\n",
    "\n",
    "Пожалуйста, оформите ваше решение в соответствии со следующими требованиями:\n",
    "\n",
    "* Решение оформляется только в Jupyter Notebook.\n",
    "* Решение оформляется в соответствии с [ноутбуком-шаблоном](https://lms.skillfactory.ru/assets/courseware/v1/49faf12fce4677b70fe36c67a9b2bd3f/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/SGA_unit6_NBC.ipynb).\n",
    "* Каждое задание выполняется в отдельной ячейке, выделенной под задание (в шаблоне они помечены как «ваш код здесь»). Не создавайте дополнительные ячейки.\n",
    "* Решение не должно содержать функции из библиотек для машинного обучения и оптимизации, кроме тех ячеек, где это указано явным образом.\n",
    "* Код должен быть читаемым и понятным: имена переменных и функций отражают их сущность, отсутствуют многострочные конструкции и условия.\n",
    "    * [Пользуйтесь руководством PEP-8](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DST-3.0+28FEB2021/jump_to_id/f84d01ce76a54f75a45d5d2a97627a01).\n",
    "* Обратите внимание, что в ноутбуке-шаблоне есть промежуточные проверяемые действия, не отражённые в заданиях ниже.\n",
    "\n",
    "Для решения задачи мы будем использовать набор данных с e-mail-сообщениями. Его можно скачать [здесь](https://lms.skillfactory.ru/assets/courseware/v1/3d8cb71ded70aa8810ac73aa43e85eac/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/spam_or_not_spam.zip).\n",
    "\n",
    "**КРИТЕРИИ ОЦЕНИВАНИЯ**\n",
    "\n",
    "Вам предстоит выполнить пять заданий, каждое из которых состоит из более мелких подзадач.\n",
    "\n",
    "Для каждой задачи в ноутбуке-шаблоне указано количество баллов, которое можно получить за её выполнение.\n",
    "\n",
    "Максимальное количество баллов — 11."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Случайная величина и её характеристики"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущих юнитах этого модуля мы узнали основные понятия и теоремы из теории вероятностей. Теперь пришло время поближе познакомиться со **случайными величинами**, которые мы уже упоминали в начале модуля, но пока не уделили им должного внимания.\n",
    "\n",
    "Напомним, что случайные величины отличаются от детерминированных наличием **неопределённости**.\n",
    "\n",
    "Например, если мы решаем уравнение $x^2-1=0$, то корень уравнения является детерминированной величиной, то есть значения всегда будут одними и теми же. Если мы подбрасываем игральный кубик, то число очков на нём — случайная величина, ведь она каждый раз будет разной, и мы никогда не сможем точно её предсказать.\n",
    "\n",
    "Случайные величины удобно вводить для численного описания результатов случайного эксперимента и случайных событий, например для описания количества продаж в магазине на этой неделе или количества новых клиентов в компании за предыдущий год.\n",
    "\n",
    "Случайные величины бывают двух видов — **дискретные** и **непрерывные**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bеличина является **дискретной**, если может принимать значения только из конечного или счётного (бесконечного) множества.\n",
    "\n",
    "Например, если мы описываем количество клиентов, то это, разумеется, дискретная величина, так как оно может быть выражено только целым неотрицательным числом (не может быть 1.5 клиента или 0.2 клиента).\n",
    "\n",
    "Если величина может принимать любое значение, то она является **непрерывной**.\n",
    "\n",
    "К примеру, человеческий рост — это непрерывная величина, так как может принимать бесконечно много значений: 170 см, 170 см и 1 см, 170 см 1 см и 0001 мм и так далее.\n",
    "\n",
    "Про непрерывные величины мы поговорим чуть позже, а пока сконцентрируемся на дискретных случайных величинах.\n",
    "\n",
    "Дискретные случайные величины используются в машинном обучении, например в задачах классификации, а также при моделировании распределения слов в тексте для обработки естественного языка — вы встречались с этим в предыдущем юните, когда делали векторизацию текста.\n",
    "\n",
    "Для того чтобы задать дискретную случайную величину, необходимо задать список её значений и список вероятностей каждого из этих значений.       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, пусть у нас есть величина , принимающая два разных значения, $0$ и $1$:\n",
    "\n",
    "Также есть вероятности того, что случайная величина примет эти значения:\n",
    "\n",
    "$P \\in \\left (\\frac{1}{4}, \\frac{3}{4}  \\right )$\n",
    "\n",
    "Тогда для того чтобы задать эту дискретную величину, достаточно лишь описать, какие значения она может принимать и с какими вероятностями:\n",
    "\n",
    "$P(X = 0) = \\frac{1}{4}$\n",
    "\n",
    "$P(X = 1) = \\frac{3}{4}$\n",
    "\n",
    "В более классическом варианте это оформляется в табличном виде:\n",
    "\n",
    "\n",
    "X|0|1\n",
    "-|-|-\n",
    "P|1/4|3/4\n",
    "\n",
    "\n",
    "Предположим, что нам необходимо задать дискретную случайную величину, равную количеству выпавших орлов при подбрасывании одной или двух идеальных монеток."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для одной монетки мы получим таблицу, расположенную ниже. В первой строке прописано количество выпавших орлов, во второй — то, что выпало на монетке, а в третьей — вероятность соответствующего события.\n",
    "\n",
    "X|0|1\n",
    "-|-|-\n",
    "Исходы|Р|О\n",
    "P|0.5|0.5\n",
    "\n",
    "Немного усложним задачу. Теперь будем рассматривать количество орлов при подбрасывании двух монеток. В таком случае получим следующее распределение:\n",
    "\n",
    "Y|0|1|2\n",
    "-|-|-|-\n",
    "Исходы|РP|ОР или РО|ОО\n",
    "P|0.25|0.5|0.25\n",
    "\n",
    "Здесь представлены не все одинаковые вероятности по той причине, что всего возможны четыре равновероятных исхода (РР, ОР, РО, ОО), но второй и третий (ОР и РО) объединяются здесь в одно событие (выпал один орёл), и их вероятности складываются.\n",
    "\n",
    "Усложним этот пример ещё больше. Предположим, что вы играете в игру, в которой подбрасываются две идеальные монетки. Если выпало две решки, вы проиграли и платите противнику 100 рублей. Если выпало два орла, вы победили и противник платит вам 100 рублей. Если выпали один орёл и одна решка, объявляется ничья и никто ничего не платит. Необходимо задать случайную величину, равную вашему выигрышу."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся таблицей, которую мы составили, чтобы задать случайную величину количества выпавших орлов. Однако теперь добавим, что если выпадает ноль орлов, то выигрыш равняется -100, если один орёл — 0, а если два орла — 100:\n",
    "\n",
    "Y|0|1|2\n",
    "-|-|-|-\n",
    "Исходы|РP|ОР или РО|ОО\n",
    "P|0.25|0.5|0.25\n",
    "\n",
    "→\n",
    "\n",
    "Profit|-100|0|100\n",
    "-|-|-|-\n",
    "Y|0|1|2\n",
    "Исходы|РP|ОР или РО|ОО\n",
    "P|0.25|0.5|0.25\n",
    "\n",
    "В целом, мы могли бы опустить часть таблицы и определить случайную величину более компактным способом:\n",
    "\n",
    "Profit|-100|0|100\n",
    "-|-|-|-\n",
    "P|0.25|0.5|0.25\n",
    "\n",
    "При работе с дискретными распределениями обязательно следите за корректностью составляемых моделей.\n",
    "\n",
    "В начале этого модуля мы говорили, что сумма вероятностей для событий, которые заключают в себе все возможные исходы, равна 1. То же самое правило работает и здесь. К примеру, следующие две модели являются некорректными, так как в первой суммарная вероятность больше единицы, а во второй — меньше:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X|0|1|4\n",
    "-|-|-|-\n",
    "P|0.5|0.5|0.5\n",
    "Y|0|1|4\n",
    "P|0.3|0.2|0.1\n",
    "\n",
    "Разумеется, нам интересно не просто уметь определять случайную величину, но также находить вероятности для значений по распределению.\n",
    "\n",
    "Возвращаясь к примеру с выбрасыванием разного количество орлов, попробуем найти следующие вероятности:\n",
    "\n",
    "Для удобства ещё раз возьмём таблицу, которую оформляли ранее:\n",
    "\n",
    "Y|0|1|2\n",
    "-|-|-|-\n",
    "Исходы|РP|ОР или РО|ОО\n",
    "P|0.25|0.5|0.25\n",
    "\n",
    "Для начала найдём вероятность .\n",
    "\n",
    "Если нам подходят все случаи, где выпадает один орёл или более, то тогда нас интересует следующая часть распределения:\n",
    "\n",
    "1|2\n",
    "-|-\n",
    "ОР или РО|ОО\n",
    "0.5|0.25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Складываем вероятности для всех подходящих нам значений:\n",
    "\n",
    "$P(Y \\geq 1) = P(Y = 1 \\ или \\ Y = 2) = 0.25 + 0.5 = 0.75$\n",
    "\n",
    "Для поиска вероятности $$P(Y=1) нам подходит только одно значение: $P(Y=1)=0.5$.\n",
    "\n",
    "Для того чтобы найти условную вероятность, мы можем просто воспользоваться формулой, с которой вы познакомились в одним из предыдущих юнитов:\n",
    "\n",
    "$P(Y=1 \\mid Y \\geq 1)=\\frac{P(Y=1 \\cap Y \\geq 1)}{P(Y \\geq 1)}=\\frac{P(Y=1)}{P(Y \\geq 1)}=\\frac{0.5}{0.75}=\\frac{2}{3}$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Мы научились определять случайную величину и задавать её распределение. Пока мы можем только оценивать для неё какие-то отдельные вероятности. Однако представим, что у нас есть распределение выручки в магазине за год. Значение за каждый день нас не особенно интересует (очевидно, что где-то доход будет больше, а где-то — меньше), да и изучать весь набор вероятностей распределения, чтобы разобраться в тенденциях и спрогнозировать прибыль на будущее, может быть довольно долго и трудозатратно. Нам хотелось бы описать распределение всех значений кратко и ёмко. Например, «В среднем ожидаемая выручка в этом магазине составляет 50 тысяч рублей в день, причём в разные дни колебания значений не очень большие, в районе 10 тысяч».  Для того чтобы это сделать, нам понадобится научиться искать два значения: **математическое ожидание** (оно будет помогать найти центр распределения) и **дисперсию** (с её помощью мы будем оценивать разброс значений).\n",
    "\n",
    "> **Математическое ожидание случайной величины** — это взвешенное среднее значений этой величины с учётом вероятностей. Чаще всего оно обозначается буквой $E$ (от англ. Expectation), ещё можно общепринятое обозначение — $\\mu$ (греческая буква «мю»). В русскоязычной литературе принято обозначать математическое ожидание буквой $M$.\n",
    "\n",
    "Оно вычисляется по следующей формуле:\n",
    "\n",
    "$$E(X) = \\mu_X = \\sum x_i \\cdot P(X = x_i)$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь:\n",
    "\n",
    "$i$ — индекс переменной;\n",
    "$x_i$ — значение случайной величины с индексом ;\n",
    "$P(X=x_i)$ — вероятность того, что случайная величина принимает значение .\n",
    "\n",
    "Давайте разберём пример ↓\n",
    "\n",
    "Вы — владелец магазина одежды. За год у вас накопилось много разных очень близких друг к другу по значениям номиналов чека. Это огромная, сложная для восприятия таблица данных, по которой ничего не ясно.\n",
    "\n",
    "Номер|Номинал чека|Как часто встречается\n",
    "-|-|-\n",
    "1|2400|0.0001\n",
    "2|2401|0.0011\n",
    "3|2408.5|0.00012\n",
    "...|...|...\n",
    "2000|3850.7|0.0009\n",
    "\n",
    "Найдите «типичный» чек магазина."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Математическое ожидание покажет информацию о среднем чеке. Мы можем рассчитать его следующим образом (на месте многоточия мы предполагаем наличие ещё 1996 произведений):\n",
    "\n",
    "$E(X) = 2400 \\cdot 0.0001 + 2401 \\cdot 0.0011 + ... +  3850 \\cdot 0.0009 = 3400$\n",
    "\n",
    "Таким образом вы поймёте, что «типичный» чек вашего магазина составляет, к примеру, 3400  рублей.\n",
    "\n",
    "→ Важно отметить, что некоторые значения в ряде распределения могут намного сильнее других влиять на значение математического ожидания.\n",
    "\n",
    "Например, в распределении ниже точка 2 будет очень сильно «притягивать» в свою сторону математическое ожидание за счёт большого значения вероятности:\n",
    "\n",
    "X|1|2|4|5\n",
    "-|-|-|-|-\n",
    "P|0.05|0.8|0.1|0.05\n",
    "\n",
    "$E(X) = \\sum_{i=1}^{4} x_{i} \\cdot P\\left(X=x_{i}\\right)=1 \\cdot 0.05+2 \\cdot 0.8+4 \\cdot 0.1+5 \\cdot 0.05=2.3$\n",
    "\n",
    "Однако в этом нет ничего страшного. Раз значение 2 встречается с вероятностью $0.8$, это значит, что оно является типичным для распределения, и совершенно верно, что мы получаем математическое ожидание, близкое к нему.\n",
    "\n",
    "Также значение случайной величины может сильно влиять на математическое ожидание, если очень отличается от других значений в распределении. В примере ниже такой точкой является 1000:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W|1|2|4|5|1000\n",
    "-|-|-|-|-|-\n",
    "P|0.05|0.79|0.1|0.05|0.01\n",
    "\n",
    "$E(X) = \\sum^4_{i = 1} x_i \\cdot P(X = x_i) = 1 \\cdot 0.05 + 2 \\cdot 0.79 + 4 \\cdot 0.1 + 5 \\cdot 0.05 + 1000 \\cdot 0.01 = 12.28$\n",
    "\n",
    "Тут мы уже сталкиваемся с проблемой: по сути, 1000 здесь является выбросом, то есть влияние этой величины на математическое ожидание мешает нам получить релевантный показатель."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы посмотрели, как оценить математическое ожидание для величины. Но, чтобы корректно описывать ряд данных, также нужно уметь оценивать и разброс. \n",
    "\n",
    "Давайте на примере рассмотрим, почему это может быть полезно ↓\n",
    "\n",
    "Вы выбираете между акциями двух компаний, чтобы инвестировать в них.\n",
    "\n",
    "У обеих компаний средняя цена за акцию равна 100 долларов. Однако у первой компании цена была довольно стабильна весь год:\n",
    "\n",
    "Месяц|1|2|3|4|5|6|7|8|9|10|11|12\n",
    "-|-|-|-|-|-|-|-|-|-|-|-|-\n",
    "Цена|89|90|93|98|100|102|102|103|105|105|106|107\n",
    "\n",
    "У второй компании цена акции довольно сильно менялась:\n",
    "\n",
    "Месяц|1|2|3|4|5|6|7|8|9|10|11|12\n",
    "-|-|-|-|-|-|-|-|-|-|-|-|-\n",
    "Цена|56|122|56|85|160|98|102|218|23|180|42|58\n",
    "\n",
    "Математическое ожидание для обеих акций одинаково, однако за счёт разброса можно оценить, что первая акция довольно надёжна, а вторая — нет. \n",
    "\n",
    "Для того чтобы численно оценить разброс, используют **дисперсию**. Она вычисляется по следующей формуле:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$V(\\mathrm{X})=D(\\mathrm{X})=\\sigma_{X}^{2}=E\\left(\\mathrm{X}^{2}\\right)-(E(\\mathrm{X}))^{2}$$\n",
    "\n",
    "Дисперсию принято обозначать буквой $V$ (от англ. Variance) или буквой $D$. Иногда встречается обозначение $\\sigma^2_X$.\n",
    "\n",
    "→ Если внимательно посмотреть на формулу, можно увидеть, что для вычисления дисперсии приходится возводить значения в квадрат. Это очень неудобно для интерпретации, так как непонятно, как содержательно оценивать разброс в 100 рублей в квадрате или 15 метров в четвёртой степени. Поэтому на практике обычно используют не саму дисперсию, а корень из неё — **стандартное отклонение**. Оно обозначается греческой буквой  («сигма»).\n",
    "\n",
    "Давайте рассмотрим алгоритм вычисления дисперсии и стандартного отклонения на примере:\n",
    "\n",
    "X|-1|0|1|3\n",
    "-|-|-|-|-\n",
    "P|0.05|0.8|0.1|0.05\n",
    "\n",
    "Находим математическое ожидание:\n",
    "\n",
    "$E(X) = \\sum x_i \\cdot P(X = x_i) = -1 \\cdot 0.05 + 0 \\cdot 0.8 + 1 \\cdot 0.1 + 3 \\cdot 0.05 = 0.2$\n",
    "\n",
    "Теперь необходимо вычислить математическое ожидание для квадратов значений случайной величины:\n",
    "\n",
    "$E(X^2) = \\sum x_i^2 \\cdot P(X = x_i) = 1 \\cdot 0.05 + 0 \\cdot 0.8 + 1 \\cdot 0.1 + 9 \\cdot 0.05 = 0.6$\n",
    "\n",
    "Вычислим дисперсию:\n",
    "\n",
    "$$D(X)=E\\left(X^{2}\\right)-(E X)^{2}=0.6-0.2^{2}=0.6-0.04=0.56$$\n",
    "\n",
    "Осталось найти стандартное отклонение:\n",
    "\n",
    "$$\\sigma_{X}=\\sqrt{D X}=\\sqrt{0.56} \\approx 0.74833$$\n",
    "\n",
    "Дисперсия, как и математическое ожидание, чувствительна к выбросам."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Дискретные распределения"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущем юните мы обсудили, что такое дискретная случайная величина, как её определить и какими характеристиками она описывается.\n",
    "\n",
    "В математике существует огромное количество различных распределений дискретных случайных величин, однако некоторые из них в теории вероятностей встречаются намного чаще остальных. Они хорошо изучены и называются **стандартными**. Это:\n",
    "\n",
    "* равномерное распределение;\n",
    "* распределение Бернулли;\n",
    "* биномиальное распределение;\n",
    "* распределение Пуассона.\n",
    "\n",
    "В этом юните мы познакомимся с этими распределениями, узнаем, где они встречаются и какими свойствами обладают.\n",
    "\n",
    "## РАВНОМЕРНОЕ РАСПРЕДЕЛЕНИЕ\n",
    "\n",
    "> **Равномерное распределение** — это распределение вероятностей, в качестве значений которого могут выступать любые целые числа от  до , а вероятности их появления одинаковы.\n",
    "\n",
    "Равномерное распределение применяется там, где нужны равновероятные модели."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, равномерное распределение пригодится, если для розыгрыша призов необходимо реализовать генератор случайных чисел, который будет с одинаковыми вероятностями выбирать натуральные числа в заданном интервале.\n",
    "\n",
    "Для равномерного распределения уже известны математическое ожидание\n",
    "\n",
    "$$EX = \\frac{N+1}{2}$$\n",
    "\n",
    "и стандартное отклонение\n",
    "\n",
    "$$\\sigma_X = \\sqrt{\\frac{N^2 - 1}{12}}$$\n",
    "\n",
    "Давайте посмотрим, как можно решить задачу на равномерное распределение. Вспомним пример в одном предыдущих из юнитов, где у нас была кондитерская, в которой покупатели приобретали от одного до шести пирожных с равными вероятностями:\n",
    "\n",
    "X|1|2|3|4|5|6\n",
    "-|-|-|-|-|-|-\n",
    "P|1/6|1/6|1/6|1/6|1/6|1/6\n",
    "\n",
    "Пусть нас просят найти ожидаемое количество купленных пирожных и стандартное отклонение при покупке в такой равновероятной модели.\n",
    "\n",
    "Мы могли бы воспользоваться формулами для этих метрик и рассчитать значения, как мы это делали в предыдущем юните. Но теперь мы знаем, что это равномерное распределение — в нём уже всё рассчитали за нас и вывели более краткие и удобные формулы. Поэтому просто подставляем значения и получаем ответы:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$EX = \\frac{N+1}{2} = \\frac{6+1}{2} = 3.5$\n",
    "\n",
    "$\\sigma_X = \\sqrt{\\frac{N^2 - 1}{12}} = \\sqrt{\\frac{6^2 - 1}{12}} \\approx 1.7$\n",
    "\n",
    "Получаем, что ожидаемое количество купленных пирожных — $3.5$ со стандартным отклонением в $1.7$.\n",
    "\n",
    "Также мы можем определить ряд распределения для дискретного равномерного распределения с помощью Python. Попробуем рассчитать вероятности для случайной величины, которая принимает значения от 1 включительно до 7 не включительно (собственно, это как раз пример с пирожными):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(1, 7)\n",
    "disc_uni_dist = randint(1,7)\n",
    "pmf = disc_uni_dist.pmf(x)\n",
    "print(pmf)\n",
    "\n",
    "# Получаем вероятности для каждого из шести значений:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также мы можем найти кумулятивную вероятность для распределения, то есть для каждого $x_i$ вероятность того, что случайная величина примет значение $x_i$ или меньше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16666667 0.33333333 0.5        0.66666667 0.83333333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "cdf = disc_uni_dist.cdf(x)\n",
    "print(cdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем с помощью функций Python решить другую задачу.\n",
    "\n",
    "Вы участвуете в розыгрыше бесплатного места на новый курс по Data Science. Вы знаете, что участников 250.\n",
    "\n",
    "Какова вероятность, что на курс попадёт кто-то из первых пятидесяти зарегистрировавшихся?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(1, 251)\n",
    "disc_uni_dist = randint(1,251)\n",
    "cdf = disc_uni_dist.cdf(x)\n",
    "print(cdf[49])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате получаем $0.2$ — это вероятность того, что выигрыш получит кто-то, чей порядковый номер — от 1 до 50. Разумеется, вероятность не зависит от самого номера, поэтому для номеров с 51 по 100 вероятность будет ровно такая же."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАСПРЕДЕЛЕНИЕ БЕРНУЛЛИ\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующее популярное распределение — это **распределение Бернулли**.\n",
    "\n",
    "> **Распределение Бернулли**, по сути, моделирует однократное подбрасывание «фальшивой» монеты. Это распределение вероятностей случайной величины, принимающей только два значения: 1 («успех») и 0 («неудача») с вероятностями $p$ и $1-p$ соответственно. Таким образом, распределение Бернулли **описывает события, имеющие ровно два исхода**. Такие события повсеместно встречаются в реальной жизни (выиграет команда чемпионат или нет, сдаст студент экзамен или провалит его, распознает алгоритм объект на фото или нет).\n",
    "\n",
    "Кроме того, что распределение Бернулли само по себе моделирует некоторые события из реальной жизни, оно также является фундаментом для других дискретных распределений, таких как биномиальное и геометрическое распределения.\n",
    "\n",
    "Основной параметр, определяющий это распределение, — $p$ (вероятность «успеха»).\n",
    "\n",
    "Распределение Бернулли формально описывается следующим образом:\n",
    "\n",
    "$$P(X = x)= \\left\\{\\begin{matrix} p & x = 1\\\\ 1 - p & x = 0 \\\\ \\end{matrix}\\right.$$\n",
    "\n",
    "Для этого распределения также известны математическое ожидание\n",
    "\n",
    "$$EX = 1 \\cdot p + 0 \\cdot (1-p) = p$$\n",
    "\n",
    "и стандартное отклонение\n",
    "\n",
    "$$\\sigma_X = \\sqrt{p(1-p)}$$\n",
    "\n",
    "Давайте разберём задачу на применение этого распределения ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы стреляете по мишени в тире. Вероятность попасть составляет . В случае успеха вы выиграете плюшевого медведя стоимостью 3000 рублей, а в случае промаха — не выиграете ничего. У вас есть только один выстрел.\n",
    "\n",
    "Какой должна быть стоимость билета, чтобы игра была честной, то есть чтобы цена билета равнялась ожидаемому выигрышу, а значит, не уводила в убыток продавца или вас при большом количестве выстрелов?\n",
    "\n",
    "Пусть случайная величина $X$ принимает значение $1$, если вы попали, и $0$, если промахнулись. Тогда ожидаемое число попаданий равно:\n",
    "\n",
    "$1*0.6+0*0.4 = 0.6$\n",
    "\n",
    "Ожидаемый выигрыш:\n",
    "\n",
    "$0.6*3000  + 0.4*0 = 1800$\n",
    "\n",
    "Получаем, что «справедливая» стоимость билета должна быть равна 1800 рублей.\n",
    "\n",
    "С помощью специальной функции Python можно смоделировать распределение Бернулли и, например, увидеть ожидаемое соотношение попаданий и промахов для решённой задачи, если будет сделано 500 выстрелов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import bernoulli\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "data = bernoulli.rvs(size=500,p=0.6)\n",
    "ax = sns.distplot(data,\n",
    "                  kde = False,\n",
    "                  color='dodgerblue')\n",
    "ax.set(xlabel='Значение случайной величины', ylabel='Частота');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно вывести количество неудач и попаданий в нашей модели:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 195]\n",
      " [  1 305]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(data, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили результат, близкий к ожидаемому, но с некоторыми погрешностями, что, разумеется, является нормальным."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## БИНОМИАЛЬНОЕ РАСПРЕДЕЛЕНИЕ\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторение нескольких независимых испытаний Бернулли называется **процессом Бернулли.** Результаты процесса Бернулли в свою очередь будут следовать биномиальному распределению.\n",
    "\n",
    "> **Биномиальным** называют распределение, при котором возможны только два исхода (успех или неудача, выигрыш или проигрыш) и вероятность успеха и неудачи одинакова для всех испытаний. Однако исходы не обязательно должны быть равновероятными, и каждое испытание не зависит от других.\n",
    "\n",
    "Параметры биномиального распределения — $n$ и $p$, где $n$ — общее количество испытаний, а $p$ — вероятность успеха в каждом испытании.\n",
    "\n",
    "Для того чтобы оценить вероятность, что среди $n$ испытаний будет $k$ успехов, используют следующую формулу:\n",
    "\n",
    "$$P(X = k) = \\begin{pmatrix} n \\\\ k \\end{pmatrix} p^k (1-p)^{n-k}$$\n",
    "\n",
    "$\\begin{pmatrix} n \\\\ k \\end{pmatrix}$ называют **биномиальным коэффициентом**, и он вычисляется следующим образом:\n",
    "\n",
    "$$\\frac{n!}{k! (n-k)!}$$\n",
    "\n",
    "Математическое ожидание биномиального распределения равно:\n",
    "\n",
    "$$EX=np$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартное отклонение:\n",
    "\n",
    "$$\\sigma_X = \\sqrt{np (1-p)}$$\n",
    "\n",
    "Давайте рассмотрим это распределение на примере ↓\n",
    "\n",
    "*Сравним две рекламных кампании: в одной конверсия составляет 2 %, но баннер увидит 100 000 пользователей, а в другой конверсия 40 %, но охват — всего 5 000 пользователей.*\n",
    "\n",
    "У нас есть следующая величина для количества пользователей, кликнувших по рекламе в первом случае:\n",
    "\n",
    "$X \\sim Binomial (n_X  = 100000, p_X = 0.02)$\n",
    "\n",
    "Случайная величина, отражающая количество пользователей, перешедших по рекламе, для второй рекламной кампании:\n",
    "\n",
    "$Y \\sim Binomial (n_Y = 5000, p_Y = 0.4)$\n",
    "\n",
    "Математическое ожидание и разброс для первой кампании:\n",
    "\n",
    "$EX = n_X p_X = 100000 \\cdot 0.02 = 2000$\n",
    "\n",
    "$\\sigma_X = \\sqrt{n_X p_X (1 - p_X)} = \\sqrt{100000 \\cdot 0.02 \\cdot 0.98} \\approx 44 \\ человека$\n",
    "\n",
    "\n",
    "Математическое ожидание и разброс для второй кампании:\n",
    "\n",
    "$EY = n_Y p_Y = 5000 \\cdot 0.4 = 2000$\n",
    "\n",
    "$\\sigma_Y = \\sqrt{n_Y p_Y (1 - p_Y)} = \\sqrt{5000 \\cdot 0.42 \\cdot 0.6} \\approx 34 \\ человека$\n",
    "\n",
    "Получаем, что ожидаемое количество кликов в обеих кампаниях одинаковое, так что более выгодным вариантом было бы выбрать менее затратную с финансовой точки зрения.\n",
    "\n",
    "Также можно сказать, что в первой стратегии разброс значений больше, а значит она менее стабильная.\n",
    "\n",
    "Рассмотрим ещё один пример ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Производитель гаджетов знает, что 20 % производимых им товаров — бракованные.*\n",
    "\n",
    "*Если он производит десять изделий в день, какова вероятность того, что не более двух из них бракованные?*\n",
    "\n",
    "Для решения этой задачи мы уже будем использовать формулу $P(X = k) = \\begin{pmatrix} n \\\\ k \\end{pmatrix} p^k (1-p)^{n-k}$ и вычислять вероятность того, что за день производится от восьми до десяти небракованных изделий:\n",
    "\n",
    "$\\begin{pmatrix} 10 \\\\ 8 \\end{pmatrix} (0.8)^8 (0.2)^2 + \\begin{pmatrix} 10 \\\\ 9 \\end{pmatrix} (0.8)^9 (0.2)^1 + \\begin{pmatrix} 10 \\\\ 10 \\end{pmatrix} (0.8)^{10} \\approx 0.678$\n",
    "\n",
    "Конечно, это выражение очень сложное с точки зрения вычислений, поэтому для нахождения ответа можно воспользоваться специальными функциями Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6777995264000004"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.binom.pmf(8,10,0.8) + \\\n",
    "scipy.stats.binom.pmf(9,10,0.8) + \\\n",
    "scipy.stats.binom.pmf(10,10,0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем, что с вероятностью $0.678$ будет производиться не более двух бракованных изделий в день.\n",
    "\n",
    "Как и для распределения Бернулли, для биномиального распределения можно смоделировать какое-то количество попыток и получить результат. Например, можно смоделировать биноминальное распределение с параметром p = 0.5 и количеством испытаний, равным 10, и реализовать 1000 попыток:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "\n",
    "x = random.binomial(n=10, p=0.5, size=10)\n",
    "\n",
    "sns.distplot(random.binomial(n=10, p=0.5, size=1000), hist=True, kde=False)\n",
    "plt.title('Значение случайной величины')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что чаще всего можно наблюдать пять успешных исходов.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАСПРЕДЕЛЕНИЕ ПУАССОНА\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Распределение Пуассона** — это дискретное распределение вероятностей числа событий, происходящих в данный период времени, с учётом среднего количества раз, когда событие происходит за этот период времени.\n",
    "\n",
    "Допустим, у нас есть ресторан быстрого питания, в который приходят  в среднем Три посетителя в минуту. Однако это всего лишь средний показатель — фактический показатель может варьироваться.\n",
    "\n",
    "Распределение Пуассона можно использовать для анализа вероятности различных событий, касающихся того, сколько клиентов придёт в ресторан. С его помощью можно рассчитать вероятность затишья (когда в течение какого-то периода времени не будет ни одного клиента), а также вероятность всплеска активности (когда в ресторан за минуту придут пять и более клиентов). Эта информация, в свою очередь, может помочь менеджеру спланировать рабочую нагрузку и график сотрудников, а также план по закупкам продуктов.\n",
    "\n",
    "Кроме использования в планировании нагрузки на персонал и производство, распределение Пуассона также используется в биологии (обнаружение мутаций), финансах (прогнозирование количества заявлений о банкротстве или просрочек кредитов), информационной безопасности (предсказание количества вирусных атак) и любой другой ситуации, в которой события не зависят от времени.\n",
    "\n",
    "В распределении Пуассона значение случайной величины может быть любым неотрицательным числом.  Случайная величина будет обладать следующими **характеристиками**:\n",
    "\n",
    "$$EX  = \\lambda$$\n",
    "\n",
    "$$\\sigma_X = \\sqrt{\\lambda},$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "где $\\lambda$ — ожидаемое число событий за период времени.\n",
    "\n",
    "Чтобы рассчитать вероятность того, что за период времени произойдёт $k$ событий, можно пользоваться следующей формулой:\n",
    "\n",
    "$$P(X = k) = \\frac{\\lambda^k e^{- \\lambda}}{k!}$$\n",
    "\n",
    "Давайте рассмотрим задачу ↓\n",
    "\n",
    "*Колл-центр получает в среднем 4.5 звонка за каждые пять минут. Каждый оператор может обработать один из этих вызовов в течение пяти минут. Если вызов получен, но оператор  не может его принять, то вызывающий абонент будет переведён в режим ожидания ответа.*\n",
    "\n",
    "*Если вызовы следуют распределению Пуассона, какое минимальное количество операторов необходимо колл-центру, чтобы вызовы удерживались в ожидании ответа не более 10 % времени?*\n",
    "\n",
    "Рассчитаем вероятности для всех возможных количеств операторов, пока не получим вероятность того, что вызов на удержании, которая будет меньше 10 %:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/448605de0326953c53753ad5de9752c8/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md7_8_3.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве параметра $\\lambda$ мы берём среднее количество звонков, так как это наше ожидаемое число событий, а в качестве $k$ — количество операторов, т. к. в данный период времени мы сможем принять столько звонков (один оператор принимает один звонок).\n",
    "\n",
    "Получаем, что колл-центру необходимо нанять на работу хотя бы семь операторов.\n",
    "\n",
    "Разумеется, все эти значения можно было бы рассчитать намного проще с использованием функций Python. Например, для пяти операторов мы бы получили следующее выражение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17082685848611215"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.distributions.poisson.pmf(5, 4.5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно смоделировать распределение Пуассона. Например, будем рассматривать 1000 реализаций случайной величины, у которой $\\lambda= 3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(random.poisson(lam=3, size=1000), kde=False)\n",
    "\n",
    "plt.xlabel('Значение случайной величины')\n",
    "plt.ylabel('Частота')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы рассмотрели самые известные дискретные распределения и познакомились с их свойствами. Данные распределения необходимо знать, так как они используются в различных статистических тестах и алгоритмах машинного обучения: например, распределение Пуассона задействовано в алгоритме решающих деревьев, а на биномиальном распределении основан статистический критерий, который может быть использован в анализе A/B-тестов. В следующем юните мы продолжим знакомство с популярными распределениями, однако это уже будут **непрерывные распределения**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## МОДЕЛИРОВАНИЕ РАСПРЕДЕЛЕНИЙ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "950b5653ccfc34417735dd321d006fd482b31f7611416c3d8236dc5b17587d3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

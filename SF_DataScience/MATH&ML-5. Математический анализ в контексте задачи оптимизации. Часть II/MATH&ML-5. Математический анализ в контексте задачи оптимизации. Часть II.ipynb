{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MATH&ML-5. Математический анализ в контексте задачи оптимизации. Часть II**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение. Функции нескольких переменных\n",
    "\n",
    "✍ В предыдущем модуле мы познакомились с функцией одной переменной, а также научились её исследовать. Разумеется, функции от одной переменной встречаются в различных задачах, однако на практике мы чаще всего имеем дело с функциями нескольких переменных, то есть, с такими, которые зависят от нескольких параметров. Например, если мы хотим предсказать цену на квартиру, то не будем предсказывать её только на основании площади — мы возьмём площадь, этаж, расстояние до метро, экологию и так далее.\n",
    "\n",
    "Интересно анализировать именно многомерные функции, ведь они помогают изучать окружающую действительность и прогнозировать интересующие показатели. Мы должны уметь исследовать многомерные функции так же, как и функции одной переменной. Это подводит нас к главной цели — задачам оптимизации. Именно во время решения задач оптимизации мы исследуем поведение функции, ищем для неё производные, находим минимумы и максимумы.\n",
    "\n",
    "Такая острая необходимость изучать и оптимизировать функции обусловлена тем, что практически все алгоритмы машинного обучения можно рассматривать как вариацию задачи оптимизации. К примеру:\n",
    "\n",
    "При решении задачи кредитного скоринга мы минимизируем ошибку модели и количество потерянных банком денег.\n",
    "При создании алгоритма для навигатора — минимизируем время, которое потратит пользователь на дорогу до работы.\n",
    "При работе в интернет-магазине — минимизируем количество сотрудников колл-центра, необходимых для обслуживания входящих заказов.\n",
    "При игре на бирже — максимизируем ожидаемую от продажи и покупки акций прибыль.\n",
    "Задача оптимизации может быть очень сложной, поскольку функция может иметь десятки, сотни, тысячи или даже миллионы входных данных, а структура функции неизвестна, часто недифференцируема и зашумлена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Существует функция $n$ переменных $x, y, z, ...$, если по некоторому закону каждой системе $n$ чисел ($x, y, z, ...$) из некоторого множества ставится в соответствие число $u$.\n",
    "\n",
    "То есть, по сути, относительно функции одной переменной меняется только то, что значение функции зависит от нескольких аргументов, а не от одного:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3edbff8f1e8b498b95e52399ed595a84/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_1_1.png)\n",
    "\n",
    "**Примечание**. Исключением из этого правила являются так называемые **векторнозначные функции**, для которых значением может быть не одно число, а несколько:\n",
    "\n",
    "$$f(x) = \\begin{bmatrix} cos(x) \\\\ sin(x)\\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции, зависящие от нескольких переменных, очень часто используются в разных научных областях и, конечно же, в Data Science.\n",
    "\n",
    "Например, вспомним метод классификации KNN. В чём его суть? Ее можно выразить фразой: «Скажи мне, кто твой друг, и я скажу, кто ты». Когда мы получаем обучающую выборку, мы располагаем все её объекты на координатной плоскости (или в пространстве) и затем выбираем количество ближайших соседей. Количество соседей является основным решающим фактором. Обычно это нечётное число. Когда $k=1$, алгоритм называется алгоритмом ближайших соседей. Это самый простой случай.\n",
    "\n",
    "Далее мы получаем новую точку, для которой неизвестен класс и необходимо предсказать метку. Мы отмечаем эту точку на плоскости (или в пространстве) и находим ближайшую к ней точку из обучающей выборки. Мы присваиваем нашей точке метку найденной ближайшей точки.\n",
    "\n",
    "На рисунке ниже точки одного класса обучающей выборки отмечены красными звёздочками, а точки другого — зелёными треугольниками. Мы получаем новую точку (знак вопроса) и видим, что ближе всего к ней расположена красная звёздочка. Значит, нашей новой точке мы присваиваем такой же класс.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/21ee3c1cf2dbd2141b42a4aeafd084b5/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_1_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что если $k$ больше 1? Предположим, что $P$ — это точка, для которой необходимо предсказать метку. Сначала вы находите $k$ ближайших к $P$ точек, а затем классифицируете точки большинством «голосов» $k$ соседей. Каждый объект «голосует» за свой класс, и класс с наибольшим количеством «голосов» принимается за прогноз. Чтобы найти ближайшие похожие точки, вычисляются расстояния между точками с использованием мер расстояния, таких как **евклидово расстояние**, **расстояние Хэмминга**, **расстояние Манхэттена** и **расстояние Минковского**. \n",
    "\n",
    "Итак, алгоритм KNN включает в себя следующие основные шаги:\n",
    "\n",
    "* Рассчитать расстояния до всех точек.\n",
    "* Найти ближайших соседей (точки с наименьшим расстоянием).\n",
    "* Посчитать «голоса» за классы.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3e509296d919af7871b34b42531cc66d/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_1_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как уже упоминалось, в этом алгоритме необходимо вычислять расстояние между двумя точками. Для этого используются различные функции нескольких переменных. Рассмотрим самую популярную — **евклидово расстояние**.\n",
    "\n",
    "Если говорить про евклидово расстояние для двух переменных, то его функция записывается как $f(x) = \\ \\sqrt{x^2 + y^2}$ и вычисляет корень из суммы квадратов $x$ и $y$. Это не что иное, как расстояние от точки $(x, y)$ до начала координат или длина вектора с координатами $(x, y)$. В качестве области определения для такой функции могут выступать **любые вещественные числа**, а её областью значений являются **все неотрицательные числа**.\n",
    "\n",
    "**Евклидово расстояние до начала координат:**\n",
    "\n",
    "$f(x,y) = \\sqrt{x^2 + y^2} = \\rho (M(x,y), O(0,0)) = \\left\\|\\overrightarrow{r} \\right\\|$\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3fc0a0d83572bc36e64a95b6d514d1f2/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_1_4.png)\n",
    "\n",
    "Также евклидово расстояние можно использовать для того, чтобы найти **расстояние между двумя точками**:\n",
    "\n",
    "$f(x,y) = \\sqrt{(x-1)^2 + (y-8)^2} = \\rho (M(x,y), A(1,8))$\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/e82a6a6f1586460b83b1b11779469ffd/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_1_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также функцией нескольких переменных является квадратичная функция потерь или, как её ещё называют, $L^2$-loss функция:\n",
    "\n",
    "$$L^2 LossFunction = \\sum_{i=1}^{n} (y_{true} - y_{predicted})^2$$\n",
    "\n",
    "Эта функция находит сумму квадратов всех ошибок, то есть, сумму квадратов разностей между реальным значением и значением, предсказанным моделью. Вы уже сталкивались с ней, так как она используется для построения и оценки качества в линейных регрессиях (в методе наименьших квадратов), а также для метода обратного распространения ошибки, применяемого в нейронных сетях.\n",
    "\n",
    "→ Так как эта функция выражает величину отклонения от истины, нам очень важно уметь её исследовать и находить её минимальное значение, чтобы достигать максимально точных предсказаний.\n",
    "\n",
    "В качестве аргументов функция $L^2$-loss принимает любые вещественные числа, а её значения могут быть любыми неотрицательными числами.\n",
    "\n",
    "Реальные|6|7|6|4|5|6|8\n",
    "-|-|-|-|-|-|-|-\n",
    "Предсказанные|6.4|7.1|5.9|4.2|5.2|6.2|7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.7\n",
    "\n",
    "Пусть у нас есть реальные и предсказанные значения в некоторой прогностической модели.\n",
    "\n",
    "Найдите значение метрики $L^2$-loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5500000000000004"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_true = np.array([6, 7, 6, 4, 5, 6, 8])\n",
    "y_predict = np.array([6.4, 7.1, 5.9, 4.2, 5.2, 6.2, 7.5])\n",
    "sum((y_true - y_predict)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним ещё одну функцию, с которой мы уже сталкивались в одномерном случае — это **сигмоида**. Сигмоида является функцией активации нейрона, которая используется при обучении нейронных сетей. Её вариацией является **логистическая функция**, используемая для решения задачи классификации. Если параметров много, то, разумеется, мы получаем её как функцию многих переменных:\n",
    "\n",
    "$E(y) = \\frac{\\alpha}{(1 + e^{-(\\beta_0 + \\beta_1 x_1  + \\beta_2 x_2)})}$\n",
    "\n",
    "Ровно так же, как и одномерная, она может принимать любые значения от 0 до 1 не включительно, и в качестве её аргументов могут выступать любые вещественные числа.\n",
    "\n",
    "Это лишь несколько примеров функций многих переменных, которые могут вам встретиться. Разумеется, в прикладных задачах вы будете сталкиваться с самыми разным вариантами зависимостей. Их спектр огромен. Например, вы уже умеете работать со случаями линейной зависимости — именно такой зависимостью является линейная регрессия. В логистической регрессии вы уже поработали с сигмоидальной функцией. Если вы будете предсказывать экономические процессы, то встретитесь с экспоненциальной зависимостью, а если решите предсказать временной ряд, вам понадобится логарифмическая функция. В зависимости от области знаний и ситуации вы будете постоянно работать с различными функциональными зависимостями — для любого кейса важно уметь найти подход.\n",
    "\n",
    "В следующих юнитах мы научимся исследовать и оптимизировать зависимости разных видов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЦЕЛИ НА ДАННЫЙ МОДУЛЬ:\n",
    "\n",
    "* научиться вычислять частные производные для функций нескольких переменных;\n",
    "* научиться находить безусловные и условные экстремумы для функции нескольких переменных;\n",
    "* узнать и понять основную терминологию, связанную с задачами оптимизации;\n",
    "* понять принцип работы градиентного спуска;\n",
    "* научиться применять градиентный спуск для решения практических задач.\n",
    "\n",
    "Для достижения каждой цели мы будем изучать всю необходимую теорию, рассматривать применимость данных знаний для решения задач из DS и закреплять полученные знания на практических заданиях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.9\n",
    "\n",
    "$f(x_1, x_2, x_3) = \\frac{1}{1 + e^{-2(x_1 + x_2 + x_3)}}$\n",
    "\n",
    "2. Вычислите $f(1,1,0)$. Ответ округлите до второго знака после точки-разделителя.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "round(1/(1+math.exp(-2*(1+1+0))),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. На вход нейрона $А$ в искуственной нейросети поступает три сигнала: $x_1, x_2 \\ и \\ x_3$. Выходной сигнал определяется сигмоидальной функцией активации $f(x_1, x_2, x_3)$. Какое число будет на выходе нейрона $А$, если на вход поступят $x_1=0.1$, $x_2=0.3$, $x_3=0.6$. Ответ округлите до второго знака после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/(1+math.exp(-2*(0.1 + 0.3 + 0.6))),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.10\n",
    "\n",
    "В модели линейной регрессии три наблюдения:\n",
    "\n",
    "$x_1 = 1, x_2 = 3, x_3 = 5$\n",
    "\n",
    "$y_1 = 2.1, y_2 = 2.9, y_3 = 4.1$\n",
    "\n",
    "$\\hat{y} = w_0 + w_1 x$\n",
    "\n",
    "3. Найдите значение $L^2$-loss функции, если $w_0 = 1, w_1 = 1$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.830000000000002"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 3, 5])\n",
    "y_true = np.array([2.1, 2.9, 4.1])\n",
    "w_0 = 1\n",
    "w_1 = 1\n",
    "y_pred = w_0 + w_1*x\n",
    "sum((y_true - y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Частные производные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Мы разобрались с тем, что такое функция многих переменных. Теперь давайте научимся дифференцировать такие функции, т. е. находить для них производные.\n",
    "\n",
    "> Производные для функций нескольких переменных называются **частными производными**.\n",
    "\n",
    "На данный момент в машинном обучении очень популярны и эффективны методы глубокого обучения, то есть методы, использующие нейронные сети. В обучении нейронных сетей есть два важных этапа:\n",
    "\n",
    "* **Прямое распространение ошибки** (на этом этапе нейронная сеть предсказывает результат).\n",
    "* **Обратное распространение ошибки** (на этом этапе нейронная сеть минимизирует разницу между реальным значением и предсказанным).\n",
    "\n",
    "Именно на втором шаге большую роль играют частные производные, так как позволяют узнать, каков вклад каждого признака в ошибку, и это даёт возможность точно настроить модель.\n",
    "\n",
    "Представьте, что вы решаете много задач по математике: в каких-то ваш ответ абсолютно верен, в каких-то вы ошиблись на сотые, а в каких-то ошибка довольно значительна. Если теперь посчитать, на сколько в среднем вы ошиблись, и вычесть эту среднюю ошибку из всех ответов, скорее всего, все ответы станут неверными. Почему так? Потому что необходимо рассматривать ответ в каждой задаче независимо от других."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же и в построении модели очень важно иметь возможность рассматривать вес каждого признака независимо и настраивать его отдельно — именно за это отвечают частные производные. Без них пришлось бы корректировать все параметры одновременно и одинаково, и мы бы никогда не получили нормальную модель. Если вы захотите углубиться в изучение различных архитектур нейронных сетей и в принцип их работы в целом, то обязательно столкнётесь с математической записью этого процесса, которая будет содержать в себе частные производные.\n",
    "\n",
    "Итак, мы обсудили, зачем нужны частные производные — теперь можно учиться их находить ↓\n",
    "\n",
    "Вероятно, вы помните, что обычную производную для функции одной переменной мы обозначали как $\\frac{df}{dx}$. Эту запись можно интерпретировать следующим образом: «Очень маленькое изменение значения функции $f$, произошедшее вследствие очень маленького изменения аргумента $x$».\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/a6773e7961da8f513fa54d616f79cbf9/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_1.png)\n",
    "\n",
    "Важно интуитивно понимать это обозначение, так как оно поможет нам проще разобраться с понятием частных производных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте перейдём к функциям нескольких переменных и начнём с **функции двух переменных**. Например, с такой:\n",
    "\n",
    "$f(x,y) = x^2 - 2xy$\n",
    "\n",
    "Ничто не мешает нам написать такое же выражение $\\frac{df}{dx}$, которое и в этом случае можно будет интерпретировать абсолютно так же: «Очень маленькое изменение значения функции $f$, произошедшее вследствие очень маленького изменения аргумента $x$». Но тут появляется нюанс: существование аргумента $y$. Теперь у данных, к которым применяется функция, несколько измерений, а значит изменения могут происходить в нескольких направлениях: то есть мы можем поменять не только $x$, но и немного поменять $y$, вследствие чего значение функции также изменится и мы получим другую производную: $\\frac{df}{dy}$.\n",
    "\n",
    "Разберём пример дифференцирования следующей функции:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3e329fb52790f34b1d59dadf2dd670ba/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_2.png)\n",
    "\n",
    "Предположим, мы хотим посчитать производную для этой функции в точке $(3;2)$. Механизм этого действия будет ровно такой же, как и с одномерной функцией.\n",
    "\n",
    "Вспомним, что производная характеризует скорость изменения одной величины при изменении другой.\n",
    "\n",
    "Найдём производную по $x$ или, проще говоря, скорость изменения функции: если $x$ изменяется, а $y$ остаётся на месте, то есть, например, если мы перемещаемся из точки $(3;2)$ в точку $(3.01;2)$. Так как $y$ не меняется, мы могли бы сразу заменить его значение в функции на константное:\n",
    "\n",
    "$x^2 \\cdot 2^3 = x^2 \\cdot 8$\n",
    "\n",
    "Теперь мы можем найти производную так, как будто это функция одной переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разумеется, необязательно искать производные в определённых точках — мы можем, как и в случае с одномерными функциями, находить значения производных в общем виде.\n",
    "\n",
    "Можно сказать, что мы ищем производную для функции $f(x,y) = x^2 y^3$ именно по $x$. Таким образом, значение функции будет меняться вследствие изменения значения $x$, а значение переменной $y$ будет оставаться прежним. Раз значение $y$ не будет изменяться, мы можем воспринимать его как константу.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/d74a288758a4708aef915412e76b87af/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_3.png)\n",
    "\n",
    "Иногда для того, чтобы подчеркнуть, что это именно многомерная функция, используют следующую запись:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/d33f93ae53a9e23cd55fb5ae42c0747c/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_4.png)\n",
    "\n",
    "Есть ли разница в записи между $\\frac{d}{dx}$ и $\\frac{\\partial}{\\partial x}$? На самом деле нет, хотя если быть очень педантичными, то можно сказать, что первый вариант используется скорее для функции одной переменной, а второй — для функций нескольких переменных. Но в литературе вы можете встретить оба варианта, и их стоит воспринимать одинаково.\n",
    "\n",
    "Также вы можете встретить (в том числе и в наших юнитах) следующие общепринятые обозначения:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lms.skillfactory.ru/assets/courseware/v1/ae8e4e20225c7bf3d4410ccfbc8ace01/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_5.png)\n",
    "\n",
    "Это можно прочитать как «производная от функции $f$ по $x$» или «производная от функции $f$ по $y$» (в зависимости от переменной). Вне зависимости от формы записи, читаются они одинаково, и обе являются верными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, для вывода понятия частной производной можно использовать **геометрическую интерпретацию**. В предыдущем модуле мы уже выяснили, что значение производной в точке равняется тангенсу угла наклона касательной, проведённой в этой точке к графику функции. Но график функции многих переменных — это поверхность, поэтому у неё таких касательных — целая касательная плоскость. Получается, что у функции есть по касательной для каждого направления, а значит и по своей частной производной, так как внутри плоскости можно провести множество касательных.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/dbf7658e9ffb1da9e5479473f45bdb8b/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_6.png)\n",
    "\n",
    "Из всех направлений можно выбрать **каноничные** — параллельные координатным осям. Для нас это будет оптимальным решением, так как мы хотим рассмотреть изменение функции только в зависимости от изменения одной из переменных (например, только от $x$ или только от $y$). И если мы, к примеру, берём направление, параллельное оси абсцисс, в таком случае мы фиксируем координату по оси ординат (т. е. воспринимаем её как константу — она одинакова в каждой точке прямой, параллельной оси x). Можно варьировать значение $x$. Так мы и поступим и посмотрим, как меняется функция вдоль оси x. На рисунке ниже это изменение изображено красной кривой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lms.skillfactory.ru/assets/courseware/v1/ad320ef1043b970541a480795283afea/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_7.png)\n",
    "\n",
    "Отношение приращения вдоль красной кривой к приращению $x$ — и есть значение частной производной по $x$:\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x} \\approx \\frac{f(x_0 + \\Delta x, y_0) - f(x_0, y_0)}{\\Delta x}$$\n",
    "\n",
    "Теперь из всей касательной плоскости можно найти прямую, соответствующую этой красной линии. Тангенс её наклона будет равен частной производной по $x$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, можно сказать, что **алгоритм поиска частной производной** аналогичен алгоритму поиска обычной производной для одномерного случая.\n",
    "\n",
    "Пусть дана функция. Чтобы найти частную производную по переменной $x_i$:\n",
    "\n",
    "* Фиксируем все переменные, кроме $x_i$.\n",
    "* Считаем приращение функции при изменении только этой переменной.\n",
    "* Делим приращение из пункта 2 на приращение нашей переменной.\n",
    "* Уменьшаем $\\Delta x_i$ и получаем $\\frac{df}{dx_i}$.\n",
    "\n",
    "В пункте 1 этого алгоритма указано, что мы фиксируем все переменные, кроме одной. Несмотря на то что в разобранных примерах мы рассматривали функции, зависящие от двух аргументов, ровно таким же образом мы можем найти частные производные и для функций трёх, четырёх и более переменных. Такую функцию мы рассмотрим чуть позже.\n",
    "\n",
    "Разберём ещё несколько примеров нахождения частных производных ↓\n",
    "\n",
    "**Пример № 1**\n",
    "\n",
    "*Найти обе частные производные для функции $f(x,y) = cos(x^2 y) + y^3$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала найдём производную по $x$ — $f'_x$.\n",
    "\n",
    "Фиксируем  как константу и дифференцируем:\n",
    "\n",
    "$f'(x) = (cos(x^2 y))'_x + (y^3)'_x = -sin(x^2 y) \\cdot (x^2 y)'_x + 0 =$\n",
    "\n",
    "$= -sin(x^2 y) \\cdot 2xy = -2xy \\cdot sin(x^2 y)$\n",
    "\n",
    "Повторим то же самое для $y$:\n",
    "\n",
    "$f'(y) = (cos(x^2 y))'_y + (y^3)'_y = -sin(x^2 y) \\cdot (x^2 y)'_y + 3y^2 =$\n",
    "\n",
    "$= -sin(x^2 y) \\cdot x^2 + 3y^2 = -x^2 \\cdot sin(x^2 y) + 3y^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример № 2**\n",
    "\n",
    "*Найти обе частные производные для функции $f(x,y) = e^{x^2 + y^2}$.*\n",
    "\n",
    "Найдём частную производную по $x$:\n",
    "\n",
    "$f'(x) = (e^{x^2 + y^2})'_x = e^{x^2 + y^2} \\cdot (x^2 + y^2)'_x = e^{x^2 + y^2} \\cdot 2x$\n",
    "\n",
    "Найдём частную производную по $y$:\n",
    "\n",
    "$f'(y) = (e^{x^2 + y^2})'_y = e^{x^2 + y^2} \\cdot (x^2 + y^2)'_y = e^{x^2 + y^2} \\cdot 2y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример № 3**\n",
    "\n",
    "*Найти обе частные производные для функции $f(x,y) = \\frac{1}{xy}$.*\n",
    "\n",
    "Найдём частную производную по $x$:\n",
    "\n",
    "$f'(x) = \\left ( \\frac{1}{xy} \\right )'_x = \\left ( \\frac{1}{y} \\cdot x^{-1} \\right )'_x = - \\frac{1}{y} \\cdot x^{-2} = - \\frac{1}{x^2 y}$\n",
    "\n",
    "Найдём частную производную по $y$:\n",
    "\n",
    "$f'(x) = \\left ( \\frac{1}{xy} \\right )'_y = \\left ( \\frac{1}{y} \\cdot x^{-1} \\right )'_y = - \\frac{1}{x} \\cdot y^{-2} = - \\frac{1}{y^2 x}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример № 4**\n",
    "\n",
    "*Найти все частные производные для функции $t(x,y,z) = xe^y + ye^z$.*\n",
    "\n",
    "Найдём частную производную по $x$:\n",
    "\n",
    "$t'_x = (xe^y + ye^z)'_x = (x \\cdot e^y)'_x + (y \\cdot e^z)'_x =$\n",
    "\n",
    "$= (x)'_x \\cdot e^y + x \\cdot (e^y)'_x = 1 \\cdot e^y + x \\cdot 0 = e^y$\n",
    "\n",
    "Найдём частную производную по $y$:\n",
    "\n",
    "$t'_y = (x \\cdot e^y + y \\cdot e^z)'_y = (x \\cdot e^y)'_y + (y \\cdot e^z)'_y =$\n",
    "\n",
    "$= x \\cdot (e^y)'_y + e^z \\cdot (y)'_y = x \\cdot e^y + e^z$\n",
    "\n",
    "Наконец, дифференцируем функцию по $z$:\n",
    "\n",
    "$t'_z = (x \\cdot e^y + y^z)'_z = (x \\cdot e^y)'_z + (y \\cdot e^z)'_z =$\n",
    "\n",
    "$= 0 + y \\cdot (e^z)'_z = y \\cdot e^z$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же, по аналогии с одномерными функциями, мы можем найти и вторые частные производные.\n",
    "\n",
    "Для вторых производных используются следующие обозначения:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/94b5f6c44479ce540638e25a76da763a/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_8.png)\n",
    "\n",
    "Также могут использоваться такие вариации:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/42b90a0b6192ca68dd82618f50a243b0/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_9.png)\n",
    "\n",
    "Рассмотрим пример вычисления всех вторых частных производных для функции $f(x,y) = sin(x) y^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала вычислим первые частные производные по $x$ и по $y$:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/4d87f68d02066a3999aa3b14ebab2cbf/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_10.png)\n",
    "\n",
    "Теперь для каждой из двух частных производных возьмём ещё по две частных производных, чтобы получить все четыре возможных частных производных:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/20a8cb6745d65690c9df4977bdc0d3ae/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_11.png)\n",
    "\n",
    "Можно заметить, что **значения смешанных производных** (когда ищем производную сначала по одной переменной, а затем — по другой) **совпадают**. Это свойство очень поможет нам при поиске минимумов и максимумов функции, так как сильно упростит расчёты: получается, что для функции с двумя переменными нужно вычислить не четыре производных, а только три. Уже в следующем юните вы сможете по достоинству оценить, как это упростит вам жизнь и сократит длительность вычислений.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5f884a606d6bff003f75b99d1a387d93/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/MATHML_md5_2_12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры, которые мы разбирали выше, подразумевали, что переменные, от которых зависит наша функция, являются независимыми. Но что, если они тоже зависят друг от друга?\n",
    "\n",
    "В таком случае мы можем найти **полную производную**, то есть производную, в которой учитываются зависимости между переменными. По сути, задача поиска полной производной сводится к замене одной из переменных на функциональную зависимость от другой и поиск производной по единственной оставшейся переменной.\n",
    "\n",
    "**Пример № 5**\n",
    "\n",
    "*Найти полную производную для функции $f(x,y) = x^2 + y^2$ по $x$, если $y = lnx$.*\n",
    "\n",
    "$f(x,y(x)) = x^2 + y^2(x) = x^2 + (ln \\ x)^2$\n",
    "\n",
    "$\\frac{df(x,y(x))}{dx} = (x^2 + y^2(x))'_x = 2x + 2y \\cdot y' = 2x + 2ln \\ x \\cdot \\frac{1}{x}$\n",
    "\n",
    "Разумеется, мы можем вычислять частные производные с помощью уже известной нам библиотеки SymPy. По сути, в коде ничего не меняется — надо лишь не забыть указать, по какой переменной вы ищете производную.\n",
    "\n",
    "Например, попробуем найти производную для функции $f(a,b,c) = 5ab - a*cos(c) + a^2+c^8*b$ по переменной $a$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*a + 5*b - cos(c)\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, cos, diff\n",
    "\n",
    "a, b, c = symbols('a b c', real=True)\n",
    "f = 5*a*b - a*cos(c) + a**2 + c**8*b\n",
    "\n",
    "print(diff(f, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальнейшие задания вы можете выполнять как вручную, так и с помощью SymPy, однако рекомендуем на первых порах использовать оба инструмента для самопроверки, а не ограничиваться только одним."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.3\n",
    "\n",
    "$f(x,y) = x^2 − y^2$\n",
    "\n",
    "1. Чему равны частные производные $f(x,y)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*x\n",
      "-2*y\n"
     ]
    }
   ],
   "source": [
    "x, y = symbols('x y', real=True)\n",
    "f = x**2 - y**2\n",
    "\n",
    "print(diff(f, x))\n",
    "\n",
    "print(diff(f, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Вычислите частные производные в точке $M(−2,−1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -4$"
      ],
      "text/plain": [
       "-4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(f, x).subs(x, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2$"
      ],
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(f, y).subs(y, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Безусловные экстремумы. Функции нескольких переменных"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "950b5653ccfc34417735dd321d006fd482b31f7611416c3d8236dc5b17587d3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

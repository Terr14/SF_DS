{"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":128.230746,"end_time":"2023-04-15T19:52:53.810255","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-04-15T19:50:45.579509","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> Кластеризация изображений транспортных средств","metadata":{"id":"e25ed3d4","papermill":{"duration":0.008076,"end_time":"2023-04-15T19:50:55.680403","exception":false,"start_time":"2023-04-15T19:50:55.672327","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Постановка задачи","metadata":{"id":"1e9fef1b","papermill":{"duration":0.00637,"end_time":"2023-04-15T19:50:55.693603","exception":false,"start_time":"2023-04-15T19:50:55.687233","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<center> <img src=https://i.ibb.co/t8DvkyB/smart-city-image-1.jpg align=\"right\" width=\"300\"/> </center>\n<center> <img src=https://i.ibb.co/qYkWNVh/smart-city-image-3.jpg align=\"right\" width=\"300\"/> </center>\n\n\nОдин из ключевых проектов IntelliVision — Smart City/Transportation, система, обеспечивающая безопасность дорожного движения и более эффективную работу парковок. С помощью Smart City/Transportation можно контролировать сигналы светофоров и соблюдение ограничений скорости, определять виды транспортных средств, распознавать номерные знаки, считать автомобили и людей.\n\nВ основе всех перечисленных возможностей проекта лежит CV (Computer Vision, компьютерное зрение). Чтобы их реализовать, компания использует модели, для обучения которых применяются огромные размеченные датасеты с изображениями транспортных средств. Однако система работает в режиме реального времени и с каждым днём данных становится всё больше. Алгоритм нуждается в постоянной модернизации и должен учитывать множество факторов.\n\nДля модификации и повышения эффективности системы Smart City/Transportation команде необходимо автоматизировать определение дополнительных параметров авто на изображении:\n\n* тип автомобиля (кузова),\n* ракурс снимка (вид сзади/спереди),\n* цвет автомобиля,\n* другие характеристики.\n\nТакже необходимо автоматизировать поиск выбросов в данных (засветы и блики на изображениях, изображения, на которых отсутствуют автомобили и т. д.).\n\nК сожалению, у компании нет комплексной модели, которая могла бы одновременно находить на изображении автомобиль и определять все нужные параметры. Её нужно построить, однако многокомпонентная разметка новых данных по всем этим параметрам — очень трудозатратное занятие, которое стоит больших денег.\n\nПри решении задачи разметки данных у команды возникла гипотеза, которая нуждается в исследовании.\n\n\n**Гипотеза:** разметку исходных данных можно эффективно провести с помощью методов кластеризации. \n\n\n**В чём идея?**\n\n*Давайте будем использовать небольшой набор моделей свёрточных нейронных сетей, обученных на различных датасетах и решающих различные задачи от классификации изображений по цвету до классификации типов транспортных средств, пропустим нашу базу изображений через каждую модель, но возьмём не выходной результат модели, а только промежуточное представление признаков (дескриптор), полученное на свёрточных слоях сети.*\n\n*Выполним такую операцию для всех изображений из набора данных, на основе полученных дескрипторов кластеризуем изображения, проинтерпретируем полученные кластеры и попробуем найти в них необходимую информацию.*\n\nТеперь, когда мы обсудили гипотезу, перейдём к постановке задачи.\n\n<center> <img src=https://i.ibb.co/hLcBpZF/2023-03-27-12-11-17.png align=\"right\" width=\"500\"/> </center>\n\nУ вас будет набор из 416 314 изображений транспортных средств различных типов, цветов и снятых с разных ракурсов.\n\nКоманда IntelliVision уже обработала свой набор данных с помощью нескольких моделей глубокого обучения (свёрточных нейронных сетей) и получила четыре варианта вектора признаков (дескрипторов) для каждого изображения.\n\n**Ваша задача** — используя готовые дескрипторы, разбить изображения на кластеры и проинтерпретировать каждый из них. Для всех вариантов дескрипторов нужно применить несколько алгоритмов кластеризации и сравнить полученные результаты. Сравнивать можно на основе метрик, визуализаций плотностей кластеров и по тому, насколько хорошо интерпретируются кластеры.\n\nДополнительная подзадача — найти выбросы среди изображений. Это могут быть изображения плохого качества, изображения с бликами или изображения, на которых нет транспортных средств и т. д.\n\nБизнес-задача: исследовать возможность применения алгоритмов кластеризации для разметки новых данных и поиска выбросов.\n\nТехническая задача для вас как для специалиста в Data Science: построить модель кластеризации изображений на основе дескрипторов, выделяемых с помощью различных архитектур нейронных сетей, проинтерпретировать полученные результаты и выбрать модель или комбинацию моделей, которая выделяет наиболее пригодные для интерпретации признаки.\n\n**Ваши основные цели:**\n1. Для каждого типа дескрипторов необходимо:\n    * выполнить предобработку дескрипторов;\n    * произвести кластеризацию изображений на основе их дескрипторов, подобрав алгоритм и параметры кластеризации;\n    * сделать визуализацию полученных кластеров в 2D- или 3D-пространстве;\n    * проинтерпретировать полученные кластеры — в паре предложений сформулировать, какие изображения попали в каждый из кластеров.\n2. Сравнить между собой полученные кластеризации для каждого типа дескрипторов (по метрикам, визуализации и результатам интерпретации).\n3. Выполнить автоматизированный поиск выбросов среди изображений на основе дескрипторов.\n4. Дополнительная задача (не оценивается): попробовать воспользоваться смесью дескрипторов, полученных различными моделями, и проинтерпретировать полученные результаты.\n\n**Примечание.** При выборе алгоритма кластеризации следует ориентироваться на внутренние метрики, а именно на индекс Калински — Харабаса (`calinski_harabasz_score`) и индекс Дэвиса — Болдина (`davies_bouldin_score`), а также на интерпретируемость кластеров и визуализацию.","metadata":{"id":"19193c5d","papermill":{"duration":0.006231,"end_time":"2023-04-15T19:50:55.706382","exception":false,"start_time":"2023-04-15T19:50:55.700151","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Данные и их описание","metadata":{"id":"2be9a5ee","papermill":{"duration":0.006492,"end_time":"2023-04-15T19:50:55.719509","exception":false,"start_time":"2023-04-15T19:50:55.713017","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Исходная папка с данными имеет следующую структуру:\n\n```\nIntelliVision_case\n├─descriptors\n    └─efficientnet-b7.pickle\n    └─osnet.pickle\n    └─vdc_color.pickle\n    └─vdc_type.pickle\n├─row_data\n    └─veriwild.zip\n├─images_paths.csv \n```\n\nДавайте разберёмся в ней:\n\n* В папке `descriptors` содержатся дескрипторы, полученные для каждого из изображений с помощью соответствующих нейронных сетей, в формате numpy-массивов, сохранённых в файлах pickle:\n    * `efficientnet-b7.pickle` — дескрипторы, выделенные моделью классификации с архитектурой EfficientNet версии 7. Эта модель является свёрточной нейронной сетью, предобученной на на датасете ImageNet, в котором содержатся изображения более 1000 различных классов. Эта модель при обучении не видела датасета veriwiId. \n\n    * `osnet.pickle` — дескрипторы, выделенные моделью OSNet, обученной для детектирования людей, животных и машин. Модель не обучалась на исходном датасете veriwiId.\n\n    * `vdc_color.pickle` — дескрипторы, выделенные моделью регрессии для определения цвета транспортных средств в формате RGB. Частично обучена на исходном датасете veriwild.\n    \n    * `vdc_type.pickle` — дескрипторы, выделенные моделью классификации транспортных средств по типу на десяти классах. Частично обучена на исходном датасете veriwild.\n\n* В папке `row_data` содержится zip-архив с исходными изображениями автомобилей. Распакуйте его содержимое в папку row_data. Архив содержит десять папок с изображениями, пронумерованных от 1 до 10. Каждая папка содержит подпапки, обозначенные пятизначными цифрами, например 36191. \n\nВ каждой из таких подпапок содержатся фотографии одного конкретного автомобиля с разных ракурсов, снятые с помощью дорожных видеокамер.\n\n* В файле `images_paths.csv` представлен список из полных путей до изображений. Он пригодится вам при анализе изображений, попавших в определённый кластер.\n","metadata":{"id":"ddfa9d63","papermill":{"duration":0.00662,"end_time":"2023-04-15T19:50:55.732777","exception":false,"start_time":"2023-04-15T19:50:55.726157","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Импорт базовых библиотек:","metadata":{"id":"12d71418","papermill":{"duration":0.006293,"end_time":"2023-04-15T19:50:55.745671","exception":false,"start_time":"2023-04-15T19:50:55.739378","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ! pip install cudf-cu11 dask-cudf-cu11 --extra-index-url=https://pypi.nvidia.com\n# ! pip install cuml-cu11 --extra-index-url=https://pypi.nvidia.com\n# ! pip install cugraph-cu11 --extra-index-url=https://pypi.nvidia.com\n!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n!python rapidsai-csp-utils/colab/pip-install.py","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yJ-cRHP8DHg","outputId":"0727fdb6-ed8b-459f-fd5c-739b55d501b6","execution":{"iopub.status.busy":"2023-04-20T21:10:29.070304Z","iopub.execute_input":"2023-04-20T21:10:29.071325Z","iopub.status.idle":"2023-04-20T21:10:48.137182Z","shell.execute_reply.started":"2023-04-20T21:10:29.071271Z","shell.execute_reply":"2023-04-20T21:10:48.135885Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'rapidsai-csp-utils'...\nremote: Enumerating objects: 385, done.\u001b[K\nremote: Counting objects: 100% (116/116), done.\u001b[K\nremote: Compressing objects: 100% (65/65), done.\u001b[K\nremote: Total 385 (delta 86), reused 51 (delta 51), pack-reused 269\u001b[K\nReceiving objects: 100% (385/385), 105.74 KiB | 3.92 MiB/s, done.\nResolving deltas: 100% (188/188), done.\n***********************************************************************\nWoo! Your instance has the right kind of GPU, a Tesla T4!\nWe will now install RAPIDS cuDF, cuML, and cuGraph via pip! \nPlease stand by, should be quick...\n***********************************************************************\n\nLooking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\nCollecting cudf-cu11\n  Downloading cudf_cu11-23.4.0.1681363056.tar.gz (6.8 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'error'\n  error: subprocess-exited-with-error\n\n  × python setup.py egg_info did not run successfully.\n  │ exit code: 1\n  ╰─> [16 lines of output]\n      Traceback (most recent call last):\n        File \"<string>\", line 36, in <module>\n        File \"<pip-setuptools-caller>\", line 34, in <module>\n        File \"/tmp/pip-install-vt74gbw_/cudf-cu11_0a7b4a2e6480477691927947441797eb/setup.py\", line 137, in <module>\n          raise RuntimeError(open(\"ERROR.txt\", \"r\").read())\n      RuntimeError:\n      ###########################################################################################\n      The package you are trying to install is only a placeholder project on PyPI.org repository.\n      This package is hosted on NVIDIA Python Package Index.\n\n      This package can be installed as:\n      ```\n      $ pip install --extra-index-url https://pypi.nvidia.com cudf_cu11\n      ```\n      ###########################################################################################\n\n      [end of output]\n\n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: metadata-generation-failed\n\n× Encountered error while generating package metadata.\n╰─> See above for output.\n\nnote: This is an issue with the package mentioned above, not pip.\nhint: See above for details.\nCollecting cupy-cuda11x\n  Downloading cupy_cuda11x-11.6.0-cp37-cp37m-manylinux1_x86_64.whl (90.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.2/90.2 MB 13.8 MB/s eta 0:00:00\nRequirement already satisfied: numpy<1.27,>=1.20 in /opt/conda/lib/python3.7/site-packages (from cupy-cuda11x) (1.21.6)\nRequirement already satisfied: fastrlock>=0.5 in /opt/conda/lib/python3.7/site-packages (from cupy-cuda11x) (0.8)\nInstalling collected packages: cupy-cuda11x\nSuccessfully installed cupy-cuda11x-11.6.0\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n\n          ***********************************************************************\n          The pip install of RAPIDS is complete.\n          \n          Please do not run any further installation from the conda based installation methods, as they may cause issues!  \n          \n          Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts. \nr          \n          Troubleshooting:\n             - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n             - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n          ***********************************************************************\n          \n","output_type":"stream"}]},{"cell_type":"code","source":"import cupy as cp\nimport cudf\nimport pandas as pd\nimport numpy as np\nimport cupy as cp\nimport cudf\nimport matplotlib.pyplot as plt\n# import seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\n\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\nimport warnings \n\nfrom IPython.display import display, HTML\n\nwarnings.filterwarnings(\"ignore\")\n\nplt.rcParams[\"patch.force_edgecolor\"] = True","metadata":{"id":"37ea9229","papermill":{"duration":2.868477,"end_time":"2023-04-15T19:50:58.620761","exception":false,"start_time":"2023-04-15T19:50:55.752284","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"d8210224-d717-46cd-c841-d3e7483c2b58","execution":{"iopub.status.busy":"2023-04-20T21:10:48.139721Z","iopub.execute_input":"2023-04-20T21:10:48.140072Z","iopub.status.idle":"2023-04-20T21:10:51.306843Z","shell.execute_reply.started":"2023-04-20T21:10:48.140037Z","shell.execute_reply":"2023-04-20T21:10:51.305558Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 1. Знакомство со структурой данных","metadata":{"id":"fe174c2e","papermill":{"duration":0.006962,"end_time":"2023-04-15T19:50:58.635367","exception":false,"start_time":"2023-04-15T19:50:58.628405","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Прочитайте numpy-массивы из предоставленных pickle-файлов.\n\n**Примечание** Для удобства дальнейшей работы вы можете составить четыре DataFrame с путями до изображений и соответствующими им дескрипторами.\n\nПосмотрите на размерности каждой из четырёх заданных матриц и сравните использованные модели глубокого обучения по размерностям выходных дескрипторов изображений. \n","metadata":{"id":"24a91840","papermill":{"duration":0.006546,"end_time":"2023-04-15T19:50:58.648838","exception":false,"start_time":"2023-04-15T19:50:58.642292","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"B6DhFfE7hsi1","execution":{"iopub.status.busy":"2023-04-20T21:10:51.308853Z","iopub.execute_input":"2023-04-20T21:10:51.309266Z","iopub.status.idle":"2023-04-20T21:10:51.315788Z","shell.execute_reply.started":"2023-04-20T21:10:51.309229Z","shell.execute_reply":"2023-04-20T21:10:51.313540Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pickle\n\ndesc = cudf.DataFrame(pickle.load(open(\n    '/kaggle/input/intellivision-case/IntelliVision_case/descriptors/efficientnet-b7.pickle', \n    'rb'))).sample(frac=0.05)\n# desc_2 = pd.DataFrame(pickle.load(open(\n#     '/kaggle/input/IntelliVision_case/descriptors/osnet.pickle', \n#     'rb')))\n# desc_3 = pd.DataFrame(pickle.load(open(\n#     '/kaggle/input/IntelliVision_case/descriptors/vdc_color.pickle', \n#     'rb')))\n# desc_4 = pd.DataFrame(pickle.load(open(\n#     '/kaggle/input/IntelliVision_case/descriptors/vdc_type.pickle', \n#     'rb')))\n\nimages = cudf.DataFrame(pd.read_csv(\n    '/kaggle/input/intellivision-case/IntelliVision_case/images_paths.csv')).iloc[desc.index]\n\n","metadata":{"id":"b722848f","papermill":{"duration":113.345301,"end_time":"2023-04-15T19:52:52.000876","exception":false,"start_time":"2023-04-15T19:50:58.655575","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-20T21:10:51.319455Z","iopub.execute_input":"2023-04-20T21:10:51.319864Z","iopub.status.idle":"2023-04-20T21:11:46.182040Z","shell.execute_reply.started":"2023-04-20T21:10:51.319831Z","shell.execute_reply":"2023-04-20T21:11:46.180957Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 2. Преобразование, очистка и анализ данных","metadata":{"id":"1deb7090","papermill":{"duration":0.006641,"end_time":"2023-04-15T19:52:52.015029","exception":false,"start_time":"2023-04-15T19:52:52.008388","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Признаки, найденные с помощью некоторых моделей, исчисляются тысячами, что довольно много, учитывая общее количество наблюдений.\n\nКак вы понимаете, производить кластеризацию на таком большом количестве признаков, которые были сформированы исходными моделями глубокого обучения, довольно сложно и затратно по времени. К тому же, многие признаки, найденные моделями на изображениях, могут быть сильно скоррелированы между собой.\n\nПонизьте размерность исходных дескрипторов с помощью соответствующих методов. Можно уменьшить размерность входных данных до 100 или 200 признаков — этого будет достаточно, чтобы произвести кластеризацию, однако рекомендуем вам самостоятельно подобрать необходимое количество компонент в новом пространстве признаков.\n\nТакже позаботьтесь о масштабе признаков, воспользовавшись стандартизацией и нормализацией. После кластеризации определите, какой вариант масштабирования более успешен для каждого варианта дескрипторов.\n","metadata":{"id":"ef81c101","papermill":{"duration":0.00645,"end_time":"2023-04-15T19:52:52.028316","exception":false,"start_time":"2023-04-15T19:52:52.021866","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from cuml.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndesc = cudf.DataFrame(scaler.fit_transform(desc))\n\n# desc_2_scaled = cudf.DataFrame(scaler.fit_transform(desc_2))\n# desc_3_scaled = cudf.DataFrame(scaler.fit_transform(desc_3))\n# desc_4_scaled = cudf.DataFrame(scaler.fit_transform(desc_4))","metadata":{"id":"2f0f5a7f","papermill":{"duration":0.050996,"end_time":"2023-04-15T19:52:52.086096","exception":false,"start_time":"2023-04-15T19:52:52.035100","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-20T21:11:46.183678Z","iopub.execute_input":"2023-04-20T21:11:46.184682Z","iopub.status.idle":"2023-04-20T21:12:07.827012Z","shell.execute_reply.started":"2023-04-20T21:11:46.184642Z","shell.execute_reply":"2023-04-20T21:12:07.825878Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from cuml.decomposition import PCA\n\ndef get_principal_components(data):\n  for n in range(100, 1000, 25):\n    pca = PCA(n_components=n)\n    principal_components = pca.fit_transform(desc)\n    if pca.explained_variance_ratio_.sum() > 0.8:\n      return principal_components\n","metadata":{"id":"PMKuDmpmECNm","execution":{"iopub.status.busy":"2023-04-20T21:12:07.828831Z","iopub.execute_input":"2023-04-20T21:12:07.829284Z","iopub.status.idle":"2023-04-20T21:12:07.836108Z","shell.execute_reply.started":"2023-04-20T21:12:07.829243Z","shell.execute_reply":"2023-04-20T21:12:07.834688Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# from cuml.decomposition import PCA\n\n# def get_principal_components(data):\n\n#   n_components = []\n\n#   for n in np.linspace(0.9,0.5,5):\n#       pca = PCA(n_components=n)\n#       principal_components = pca.fit_transform(desc_1_scaled)\n#       n_components.append(principal_components.shape[1])\n        \n#   result = pd.DataFrame({\n#       'explained variance':np.linspace(0.9,0.5,5),\n#       'n_components':n_components\n#       })\n  \n#   return display(result)","metadata":{"id":"df78ff5e","execution":{"iopub.status.busy":"2023-04-20T21:12:07.838126Z","iopub.execute_input":"2023-04-20T21:12:07.838542Z","iopub.status.idle":"2023-04-20T21:12:07.856086Z","shell.execute_reply.started":"2023-04-20T21:12:07.838504Z","shell.execute_reply":"2023-04-20T21:12:07.854839Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# def get_principal_components(data):\n\n#   pca = PCA(n_components=0.8)\n#   principal_components = pca.fit_transform(desc_1_scaled)\n\n#   return principal_components","metadata":{"id":"klB86eYQFbHN","execution":{"iopub.status.busy":"2023-04-20T21:12:07.857861Z","iopub.execute_input":"2023-04-20T21:12:07.858309Z","iopub.status.idle":"2023-04-20T21:12:07.866233Z","shell.execute_reply.started":"2023-04-20T21:12:07.858268Z","shell.execute_reply":"2023-04-20T21:12:07.865071Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"desc = get_principal_components(desc)\n\n# desc_2_pca = get_principal_components(desc_2_scaled)\n# desc_3_pca = get_principal_components(desc_3_scaled)\n# desc_4_pca = get_principal_components(desc_4_scaled)","metadata":{"id":"qdn7_sDbErTv","execution":{"iopub.status.busy":"2023-04-20T21:12:07.869320Z","iopub.execute_input":"2023-04-20T21:12:07.869808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Моделирование и оценка качества модели","metadata":{"id":"b9e20031","papermill":{"duration":0.006878,"end_time":"2023-04-15T19:52:52.100351","exception":false,"start_time":"2023-04-15T19:52:52.093473","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### 3.1. Кластеризация изображений","metadata":{"id":"537e8338","papermill":{"duration":0.006919,"end_time":"2023-04-15T19:52:52.115132","exception":false,"start_time":"2023-04-15T19:52:52.108213","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"После предобработки исходных данных произведите кластеризацию для каждого набора дескрипторов.\n\nДля решения задачи используйте несколько различных методов, подобрав оптимальное количество кластеров для каждого метода и варианта дескрипторов.\n\nВ качестве метрики для подбора оптимального количества кластеров используйте внутренние меры индекс Калински — Харабаса (`calinski_harabasz_score`) и индекс Дэвиса — Болдина (`davies_bouldin_score`).\n\nРекомендуем вынести код для построения моделей кластеризации и подбора их параметров в отдельную функцию, чтобы не множить одинаковый код для четырёх случаев дескрипторов.\n\n**Примечание.** Поскольку исходных данных много, могут возникнуть проблемы с оперативной памятью и скоростью работы таких алгоритмов, как K-Means. Вместо стандартного алгоритма K-Means можно воспользоваться реализацией MiniBatchKMeans. \n\n**Примечание.** Постарайтесь написать чистый код, максимально уменьшая количество дублирующихся участков.","metadata":{"id":"bd253bf3","papermill":{"duration":0.006998,"end_time":"2023-04-15T19:52:52.129455","exception":false,"start_time":"2023-04-15T19:52:52.122457","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# from sklearn.cluster import MiniBatchKMeans\n\n# from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n\n# def get_scales_figs(data):\n\n#   silhouette = []\n#   calinski_harabasz = []\n#   davies_bouldin = []\n\n#   for n in range(2,11):\n\n#       mbkmeans = MiniBatchKMeans(\n#           n_clusters=n)    \n#       mbkmeans.fit_predict(data.to_numpy())      \n\n#       calinski_harabasz.append(calinski_harabasz_score(data.to_numpy(), mbkmeans.labels_))\n#       davies_bouldin.append(davies_bouldin_score(data.to_numpy(), mbkmeans.labels_))\n#       silhouette.append(silhouette_score(data.to_numpy(), mbkmeans.labels_))\n            \n#   n_clusters_scales = pd.DataFrame({\n#     'n_clusters':range(2,11),\n#     'silhouette_score':silhouette,\n#     'calinski_harabasz':calinski_harabasz,\n#     'davies_bouldin':davies_bouldin\n#     })\n\n#   fig_sil = px.line(\n#     data_frame = n_clusters_scales,\n#     x = 'n_clusters',\n#     y = 'silhouette_score',\n#     title = 'Зависимость коэффициента силуэта от количества кластеров',\n#     width=600\n#     )   \n\n#   fig_ch = px.line(\n#     data_frame = n_clusters_scales,\n#     x = 'n_clusters',\n#     y = 'calinski_harabasz',\n#     title = 'Зависимость индекса Калински — Харабаса от количества кластеров',\n#     width=600\n#     )\n\n#   fig_db = px.line(data_frame = n_clusters_scales,\n#     x = 'n_clusters',\n#     y = 'davies_bouldin',\n#     title='Зависимость индекса Дэвиса — Болдина от количества кластеров',\n#     width=600\n#     )\n\n#   fig_sil.show()\n#   fig_ch.show()\n#   fig_db.show()\n\n\n# def get_cluster(data, best_n):\n#   mbkmeans = MiniBatchKMeans(\n#       n_clusters=best_n)    \n#   mbkmeans.fit_predict(data.to_numpy())\n#   return mbkmeans.labels_","metadata":{"id":"754e0bbd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\nfrom sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n\ndef get_scales_figs(data):    \n\n    calinski_harabasz = []\n    davies_bouldin = []\n    silhouette = []\n\n    for n in range(2,11):\n        \n        gm = GaussianMixture(n_components=n)\n   \n        labels = gm.fit_predict(data.to_numpy())      \n\n        calinski_harabasz.append(calinski_harabasz_score(data.to_numpy(), labels))\n        davies_bouldin.append(davies_bouldin_score(data.to_numpy(), labels))\n        silhouette.append(silhouette_score(data.to_numpy(), labels))\n            \n    n_clusters_scales = pd.DataFrame({\n        'n_clusters':range(2,11),\n        'silhouette_score':silhouette,\n        'calinski_harabasz':calinski_harabasz,\n        'davies_bouldin':davies_bouldin\n    })\n\n    fig_sil = px.line(\n        data_frame = n_clusters_scales,\n        x = 'n_clusters',\n        y = 'silhouette_score',\n        title = 'Зависимость коэффициента силуэта от количества кластеров',\n        width=800\n        )   \n\n    fig_ch = px.line(\n        data_frame = n_clusters_scales,\n        x = 'n_clusters',\n        y = 'calinski_harabasz',\n        title = 'Зависимость индекса Калински — Харабаса от количества кластеров',\n        width=800\n        )\n\n    fig_db = px.line(data_frame = n_clusters_scales,\n        x = 'n_clusters',\n        y = 'davies_bouldin',\n        title='Зависимость индекса Дэвиса — Болдина от количества кластеров',\n        width=800\n    )\n\n    fig_sil.show()\n    fig_ch.show()\n    fig_db.show()\n    \n    \ndef get_cluster(data, best_n):\n        gm = GaussianMixture(n_components=best_n)    \n        labels = gm.fit_predict(data.to_numpy())\n        return labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.cluster import AgglomerativeClustering\n# from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n\n# def get_scales_figs(data):    \n\n#     calinski_harabasz = []\n#     davies_bouldin = []\n#     silhouette = []\n\n#     for n in range(2,11):\n        \n#         agg = AgglomerativeClustering(\n#             n_clusters=n,\n#             linkage='complete'\n#             )\n   \n#         agg.fit_predict(data.to_numpy())      \n\n#         calinski_harabasz.append(calinski_harabasz_score(data.to_numpy(), agg.labels_))\n#         davies_bouldin.append(davies_bouldin_score(data.to_numpy(), agg.labels_))\n#         silhouette.append(silhouette_score(data.to_numpy(), agg.labels_))\n            \n#     n_clusters_scales = pd.DataFrame({\n#         'n_clusters':range(2,11),\n#         'silhouette_score':silhouette,\n#         'calinski_harabasz':calinski_harabasz,\n#         'davies_bouldin':davies_bouldin\n#     })\n\n#     fig_sil = px.line(\n#         data_frame = n_clusters_scales,\n#         x = 'n_clusters',\n#         y = 'silhouette_score',\n#         title = 'Зависимость коэффициента силуэта от количества кластеров',\n#         width=800\n#         )   \n\n#     fig_ch = px.line(\n#         data_frame = n_clusters_scales,\n#         x = 'n_clusters',\n#         y = 'calinski_harabasz',\n#         title = 'Зависимость индекса Калински — Харабаса от количества кластеров',\n#         width=800\n#         )\n\n#     fig_db = px.line(data_frame = n_clusters_scales,\n#         x = 'n_clusters',\n#         y = 'davies_bouldin',\n#         title='Зависимость индекса Дэвиса — Болдина от количества кластеров',\n#         width=800\n#     )\n\n#     fig_sil.show()\n#     fig_ch.show()\n#     fig_db.show()\n\n    \n# def get_cluster(data, best_n):\n#         agg = AgglomerativeClustering(\n#             n_clusters=best_n,\n#             linkage='complete')        \n#         agg.fit_predict(data.to_numpy())\n#         return agg.labels_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Вычислим метрики кластеризации в зависимости от количества кластеров для первого дескриптора:","metadata":{"id":"059bed3b"}},{"cell_type":"code","source":"get_scales_figs(desc)","metadata":{"id":"9d3232a0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Наилучшие результаты кластеризации первого дескриптора наблюдаются при разбиении на 2 кластера.","metadata":{"id":"3d47c8dd"}},{"cell_type":"code","source":"best_n = 2\n\nlabels = get_cluster(desc, best_n)","metadata":{"id":"50f3687c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Вычислим метрики кластеризации в зависимости от количества кластеров для второго дескриптора:","metadata":{"id":"beab852c"}},{"cell_type":"markdown","source":"### 3.2. Интерпретация кластеров","metadata":{"id":"37e4f91b","papermill":{"duration":0.007246,"end_time":"2023-04-15T19:52:52.158279","exception":false,"start_time":"2023-04-15T19:52:52.151033","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"#### 3.2.1 Визуализация кластеров","metadata":{"id":"60767619","papermill":{"duration":0.006786,"end_time":"2023-04-15T19:52:52.172404","exception":false,"start_time":"2023-04-15T19:52:52.165618","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Визуализируйте результаты кластеризации в двух- или трёхмерном пространстве, предварительно понизив размерность дескрипторов изображений до соответствующих размерностей с помощью метода t-SNE. \n\nПо результатам визуализации кластеров сделайте предположение о качестве полученной кластеризации.","metadata":{"id":"c4c8fae3","papermill":{"duration":0.007002,"end_time":"2023-04-15T19:52:52.187071","exception":false,"start_time":"2023-04-15T19:52:52.180069","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from cuml.manifold import TSNE\n\ndef cluster_fig(data):\n\n    tsne = TSNE(n_components=2)\n    data_tsne = pd.DataFrame(tsne.fit_transform(data).to_numpy())\n\n    data_tsne['label'] = labels\n\n    fig = px.scatter(\n        data_frame=data_tsne,\n        x=0,\n        y=1,\n        color='label',\n        title='Визуализация кластеров'\n    )\n    \n    return fig.show()","metadata":{"id":"5fb424e6","papermill":{"duration":0.006841,"end_time":"2023-04-15T19:52:52.201306","exception":false,"start_time":"2023-04-15T19:52:52.194465","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_fig(desc)\n# cluster_fig(desc_2_pca)\n# cluster_fig(desc_3_pca)\n# cluster_fig(desc_4_pca)","metadata":{"id":"07506eb3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.2.2. Визуализация изображений в кластере\n","metadata":{"id":"cb7f0903","papermill":{"duration":0.006947,"end_time":"2023-04-15T19:52:52.215899","exception":false,"start_time":"2023-04-15T19:52:52.208952","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Визуализируйте несколько изображений из каждого кластера, чтобы проинтерпретировать результаты.\n\n**Как визуализировать изображения, соответствующие определённому кластеру?**\n\nМы не рассматривали работу с изображениями как отдельную тему, однако не волнуйтесь — в этом нет ничего страшного.\n\nВ стандартных библиотеках для визуализации, которые мы изучали ранее, есть встроенный функционал для чтения и визуализации изображений. Например, в библиотеке matplotlib есть функция `plt.imread()`, которая позволяет читать изображение по переданному пути. Она возвращает numpy-массив размерности (h, w, c), где:\n\n* h — высота изображения, \n* w — его ширина,\n* c — количество каналов.\n\nТак как все изображения в нашем датасете цветные, каналов (c) три:\n\n* R — матрица интенсивности пикселей красного цвета,\n* G — матрица интенсивности пикселей зелёного цвета,\n* B — матрица интенсивности пикселей синего цвета.\n\nНапример, вот так можно прочитать изображение 000001.jpg:\n\n```python\nimg = plt.imread('raw_data/veriwild/1/00001/000001.jpg')\nprint(img.shape)\n## (557, 756, 3)\n```\n\nТо есть изображение состоит из трёх матриц (R, G и B) с размерностью 557 строк на 756 столбцов. Элементами каждой из матриц являются интенсивности пикселей (от 0 до 255) соответствующего цвета.\n\nЧто касается вывода изображений на экран, в библиотеке matplotlib есть встроенная функция `plt.imshow()`, которая позволяет вывести переданное ей в аргументы изображение:\n\n```python\nfig = plt.figure(figsize=(5, 5))\nplt.imshow(img);\n```\n\nФункцию `imshow()` можно вызывать и от имени координатных плоскостей при использовании `subplots` из библиотеки `matplotlib`:\n\n```python\nimg1 = plt.imread('raw_data/veriwild/1/00001/000001.jpg')\nimg2 = plt.imread('raw_data/veriwild/1/00001/000002.jpg')\nfig, axes = plt.subplots(1, 2, figsize=(5, 5))\naxes[0].imshow(img1);\naxes[1].imshow(img2);\n```\n\nПосле кластеризации для интерпретации результатов вам понадобится визуализировать несколько изображений из каждого кластера. Для этого мы подготовили функцию `plot_sample_cluster_images()`.","metadata":{"id":"82229b96","papermill":{"duration":0.006908,"end_time":"2023-04-15T19:52:52.230113","exception":false,"start_time":"2023-04-15T19:52:52.223205","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_samples_images(data, cluster_label, nrows=3, ncols=3, figsize=(12, 5)):\n    \"\"\"Функция для визуализации нескольких случайных изображений из кластера cluster_label.\n    Пути до изображений и метки кластеров должны быть представлены в виде DataFrame со столбцами \"paths\" и \"cluster\".\n\n\n    Args:\n        data (DataFrame): таблица с разметкой изображений и соответствующих им кластеров.\n        cluster_label (int): номер кластера изображений.\n        nrows (int, optional): количество изображений по строкам таблицы (по умолчанию 3).\n        ncols (int, optional): количество изображений по столбцам (по умолчанию 3).\n        figsize (tuple, optional): размер фигуры (по умолчанию (12, 5)).\n    \"\"\"\n    # Фильтруем данные по номеру кластера\n    samples_indexes = np.array(data[data['cluster'] == cluster_label].index)\n    # Перемешиваем результаты\n    np.random.shuffle(samples_indexes)\n    # Составляем пути до изображений\n    paths = data.loc[samples_indexes, 'paths']\n   \n    # Создаём фигуру и набор координатных плоскостей\n    fig, axes = plt.subplots(nrows,ncols)\n    # Устанавливаем размер фигуры\n    fig.set_size_inches(*figsize)\n    # Устанавливаем название графика\n    fig.suptitle(f\"Images from cluster {cluster_label}\", fontsize=16)\n    # Создаём цикл по строкам в таблице с координатными плоскостями\n    for i in range(nrows):\n        # Создаём цикл по столбцам в таблице с координатными плоскостями\n        for j in range(ncols):\n            # Определяем индекс пути до изображения\n            path_idx = i * ncols + j\n            if path_idx >= len(paths):\n                break\n            # Извлекаем путь до изображения\n            path = paths.iloc[path_idx]\n            # Читаем изображение            \n            img = plt.imread('/kaggle/input/intellivision-case/IntelliVision_case/raw_data/'+path.replace('\\\\','/'))\n            # Отображаем его на соответствующей координатной плоскости\n            axes[i,j].imshow(img)\n            # Убираем пометки координатных осей\n            axes[i,j].axis('off')\n","metadata":{"id":"e38ebe3f","papermill":{"duration":0.023662,"end_time":"2023-04-15T19:52:52.261817","exception":false,"start_time":"2023-04-15T19:52:52.238155","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Например, вы произвели кластеризацию и записали пути до изображений в виде столбца \"paths\" и метки кластеров в виде столбца \"cluster\" в некоторый DataFrame с именем data. Тогда, чтобы визуализировать несколько случайных изображений из кластера 0, вам нужно вызвать функцию `plot_sample_cluster_images()` следующим образом:\n\n```python\nplot_samples_images(data=data, cluster_label=0)\n```","metadata":{"id":"7785c7bd","papermill":{"duration":0.00687,"end_time":"2023-04-15T19:52:52.276168","exception":false,"start_time":"2023-04-15T19:52:52.269298","status":"completed"},"tags":[]}},{"cell_type":"code","source":"clustered_images_desc = pd.DataFrame(images.to_numpy(), columns = images.columns)\nclustered_images_desc['cluster'] = labels\n\nfor n in range(best_n):\n    plot_samples_images(data=clustered_images_desc, cluster_label=n)\n","metadata":{"id":"4513ad20","papermill":{"duration":0.006877,"end_time":"2023-04-15T19:52:52.290193","exception":false,"start_time":"2023-04-15T19:52:52.283316","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clustered_images_desc_2 = images\n# clustered_images_desc_2['cluster'] = labels_1\n# plot_samples_images(data=clustered_images_desc_1, cluster_label=0)\n# plot_samples_images(data=clustered_images_desc_1, cluster_label=1)","metadata":{"id":"d8f9cc3e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clustered_images_desc_3 = images\n# clustered_images_desc_3['cluster'] = labels_1\n# plot_samples_images(data=clustered_images_desc_1, cluster_label=0)\n# plot_samples_images(data=clustered_images_desc_1, cluster_label=1)","metadata":{"id":"1ec27083","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clustered_images_desc_4 = images\n# clustered_images_desc_4['cluster'] = labels_1\n# plot_samples_images(data=clustered_images_desc_1, cluster_label=0)\n# plot_samples_images(data=clustered_images_desc_1, cluster_label=1)","metadata":{"id":"323cd8bb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3. Поиск выбросов","metadata":{"id":"4c2de170","papermill":{"duration":0.006854,"end_time":"2023-04-15T19:52:52.304639","exception":false,"start_time":"2023-04-15T19:52:52.297785","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"С помощью известных вам методов поиска выбросов (например, DBSCAN) попытайтесь найти выбросы среди изображений, используя все варианты дескрипторов. Подберите параметры алгоритма.\n\nВизуализируйте изображения, попавшие в раздел выбросов, и попробуйте проинтерпретировать полученные результаты. Подумайте, почему именно эти изображения попали в выбросы.\n\nСравните результаты для всех вариантов дескрипторов. Какой вариант дескрипторов даёт наилучшее представление о выбросах?\n\n","metadata":{"id":"0c52076e","papermill":{"duration":0.00677,"end_time":"2023-04-15T19:52:52.318559","exception":false,"start_time":"2023-04-15T19:52:52.311789","status":"completed"},"tags":[]}},{"cell_type":"code","source":"desc.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\nfrom sklearn.cluster import DBSCAN\n\ndb = DBSCAN(eps=2)\n\ndb.fit(pd.DataFrame(desc))\n\nprint(dict(Counter(db.labels_)))","metadata":{"id":"04186e9e","papermill":{"duration":0.006916,"end_time":"2023-04-15T19:52:52.332826","exception":false,"start_time":"2023-04-15T19:52:52.325910","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Выводы и оформление проекта","metadata":{"id":"1247b4f3","papermill":{"duration":0.007285,"end_time":"2023-04-15T19:52:52.347417","exception":false,"start_time":"2023-04-15T19:52:52.340132","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"На основе результатов, полученных при выполнении проекта, сделайте вывод по задаче, приведя таблицу со сравнением результатов кластеризации на каждом из наборов дескрипторов. Приведите сравнение вариантов предобработки исходных данных по качеству кластеризации.\n\nРезультатом вашей работы должно стать небольшое исследование, в котором вы даёте команде IntelliVision рекомендации, какие дескрипторы, с какой предобработкой и каким алгоритмом кластеризации лучше всего подходят для решения задачи.\n\nТакже сохраните результаты лучшего алгоритма в CSV-файл со столбцами path (путь до изображения) и cluster (номер кластера). В описании к проекту приведите расшифровку каждого из кластеров.\n\nКогда вы закончите выполнять проект, создайте в своём репозитории файл README.md и кратко опишите содержание проекта по принципу, который мы приводили ранее.\n\nВыложите свой проект на GitHub и оформите удалённый репозиторий, добавив в него описание и теги (придумайте их самостоятельно в зависимости от того, какую задачу вы решали).","metadata":{"id":"ccc9f559","papermill":{"duration":0.007683,"end_time":"2023-04-15T19:52:52.362485","exception":false,"start_time":"2023-04-15T19:52:52.354802","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"id":"1d27262f","papermill":{"duration":0.006773,"end_time":"2023-04-15T19:52:52.376773","exception":false,"start_time":"2023-04-15T19:52:52.370000","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}
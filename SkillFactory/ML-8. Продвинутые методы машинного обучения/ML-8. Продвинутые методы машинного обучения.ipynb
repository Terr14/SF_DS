{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ML-8. Продвинутые методы машинного обучения**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ В прошлом модуле мы научились важному этапу в разработке модели — поиску оптимальных гиперпараметров. Этот этап важен для получения лучшего качества модели. \n",
    "\n",
    "В этом модуле мы поговорим о способах ансамблирования и сбора в пайплайн как о дальнейшем шаге развёртывания модели. Дальнейшим этапом в освоении профессии дата-сайентиста станет погружение в тематику задач и основных методов решения задач **metric learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## АНСАМБЛИРОВАНИЕ МОДЕЛЕЙ\n",
    "\n",
    "При изучении Data Science идея ансамблирования впервые встречается при упоминании такой модели, как **случайный лес**. В данной модели обучаются базовые модели, представленные решающими деревьями,  предсказания которых впоследствии агрегируются некоторым образом, зависящим от задачи. В случае задачи регрессии берётся среднее либо средневзвешенное. В случае задачи классификации класс присваивается по принципу большинства. \n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/67a412a1866884f5928f98e5781cfec3/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dspr-ml-8-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот знакомый нам подход построения ансамбля называется **бэггингом** и позволяет улучшить качество предсказания. Однако существуют и другие техники ансамблирования, которым и посвятим часть модуля.\n",
    "\n",
    "## PIPELINE\n",
    "\n",
    "Как известно, любая задача классического машинного обучения сводится к этапам обработки данных с последующей генерацией признаков. Позднее признаки отбираются и подаются на модель, которую в свою очередь обучают и настраивают, находя оптимальные гиперпараметры. Качество модели проверяют с помощью методов валидации (например, **кросс-валидации**). \n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/69e171db9504de109deb18b06242a056/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Процесс автоматического поэтапного выполнения манипуляций с данными, включающий в себя сбор, обработку, генерацию и отбор признаков, обучение модели с последующей её настройкой и проверкой качества называется **пайплайном**. \n",
    "\n",
    "Также  под пайплайном иногда подразумевают автоматизацию одного или нескольких этапов, названных ранее, например обработку данных. \n",
    "\n",
    "В этом модуле мы рассмотрим, для чего стоит использовать пайплайны, а также познакомимся с базовыми подходами по созданию пайплайнов на базе библиотеки scikit-learn.\n",
    "\n",
    "## METRIC LEARNING\n",
    "\n",
    "Любые подходы в машинном обучении, которые требуют измерения расстояния между объектами в выборке, являются подходами **metric learning**. Основными задачами, решаемыми подходами metric learning, наряду с классическими задачами обучения с учителем, являются задача **кластеризации** и задача **понижения размерности**. Также metric learning иногда используется в задачах восстановления данных по принципу нахождения ближайшего похоже объекта.\n",
    "\n",
    "В этом модуле мы научимся применять на практике основные методы и подходы metric learning, в частности **kNN, k-means**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЦЕЛИ МОДУЛЯ\n",
    "\n",
    "Целями модуля являются:\n",
    "\n",
    "✔️ Научиться самостоятельно ансамблировать различными методами модели для повышения качества предсказаний.\n",
    "\n",
    "✔️ Освоить практические методы создания пайплайнов и создать свой.\n",
    "\n",
    "✔️ Применить подходы metric learning на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ансамблирование: бэггинг, случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Основным подходом для улучшения качества слабых и нестабильных моделей является обучение моделей для решения одной и той же поставленной задачи с последующим объединением и получением некоторого более сильного и стабильного консенсус-решения.  Как мы знаем, модели, используемые для ансамблирования, называются **базовыми**.\n",
    "\n",
    "[→ Скачайте ноутбук с кодом](https://lms.skillfactory.ru/assets/courseware/v1/7699e6679ca8749f3e5bc78cc40fb40e/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/ML-8._Ensembles.ipynb)\n",
    "\n",
    "Существует три основных способа построения ансамблей:\n",
    "\n",
    "**Бэггинг** — параллельно обучаем множество одинаковых моделей, а для предсказания берём среднее по предсказаниям каждой из моделей.\n",
    "\n",
    "**Бустинг** — последовательно обучаем множество одинаковых моделей, где каждая новая модель концентрируется на тех примерах, где предыдущая допустила ошибку.\n",
    "\n",
    "**Стекинг** — параллельно обучаем множество разных моделей, отправляем их результаты в финальную модель, и уже она принимает решение. \n",
    "\n",
    "> **Бэггинг (bagging)** — алгоритм построения ансамбля путём параллельного обучения множества независимых друг от друга моделей.\n",
    "\n",
    "Самым распространённым примером ансамбля типа бэггинг является уже знакомый нам **случайный лес** (Random Forest). \n",
    "\n",
    "Вам уже известно, что случайный лес является ансамблем решающих деревьев, в котором выборка выбирается посредством бутстрапа. Далее каждое решающее дерево обучается на случайной подвыборке из признакового пространства. Иными словами, случайный лес содержит в себе две случайности: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обучения отдельные решающие деревья объединяются в ансамбль. Ранее мы узнали, что в случайном лесу для задачи **классификации** ансамблирование происходит посредством большинства голосов (Majority Vote). Для задачи **регрессии** же ансамблирование происходит посредством усреднения результата предсказания каждой базовой модели (Averaging).\n",
    "\n",
    "Давайте рассмотрим это на примере. \n",
    "\n",
    "Для задачи регрессии ансамблирование решения 10 случайных деревьев есть не что иное, как среднее значение предсказаний данных моделей. Пускай вектор ответов моделей равен out = [0.5, 0.6, 0.2, 0.4, 0.9, 1.0, -0.5, 0.3, 0.2, 0.0]. \n",
    "\n",
    "Посчитаем среднее значение: \n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/108d9322eaadc994332c3f9494b07670/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-50.png)\n",
    "\n",
    "Итак, среднее значение вектора out равно 0.36, что и является предсказанием случайного леса.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/42662ce6e6df7bda5ff3de6115a67abf/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍️ Давайте проверим на практике, что случайный лес улучшает предсказание случайного дерева. \n",
    "\n",
    "Для этого возьмём [датасет по решению задачи на прогрессирование диабета](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset). Мы будем предсказывать уровень прогрессирования болезни относительно базового уровня (некоторая численная мера, насколько «сильно» болен пациент диабетом). Минимальное значение составляет 25, максимальное — 346. Далее посмотрим на распределение, чтобы убедиться, что это не многоклассовая классификация, данные нормированы и закодированы категориальным кодировщиком. \n",
    "\n",
    "Качество будем измерять по среднему квадрату ошибки (MSE) на кросс-валидации с точностью до второго знака после запятой. \n",
    "\n",
    "Для чистоты эксперимента возьмём решающее дерево с глубиной 10 (DecisionTreeRegressor) и случайный лес из 10 деревьев (параметр n_estimators) с глубиной 10 (RandomForestRegression). Предлагается исполнить код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019907 -0.017646   151.0  \n",
       "1 -0.039493 -0.068332 -0.092204    75.0  \n",
       "2 -0.002592  0.002861 -0.025930   141.0  \n",
       "3  0.034309  0.022688 -0.009362   206.0  \n",
       "4 -0.002592 -0.031988 -0.046641   135.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = load_diabetes(as_frame=True)\n",
    "X = data['frame']\n",
    "y = data['target']\n",
    " \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность обучающей выборки (296, 11)\n",
      "Размерность тестовой выборки (146, 11)\n",
      "Качество предсказания по MSE для решающего дерева 4.06\n",
      "Качество предсказания по MSE для случайного леса  1.84\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    " \n",
    "print(f'Размерность обучающей выборки {X_train.shape}')\n",
    "print(f'Размерность тестовой выборки {X_test.shape}')\n",
    "#Размерность обучающей выборки (296, 11)\n",
    "#Размерность тестовой выборки (146, 11)\n",
    " \n",
    "regr1 = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "regr1.fit(X_train, y_train)\n",
    "##DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    " \n",
    "regr2 = RandomForestRegressor(max_depth=10, n_estimators=10, random_state=42)\n",
    "regr2.fit(X_train, y_train)\n",
    "##RandomForestRegressor(max_depth=10, n_estimators=10, random_state=42)\n",
    " \n",
    "y_pred1 = regr1.predict(X_test)\n",
    "y_pred2 = regr2.predict(X_test)\n",
    " \n",
    "print(f'Качество предсказания по MSE для решающего дерева {round(mean_squared_error(y_test, y_pred1),2)}')\n",
    "print(f'Качество предсказания по MSE для случайного леса  {round(mean_squared_error(y_test, y_pred2),2)}')\n",
    "\n",
    "#вывод: Качество предсказания по MSE для решающего дерева 4.09\n",
    "#Качество предсказания по MSE для случайного леса  1.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐️ На примере случайного леса мы убедились, что качество базовой модели улучшают даже простейшие методы ансамблирования моделей, основанные на бутстрапе, такие как усреднение (Averaging) и голосование большинством (Majority Vote).\n",
    "\n",
    "Давайте разберёмся, почему ансамблирование моделей улучшает качество. Дело в том, что идея ансамблирования основана на уменьшении разброса предсказаний модели.  \n",
    "\n",
    "Доказано, что дисперсия ансамбля типа бэггинг (variance) в  раз меньше, чем смещение отдельной базовой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Доказательство**\n",
    "\n",
    "Выберем из нашей выборки $X$ бутстрапом $K$ раз выборку длиной $N$. Получим выборки $X_{1}, X_{2}, ..., X_{K}$. Обучим базовые модели $a(x)$ на данных подвыборках. Первую модель $a_{1}(x) = a(x,X_{1})$ обучим на первой выборке бутстрапа, вторую $a_{2}(x) = a(x,X_{2})$ — на второй и так далее. Выполнив данную процедуру  раз, мы получим предсказание как усреднение по всем обученным на подвыборках моделях.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/eeae6ae8e03e184ff94a533a020c1a73/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-58.png)\n",
    "\n",
    "Теперь рассмотрим изменение смещения (bias) и разброса (variance) ансамблирования по отношению к базовым моделям.\n",
    "\n",
    "> **Смещение** (bias) есть не что иное, как математическое ожидание разности между истинными ответами y и предсказаниями ансамбля: \n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/0010efcbd8914782f96e32442230250f/asset-v1:SkillFactory+DST-3.0\n",
    "+28FEB2021+type@asset+block/dst-3-ml-8-51.png)\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c742c46100695e837ba46566856184cb/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-52.png)\n",
    "\n",
    "Вывод: смещение ансамбля равно смещению базовой модели ансамбля!\n",
    "\n",
    "Разброс (variance, обозначим далее как ) — это дисперсия ответов алгоритма:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3d239a00c5d9d71aec09651f109a150f/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-53.png)\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c704097ba958bf98bb20e2aa7bbac971/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-54.png)\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/bc1b9ab29110bd4e40c3d2b1f947fbf1/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-55.png)\n",
    "\n",
    "При условии некоррелированности базовых моделей, которая достигается за счёт обучения на бустрапе, последнее слагаемое равно нулю. Итого:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/1781bfac94b0757870c894169fbe2e0b/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-56.png)\n",
    "\n",
    "Тогда, зная, что модели не коррелированы, получаем:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/7c8d37f4978d49117ffa159ebaf2c527/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-57.png)\n",
    "\n",
    "**Вывод**: разброс ансамбля уменьшается в  раз по сравнению с разбросом базовой модели!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта методика ансамблирования применима не только к одинаковым моделям (например к решающим деревьям), но и к любым другим моделям. Главное — чтобы базовые модели были максимально нескоррелированы. Такую методику часто используют в соревновательном Data Science на различных хакатонах и Kaggle-контестах. \n",
    "\n",
    "⭐️ В этом юните мы разобрали и научились применять на практике методы, лежащие в основе ансамблирования в случайном лесу. О более сложных методах поговорим в следующих юнитах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.6\n",
    "\n",
    "Одним из самых важных параметров, который непосредственно отвечает за переобучение и недообучение в деревьях, является глубина дерева. Предлагается используя код из модуля попытаться добиться неообучения для решающего дерева и случайного леса. Для этого:\n",
    "\n",
    "Используя код из модуля, поставьте глубину деревьев в решающем дереве и случайном лесу, равную 2.\n",
    "\n",
    "В качестве ответа приведите MSE решающего дерева и случайного леса (по модулю), округлённую до второго знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для решающего дерева 397.47\n",
      "Качество предсказания по MSE для случайного леса  303.12\n"
     ]
    }
   ],
   "source": [
    "regr3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "regr3.fit(X_train, y_train)\n",
    " \n",
    "regr4 = RandomForestRegressor(max_depth=2, n_estimators=10, random_state=42)\n",
    "regr4.fit(X_train, y_train)\n",
    " \n",
    "y_pred3 = regr3.predict(X_test)\n",
    "y_pred4 = regr4.predict(X_test)\n",
    " \n",
    "print(f'Качество предсказания по MSE для решающего дерева {round(mean_squared_error(y_test, y_pred3),2)}')\n",
    "print(f'Качество предсказания по MSE для случайного леса  {round(mean_squared_error(y_test, y_pred4),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.7\n",
    "\n",
    "Известно, что при большой глубине деревья склонны к переобучению. В данном задании предлагается, используя код и прошлого задания, попытаться искусственно добиться переобучения модели решающего дерева и случайного леса.\n",
    "\n",
    "Используя код из модуля, поставьте глубину деревьев в решающем дереве и случайном лесу, равную 1000.\n",
    "\n",
    "В качестве ответа приведите MSE решающего дерева и случайного леса (по модулю), округлённую до второго знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для решающего дерева 4.06\n",
      "Качество предсказания по MSE для случайного леса 1.84\n"
     ]
    }
   ],
   "source": [
    "regr5 = DecisionTreeRegressor(max_depth=1000, random_state=42)\n",
    "regr5.fit(X_train, y_train)\n",
    " \n",
    "regr6 = RandomForestRegressor(max_depth=1000, n_estimators=10, random_state=42)\n",
    "regr6.fit(X_train, y_train)\n",
    " \n",
    "y_pred5 = regr5.predict(X_test)\n",
    "y_pred6 = regr6.predict(X_test)\n",
    " \n",
    "print(f'Качество предсказания по MSE для решающего дерева {round(mean_squared_error(y_test, y_pred5),2)}')\n",
    "print(f'Качество предсказания по MSE для случайного леса {round(mean_squared_error(y_test, y_pred6),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ансамблирование: блендинг и стекинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Стекинг** (stacking) — алгоритм построения ансамбля, в котором параллельно и независимо друг от друга обучаются несколько базовых моделей (необязательно одной природы), а их предсказания используются для обучения **метамодели** (финальная модель) как факторы.\n",
    "\n",
    "Предсказания базовых алгоритмов называются **метапризнаками**. \n",
    "\n",
    "### БЛЕНДИНГ\n",
    "\n",
    "Простейшая реализация стекинга заключается в блендинге (blending). \n",
    "\n",
    "Схематично блендинг можно представить следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/e6928c858c286dde36c590f57d4d6b66/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-5.png)\n",
    "\n",
    "Суть блендинга состоит в следующем: предположим у нас есть обучающая выборка $X$, которую мы делим пополам. Первая часть используется для обучения базовых моделей, а на второй базовые модели делают предсказания – **метапризнаки**, на которых уже и обучается в дальнейшем метамодель. \n",
    "\n",
    "**Недостатки блендинга** видны невооруженным глазом: ни базовые модели, ни метамодель не обучаются на полных данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СТЕКИНГ\n",
    "\n",
    "Для решения этой проблемы используется усовершенствованная модель блендинга, которая имеет полноценное название — **стекинг**. Идея борьбы с недостатком блендинга — использование **кросс-валидации**.\n",
    "\n",
    "Рассмотрим как обучается классический стекинг. Пусть у нас есть таблица с примерами X и ответами на них y. Количество признаков — $m$, количество наблюдений — $n$, количество моделей в стекинге — $K$.\n",
    "\n",
    "1. Обучающая выборка разбивается на $L$ равных частей, называемых **фолдами**. Например, для трёх фолдов ($L=3$) схематично это будет выглядеть следующим образом:\n",
    "\n",
    "    ![](https://lms.skillfactory.ru/assets/courseware/v1/a8d9de09d8f6a07ac8b04d84fa837454/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-8_1.png)\n",
    "\n",
    "2. Затем для каждой базовой модели эти фолды перебираются следующим образом: на каждом шаге фиксируются $L-1$ фолдов для обучения базовых моделей и один фолд для предсказания (в случае бинарной классификации каждая модель предсказывает вероятность принадлежности к классу 1, в случае мультиклассовой классификации — к каждому классу). В результате будет сформировано $L$ предсказаний, из которых формируется метапризнак $M_j$, где $j$ — номер модели:\n",
    "\n",
    "    ![](https://lms.skillfactory.ru/assets/courseware/v1/c3a923e9a53df27fe9098d747eda6f1f/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-8_2.png)\n",
    "\n",
    "    Такой подход к формированию метапризнаков позволяет избежать переобучения. Действительно, можно рассматривать $L-1$-фолд как обучающую выборку, а оставшийся — как тестовую. Таким образом, мы обучаемся на тренировочной выборке, но предсказания делаем для той выборки, которую ещё не видели.\n",
    "\n",
    "3. После того как мы проделаем шаг 2 для всех базовых моделей, мы получим новый набор данных, состоящий из $K$ метапризнаков — предсказаний каждой из моделей. Предсказания моделей будут использоваться в качестве метапризнаков, на которых будет обучена метамодель.\n",
    "\n",
    "    Пусть мы взяли три разных модели, т. е. $K=3$. Это будет выглядеть следующим образом:\n",
    "\n",
    "    ![](https://lms.skillfactory.ru/assets/courseware/v1/b7b2bde8db3159532ee0042b395858a6/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-8_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Кроме метафакторов, метамодель может использовать для своего обучения изначальные признаки из исходного набора данных.\n",
    "\n",
    "Давайте посмотрим, как работает алгоритм на конкретной таблице. Пусть у нас есть некоторый набор данных из четырёх признаков, характеризующих клиента (x_0, x_1, x_2 и x_3), и восемь наблюдений. На основе этих признаков необходимо предсказать бинарный целевой признак (y) покупки товара со значениями 1 (купил) и 0 (не купил). Будем использовать стекинг, состоящий из трёх различных моделей.\n",
    "\n",
    "Разбиваем выборку на четыре фолда, то есть в каждом фолде будет по две строки таблицы (обозначены цветом). Обучаем каждую модель на трёх из этих фолдов и делаем предсказание вероятности покупки для оставшегося.\n",
    "\n",
    "Из предсказаний будет сформировано три метапризнака (по одному на каждую базовую модель). Это будут предсказанные базовыми классификаторами вероятности покупки (вероятность принадлежности к классу 1).\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/de1cba156b331d27e229eec3ec107819/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-8_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формируем новый набор данных и отправляем его в метамодель, которая уже и делает финальное предсказание целевого признака покупки:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/476d2d3365cad4c4b9cf2738ef982ca4/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-8_5.png)\n",
    "\n",
    "Метамодель будет производить поиск зависимостей в данных и принимать решение уже на основе предсказанных вероятностей покупки, которые были получены на первом этапе. \n",
    "\n",
    "В общем случае, когда у нас есть $K$ моделей, общая схема стекинга будет иметь вид:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/bbe06be5289a83d9300f7d073f4ad468/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-8_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно понимать, стекинг — это чистая эвристика, эффективность которой доказана только практическим применением. Стекинг использует тот же подход, что и нейронные сети: предсказания предыдущего этапа (слоя) используются в качестве признаков для следующего этапа (слоя).\n",
    "\n",
    "С точки зрения смещения и разброса, стекинг не имеет прямой математической интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, но гарантий уменьшения смещения или разброса нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть некоторые **рекомендации, как правильно строить стекинг**:\n",
    "\n",
    "* В качестве метамоделей лучше всего применять простые модели: например, для задачи регрессии — линейную регрессию, а для задачи классификации — логистическую регрессию.\n",
    "* В качестве базовых моделей лучшего всего использовать модели различной природы.\n",
    "\n",
    "Из всех ансамблевых методов стекинг применяется реже всего. Главная причина: так как используется много разных моделей, необходимо подбирать их внешние параметры (коэффициенты регуляризации, глубина деревьев, число деревьев, темп обучения и т. д.) в совокупности, а подбор огромного количества параметров очень затратен по времени (мы убедились в этом в модуле по подбору внешних параметров моделей).\n",
    "\n",
    "Вторая причина — в отличие от бэггинга и бустинга, для стекинга нет каких-то готовых решений, таких как случайный лес и градиентный бустинг над деревьями. Базовые модели нужно подбирать самому, а какие из них подойдут лучше всего — открытый вопрос.\n",
    "\n",
    "Но, несмотря на эти недостатки, при грамотном подходе опытные специалисты выигрывают соревнования на Kaggle благодаря стекингу. Хотя зачастую таких участников называют «читерами» (от англ. cheat — «жульничать, обманывать»), ведь часто они собирают чуть ли не все возможные ML-модели в стекинг, запускают на мощном сервере подбор внешних параметров и комбинации из этих моделей в стекинге получают заветные 1.5 % прироста качества модели. На Kaggle даже существует фраза — «настекали».\n",
    "\n",
    "В реальных условиях такой прирост значит мало, поэтому мы не будем концентрироваться на стекинге в нашем курсе, но пример разберём."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СТЕКИНГ В SKLEARN\n",
    "\n",
    "Стекинг для задачи регрессии имеет реализацию в библиотеке scikit-learn в классе StackingRegressor, для задачи классификации — в классе StackingClassifier. На вход подаётся список базовых моделей (атрибут estimators) и метамодель (атрибут final_estimator).\n",
    "\n",
    "**Примечание**. Стоит понимать, что для задачи регрессии все базовые модели должны быть регрессорами, а для задачи классификации — классификаторами.  \n",
    "\n",
    "Попробуем на практике применить стекинг, используя реализацию из библиотеки sklearn. В качестве входных данных будем использовать данные про диабет, использованные ранее. Обратимся снова к коду и обучим модель на данных.\n",
    "\n",
    "Как и все ансамбли, модель стекинга находится в модуле ensemble.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры StackingRegressor:\n",
    "\n",
    "* estimators — список из кортежей базовых моделей в виде (str, model). Первым элементом в каждом кортеже идет строка с именем модели, вторым — собственно сама модель.\n",
    "* final_estimator — метамодель.\n",
    "* cv — количество фолдов, на которые делится выборка. По умолчанию используется пять фолдов.\n",
    "\n",
    "Будем строить стекинг на следующих моделях:\n",
    "\n",
    "* 'dt' — дерево решений;\n",
    "* 'lr' — ридж-регрессия, линейная модель регрессии с L2-регуляризацией;\n",
    "* случайный лес с количеством деревьев, равным 10, в качестве метамодели.\n",
    "\n",
    "**Примечание**. В данном случае мы рассматриваем **RidgeCV**, которая представляет собой ридж-регрессию со встроенной кросс-валидацией по методу **Leave-One-Out Cross-Validation**. Подробнее читайте по [ссылке](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html).\n",
    "\n",
    "Создадим список кортежей в формате (\"наименование модели\", модель) из этих моделей, и назовем его estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем список кортежей вида: (наименование модели, модель)\n",
    "estimators = [\n",
    "    ('lr', RidgeCV()),\n",
    "    ('dt',  DecisionTreeRegressor(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда список из базовых моделей готов, создадим объект класса StackingRegressor. Первым аргументом передаём список из базовых моделей. Будем использовать в качестве метамодели модель случайного леса. Для этого передаём её в параметр final_estimator. Остальные параметры оставим по умолчанию.\n",
    "\n",
    "Обучаем модель с помощью метода fit(), делаем предсказание классов с помощью метода predict(), а затем считаем метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;lr&#x27;, RidgeCV()),\n",
       "                              (&#x27;dt&#x27;, DecisionTreeRegressor(random_state=42))],\n",
       "                  final_estimator=RandomForestRegressor(n_estimators=10,\n",
       "                                                        random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;lr&#x27;, RidgeCV()),\n",
       "                              (&#x27;dt&#x27;, DecisionTreeRegressor(random_state=42))],\n",
       "                  final_estimator=RandomForestRegressor(n_estimators=10,\n",
       "                                                        random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeCV</label><div class=\"sk-toggleable__content\"><pre>RidgeCV()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('lr', RidgeCV()),\n",
       "                              ('dt', DecisionTreeRegressor(random_state=42))],\n",
       "                  final_estimator=RandomForestRegressor(n_estimators=10,\n",
       "                                                        random_state=42))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создаем объект класса стекинг\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                          random_state=42)\n",
    ")\n",
    " \n",
    "#Обучаем модель\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для стекинга 0.82\n"
     ]
    }
   ],
   "source": [
    "y_pred_stack = reg.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для стекинга {round(mean_squared_error(y_test, y_pred_stack),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотреть на метапризнаки можно с помощью метода **transform()**. Для этого в метод нужно передать матрицу наблюдений X. В результате вызова метода для всех объектов каждая из трёх моделей сделает предсказание вероятностей и вернёт матрицу из двух столбцов. Оформим её в виде DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_feature1</th>\n",
       "      <th>meta_feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.000001</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.000002</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.000007</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122.000005</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meta_feature1  meta_feature2\n",
       "0     154.000000          154.0\n",
       "1     192.000001          192.0\n",
       "2     116.000002          116.0\n",
       "3      81.000007           81.0\n",
       "4     122.000005          122.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data = reg.transform(X_train)\n",
    "#Создаем DataFrame\n",
    "meta_df = pd.DataFrame(\n",
    "    meta_data, #содержимое таблицы\n",
    "    columns=['meta_feature1', 'meta_feature2',] #название столбцов\n",
    ")\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Наша таблица метапризнаков, на которой происходит обучение метамодели случайного леса. \n",
    "\n",
    "Примечание. При желании к метапризнакам можно добавить столбцы из изначального набора данных и попробовать обучить модель на этом наборе данных.\n",
    "\n",
    " ⬇️ Мы рассмотрели основные принципы работы стекинга и его реализацию в sklearn. Попробуйте применить стекинг для решения следующей задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.5\n",
    "\n",
    "Для выполнения задания используйте набор данных о диабете, который представлен в ноутбуке с примерами.\n",
    "\n",
    "Постройте стекинг из следующих базовых моделей:\n",
    "\n",
    "* Ридж-регрессия (RidgeCV());\n",
    "* Линейная регрессия.\n",
    "\n",
    "В качестве метамодели используйте случайный лес с количеством деревьев 100, максимальной глубиной 10, все параметры для базовых моделей стандартные. Для всех алгоритмов параметр random_state=42.\n",
    "\n",
    "Сделайте предсказание целевой метки для тестового набора данных. Рассчитайте метрику MSE для набора данных и запишите её в качестве ответа с точностью до двух знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем список кортежей вида: (наименование модели, модель)\n",
    "estimators = [\n",
    "    ('lr', RidgeCV()),\n",
    "    ('dt',  LinearRegression())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;lr&#x27;, RidgeCV()), (&#x27;dt&#x27;, LinearRegression())],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=10,\n",
       "                                                        random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;lr&#x27;, RidgeCV()), (&#x27;dt&#x27;, LinearRegression())],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=10,\n",
       "                                                        random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeCV</label><div class=\"sk-toggleable__content\"><pre>RidgeCV()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('lr', RidgeCV()), ('dt', LinearRegression())],\n",
       "                  final_estimator=RandomForestRegressor(max_depth=10,\n",
       "                                                        random_state=42))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создаем объект класса стекинг\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=100,\n",
    "                                          max_depth=10,\n",
    "                                          random_state=42)\n",
    ")\n",
    " \n",
    "#Обучаем модель\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для стекинга 0.27\n"
     ]
    }
   ],
   "source": [
    "y_pred_stack = reg.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для стекинга {round(mean_squared_error(y_test, y_pred_stack),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ансамблирование: бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Последней реализацией ансамблирования, которую мы рассмотрим, станет бустинг. Этот метод отличается от предыдущих своей структурой. \n",
    "\n",
    "> **Бустинг (boosting)** — это алгоритм построения ансамбля, основанный на последовательном построении слабых моделей, причём каждая новая модель пытается уменьшить ошибку предыдущей. После того как все модели обучены, они объединяются в композицию.\n",
    "\n",
    "Примечание. Под слабыми моделями мы подразумеваем модели, точность которых немногим выше, чем случайное угадывание. Как правило, это короткие деревья решений, они обладают слабой предсказательной способностью.\n",
    "\n",
    "Обратите внимание, что в бустинге базовые модели обучаются последовательно, а не параллельно, как в предыдущих методах, исправляя ошибки своего «предшественника»  и повышая качество всего ансамбля. \n",
    "\n",
    "Бустинг основан на вопросе, поднятом исследователями [М. Кернсом](https://en.wikipedia.org/wiki/Michael_Kearns_(computer_scientist)) и [Л. Вэлиантом](https://ru.wikipedia.org/wiki/%D0%92%D1%8D%D0%BB%D0%B8%D0%B0%D0%BD%D1%82,_%D0%9B%D0%B5%D1%81%D0%BB%D0%B8): «Может ли набор слабых обучающих алгоритмов создать сильный обучающий алгоритм?»\n",
    "\n",
    "В отличие от бэггинга, бустинг обучается на одном и том же наборе данных, без генерации дополнительных выборок. Однако в процессе обучения меняются так называемые **веса наблюдений**. Если слабая модель допустила ошибку на каких-то примерах, то значимость (вес) этих примеров увеличивается и на них концентрируется следующая за ней модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представить алгоритм бустинга можно следующей схемой:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/f57e9e2fc278d940a8a1074e62b904f3/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-7_1.png)\n",
    "\n",
    "На схеме  представлено 11 разных наблюдений трёх различных классов (красные, зелёные и синие шарики). После того как модель делает предсказания, мы смотрим, на каких объектах мы угадали класс верно, а на каких ошиблись. Для тех объектов, на которых мы допустили ошибку, мы задаём больший вес. Вес наблюдения обозначается интенсивностью цвета. Чем больше вес наблюдения, тем ярче его цвет.\n",
    "\n",
    "Так же как и бэггинг, бустинг предназначен для обучения моделей одного типа. То есть нельзя последовательно обучить 50 логистических регрессий, а затем 50 деревьев решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая модель создаётся для того, чтобы найти ошибки предыдущей. Сами по себе они решают задачу плохо, но стоит объединить их усилия, и мы получим супермодель.\n",
    "\n",
    "Очень наглядно будет выглядеть модель бустинга для логистической регрессии при обучении на двух признаках:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/46bb0f960392c6a39fcf52d6da588054/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-7_2.png)\n",
    "\n",
    "На рисунке изображено расположение двух линейно неразделимых классов. Нельзя провести одну такую плоскость, которая идеально решает задачу классификации. Раз нельзя одну, давайте проведём две.\n",
    "\n",
    "Возьмём точки, для которых первая логистическая регрессия совершила ошибку. Увеличим вес этих точек (их значимость). Далее построим такую разделяющую плоскость, которая в первую очередь обращает внимание на наблюдения, имеющие наибольший вес."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, объединим две модели в одну — получим модель-композицию, которая идеально решает задачу классификации!\n",
    "\n",
    "**Примечание**. Когда все модели из ансамбля обучены и составлена композиция из них, для того, чтобы совершить предсказание на новом объекте, необходимо «прогнать» характеристики объекта через все модели в той же последовательности, в которой они обучались, и объединить их результат.\n",
    "\n",
    "Если бэггинг создавался с целью уменьшить разброс модели, то **цель бустинга** — уменьшить смещение модели.\n",
    "\n",
    "Каждый следующий базовый алгоритм в бустинге обучается так, чтобы уменьшить общую ошибку всех своих предшественников. Как следствие, итоговая композиция будет иметь меньшее смещение, чем каждый отдельный базовый алгоритм (хотя уменьшение разброса также может происходить).\n",
    "\n",
    "В предельном случае модель может обучиться так, что не будет допускать ошибок вовсе. Однако мы знаем, что это не всегда хорошо, ведь в таком случае модель может полностью подстроиться под обучающий набор данных и переобучиться.\n",
    "\n",
    "Поскольку основная цель бустинга — уменьшение смещения, в качестве базовых моделей часто выбирают **алгоритмы с высоким смещением и небольшим разбросом**, например короткие деревья решений. У каждого из таких деревьев слабая предсказательная способность, но если их объединить, мы получим очень мощную модель. \n",
    "\n",
    "В этом юните мы постараемся затронуть основные шаги эволюции бустинга от первой успешной модели до современных модификаций. Начнём рассмотрение с самой первой модели бустинга — **адаптивного бустинга**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## АДАПТИВНЫЙ БУСТИНГ \n",
    "\n",
    "Первая реализация бустинга называлась AdaBoost. Это модель, которая подразумевает воплощение той самой идеи взвешивания объектов, которую мы рассмотрели выше. Алгоритм предполагает постоянную модификацию объектов выборки путём их взвешивания, причём веса обновляются специальным образом: каждая новая модель из ансамбля обучается на взвешенных данных и обращает большее внимание на ошибки своих предшественников.\n",
    "\n",
    "Так как алгоритм является несовершенным и в дальнейшем получил свое развитие, мы не будем подробно останавливаться на его работе. Однако приведем краткое описание работы алгоритма на примере задачи **бинарной классификации**. \n",
    "\n",
    "Пусть у нас есть набор данных $X$, в котором $N$ объектов размерности $m$ (вектора в признаковом пространстве размера $M$) и метки класса $y \\in  {-1,1}$, где -1 и 1 — метки отрицательного и положительного класса соответственно.\n",
    "\n",
    "Будем строить ансамбль из  абстрактных базовых моделей — классификаторов. Обозначим их как  (это могут быть логистические регрессии/деревья решений или что-то ещё).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Перед обучением базовой модели мы инициализируем веса объектов обучающей выборки следующим образом: $w_j = \\frac{1}{N}, \\, j=1,2,\\dots,N$\n",
    "2. Для всех $i$ от $1$ до $K$:\n",
    "\n",
    "1. Обучить базовую модель $a_{i}(x)$ с учётом весов объектов $w_{j}$.\n",
    "\n",
    "2. Вычислить ошибку классификатора $a_{i}(x)$, обозначим её за :\n",
    "\n",
    "\n",
    "\n",
    "    Примечание. Здесь выражение $[y_{j} \\neq a_{i}(x_{j})]$ — это знакомая нам по модулю классификации индикаторная функция. Она равна 1, если ответ $y_i$ не совпал с предсказанием базовой модели $a_{i}(x_{j})$, и 0 — в противном случае.\n",
    "\n",
    "3. Тогда вес предсказаний данного классификатора (мера «вклада» предсказаний -ой модели в общий ансамбль) вычисляется по формуле: $n_{i} = \\frac{1}{2}ln (\\frac{1 - e_{i}}{e_{i}})$\n",
    "\n",
    "    Формула веса становится нулевой только при **случайном угадывании**, то есть когда классификатор ошибается в половине меток — работает ровно так же, как и подбрасывание монетки. Однако остальные будут вносить вес в итоговую модель с положительным или отрицательным знаком (в этом легко убедиться, подставив вероятность ошибки, отличную от 0.5). Тем самым мы исключаем возможность вклада случайных классификаторов в результирующую модель.\n",
    "\n",
    "4. Обновляем веса объектов в выборке. Для тех объектов, на которых мы допустили ошибку, вес увеличивается; для тех объектов, для которых наш ансамбль предсказал верный ответ — не изменяется. Формула обновления весов:\n",
    "\n",
    "    ![](https://lms.skillfactory.ru/assets/courseware/v1/8fd37ebf163d92d4f96f358e6b37a414/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-60.png)\n",
    "\n",
    "    Видно, что если классификация была произведена верно для объекта $x_j$, то степень экспоненты будет равна 0, а значит множитель $e^{-n_{j}[y_{j}\\neq a_{i}(x_{j}]}=1$ и вес $w_{j}$ не изменится. \n",
    "\n",
    "    Для того, чтобы привести все веса объектов к единому масштабу от 0 до 1, производится их нормировка путем деления каждого веса  на сумму всех весов:\n",
    "\n",
    "    ![](https://lms.skillfactory.ru/assets/courseware/v1/a5a60869b39154a53ff4da9ec785b530/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-3-ml-8-61.png)\n",
    "\n",
    "5. После обучения каждой базовой модели предсказания ансамбля строятся как сумма из предсказаний базовых моделей, взятых с весом $\\eta_{i}$:  \n",
    "        \n",
    "    $f(x) = sign (\\sum_{i = 1}^{N} \\eta_{i}a_{i}(x))$.\n",
    "\n",
    "    **Примечание**. Функция $sign$ — функция взятия знака, принимает значение -1, если аргумент функции отрицательный, 0 — если аргумент функции нулевой, и 1 — если аргумент функции положительный.\n",
    "\n",
    "    $sign(x) = \\left\\{\\begin{matrix} 1,x > 0 \\\\ 0, x = 0 \\\\ -1, x < 0 \\end{matrix}\\right.$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В чём плюсы такого алгоритма?**\n",
    "\n",
    "✔️ Он прост. Обратите внимание: все математические операции — школьный курс математики, о высшей математике даже не идёт речи. Операции просты в реализации и не требуют вычисления производных, умножений матриц и прочих сложных математических конструкций.\n",
    "\n",
    "✔️ Накладные расходы бустинга минимальны. Время построения определяется временем построения базовых моделей.\n",
    "\n",
    "✔️ Показывает хорошую обобщающую способность.\n",
    "\n",
    "✔️ Имеет возможность идентификации шумовых объектов.\n",
    "\n",
    "**Но в чём минусы?**\n",
    "\n",
    "⛔️ Жадное добавление алгоритмов приводит к неоптимальности композиции.\n",
    "\n",
    "⛔️ Склонен к переобучению при наличии шума в данных.\n",
    "\n",
    "⛔️ Алгоритм является эвристикой, и «взвешивание» объектов, на котором он основан, не подкреплено математическим обоснованием."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## АДАПТИВНЫЙ БУСТИНГ В SKLEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn адаптивный бустинг над решающими деревьями реализован в модуле sklearn.ensemble в виде классов [AdaBoostRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html) и [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier) для задач регрессии и классификации соответственно. Давайте проведём обучение на тех же данных, что и в предыдущих моделях ансамблирования — на данных о диабете. \n",
    "\n",
    "Прежде чем перейти к практической части, предлагаем ознакомиться с параметрами AdaBoost:\n",
    "\n",
    "* base_estimator — параметр отвечает за природу базовых моделей, по умолчанию это DecisionTreeRegressor c максимальной глубиной (max_depth) 3.\n",
    "* n_estimators — максимальное количество базовых моделей, по умолчанию равно 50. В случае идеального обучения алгоритм завершается ранее, чем данное значение.\n",
    "* learning_rate — темп обучения, параметр, добавляющий дополнительный множитель весу базовой модели, по умолчанию он равен 1.\n",
    "* loss{'linear', 'square', 'exponential'} — функция ошибки для обновления весов (в теоретической части мы рассматривали экспоненциальную форму обновления весов — 'exponential')\n",
    "* random_state — параметр, фиксирующий случайные процессы в модели.\n",
    "\n",
    "Для сравнимости результатов со случайным лесом возьмём количество базовых моделей, равное 10. Как говорилось ранее, глубина деревьев должна быть меньше, чем у случайного леса. По умолчанию она равна 3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для AdaBoost 40.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "dt = DecisionTreeRegressor(\n",
    "    max_depth=3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada = AdaBoostRegressor(\n",
    "    base_estimator=dt,\n",
    "    random_state=42, \n",
    "    n_estimators=10\n",
    ")\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    " \n",
    " \n",
    "ada_pred  = ada.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для AdaBoost {round(mean_squared_error(y_test, ada_pred),2)}')\n",
    "\n",
    "# Качество предсказания по MSE для AdaBoost 40.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.1\n",
    "\n",
    "Измените количество базовых моделей до 50 и 100. В качестве ответа приведите полученные результаты, округленные до второго знака после запятой. Остальные параметры оставьте неизменными.\n",
    "\n",
    "Качество модели по MSE для 50 базовых моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для AdaBoost 10.41\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostRegressor(\n",
    "    base_estimator=dt,\n",
    "    random_state=42, \n",
    "    n_estimators=50\n",
    ")\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    " \n",
    " \n",
    "ada_pred  = ada.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для AdaBoost {round(mean_squared_error(y_test, ada_pred),2)}')\n",
    "\n",
    "# Качество предсказания по MSE для AdaBoost 40.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для AdaBoost 10.15\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostRegressor(\n",
    "    base_estimator=dt,\n",
    "    random_state=42, \n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    " \n",
    " \n",
    "ada_pred  = ada.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для AdaBoost {round(mean_squared_error(y_test, ada_pred),2)}')\n",
    "\n",
    "# Качество предсказания по MSE для AdaBoost 40.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основное отличие градиентного бустинга от адаптивного заключается в том, что градиентный бустинг строит композицию из своих базовых моделей, подбирая их оптимальным образом на основе принципа градиентных методов оптимизации. Такая модификация позволяет значительно ускорить процесс последовательного построения ансамбля в сравнении с реализации AdaBoost и добиться лучшего качества за счет меньшего количества моделей в ансамбле. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ГРАДИЕНТНЫЙ БУСТИНГ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Градиентный бустинг (Gradient Boosting, GB)** — это наиболее обобщённая версия бустинга, закреплённая математическим обоснованием. Впервые алгоритм был опубликован профессором статистики Стэнфордского университета Джеромом Фридманом. Алгоритм оказался очень эффективным и в дальнейшем был множество раз модифицирован — до Extreme Gradient Boosting ([XgBoost](https://xgboost.readthedocs.io/en/stable/)) и других модификаций, таких как [CatBoost](https://catboost.ai/) от Яндекса и [LightGMB](https://lightgbm.readthedocs.io/en/latest/) от Microsoft.\n",
    "\n",
    "Сейчас градиентный бустинг и его модификации применяются практически везде. Любой запрос на Яндексе, выбор отеля на Booking или сериала на Netflix — всё это работает на градиентном бустинге. \n",
    "\n",
    "→ В этом модуле мы кратко рассмотрим принцип работы, а в модулях по математике разберём математическую формализацию алгоритма. \n",
    "\n",
    "В GB принцип классического бустинга сохраняется: каждый последующий алгоритм улучшает предыдущий, но, в отличие эвристического «взвешивания» наблюдений, градиентный бустинг использует информацию о функции потерь для построения нового алгоритма. \n",
    "\n",
    "Допустим, у нас есть некоторая функция потерь $L(y, \\hat{y})$. Она зависит от двух аргументов: $y$ — истинный ответ, $\\hat{y}=a(x)$ — прогноз модели $a(x)$. Причём неважно, какая это функция потерь (на самом деле ограничение есть — это дифференцируемость функции, то есть существование производной).\n",
    "\n",
    "Для задачи регрессии это может быть, например, MSE:\n",
    "\n",
    "$$L(y, \\hat{y})=-\\frac{1}{n} \\sum_{i}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи классификации это может быть, например, logloss:\n",
    "\n",
    "$$L(y, \\hat{y})=-\\sum_{i}^{n}\\left(y_{i} \\log \\left(\\hat{y}_{i}\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\hat{y}_{i}\\right)\\right)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Для logloss $\\hat{y}_i$ в данном контексте означает не предсказанный класс для -ого наблюдения, а вероятность принадлежности к классу 1 $i$-ого наблюдения, то есть на самом деле $y_i=P_i$. Чистая формальность для идентичности записей для регрессии и классификации.\n",
    "\n",
    "Пусть мы построили какую-то модель, которая решает задачу классификации или регрессии. Обозначим её $a_1(x)$ — это какая-то функция, которая принимает на вход объекты  и выдаёт для них предсказания. Качество такой модели, скорее всего, будет не очень хорошим, ведь мы обучаем слабые модели.\n",
    "\n",
    "Однако мы знаем, на каких объектах модель давала точные предсказания, а на каких — ошибалась. Нужно попробовать использовать эту информацию и обучить ещё одну модель $a_2(x)$.\n",
    "\n",
    "Допустим, мы знаем, что предсказание первой модели на каком-то объекте  на 10 больше, чем в реальности. То есть $a_{1}(x_{i})=y_{i}+10$. То есть нам необходимо обучить следующую модель $a_2(x)$ таким образом, чтобы она предсказала для $x_i$ ответ -10, то есть $a_2(x_i)=-10$. Тогда предсказание идеально совпадает с действительностью:\n",
    "\n",
    "$$a_{1}(x_{i})+a_{2}(x_{i})=y_{i}+10-10=y_{i}$$\n",
    "\n",
    "→ Другими словами, следующая модель должна научиться предсказывать ошибки предыдущей.\n",
    "\n",
    "В реальности вторая модель тоже не сможет обучиться идеально, поэтому обучим третью модель $a_3(x)$, которая будет «компенсировать» неточности первых двух. Будем продолжать так, пока не построим композицию из $K$ алгоритмов.\n",
    "\n",
    "Финальная модель (обозначим её за $f(x)$), ищется в виде композиции из $K$ базовых алгоритмов определённого семейства (например, линейных моделей/деревьев):\n",
    "\n",
    "$$f(x)=\\sum_{k=1}^{K} a_{k}(x)=a_{1}(x)+a_{2}(x)+\\ldots+a_{K}(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Этот подход можно интуитивно представить как игру в гольф. Цель гольфиста — закатить мяч в лунку (для нас это значит с абсолютной точностью предсказать $y$). Гольфист делает свой первый удар, получает новую координату мяча $\\hat{y}_1$ (у нас это ответы алгоритма $a_1(x)$). Следующий удар гольфист производит из положения: $\\hat{y_{1}}=f_{1}(x)=a_{1}(x)$ и снова промахивается. Для нас это значит построить следующий алгоритм $a_2(x)$, который учится предсказывать ошибки предыдущего. После второго удара композиция — новое положение мяча будет равно:\n",
    "\n",
    "$$f_{2}(x) = a_{1}(x) + a_{2}(x)$$\n",
    "\n",
    "Гольфист делает следующий удар $a_3(x)$ из положения: $\\hat{y_{2}}=a_{1}(x)+a_{2}(x)$. Новая координата мяча снова приближается к лунке и становится равной композиции:\n",
    "\n",
    "$$f_{3}(x) = a_{1}(x) + a_{2}(x) + a_{3}(x)$$\n",
    "\n",
    "А затем следует ещё один удар, и ещё один… И так, пока гольфист не попадёт в заветную лунку. А мы продолжаем обучать всё новые и новые модели $a_k(x)$, пока не сделаем идеального предсказания, двигаясь в сторону минимума функции потерь.\n",
    "\n",
    "Финальная композиция, состоящая из K ударов будет равна: \n",
    "\n",
    "$$f(x)=\\sum_{k=1}^{K}{a_k(x)}$$\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/569173e552ccd595bfd01348fbecfc4d/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-7_3.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Немного математического формализма ↓**\n",
    "\n",
    "Пусть на какой-то момент было обучено $k$ алгоритмов, где $k<K$. Итоговая композиция будет иметь вид:\n",
    "\n",
    "$$f_{k}(x) = a_{1}(x) + a_{2}(x) + ... + a_{k}(x)$$\n",
    "\n",
    "Тогда следующее слагаемое, модель $a_{k+1}(x)$ (обозначим её для краткости $b_x$), должна строиться по принципу:\n",
    "\n",
    "$$L(y, f_{k}(x) + b(x)) \\rightarrow min_{b}$$\n",
    "\n",
    "Знакомая запись, не правда ли? Она означает, что нам нужно найти такой алгоритм $b(x)=a_{k+1}(x)$, при котором наблюдается минимум функции потерь.\n",
    "\n",
    "Чтобы построить эту модель $b(x)$, необходимо определить, что она будет пытаться предсказать.\n",
    "\n",
    "Наша новая модель $b(x)$, по сути, должна предсказать вектор-столбец сдвигов (ошибок между истинными $y$ и предсказаниями модели). Посмотрим на задачу под другим углом: **нужно предсказать такой вектор, который двигает предсказания в сторону уменьшения функции ошибки**.\n",
    "\n",
    "Тут на сцену и выходит градиент, а точнее — антиградиент. Пусть мы пока не знаем математических тонкостей, но мы знаем, что этот вектор направлен в сторону убывания функции. Его и будем предсказывать моделью $b(x)$.\n",
    "\n",
    "Допустим, мы каким-то образом рассчитаем этот антиградиент на обучающей выборке $-\\nabla_{f_{k}}L$ (для всех популярных функций потерь уже выведены формулы его расчёта). Это будет просто вектор-столбец из каких-то чисел. Мы умеем предсказывать числа, то есть будем решать задачу регрессии: будем с помощью модели $b(x)$ предсказывать координаты этого вектора антиградиента. Например, можно построить такую модель $b(x)$, чтобы средний квадрат ошибки между её ответами и антиградиентом (MSE) был минимален."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы построим модель $b(x)$, мы добавим её ответы в композицию, но не все сразу, а умножим ответы на коэффициент $\\eta$ — темп обучения. Этот коэффициент влияет на то, какой вклад каждая следующая модель будет оказывать на общую композицию. То есть:\n",
    "\n",
    "$$f_{k+1}(x) = f_{k}(x) + \\eta b(x),$$\n",
    "\n",
    "где $f_k(x)$ — ансамбль, построенный на $$k-ом этапе, $f_{k+1}(x)$ — новый ансамбль, который будет построен на следующем этапе $k+1$.\n",
    "\n",
    "**Примечание**. Если принять, что предсказания $b(x)$ полностью совпадают с антиградиентом $b(x)=-\\nabla_{a_{k}}L$, то получится формула градиентного спуска:\n",
    "\n",
    "$$f_{k+1}(x) = f_{k}(x) - \\eta \\nabla_{f_{k}} L$$\n",
    "\n",
    "Но градиентный спуск происходит не в пространстве параметров, а в пространстве ответов ансамбля $f_k$. Что это за пространство и как в нём считать градиенты, мы обсудим, когда будем разбирать градиентный бустинг подробнее.\n",
    "\n",
    "Сейчас же для нас важно понимать, что каждая новая модель бустинга будет строиться так, чтобы двигать всю композицию вниз по функции потерь — в сторону вектора антиградиента.\n",
    "\n",
    "**Зачем нужен параметр $\\eta$?**\n",
    "\n",
    "Он позволяет избежать переобучения и плавно приближаться к минимуму функции потерь.\n",
    "\n",
    "Например, модель для какого-то $i$-ого наблюдения $b(x)$ предсказала, что ошибка (градиент) будет равна -5. Мы могли бы прибавить к полученным ранее ответам модели $f_k(x)$ эту 5:\n",
    "\n",
    "$$f_{k}(x_{i}) + b(x_{i}) = f_{k}(x_{i}) - 5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но так мы сразу сведём эту ошибку к 0 и подстроимся под обучающую выборку. Поэтому мы прибавляем не 5, а умножаем 5 на небольшое число , например на 0.1:\n",
    "\n",
    "$$f_{k}(x_{i}) + \\eta b(x_{i}) = f_{k}(x_{i}) - 0.5$$\n",
    "\n",
    "Тогда мы будем плавно уменьшать ошибку с каждой новой моделью.\n",
    "\n",
    "Если базовая модель — это дерево решений, то схематично это будет выглядеть следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/2660d015a2887f762013ec1da2b87dcf/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-7_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве базовой модели можно использовать всё что угодно, но общепринятым является использование деревьев решений. Практика показывает, что это наилучший выбор, так как деревья решений очень просты в построении и из всех слабых моделей обладают наилучшей способностью описывать сложные зависимости.\n",
    "\n",
    "> Бустинг, использующий в качестве базовой модели дерево решений, называется **градиентным бустингом над деревьями решений (Gradient Boosting on Decision Trees, GBDT)**. \n",
    "\n",
    "Схематично работу алгоритма GBDT можно представить следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/d041c24e7a23daa059f376cd82343aee/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-7_5.png)\n",
    "\n",
    "Основным преимуществом такой схемы градиентного бустинга является эффективность в поиске нелинейных зависимостей в сравнении с любыми моделями, основанными на решающих деревьях. Это преимущество стало причиной доминирования GBDT на огромном спектре соревнований — от кредитного скоринга до рекомендательных систем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В заключение введения в градиентный бустинг приведём некоторые **рекомендации по выбору внешних параметров алгоритма:**\n",
    "\n",
    "* **Количество деревьев (n_estimators)**. Чем больше деревьев вы берёте, тем меньше ошибка на обучающем наборе данных, вплоть до 0, но, как вы понимаете, тем выше шанс переобучиться. Лучше начинать с небольшого количества моделей (50-100), а затем следить за ошибкой на тестовой выборке.\n",
    "* **Темп обучения  (learning_rate)**. Чем выше темп обучения, тем больше вклад каждого следующего дерева будет в модель и тем быстрее вы сойдётесь к минимуму функции потерь и сведёте ошибку к 0. Однако снова высок риск переобучения. Рекомендуемые значения — от 0.01 до 1.\n",
    "* **Максимальная глубина деревьев (max_depth)**. Градиентный бустинг лучше всего работает со слабыми моделями — это короткие деревья решений с глубиной от 1 до 8.\n",
    "\n",
    "→ Все параметры влияют на обучение комплексно, поэтому их следует подбирать одновременно. О том, какие инструменты для этого существуют, мы поговорим в отдельном модуле.\n",
    "\n",
    "Чтобы понять, как на градиентный бустинг влияют параметры темпа обучения, максимальной глубины деревьев и количества деревьев, предлагаем вам поиграть с настройками градиентного бустинга интерактивной демонстрации [Brilliantly wrong](http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html).\n",
    "\n",
    "Вы можете регулировать следующие параметры:\n",
    "\n",
    "* tree depth — максимальная глубина деревьев;\n",
    "* learning rate — темп обучения;\n",
    "* subsample — процент выборки, отведённый на обучение;\n",
    "* trees — количество деревьев.\n",
    "\n",
    "На демонстрации вы сможете увидеть, как меняется функция ошибки на тренировочной (train loss) и тестовой (test loss) выборках при изменении параметров, а также как меняется вид разделяющей поверхности.\n",
    "\n",
    "Пример:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/36bfee60556351f7853516eb7fd46201/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst3-ml3-7_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ГРАДИЕНТНЫЙ БУСТИНГ В SKLEARN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[→ Скачайте ноутбук с кодом.](https://lms.skillfactory.ru/assets/courseware/v1/7699e6679ca8749f3e5bc78cc40fb40e/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/ML-8._Ensembles.ipynb) Это ноутбук из предыдущего юнита — если вы скачали его ранее, заново скачивать не нужно.\n",
    "\n",
    "Как и все ансамбли, градиентный бустинг находится в модуле ensemble библиотеки sklearn. В качестве входных данных продолжим использовать данные о диабете.\n",
    "\n",
    "Градиентный бустинг над деревьями для решения задачи регрессииреализован в классе [GradientBoostingRegressor](https:/scikit-learn.org/stable/modules/generated/sklearn.ensembleGradientBoostingRegressor.html). Для задачи классификации данныйметод реализован в классе [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html). Параметры уклассов схожи, различия только в функции потерь. Поэтому мы можемрассмотреть параметры GradientBoostingRegressor, подразумевая, чтоу классификатора они идентичны.\n",
    "\n",
    "Основные параметры **GradientBoostingRegressor**:\n",
    "\n",
    "* loss — функция потерь. По умолчанию в регрессии 'squared_loss' - наша любимая MSE, а в классификации 'deviance' - логистическая функция потерь (logloss).\n",
    "\n",
    "* learning_rate — темп обучения. По умолчанию 0.1. \n",
    "* n_estimators — количество деревьев в бустинга (число  из бустинга). По умолчанию равно 100.\n",
    "* max_depth — максимальная глубина одного дерева. По умолчанию равна 3 — строятся короткие деревья с большим смещением.\n",
    "* min_samples_leaf — минимальное число объектов в листе. По умолчанию 1.\n",
    "* random_state — число, отвечающее за генерацию случайных чисел.\n",
    "\n",
    "✍️ Давайте построим модель градиентного бустинга над деревьями решений. Продолжим использовать данные о диабете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для GradientBoosting 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor(\n",
    "\tmax_depth=3, #максимальная глубина дерева\n",
    "n_estimators=50, #количество деревьев\n",
    "random_state=42 #генератор случайных чисел\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    " \n",
    "gb_pred  = gb.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для GradientBoosting {round(mean_squared_error(y_test, gb_pred),2)}')\n",
    " \n",
    "# Качество предсказания по MSE для GradientBoosting 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, при прочих равных градиентный бустинг даёт меньшую метрику по сравнению с адаптивным. Напомним, что из тестового задания по AdaBoost на 50 базовых моделях метрика MSE для адаптивного бустинга была равна 26.37. \n",
    "\n",
    "⬇️ Однако не стоит радоваться, так как в зависимости от качества данных, от различных параметров, например количества базовых моделей, картина может измениться в обратную сторону. Пример таких параметров представлен в задании ниже. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.5\n",
    "\n",
    "Измените количество базовых моделей до 10 и 100. В качестве ответа приведите полученные результаты, округленные до второго знака после запятой. Если второе число после запятой равно нулю, округлите до одного знака: например 10.10 необходимо округлить до 10.1. Остальные параметры оставьте неизменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для GradientBoosting 702.75\n"
     ]
    }
   ],
   "source": [
    "gb_10 = GradientBoostingRegressor(\n",
    "\tmax_depth=3, #максимальная глубина дерева\n",
    "    n_estimators=10, #количество деревьев\n",
    "    random_state=42 #генератор случайных чисел\n",
    ")\n",
    "gb_10.fit(X_train, y_train)\n",
    " \n",
    "gb_10_pred  = gb_10.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для GradientBoosting {round(mean_squared_error(y_test, gb_10_pred),2)}')\n",
    " \n",
    "# Качество предсказания по MSE для GradientBoosting 0.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для GradientBoosting 0.77\n"
     ]
    }
   ],
   "source": [
    "gb_100 = GradientBoostingRegressor(\n",
    "\tmax_depth=3, #максимальная глубина дерева\n",
    "    n_estimators=100, #количество деревьев\n",
    "    random_state=42 #генератор случайных чисел\n",
    ")\n",
    "gb_100.fit(X_train, y_train)\n",
    " \n",
    "gb_100_pred  = gb_100.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для GradientBoosting {round(mean_squared_error(y_test, gb_100_pred),2)}')\n",
    " \n",
    "# Качество предсказания по MSE для GradientBoosting 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученное качество говорит о том, что с повышением количества базовых моделей наша модель сходится к решению быстрее прочих моделей. Однако высокая ошибка на маленьком количестве моделей говорит о том, что использования малого количества моделей может не хватить, чтобы модель действительно качественно обучалась, то есть повышение качества у градиентного бустинга происходит нелинейно.\n",
    "\n",
    "✍️ Попробуем решить задачу **бинарной классификации** с помощью градиентного бустинга. Для этого возьмём [датасет качества вина](https://lms.skillfactory.ru/assets/courseware/v1/f739e63d4b354ed1bc7ea6b781bd8a38/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/winequality-red.zip). В качестве целевой метки будем считать качественным вино, рейтинг которого больше пяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('data/winequality-red.csv', sep = ';')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и договаривались ранее, хорошим вином будем считать все, имеющие значение признака quality больше 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['quality'],axis = 1)\n",
    "y = (df['quality'] >5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку на обучающую и тестовую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Размерность обучающей выборки (1071, 11)\n",
      " Размерность тестовой выборки (528, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    " \n",
    "print(f' Размерность обучающей выборки {X_train.shape}')\n",
    "print(f' Размерность тестовой выборки {X_test.shape}')\n",
    "\n",
    "# Размерность обучающей выборки (1071, 11)\n",
    "# Размерность тестовой выборки (528, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель градиентного бустинга:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(\n",
    "    loss='deviance', #функция потерь\n",
    "    learning_rate=0.1, #темп обучения\n",
    "    n_estimators=100, #число деревьев\n",
    "    max_depth=3, #максимальная глубина дерева\n",
    "    random_state=42 #генератор случайных чисел\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим её на тренировочной выборке:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(loss=&#x27;deviance&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(loss=&#x27;deviance&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(loss='deviance', random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на метрики классификации с помощью classification_report():\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77       238\n",
      "           1       0.81      0.80      0.81       290\n",
      "\n",
      "    accuracy                           0.79       528\n",
      "   macro avg       0.79      0.79      0.79       528\n",
      "weighted avg       0.79      0.79      0.79       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = gb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично другим классификаторам в sklearn мы можем получать оценки вероятностей для каждого класса с помощью метода predict_proba(). Можете использовать эту возможность, например, для подбора оптимального порога вероятности, как мы делали это в предыдущих модулях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7575177 , 0.2424823 ],\n",
       "       [0.81931477, 0.18068523],\n",
       "       [0.80325657, 0.19674343],\n",
       "       ...,\n",
       "       [0.0212709 , 0.9787291 ],\n",
       "       [0.90355559, 0.09644441],\n",
       "       [0.80946194, 0.19053806]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известно, что с уменьшением темпа обучения (learning_rate) возникает необходимость повышения количества базовых моделей, то есть существует некоторая дилемма (trade-off) между темпом обучения и количеством моделей (n_estimators). Посмотрим на практике, как эти параметры связаны между собой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.6\n",
    "\n",
    "Обучите на тренировочной выборке (X_train, y_train) модель градиентного бустинга, состоящего из 200 деревьев, максимальная глубина каждого из которых равна 3. Минимальное число объектов в листе — 10. Темп обучения возьмите равный 0.01. Параметр random_state установите в значение 42.\n",
    "\n",
    "Сделайте предсказание качества вина для тренировочного и тестового набора данных. Рассчитайте метрику accuracy для тестового набора (X_train, y_train) и запишите её в качестве ответа с точностью до двух знаков после запятой.\n",
    "\n",
    "accuracy на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71       238\n",
      "           1       0.77      0.73      0.75       290\n",
      "\n",
      "    accuracy                           0.73       528\n",
      "   macro avg       0.73      0.73      0.73       528\n",
      "weighted avg       0.73      0.73      0.73       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_task = GradientBoostingClassifier(\n",
    "    loss='deviance', #функция потерь\n",
    "    learning_rate=0.01, #темп обучения\n",
    "    n_estimators=200, #число деревьев\n",
    "    max_depth=3, #максимальная глубина дерева\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    min_samples_leaf=10 #минимальное количество объектов в листе\n",
    ")\n",
    "\n",
    "gb_task.fit(X_train, y_train)\n",
    "\n",
    "y_pred_task = gb_task.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.7\n",
    "\n",
    "Увеличьте количество деревьев до 500, остальные параметры оставьте прежними.\n",
    "\n",
    "Сделайте предсказание качества вина для тренировочного и тестового набора данных. Рассчитайте метрику accuracy для тестового набора (X_train, y_train) и запишите её в качестве ответа с точностью до двух знаков после запятой.\n",
    "\n",
    "accuracy на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       238\n",
      "           1       0.79      0.76      0.77       290\n",
      "\n",
      "    accuracy                           0.75       528\n",
      "   macro avg       0.75      0.75      0.75       528\n",
      "weighted avg       0.76      0.75      0.75       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_task = GradientBoostingClassifier(\n",
    "    loss='deviance', #функция потерь\n",
    "    learning_rate=0.01, #темп обучения\n",
    "    n_estimators=500, #число деревьев\n",
    "    max_depth=3, #максимальная глубина дерева\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    min_samples_leaf=10 #минимальное количество объектов в листе\n",
    ")\n",
    "\n",
    "gb_task.fit(X_train, y_train)\n",
    "\n",
    "y_pred_task = gb_task.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.8\n",
    "\n",
    "Увеличьте learning rate до 0.2.\n",
    "\n",
    "Сделайте предсказание качества вина для тренировочного и тестового набора данных. Рассчитайте метрику accuracy для тестового набора (X_train, y_train) и запишите её в качестве ответа с точностью до двух знаков после запятой.\n",
    "\n",
    "accuracy на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       238\n",
      "           1       0.81      0.83      0.82       290\n",
      "\n",
      "    accuracy                           0.80       528\n",
      "   macro avg       0.79      0.79      0.79       528\n",
      "weighted avg       0.80      0.80      0.80       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_task = GradientBoostingClassifier(\n",
    "    loss='deviance', #функция потерь\n",
    "    learning_rate=0.2, #темп обучения\n",
    "    n_estimators=500, #число деревьев\n",
    "    max_depth=3, #максимальная глубина дерева\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    min_samples_leaf=10 #минимальное количество объектов в листе\n",
    ")\n",
    "\n",
    "gb_task.fit(X_train, y_train)\n",
    "\n",
    "y_pred_task = gb_task.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐️ **Поздравляем!** Мы разобрали практически все ныне существующие методы ансамблирования — от самых простых, которые легли в основу случайного леса, до самых передовых (градиентных бустингов). Мы посмотрели на реализации в библиотеке sklearn, постарались разобрать методологию и основные параметры каждой модели. \n",
    "\n",
    "Основными рекомендациями по использованию ансамблей является использование случайных лесов и градиентных бустингов в первую очередь для классических задач классификации и регрессии с простыми табличными данными, так как подавляющее большинство соревнований в этой области было выиграно именно благодаря этим двум моделям. \n",
    "\n",
    "После данного модуля может сложиться впечатление, что ансамблирование — всегда лучший вариант для финальной модели, однако часто в задачах требуется **интерпретируемость** результатов, которой не могу похвастаться бустинг и стекинг. \n",
    "\n",
    "Кроме того, использование случайного леса на данных с большим количеством выбросов может привести к тому, что модель будет обучается на данных, у которых дисперсия в разы больше, чем у исходных, так как подвыборка для обучения выбирается случайно. Таким образом, мы не сможем получить выигрыш в дисперсии, который нам даёт ансамблирование. \n",
    "\n",
    "В заключение приведём таблицу преимуществ и недостатков методов ансамблирования:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод|✔️ Плюсы|⛔ Минусы\n",
    "-|-|-\n",
    "Бэггинг|Хорошо параллелится вычисление (модели обучаются параллельно). Снижает дисперсию.|Предполагается использование одинаковых моделей. Необходимо использование глубоких деревьев. Плохо интерпретируемая.\n",
    "Стекинг|Хорошо параллелится (модели обучаются параллельно).Хорош для использования различных по природе базовых моделей|Качество сильно зависит от качества базовых моделей. Плохо интерпретируемая.\n",
    "Бустинг|Модели обучаются последовательно, уточняя друг друга. Снижает смещение. Базовые модели — неглубокие деревья.|Плохо параллелится вычисление. Плохо интерпретируемая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Пайплайны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Поговорим о пайплайнах: чем они хороши, для чего применяются и как на практике реализовать свой пайплайн. \n",
    "\n",
    "> Как говорилось ранее, **пайплайн** — это автоматизированный поэтапный процесс выполнения манипуляций с данными, включающий в себя сбор, обработку, генерацию и отбор признаков, обучение модели с последующей её настройкой и проверкой качества. \n",
    "\n",
    "Основные цели использования пайплайнов — автоматизация, ускорение вычислений с использованием многопоточности в Python и дальнейшее развертывание пайплайна для использования в периодических расчетах (сбор данных в режиме онлайн/онлайн-работа модели). Кроме того, пайплайны хороши в случае, когда надо подобрать оптимальные гиперпараметры для всего цикла обработки данных и последующего обучения. \n",
    "\n",
    "В библиотеке scikit-learn пайплайны реализованы как класс **sklearn.pipeline.Pipeline()**. Этот класс может быть использован для сбора воедино отбора и обработки данных вместе с итоговой моделью. \n",
    "\n",
    "Важной особенностью применения пайплайна в реализации scikit-learn является обязательное наличие у каждого метода внутренних преобразований **transform()**, а для финальной модели — метод **fit()**. \n",
    "\n",
    "Давайте рассмотрим создание пайплайна на конкретном примере: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём для примера [датасет недвижимости в Калифорнии](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing), в котором решается задача регрессии (определение цены недвижимости).\n",
    "\n",
    "[→ Скачайте ноутбук с кодом](https://lms.skillfactory.ru/assets/courseware/v1/1b2c5eeeb6d41d55e982b54244f28b1c/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/ML-8._Pipelines.ipynb)\n",
    "\n",
    "**California Housing Dataset**\n",
    "\n",
    "* MedInc — медианный уровень дохода в квартале;\n",
    "* HouseAge — медианный возраст дома в квартале;\n",
    "* AveRooms — среднее количество помещений;\n",
    "* AveBedrms — среднее количество спальных комнат;\n",
    "* Population — население квартала;\n",
    "* AveOccup — средний срок проживания;\n",
    "* Latitude — значение широты квартала;\n",
    "* Longitude — значение долготы квартала;\n",
    "* Price — целевое значение.\n",
    "\n",
    "Загрузим датасет и посмотрим на него:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "data = fetch_california_housing()\n",
    "df = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "df.loc[:,'target'] = data['target']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определимся с метрикой, по которой будем оценивать качество модели — **Root Mean Squared Error (RMSE)**, корень из среднего квадрата отклонения. Для этого на метод mean_squared_error подадим атрибут squared = False, который позволяет управлять возведением метрики в квадрат. Помимо RMSE для оценки качества модели будем использовать метрику **R2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_hat, y):\n",
    "    return mean_squared_error(y_hat, y, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на типы данных с помощью метода df.info().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      20640 non-null  float64\n",
      " 1   HouseAge    20640 non-null  float64\n",
      " 2   AveRooms    20640 non-null  float64\n",
      " 3   AveBedrms   20640 non-null  float64\n",
      " 4   Population  20640 non-null  float64\n",
      " 5   AveOccup    20640 non-null  float64\n",
      " 6   Latitude    20640 non-null  float64\n",
      " 7   Longitude   20640 non-null  float64\n",
      " 8   target      20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что данные исключительно типа float, поэтому мы можем в качестве предобработки применить к ним **StandardScaler()**.\n",
    "\n",
    "Разделим данные на обучающую и тестовую выборки, используя **train_test_split**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки (15480, 8)\n",
      "Размер тестовой выборки (5160, 8)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "Y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42)\n",
    "print(f'Размер обучающей выборки {X_train.shape}')\n",
    "print(f'Размер тестовой выборки {X_test.shape}')\n",
    "\n",
    "# Размер обучающей выборки (15480, 8)\n",
    "# Размер тестовой выборки (5160, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим простейший пайплайн, вызвав метод **fit()**, состоящий из случайного леса и стандартизации (**StandardScaler**). На вход пайплайна подается список из преобразований в формате кортежа (название метода преобразования, по которому мы будем обращаться в дальнейшем к нашему преобразованию, объект  метода преобразования). Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;rf&#x27;, RandomForestRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;rf&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('rf', RandomForestRegressor())])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestRegressor())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Pipeline(steps=[('scaler', StandardScaler()), ('rf', RandomForestRegressor())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на метрики. Для этого сделаем предсказание пайплайном с помощью метода **predict(**) и посчитаем R2 и RMSE с помощью функций **r2_score()** и **rmse()** соответственно. Округлим результат до четырёх цифр после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество по метрике R2: 0.8063\n",
      "Качество по RSME: 0.5062\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print(f'Качество по метрике R2: { round(r2_score(y_test, y_pred),4)}')\n",
    "print(f'Качество по RSME: {round(rmse(y_test, y_pred),4)}')\n",
    "\n",
    "# Качество по метрике R2: 0.808\n",
    "# Качество по RMSE: 0.5041"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем посмотреть на все параметры в пайплайне, вызвав метод ```get_params()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler', StandardScaler()), ('rf', RandomForestRegressor())],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(),\n",
       " 'rf': RandomForestRegressor(),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'rf__bootstrap': True,\n",
       " 'rf__ccp_alpha': 0.0,\n",
       " 'rf__criterion': 'squared_error',\n",
       " 'rf__max_depth': None,\n",
       " 'rf__max_features': 1.0,\n",
       " 'rf__max_leaf_nodes': None,\n",
       " 'rf__max_samples': None,\n",
       " 'rf__min_impurity_decrease': 0.0,\n",
       " 'rf__min_samples_leaf': 1,\n",
       " 'rf__min_samples_split': 2,\n",
       " 'rf__min_weight_fraction_leaf': 0.0,\n",
       " 'rf__n_estimators': 100,\n",
       " 'rf__n_jobs': None,\n",
       " 'rf__oob_score': False,\n",
       " 'rf__random_state': None,\n",
       " 'rf__verbose': 0,\n",
       " 'rf__warm_start': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. В качестве альтернативного метода задания пайплайна можно использовать метод **make_pipeline**, на вход которого подаются объекты, которые будут использованы в пайплайне. В нашем случае:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestregressor&#x27;, RandomForestRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestregressor&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestregressor', RandomForestRegressor())])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "make_pipeline(StandardScaler(), RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование пайплайна в виде, полученном из ```make_pipeline```, аналогично. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь обратиться к отдельной части пайплайна. Попробуем вызвать значение **n_estimator** у случайного леса. Мы можем это сделать двумя способами: индексацией пайплайна или обращением через имя, которые мы задали ранее при создании ('rf')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(pipeline[1].n_estimators)\n",
    "print(pipeline['rf'].n_estimators)\n",
    "\n",
    "# 100\n",
    "# 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем задать этому же параметру значение 200. Можно это сделать, используя метод **set_params()**, на вход которого надо подавать конструкцию **<название модуля>__<название параметра>**. \n",
    "\n",
    "Обратите внимание на **два нижних подчеркивания**, которые используются в качестве литералов для разбиения названия модуля и названия его параметра. Без него компилятор будет неправильно интерпретировать параметр, который вы хотите изменить!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;rf&#x27;, RandomForestRegressor(n_estimators=200))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;rf&#x27;, RandomForestRegressor(n_estimators=200))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=200)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('rf', RandomForestRegressor(n_estimators=200))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.set_params(rf__n_estimators=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данную структуру надо учитывать, когда для пайплайна задается GridSearch кросс-валидация. Попробуем взять 100, 200, 500 базовых моделей и сделать поиск оптимального параметра StardardScaler with_mean (типа bool, который отвечает за центровку данных, приводит распределение к нулевому среднему, по умолчанию — True. В противном случае среднее данных остается неизменным):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('rf', RandomForestRegressor(n_estimators=500))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'scaler__with_mean':[True,False],\n",
    "              'rf__n_estimators':[100, 200, 500]}\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose = True)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество по метрике R2: 0.8097\n",
      "Качество по RSME: 0.5019\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(f'Качество по метрике R2: { round(r2_score(y_test, y_pred),4)}')\n",
    "print(f'Качество по RSME: {round(rmse(y_test, y_pred),4)}')\n",
    " \n",
    "# Качество по метрике R2: 0.81\n",
    "# Качество по RSME: 0.5013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, качество улучшилось по обеим метрикам.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании пайплайна для сборки обработки данных в один стек удобно воспользоваться Column Tranformer. Мы разберём его устройство на примере датасета [рейтинга красного вина](https://lms.skillfactory.ru/assets/courseware/v1/4ac05d2d2721ace4a495c186925a350b/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/Red.zip). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала загрузим данные и посмотрим на них:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Winery</th>\n",
       "      <th>Rating</th>\n",
       "      <th>NumberOfRatings</th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pomerol 2011</td>\n",
       "      <td>France</td>\n",
       "      <td>Pomerol</td>\n",
       "      <td>Château La Providence</td>\n",
       "      <td>4.2</td>\n",
       "      <td>100</td>\n",
       "      <td>95.00</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lirac 2017</td>\n",
       "      <td>France</td>\n",
       "      <td>Lirac</td>\n",
       "      <td>Château Mont-Redon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>100</td>\n",
       "      <td>15.50</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Erta e China Rosso di Toscana 2015</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>Renzo Masi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>100</td>\n",
       "      <td>7.45</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bardolino 2019</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Bardolino</td>\n",
       "      <td>Cavalchina</td>\n",
       "      <td>3.5</td>\n",
       "      <td>100</td>\n",
       "      <td>8.72</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ried Scheibner Pinot Noir 2016</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Carnuntum</td>\n",
       "      <td>Markowitsch</td>\n",
       "      <td>3.9</td>\n",
       "      <td>100</td>\n",
       "      <td>29.15</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name  Country     Region  \\\n",
       "0                        Pomerol 2011   France    Pomerol   \n",
       "1                          Lirac 2017   France      Lirac   \n",
       "2  Erta e China Rosso di Toscana 2015    Italy    Toscana   \n",
       "3                      Bardolino 2019    Italy  Bardolino   \n",
       "4      Ried Scheibner Pinot Noir 2016  Austria  Carnuntum   \n",
       "\n",
       "                  Winery  Rating  NumberOfRatings  Price  Year  \n",
       "0  Château La Providence     4.2              100  95.00  2011  \n",
       "1     Château Mont-Redon     4.3              100  15.50  2017  \n",
       "2             Renzo Masi     3.9              100   7.45  2015  \n",
       "3             Cavalchina     3.5              100   8.72  2019  \n",
       "4            Markowitsch     3.9              100  29.15  2016  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine= pd.read_csv('data/Red.csv')\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8666 entries, 0 to 8665\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Name             8666 non-null   object \n",
      " 1   Country          8666 non-null   object \n",
      " 2   Region           8666 non-null   object \n",
      " 3   Winery           8666 non-null   object \n",
      " 4   Rating           8666 non-null   float64\n",
      " 5   NumberOfRatings  8666 non-null   int64  \n",
      " 6   Price            8666 non-null   float64\n",
      " 7   Year             8666 non-null   object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 541.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_wine.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, у нас есть численный признак цена вина (Price) и категориальный регион производства (Region). Для первого надо применить **StandardScaler()**, для второго — **OneHotEncoder()**. Мы можем сделать это следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer(transformers=[('standardscaler', StandardScaler(), ['Price']),\n",
      "                                ('onehotencoder', OneHotEncoder(),\n",
      "                                 ['Country'])])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), ['Price']),\n",
    "    (OneHotEncoder(), ['Country']))\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Если мы хотим применить, например, OneHotEncoder, к более чем одному признаку, то просто достаточно добавить в список колонки, например ```['Country', ‘Region’]```. Теперь OneHotEncoder будет работать не только на признаке Country, но ещё и на Region.\n",
    "\n",
    "**Примечание**. Можно также использовать фильтрацию по типу колонок, используя метод **make_column_selector()** из sklearn.compose:\n",
    "\n",
    "```py\n",
    "ct = ColumnTransformer([\n",
    "       ('scale', StandardScaler(),\n",
    "       make_column_selector(dtype_include=np.number)),\n",
    "       ('onehot',\n",
    "       OneHotEncoder(),\n",
    "       make_column_selector(dtype_include=object))])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный трансформер можно использовать в качестве элемента пайплайна, например: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('ct', ct), ('rf', RandomForestRegressor())])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на результат работы ColumnTransformer в пайплайне. Для этого обучим его на колонках Price и Country, а в качестве целевой метки используем рейтинг вина Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler(), [&#x27;Price&#x27;]),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  [&#x27;Country&#x27;])])),\n",
       "                (&#x27;rf&#x27;, RandomForestRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler(), [&#x27;Price&#x27;]),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  [&#x27;Country&#x27;])])),\n",
       "                (&#x27;rf&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;, StandardScaler(), [&#x27;Price&#x27;]),\n",
       "                                (&#x27;onehotencoder&#x27;, OneHotEncoder(),\n",
       "                                 [&#x27;Country&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standardscaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Price&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehotencoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Country&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(), ['Price']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['Country'])])),\n",
       "                ('rf', RandomForestRegressor())])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_wine[['Country', 'Price']]\n",
    "y = df_wine['Rating']\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важный момент: при отображении после преобразования ваш датасет будет представлен в виде **sparse-матрицы** (специальный формат для хранения больших, практически полностью нулевых матриц), поэтому надо будет вызвать метод **toarray()**. Так же мы можем получить названия колонок с onehotencoder с помощью метода **.get_feature_names_out()**, обратившись именно к энкодеру. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Country_Argentina</th>\n",
       "      <th>Country_Australia</th>\n",
       "      <th>Country_Austria</th>\n",
       "      <th>Country_Brazil</th>\n",
       "      <th>Country_Bulgaria</th>\n",
       "      <th>Country_Canada</th>\n",
       "      <th>Country_Chile</th>\n",
       "      <th>Country_China</th>\n",
       "      <th>Country_Croatia</th>\n",
       "      <th>...</th>\n",
       "      <th>Country_Portugal</th>\n",
       "      <th>Country_Romania</th>\n",
       "      <th>Country_Slovakia</th>\n",
       "      <th>Country_Slovenia</th>\n",
       "      <th>Country_South Africa</th>\n",
       "      <th>Country_Spain</th>\n",
       "      <th>Country_Switzerland</th>\n",
       "      <th>Country_Turkey</th>\n",
       "      <th>Country_United States</th>\n",
       "      <th>Country_Uruguay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.657648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.278402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.373184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.358231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.117684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8661</th>\n",
       "      <td>-0.266981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8662</th>\n",
       "      <td>-0.224358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8663</th>\n",
       "      <td>-0.178910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8664</th>\n",
       "      <td>-0.387784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8665</th>\n",
       "      <td>-0.368121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8666 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Price  Country_Argentina  Country_Australia  Country_Austria  \\\n",
       "0     0.657648                0.0                0.0              0.0   \n",
       "1    -0.278402                0.0                0.0              0.0   \n",
       "2    -0.373184                0.0                0.0              0.0   \n",
       "3    -0.358231                0.0                0.0              0.0   \n",
       "4    -0.117684                0.0                0.0              1.0   \n",
       "...        ...                ...                ...              ...   \n",
       "8661 -0.266981                0.0                0.0              0.0   \n",
       "8662 -0.224358                0.0                0.0              0.0   \n",
       "8663 -0.178910                0.0                0.0              0.0   \n",
       "8664 -0.387784                0.0                1.0              0.0   \n",
       "8665 -0.368121                1.0                0.0              0.0   \n",
       "\n",
       "      Country_Brazil  Country_Bulgaria  Country_Canada  Country_Chile  \\\n",
       "0                0.0               0.0             0.0            0.0   \n",
       "1                0.0               0.0             0.0            0.0   \n",
       "2                0.0               0.0             0.0            0.0   \n",
       "3                0.0               0.0             0.0            0.0   \n",
       "4                0.0               0.0             0.0            0.0   \n",
       "...              ...               ...             ...            ...   \n",
       "8661             0.0               0.0             0.0            0.0   \n",
       "8662             0.0               0.0             0.0            0.0   \n",
       "8663             0.0               0.0             0.0            0.0   \n",
       "8664             0.0               0.0             0.0            0.0   \n",
       "8665             0.0               0.0             0.0            0.0   \n",
       "\n",
       "      Country_China  Country_Croatia  ...  Country_Portugal  Country_Romania  \\\n",
       "0               0.0              0.0  ...               0.0              0.0   \n",
       "1               0.0              0.0  ...               0.0              0.0   \n",
       "2               0.0              0.0  ...               0.0              0.0   \n",
       "3               0.0              0.0  ...               0.0              0.0   \n",
       "4               0.0              0.0  ...               0.0              0.0   \n",
       "...             ...              ...  ...               ...              ...   \n",
       "8661            0.0              0.0  ...               0.0              0.0   \n",
       "8662            0.0              0.0  ...               0.0              0.0   \n",
       "8663            0.0              0.0  ...               0.0              0.0   \n",
       "8664            0.0              0.0  ...               0.0              0.0   \n",
       "8665            0.0              0.0  ...               0.0              0.0   \n",
       "\n",
       "      Country_Slovakia  Country_Slovenia  Country_South Africa  Country_Spain  \\\n",
       "0                  0.0               0.0                   0.0            0.0   \n",
       "1                  0.0               0.0                   0.0            0.0   \n",
       "2                  0.0               0.0                   0.0            0.0   \n",
       "3                  0.0               0.0                   0.0            0.0   \n",
       "4                  0.0               0.0                   0.0            0.0   \n",
       "...                ...               ...                   ...            ...   \n",
       "8661               0.0               0.0                   0.0            0.0   \n",
       "8662               0.0               0.0                   0.0            0.0   \n",
       "8663               0.0               0.0                   0.0            0.0   \n",
       "8664               0.0               0.0                   0.0            0.0   \n",
       "8665               0.0               0.0                   0.0            0.0   \n",
       "\n",
       "      Country_Switzerland  Country_Turkey  Country_United States  \\\n",
       "0                     0.0             0.0                    0.0   \n",
       "1                     0.0             0.0                    0.0   \n",
       "2                     0.0             0.0                    0.0   \n",
       "3                     0.0             0.0                    0.0   \n",
       "4                     0.0             0.0                    0.0   \n",
       "...                   ...             ...                    ...   \n",
       "8661                  0.0             0.0                    1.0   \n",
       "8662                  0.0             0.0                    0.0   \n",
       "8663                  0.0             0.0                    0.0   \n",
       "8664                  0.0             0.0                    0.0   \n",
       "8665                  0.0             0.0                    0.0   \n",
       "\n",
       "      Country_Uruguay  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "8661              0.0  \n",
       "8662              0.0  \n",
       "8663              0.0  \n",
       "8664              0.0  \n",
       "8665              0.0  \n",
       "\n",
       "[8666 rows x 31 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pipeline['ct'].transform(X).toarray(), columns = ['Price']+ pipeline['ct'].transformers_[1][1].get_feature_names_out().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐️ Итак, мы научились использовать и собирать полноценный пайплайн, узнали о трансформациях колонок, которые позволяют легко и просто делать рутинные задачи типа нормализации/стандартизации и кодирования категориальных признаков. \n",
    "\n",
    "Обученный пайплайн можно сохранить в формат pickle, например, используя библиотеку joblib. Далее его можно использовать после десериализации как решение «из коробки», применяя следующие методы.\n",
    "\n",
    "**Примечание**. Формат pickle реализует двоичный протокол для сериализации/десериализации объектов для сохранения и последующего использования без каких-либо дополнительных преобразований. Удобен для переноса обученных моделей, предобработки и так далее.\n",
    "\n",
    "> **Сериализация** — процесс перевода структуры данных в последовательность битов. \n",
    "\n",
    "> **Десериализация** — процесс создания из последовательности битов  структуры данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\home\\anaconda3\\lib\\site-packages (1.1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pipeline.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install joblib\n",
    "import joblib\n",
    "joblib.dump(pipeline, 'pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого ваш пайплайн будет сохранен в файл pipeline.pkl. Вы можете использовать свой пайплайн, импортировав все библиотеки из зависимостей (которые импортировались при создании пайплайна), используя следующие строчки кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('ct',\n",
      "                 ColumnTransformer(transformers=[('standardscaler',\n",
      "                                                  StandardScaler(), ['Price']),\n",
      "                                                 ('onehotencoder',\n",
      "                                                  OneHotEncoder(),\n",
      "                                                  ['Country'])])),\n",
      "                ('rf', RandomForestRegressor())])\n"
     ]
    }
   ],
   "source": [
    "pipeline_loaded = joblib.load('pipeline.pkl')\n",
    "print(pipeline_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы можем использовать уже готовый пайплайн, например для проведения онлайн расчётов и постановки модели на постоянный регулярный расчёт. Под онлайн-расчётами мы подразумеваем сбор данных в формате онлайн и получения результатов модели в онлайне с помощью фреймворка, например [AirFlow](https://airflow.apache.org/). Это необходимо для раскатки решения, например, на сайте (модель рекомендаций фильмов, схожие товары в интернет магазинах и так далее)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Пайплайны. Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После изучения основ предлагаем сделать свой пайплайн самостоятельно. Попробуем на практике реализовать пайплайн, добавить в него преобразования, изменить параметры. Приступим!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.1\n",
    "\n",
    "Предлагаем использовать датасет, с которым вы работали при создании пайплайна (файл Red.csv ).\n",
    "\n",
    "Вам следует выполнить следующее:\n",
    "\n",
    "* Добавить обработку столбца 'Region' в пайплайн, полученный ранее в модуле, с использованием OrdinalEncoder.  \n",
    "    **Важно**! Для совпадения результатов процесс трансформации столбцов должен выполняться в следующей последовательности:\n",
    "    1. Кодирование столбца 'Region'.\n",
    "    2. Стандартизация столбца 'Price'.\n",
    "    3. Кодирование столбца 'Country'.  \n",
    "    .\n",
    "\n",
    "* Обучить на тренировочном наборе данных пайплайн и оценить качество модели по метрике RMSE на тестовом наборе (файл Red_test.csv ).\n",
    "* Зафиксировать random_state=42.\n",
    "* Сохранить пайплайн в файл pipeline_wine.pkl.\n",
    "\n",
    "    В качестве ответа на задание введите в поле ниже полученный результат по метрике RMSE, округленный до четвёртого знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество по RMSE: 0.0765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pipeline_vine.pkl']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "ct = make_column_transformer(\n",
    "    (OrdinalEncoder(), ['Region']),\n",
    "    (StandardScaler(), ['Price']),\n",
    "    (OneHotEncoder(), ['Country']))\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('ct', ct), ('rf', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "data = pd.read_csv('data/Red.csv')\n",
    "test = pd.read_csv('data/Red_test.csv')\n",
    "\n",
    "X_train = data[['Country', 'Region', 'Price']]\n",
    "y_train = data['Rating']\n",
    "\n",
    "X_test = test[['Country', 'Region', 'Price']]\n",
    "y_test = test['Rating']\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(f'Качество по RMSE: {round(rmse(y_test, y_pred),4)}')\n",
    "\n",
    "joblib.dump(pipeline, 'pipeline_vine.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.2\n",
    "\n",
    "Теперь попробуем изменить параметры случайного леса в пайплайне, полученном в предыдущем задании.\n",
    "\n",
    "Измените параметр n_estimators в случайном лесу со значения по умолчанию до 200 , используя метод set_params.\n",
    "\n",
    "В качестве ответа на задание введите в поле ниже полученный результат по метрике RMSE, округленный до четвёртого знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество по RMSE: 0.0761\n"
     ]
    }
   ],
   "source": [
    "pipeline.set_params(rf__n_estimators=200)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(f'Качество по RMSE: {round(rmse(y_test, y_pred),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.3\n",
    "\n",
    "Теперь попробуем добавить стекинг в качестве модели в пайплайн.\n",
    "\n",
    "Вам следует выполнить следующее:\n",
    "\n",
    "* Собрать StackingRegressor:\n",
    "    1. В качестве базовых моделей возьмите ридж-регрессию RidgeCV() и решающее дерево.\n",
    "    2. В качестве метамодели возьмите случайный лес с настройками (количество базовых моделей 10).\n",
    "    3. Все базовые модели стекинга модели должны быть с настройками по умолчанию (кроме random_state).\n",
    "* Зафиксировать random_state=42 (для всех моделей).\n",
    "* Заменить в пайплайне задачи 6.1 случайный лес на StackingRegressor.\n",
    "* Обучить модель на тренировочной выборке.\n",
    "\n",
    "В качестве ответа на задание введите в поле ниже полученный результат по метрике RMSE, округлённый до второго знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество по RMSE: 0.18\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса стекинг\n",
    "reg = StackingRegressor(\n",
    "    estimators=[('lr', RidgeCV()), ('dt', DecisionTreeRegressor(random_state=42))],\n",
    "    final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                          random_state=42)\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([('ct', ct), ('sr', reg)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(f'Качество по RMSE: {round(rmse(y_test, y_pred),2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "950b5653ccfc34417735dd321d006fd482b31f7611416c3d8236dc5b17587d3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
